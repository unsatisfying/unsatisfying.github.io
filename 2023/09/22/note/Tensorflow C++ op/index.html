<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 8.0.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/icon.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/icon.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/7.0.0/css/all.min.css" integrity="sha256-VHqXKFhhMxcpubYf9xiWdCiojEbY9NexQ4jh8AxbvcM=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"zhuzhuzai.top","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.25.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"always","padding":18,"offset":12},"hljswrap":true,"codeblock":{"theme":{"light":"default","dark":"stackoverflow-dark"},"prism":{"light":"prism","dark":"prism-dark"},"copy_button":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"language":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":5,"unescape":false,"preload":false}}</script><script src="/js/config.js" defer></script>

    <meta name="description" content="Tensorflow OP 代码分析，主要是OP实现部分">
<meta property="og:type" content="article">
<meta property="og:title" content="Tensorflow OP 代码分析">
<meta property="og:url" content="https://zhuzhuzai.top/2023/09/22/note/Tensorflow%20C++%20op/index.html">
<meta property="og:site_name" content="Zzzai&#39;s Blog">
<meta property="og:description" content="Tensorflow OP 代码分析，主要是OP实现部分">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://zhuzhuzaiimgbed.oss-cn-hangzhou.aliyuncs.com/img/image-20240320181116772.png">
<meta property="article:published_time" content="2023-09-21T16:00:00.000Z">
<meta property="article:modified_time" content="2025-10-07T11:30:37.609Z">
<meta property="article:author" content="Zhuzhuzai">
<meta property="article:tag" content="gpu">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://zhuzhuzaiimgbed.oss-cn-hangzhou.aliyuncs.com/img/image-20240320181116772.png">


<link rel="canonical" href="https://zhuzhuzai.top/2023/09/22/note/Tensorflow%20C++%20op/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://zhuzhuzai.top/2023/09/22/note/Tensorflow%20C++%20op/","path":"2023/09/22/note/Tensorflow C++ op/","title":"Tensorflow OP 代码分析"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Tensorflow OP 代码分析 | Zzzai's Blog</title>
  








  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
<script src="/js/utils.js" defer></script><script src="/js/motion.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.5.0/search.js" integrity="sha256-xFC6PJ82SL9b3WkGjFavNiA9gm5z6UBxWPiu4CYjptg=" crossorigin="anonymous" defer></script>
<script src="/js/third-party/search/local-search.js" defer></script>







  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js" defer></script>



  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Zzzai's Blog</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Tensorflow-OP-%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90"><span class="nav-number">1.</span> <span class="nav-text">Tensorflow OP 代码分析</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A2%9E%E5%8A%A0%E4%B8%80%E4%B8%AA%E6%96%B0%E7%9A%84op"><span class="nav-number">1.1.</span> <span class="nav-text">增加一个新的op</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A2%9E%E5%8A%A0OP%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="nav-number">1.2.</span> <span class="nav-text">增加OP的实现</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Build-OP-%E5%BA%93"><span class="nav-number">1.3.</span> <span class="nav-text">Build OP 库</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8bazel%E7%BC%96%E8%AF%91%E6%93%8D%E4%BD%9C"><span class="nav-number">1.4.</span> <span class="nav-text">使用bazel编译操作</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9D%A1%E4%BB%B6%E6%A3%80%E6%9F%A5%E5%92%8C%E9%AA%8C%E8%AF%81"><span class="nav-number">1.5.</span> <span class="nav-text">条件检查和验证</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%B1%9E%E6%80%A7"><span class="nav-number">1.6.</span> <span class="nav-text">属性</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B1%9E%E6%80%A7%E7%B1%BB%E5%9E%8B"><span class="nav-number">1.6.1.</span> <span class="nav-text">属性类型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%BB%98%E8%AE%A4%E5%80%BC%E5%92%8C%E7%BA%A6%E6%9D%9F"><span class="nav-number">1.6.2.</span> <span class="nav-text">默认值和约束</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#OP%E6%BA%90%E7%A0%81%E9%83%A8%E5%88%86"><span class="nav-number">2.</span> <span class="nav-text">OP源码部分</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#REGISTER-OP"><span class="nav-number">2.1.</span> <span class="nav-text">REGISTER_OP</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#OP%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%E6%8E%A5%E5%8F%A3"><span class="nav-number">2.2.</span> <span class="nav-text">OP注册中心接口</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#OpDef"><span class="nav-number">2.3.</span> <span class="nav-text">OpDef</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#OpDefBuilder%E6%9D%A5%E7%94%9F%E6%88%90OP"><span class="nav-number">2.4.</span> <span class="nav-text">OpDefBuilder来生成OP</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#KERNEL%E6%BA%90%E7%A0%81%E9%83%A8%E5%88%86"><span class="nav-number">3.</span> <span class="nav-text">KERNEL源码部分</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Kernel"><span class="nav-number">3.1.</span> <span class="nav-text">Kernel</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%90%8C%E6%AD%A5%E8%AE%A1%E7%AE%97-Compute%E6%96%B9%E6%B3%95"><span class="nav-number">3.2.</span> <span class="nav-text">同步计算 Compute方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BC%82%E6%AD%A5%E8%AE%A1%E7%AE%97%EF%BC%9AAsyncOpKernel"><span class="nav-number">3.3.</span> <span class="nav-text">异步计算：AsyncOpKernel</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kernel%E6%9E%84%E9%80%A0%E6%97%B6%E7%9A%84OpKernelConstruction"><span class="nav-number">3.4.</span> <span class="nav-text">Kernel构造时的OpKernelConstruction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#OP%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E5%8F%82%E6%95%B0%E5%B8%AE%E5%8A%A9%E7%B1%BB"><span class="nav-number">3.5.</span> <span class="nav-text">OP输入输出参数帮助类</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Compute%E7%9A%84%E5%8F%82%E6%95%B0OpKernelContext"><span class="nav-number">3.6.</span> <span class="nav-text">Compute的参数OpKernelContext</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E5%8F%82%E6%95%B0%E8%8E%B7%E5%8F%96"><span class="nav-number">3.6.1.</span> <span class="nav-text">输入输出参数获取</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%89%A7%E8%A1%8C%E7%8E%AF%E5%A2%83"><span class="nav-number">3.6.2.</span> <span class="nav-text">执行环境</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#kernel%E5%AE%9E%E4%BE%8B%E5%8C%96"><span class="nav-number">3.7.</span> <span class="nav-text">kernel实例化</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#REGISTER-KERNEL-BUILDER%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90"><span class="nav-number">3.7.1.</span> <span class="nav-text">REGISTER_KERNEL_BUILDER流程分析</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BB%8E%E5%8A%A8%E6%80%81%E5%BA%93%E5%8A%A0%E8%BD%BDkernel"><span class="nav-number">3.8.</span> <span class="nav-text">从动态库加载kernel</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kernel%E4%BB%8Econtext%E4%B8%AD%E8%8E%B7%E5%8F%96%E8%BE%93%E5%85%A5%EF%BC%8C%E5%88%86%E9%85%8D%E8%BE%93%E5%87%BA%E6%97%B6%E8%BF%94%E5%9B%9E%E9%94%99%E8%AF%AF"><span class="nav-number">3.9.</span> <span class="nav-text">Kernel从context中获取输入，分配输出时返回错误</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Zhuzhuzai"
      src="/images/portrait.gif">
  <p class="site-author-name" itemprop="name">Zhuzhuzai</p>
  <div class="site-description" itemprop="description">Talk is cheap, show me the code!</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">23</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/unsatisfying" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;unsatisfying" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:824941284@qq.com" title="E-Mail → mailto:824941284@qq.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://zhuzhuzai.top/2023/09/22/note/Tensorflow%20C++%20op/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/portrait.gif">
      <meta itemprop="name" content="Zhuzhuzai">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zzzai's Blog">
      <meta itemprop="description" content="Talk is cheap, show me the code!">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Tensorflow OP 代码分析 | Zzzai's Blog">
      <meta itemprop="description" content="Tensorflow OP 代码分析，主要是OP实现部分">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Tensorflow OP 代码分析
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-09-22 00:00:00" itemprop="dateCreated datePublished" datetime="2023-09-22T00:00:00+08:00">2023-09-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-10-07 19:30:37" itemprop="dateModified" datetime="2025-10-07T19:30:37+08:00">2025-10-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/note/" itemprop="url" rel="index"><span itemprop="name">note</span></a>
        </span>
    </span>

  
</div>

            <div class="post-description">Tensorflow OP 代码分析，主要是OP实现部分</div>
        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h1 id="Tensorflow-OP-代码分析"><a href="#Tensorflow-OP-代码分析" class="headerlink" title="Tensorflow OP 代码分析"></a>Tensorflow OP 代码分析</h1><p>[TOC]</p>
<h2 id="增加一个新的op"><a href="#增加一个新的op" class="headerlink" title="增加一个新的op"></a>增加一个新的op</h2><p>增加一个新的op需要通过<code>REGISTER_OP</code> 宏进行注册，如下代码所示。宏中定义了这个OP的输入，输出，attr属性等。创建文件<code>tensorflow/core/user_ops/zero_out.cc</code>并输入如下代码</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;tensorflow/core/framework/op.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="built_in">REGISTER_OP</span>(<span class="string">&quot;ZeroOut&quot;</span>)</span><br><span class="line">    .<span class="built_in">Input</span>(<span class="string">&quot;to_zero: int32&quot;</span>)</span><br><span class="line">    .<span class="built_in">Output</span>(<span class="string">&quot;zeroed: int32&quot;</span>);</span><br></pre></td></tr></table></figure>

<blockquote>
<p>ZeroOut这个op名字必须是唯一的，而以下划线<code>_</code>开头的名字一般是保留内部使用的</p>
</blockquote>
<h2 id="增加OP的实现"><a href="#增加OP的实现" class="headerlink" title="增加OP的实现"></a>增加OP的实现</h2><p>OP仅仅是定义了一个接口，而一个OP可以有很多个实现，包括<code>CPU</code>, <code>GPU</code>等的实现，可以通过继承一个<code>OpKernel </code>的类，并且重写<code>Compute</code>函数来实现一个tensorflow OP implement. <code>Compute</code>函数接收一个<code>OpKernelContext</code>类型的参数，能够通过它获取相关的op上下文，例如输入，然后对其进行处理。如下是一个例子：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;tensorflow/core/framework/op_kernel.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> tensorflow;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ZeroOutOp</span> : <span class="keyword">public</span> OpKernel &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">ZeroOutOp</span><span class="params">(OpKernelConstruction* context)</span> : OpKernel(context) &#123;</span>&#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">Compute</span><span class="params">(OpKernelContext* context)</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">    <span class="comment">// Grab the input tensor</span></span><br><span class="line">    <span class="type">const</span> Tensor&amp; input_tensor = context-&gt;<span class="built_in">input</span>(<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">auto</span> input = input_tensor.<span class="built_in">flat</span>&lt;int32&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Create an output tensor</span></span><br><span class="line">    Tensor* output_tensor = <span class="literal">NULL</span>;</span><br><span class="line">    <span class="built_in">OP_REQUIRES_OK</span>(context, context-&gt;<span class="built_in">allocate_output</span>(<span class="number">0</span>, input_tensor.<span class="built_in">shape</span>(),</span><br><span class="line">                                                     &amp;output_tensor));</span><br><span class="line">    <span class="keyword">auto</span> output = output_tensor-&gt;<span class="built_in">flat</span>&lt;int32&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Set all but the first element of the output tensor to 0.</span></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> N = input.<span class="built_in">size</span>();</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt; N; i++) &#123;</span><br><span class="line">      <span class="built_in">output</span>(i) = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Preserve the first input value if possible.</span></span><br><span class="line">    <span class="keyword">if</span> (N &gt; <span class="number">0</span>) <span class="built_in">output</span>(<span class="number">0</span>) = <span class="built_in">input</span>(<span class="number">0</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意Compute函数需要保证线程安全的，否则可能会有竞争。</p>
</blockquote>
<p>在实现内核之后，将其注册到TensorFlow系统。在注册中，您可以指定运行该内核的不同约束。例如，您可能有一个用于cpu的内核，另一个用于gpu的内核。需要使用如下宏到<code>zero_out.cc</code>文件中：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">REGISTER_KERNEL_BUILDER</span>(<span class="built_in">Name</span>(<span class="string">&quot;ZeroOut&quot;</span>).<span class="built_in">Device</span>(DEVICE_CPU), ZeroOutOp);</span><br></pre></td></tr></table></figure>

<h2 id="Build-OP-库"><a href="#Build-OP-库" class="headerlink" title="Build OP 库"></a>Build OP 库</h2><p>需要本地安装有g++，然后对<code>zero_out.cc</code>进行编译，找到<code>zero_out.cc</code>文件，对其进行编译</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">TF_CFLAGS=( $(python -c &#x27;import tensorflow as tf; print(&quot; &quot;.join(tf.sysconfig.get_compile_flags()))&#x27;) )</span><br><span class="line">TF_LFLAGS=( $(python -c &#x27;import tensorflow as tf; print(&quot; &quot;.join(tf.sysconfig.get_link_flags()))&#x27;) )</span><br><span class="line">g++ -std=c++11 -shared zero_out.cc -o zero_out.so -fPIC $&#123;TF_CFLAGS[@]&#125; $&#123;TF_LFLAGS[@]&#125; -O2</span><br></pre></td></tr></table></figure>

<p><code>zero_out.cc</code>全部内容如下：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;tensorflow/core/framework/op.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;tensorflow/core/framework/op_kernel.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="built_in">REGISTER_OP</span>(<span class="string">&quot;ZeroOutzrf&quot;</span>).<span class="built_in">Input</span>(<span class="string">&quot;to_zero: int32&quot;</span>).<span class="built_in">Output</span>(<span class="string">&quot;zeroed: int32&quot;</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> tensorflow;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ZeroOutOpZRF</span> : <span class="keyword">public</span> OpKernel &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">ZeroOutOpZRF</span><span class="params">(OpKernelConstruction* context)</span> : OpKernel(context) &#123;</span>&#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">Compute</span><span class="params">(OpKernelContext* context)</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">    <span class="comment">// Grab the input tensor</span></span><br><span class="line">    <span class="type">const</span> Tensor&amp; input_tensor = context-&gt;<span class="built_in">input</span>(<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">auto</span> input = input_tensor.<span class="built_in">flat</span>&lt;int32&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Create an output tensor</span></span><br><span class="line">    Tensor* output_tensor = <span class="literal">NULL</span>;</span><br><span class="line">    <span class="built_in">OP_REQUIRES_OK</span>(context, context-&gt;<span class="built_in">allocate_output</span>(<span class="number">0</span>, input_tensor.<span class="built_in">shape</span>(),</span><br><span class="line">                                                     &amp;output_tensor));</span><br><span class="line">    <span class="keyword">auto</span> output = output_tensor-&gt;<span class="built_in">flat</span>&lt;int32&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Set all but the first element of the output tensor to 0.</span></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> N = input.<span class="built_in">size</span>();</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt; N; i++) &#123;</span><br><span class="line">      <span class="built_in">output</span>(i) = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Preserve the first input value if possible.</span></span><br><span class="line">    <span class="keyword">if</span> (N &gt; <span class="number">0</span>) <span class="built_in">output</span>(<span class="number">0</span>) = <span class="built_in">input</span>(<span class="number">0</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="built_in">REGISTER_KERNEL_BUILDER</span>(<span class="built_in">Name</span>(<span class="string">&quot;ZeroOutzrf&quot;</span>).<span class="built_in">Device</span>(DEVICE_CPU), ZeroOutOpZRF);</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="使用bazel编译操作"><a href="#使用bazel编译操作" class="headerlink" title="使用bazel编译操作"></a>使用bazel编译操作</h2><p>如果你安装了 TensorFlow 源码，则你可以利用 TensorFLow 的构建系统来编译你的操作。把一个 BUILD 文件放在<br><a target="_blank" rel="noopener" href="https://www.tensorflow.org/code/tensorflow/core/user_ops/"><code>tensorflow/core/user_ops</code></a> 目录中，其中包含 Bazel 的构建规则，内容如下：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">load</span>(<span class="string">&quot;//tensorflow:tensorflow.bzl&quot;</span>, <span class="string">&quot;tf_custom_op_library&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">tf_custom_op_library</span>(</span><br><span class="line">    name = <span class="string">&quot;zero_out.so&quot;</span>,</span><br><span class="line">    srcs = [<span class="string">&quot;zero_out.cc&quot;</span>],</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>运行下列命令来构建 <code>zero_out.so</code>.</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">bazel build --config opt //tensorflow/core/user_ops:zero_out.so</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意：虽然你可以用标准 <code>cc_library</code> 规则来生成一个共享库文件（<code>.so</code> 文件），我们还是强烈推荐使用 <code>tf_custom_op_library</code> 宏。这个宏加了一些必要的依赖项，而且还包含一些检查，以确保输出的共享库文件与 TensorFlow 的插件加载机制兼容。</p>
</blockquote>
<h2 id="条件检查和验证"><a href="#条件检查和验证" class="headerlink" title="条件检查和验证"></a>条件检查和验证</h2><p>上述示例假定操作适用于任意形状的张量。但如果我们只处理矢量呢？那么我们就需要在 OpKernel 的实现中加入一个检查：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">Compute</span><span class="params">(OpKernelContext* context)</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 获得输入张量</span></span><br><span class="line">  <span class="type">const</span> Tensor&amp; input_tensor = context-&gt;<span class="built_in">input</span>(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">OP_REQUIRES</span>(context, TensorShapeUtils::<span class="built_in">IsVector</span>(input_tensor.<span class="built_in">shape</span>()),</span><br><span class="line">              errors::<span class="built_in">InvalidArgument</span>(<span class="string">&quot;ZeroOut expects a 1-D vector.&quot;</span>));</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这里我们加了一个断言，它要求输入是一个矢量，否则将设置 <code>InvalidArgument</code> 状态。<a target="_blank" rel="noopener" href="https://www.tensorflow.org/code/tensorflow/core/lib/core/errors.h"><code>OP_REQUIRES</code> 宏</a> 有三个参数：</p>
<ul>
<li>上下文 <code>context</code>：既可以是一个 <code>OpKernelContext</code>，也可以是一个 <code>OpKernelConstruction</code> 指针（参见<br> <a target="_blank" rel="noopener" href="https://www.tensorflow.org/code/tensorflow/core/framework/op_kernel.h"><code>tensorflow/core/framework/op_kernel.h</code></a> 文件），用于其 <code>SetStatus()</code> 方法。</li>
<li>条件：关于验证张量形状的更多函数，参见文件<br> <a target="_blank" rel="noopener" href="https://www.tensorflow.org/code/tensorflow/core/framework/tensor_shape.h"><code>tensorflow/core/framework/tensor_shape.h</code></a></li>
<li>错误本身：它由一个 <code>Status</code> 对象表示，参见文件<br> <a target="_blank" rel="noopener" href="https://www.tensorflow.org/code/tensorflow/core/lib/core/status.h"><code>tensorflow/core/lib/core/status.h</code></a>。一个 <code>Status</code> 对象包含一个类型（常为 <code>InvalidArgument</code>，但能看到类型列表）和一条消息。构建一个错误的函数参见文件<br>  <a target="_blank" rel="noopener" href="https://www.tensorflow.org/code/tensorflow/core/lib/core/errors.h"><code>tensorflow/core/lib/core/errors.h</code></a>。</li>
</ul>
<p>另外，如果你想测试从某个函数返回的 <code>Status</code> 对象是否为错误，则使用宏 <a target="_blank" rel="noopener" href="https://www.tensorflow.org/code/tensorflow/core/lib/core/errors.h"><code>OP_REQUIRES_OK</code></a>。这两个宏都会在错误报错时返回错误对象。</p>
<h2 id="属性"><a href="#属性" class="headerlink" title="属性"></a>属性</h2><p>操作可以有属性，当一个操作被加到计算图中时，它的属性就会被赋值。这些属性用于配置此操作，它们的值既可以在内核实现中访问，也可以在操作注册时的输入输出类型中进行访问。相较于输入，参数的使用要尽量避免，因为输入更为灵活一些。这是因为属性是常数，<br>必须在计算图构造时定义。相反，输入作为张量，它的值是动态的；即输入的值在每一步都可以修改，比如使用 feed。属性主要用于无法使用输入的场合：任何影响特征（输入输出的数量和类型）的配置，或无法在每一步修改的时候。</p>
<p>你需要在注册操作时定义属性，定义时要指定名称和使用 <code>Attr</code> 方法的类型，此方法的参数规范如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>: <span class="tag">&lt;<span class="name">attr-type-expr</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>其中 <code>&lt;name&gt;</code> 以字母开头，由数字、字母和下划线组成，而 <code>&lt;attr-type-expr&gt;</code> 一个类型表达式（参见<a target="_blank" rel="noopener" href="https://tensorflow.juejin.im/extend/adding_an_op.html#attr_types">下方</a>）。</p>
<p>比如，如果你想让 <code>ZeroOut</code> 操作保留用户指定的索引，而不是仅保留第 0 个元素，你可以按下面的方式来注册操作：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">REGISTER_OP</span>(<span class="string">&quot;ZeroOut&quot;</span>)</span><br><span class="line">    .<span class="built_in">Attr</span>(<span class="string">&quot;preserve_index: int&quot;</span>)</span><br><span class="line">    .<span class="built_in">Input</span>(<span class="string">&quot;to_zero: int32&quot;</span>)</span><br><span class="line">    .<span class="built_in">Output</span>(<span class="string">&quot;zeroed: int32&quot;</span>);</span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://www.tensorflow.org/api_docs/python/tf/DType"><code>tf.DType</code></a></p>
<p>你实现的内核可以在构造函数中通过 <code>context</code> 参数来访问属性：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ZeroOutOp</span> : <span class="keyword">public</span> OpKernel &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">ZeroOutOp</span><span class="params">(OpKernelConstruction* context)</span> : OpKernel(context) &#123;</span></span><br><span class="line">    <span class="comment">// 获取待保存的索引值</span></span><br><span class="line">    <span class="built_in">OP_REQUIRES_OK</span>(context,</span><br><span class="line">                   context-&gt;<span class="built_in">GetAttr</span>(<span class="string">&quot;preserve_index&quot;</span>, &amp;preserve_index_));</span><br><span class="line">    <span class="comment">// 检查 preserve_index 是否为正值</span></span><br><span class="line">    <span class="built_in">OP_REQUIRES</span>(context, preserve_index_ &gt;= <span class="number">0</span>,</span><br><span class="line">                errors::<span class="built_in">InvalidArgument</span>(<span class="string">&quot;Need preserve_index &gt;= 0, got &quot;</span>,</span><br><span class="line">                                        preserve_index_));</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">Compute</span><span class="params">(OpKernelContext* context)</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">  &#125;</span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="type">int</span> preserve_index_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>还可以在 <code>Compute</code> 方法中使用这个参数：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">Compute</span><span class="params">(OpKernelContext* context)</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 我们用保存的属性来检查动态输入的合法性</span></span><br><span class="line">  <span class="comment">// 所以，我们检查 preserve_index 是否在允许的值域范围内</span></span><br><span class="line">  <span class="built_in">OP_REQUIRES</span>(context, preserve_index_ &lt; input.<span class="built_in">dimension</span>(<span class="number">0</span>),</span><br><span class="line">              errors::<span class="built_in">InvalidArgument</span>(<span class="string">&quot;preserve_index out of range&quot;</span>));</span><br><span class="line">  <span class="comment">// 将输出张量中所有元素设置为 0</span></span><br><span class="line">  <span class="type">const</span> <span class="type">int</span> N = input.<span class="built_in">size</span>();</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; i++) &#123;</span><br><span class="line">    <span class="built_in">output_flat</span>(i) = <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 保存指定位置的输入值</span></span><br><span class="line">  <span class="built_in">output_flat</span>(preserve_index_) = <span class="built_in">input</span>(preserve_index_);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="属性类型"><a href="#属性类型" class="headerlink" title="属性类型"></a>属性类型</h3><p>属性支持下列数据类型：</p>
<ul>
<li><code>string</code>：任意字节序列（不要求是 UTF8 编码）</li>
<li><code>int</code>：有符号整数</li>
<li><code>float</code>: 浮点数</li>
<li><code>bool</code>: True 或 false</li>
<li><code>type</code>： <a target="_blank" rel="noopener" href="https://www.tensorflow.org/code/tensorflow/core/framework/types.cc"><code>DataType</code></a> 的其中一个（非引用）值</li>
<li><code>shape</code>：一个 <a target="_blank" rel="noopener" href="https://www.tensorflow.org/code/tensorflow/core/framework/tensor_shape.proto"><code>TensorShapeProto</code></a></li>
<li><code>tensor</code>：一个 <a target="_blank" rel="noopener" href="https://www.tensorflow.org/code/tensorflow/core/framework/tensor.proto"><code>TensorProto</code></a></li>
<li><code>list(&lt;type&gt;)</code>： <code>&lt;type&gt;</code> 的列表，其中 <code>&lt;type&gt;</code> 为其中一种上述类型<br> 注意： <code>list(list(&lt;type&gt;))</code> 是非法的。</li>
</ul>
<p>欲了解限定性列表，参见 <a target="_blank" rel="noopener" href="https://www.tensorflow.org/code/tensorflow/core/framework/op_def_builder.cc"><code>op_def_builder.cc:FinalizeAttr</code></a>。</p>
<h3 id="默认值和约束"><a href="#默认值和约束" class="headerlink" title="默认值和约束"></a>默认值和约束</h3><p>属性可以有默认值，有一些属性则还可以有约束。为了定义一个有约束的属性，可以使用下列属性类型表达式（<code>&lt;attr-type-expr&gt;</code>）：</p>
<ul>
<li><p><code>{&#39;&lt;string1&gt;&#39;, &#39;&lt;string2&gt;&#39;}</code>：表示在 <code>&lt;string1&gt;</code> 或 <code>&lt;string2&gt;</code> 这两种取值中二选一。当你使用这种语法时，系统自动推断出属性类型为 <code>string</code>。这相当于模仿构造了一个枚举：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">REGISTER_OP</span>(<span class="string">&quot;EnumExample&quot;</span>)</span><br><span class="line">    .<span class="built_in">Attr</span>(<span class="string">&quot;e: &#123;&#x27;apple&#x27;, &#x27;orange&#x27;&#125;&quot;</span>);</span><br></pre></td></tr></table></figure>
</li>
<li><p><a target="_blank" rel="noopener" href="https://www.tensorflow.org/api_docs/python/tf/DType"><code>tf.DType</code></a></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">REGISTER_OP</span>(<span class="string">&quot;RestrictedTypeExample&quot;</span>)</span><br><span class="line">    .<span class="built_in">Attr</span>(<span class="string">&quot;t: &#123;int32, float, bool&#125;&quot;</span>);</span><br></pre></td></tr></table></figure>
</li>
<li><p>常用的类型约束可以有如下别名：</p>
<ul>
<li><p><code>numbertype</code>：<code>type</code> 类型被限制为数值类型（不是字符串，也不是布尔类型）</p>
</li>
<li><p><code>realnumbertype</code>：类似于 <code>numbertype</code> 类型，但不包括复数类型</p>
</li>
<li><p><code>quantizedtype</code>：类型于 <code>numbertype</code> 类型，但只包括量化数值类型</p>
<p>属性所支持的类型列表可通过 <a target="_blank" rel="noopener" href="https://www.tensorflow.org/code/tensorflow/core/framework/types.h"><code>tensorflow/core/framework/types.h</code></a> 中的一些函数来定义（比如 <code>NumberTypes()</code>）。在本例中，属性 <code>t</code> 必须是下面一种数值类型：</p>
</li>
</ul>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">REGISTER_OP</span>(<span class="string">&quot;NumberType&quot;</span>)</span><br><span class="line">    .<span class="built_in">Attr</span>(<span class="string">&quot;t: numbertype&quot;</span>);</span><br></pre></td></tr></table></figure>

<p>  对于这个操作：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tf.number_type(t=tf.int32)  <span class="comment"># 合法</span></span><br><span class="line">tf.number_type(t=tf.<span class="built_in">bool</span>)   <span class="comment"># 不合法</span></span><br></pre></td></tr></table></figure>

<p>  列表可以和其他列表及单一类型组合。下面的操作允许属性 <code>t</code> 为任意数值类型或布尔类型：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">REGISTER_OP</span>(<span class="string">&quot;NumberOrBooleanType&quot;</span>)</span><br><span class="line">    .<span class="built_in">Attr</span>(<span class="string">&quot;t: &#123;numbertype, bool&#125;&quot;</span>);</span><br></pre></td></tr></table></figure>

<p>  对于这个操作：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tf.number_or_boolean_type(t=tf.int32)  <span class="comment"># 合法</span></span><br><span class="line">tf.number_or_boolean_type(t=tf.<span class="built_in">bool</span>)   <span class="comment"># 合法</span></span><br><span class="line">tf.number_or_boolean_type(t=tf.string) <span class="comment"># 不合法</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><code>int &gt;= &lt;n&gt;</code>：取值必须是整型，且要求大于等于 <code>&lt;n&gt;</code>，其中 <code>&lt;n&gt;</code> 是一个自然数。</p>
<p> 比如，下列操作注册中，指定了属性 <code>a</code> 必须为一个至少为 <code>2</code> 的值：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">REGISTER_OP</span>(<span class="string">&quot;MinIntExample&quot;</span>)</span><br><span class="line">    .<span class="built_in">Attr</span>(<span class="string">&quot;a: int &gt;= 2&quot;</span>);</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>list(&lt;type&gt;) &gt;= &lt;n&gt;</code>: 取值为<code>&lt;type&gt;</code> 类型的一个列表，其长度大于等于 <code>&lt;n&gt;</code>。</p>
<p> 比如，下列操作注册指定属性 <code>a</code> 是一个类型列表（要么是 <code>int32</code>，要么是 <code>float</code>），且要求长度大于等于 <code>3</code>：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">REGISTER_OP</span>(<span class="string">&quot;TypeListExample&quot;</span>)</span><br><span class="line">    .<span class="built_in">Attr</span>(<span class="string">&quot;a: list(&#123;int32, float&#125;) &gt;= 3&quot;</span>);</span><br></pre></td></tr></table></figure></li>
</ul>
<p>为设置一个属性的默认值（让它在生成代码中成为可选项），可以在最后加上 <code>= &lt;default&gt;</code>，如下面代码所示：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">REGISTER_OP</span>(<span class="string">&quot;AttrDefaultExample&quot;</span>)</span><br><span class="line">    .<span class="built_in">Attr</span>(<span class="string">&quot;i: int = 0&quot;</span>);</span><br></pre></td></tr></table></figure>

<p>这种默认值的支持语法正是计算图的 GraphDef 定义的协议缓存表达中所用的语法。</p>
<p>下面的示例展示如何为所有类型指定默认值：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">REGISTER_OP</span>(<span class="string">&quot;AttrDefaultExampleForAllTypes&quot;</span>)</span><br><span class="line">   .<span class="built_in">Attr</span>(<span class="string">&quot;s: string = &#x27;foo&#x27;&quot;</span>)</span><br><span class="line">   .<span class="built_in">Attr</span>(<span class="string">&quot;i: int = 0&quot;</span>)</span><br><span class="line">   .<span class="built_in">Attr</span>(<span class="string">&quot;f: float = 1.0&quot;</span>)</span><br><span class="line">   .<span class="built_in">Attr</span>(<span class="string">&quot;b: bool = true&quot;</span>)</span><br><span class="line">   .<span class="built_in">Attr</span>(<span class="string">&quot;ty: type = DT_INT32&quot;</span>)</span><br><span class="line">   .<span class="built_in">Attr</span>(<span class="string">&quot;sh: shape = &#123; dim &#123; size: 1 &#125; dim &#123; size: 2 &#125; &#125;&quot;</span>)</span><br><span class="line">   .<span class="built_in">Attr</span>(<span class="string">&quot;te: tensor = &#123; dtype: DT_INT32 int_val: 5 &#125;&quot;</span>)</span><br><span class="line">   .<span class="built_in">Attr</span>(<span class="string">&quot;l_empty: list(int) = []&quot;</span>)</span><br><span class="line">   .<span class="built_in">Attr</span>(<span class="string">&quot;l_int: list(int) = [2, 3, 5, 7]&quot;</span>);</span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://www.tensorflow.org/api_docs/python/tf/DType"><code>tf.DType</code></a></p>
<h1 id="OP源码部分"><a href="#OP源码部分" class="headerlink" title="OP源码部分"></a>OP源码部分</h1><h2 id="REGISTER-OP"><a href="#REGISTER-OP" class="headerlink" title="REGISTER_OP"></a>REGISTER_OP</h2><p> operator(op)是tensorflow扩展功能的的方式。OP分为声明和定义。声明叫op,实现叫kernel.一个声明可以有多个实现。或者说在不同设备上的不同实现。OP需要注册。</p>
<p>时刻注意，OP只是一个声明。如同C++的函数声明。并不涉及这些OP如何实现。比如可以声明一个OP叫Add，其功能是可以做两个数的加法int Add(int a, int b); 而这个声明用一个proto message表示就是message OpDef。而图就是多个OP的输入输出首尾相接组成的有向无环图，这个图实际上表示了函数的调用关系。</p>
<h2 id="OP注册中心接口"><a href="#OP注册中心接口" class="headerlink" title="OP注册中心接口"></a>OP注册中心接口</h2><p>只提供了根据名字查找OP的接口。tensorflow&#x2F;core&#x2F;framework&#x2F;op.h</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">OpRegistryInterface</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="keyword">virtual</span> ~<span class="built_in">OpRegistryInterface</span>();</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Status <span class="title">LookUp</span><span class="params">(<span class="type">const</span> std::string&amp; op_type_name,</span></span></span><br><span class="line"><span class="params"><span class="function">                        <span class="type">const</span> OpRegistrationData** op_reg_data)</span> <span class="type">const</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="function">Status <span class="title">LookUpOpDef</span><span class="params">(<span class="type">const</span> std::string&amp; op_type_name,</span></span></span><br><span class="line"><span class="params"><span class="function">                     <span class="type">const</span> OpDef** op_def)</span> <span class="type">const</span></span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">//实际的一个实现</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">OpRegistry</span> : <span class="keyword">public</span> OpRegistryInterface &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="keyword">typedef</span> std::function&lt;Status(OpRegistrationData*)&gt; OpRegistrationDataFactory;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">OpRegistry</span>();</span><br><span class="line">  ~<span class="built_in">OpRegistry</span>() <span class="keyword">override</span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">Register</span><span class="params">(<span class="type">const</span> OpRegistrationDataFactory&amp; op_data_factory)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="function">Status <span class="title">LookUp</span><span class="params">(<span class="type">const</span> std::string&amp; op_type_name,</span></span></span><br><span class="line"><span class="params"><span class="function">                <span class="type">const</span> OpRegistrationData** op_reg_data)</span> <span class="type">const</span> <span class="keyword">override</span></span>;</span><br><span class="line">  <span class="keyword">mutable</span> mutex mu_;</span><br><span class="line">  <span class="comment">// Functions in deferred_ may only be called with mu_ held.</span></span><br><span class="line">  <span class="function"><span class="keyword">mutable</span> std::vector&lt;OpRegistrationDataFactory&gt; deferred_ <span class="title">TF_GUARDED_BY</span><span class="params">(mu_)</span></span>;</span><br><span class="line">  <span class="comment">// Values are owned.</span></span><br><span class="line">  <span class="function"><span class="keyword">mutable</span> std::unordered_map&lt;string, <span class="type">const</span> OpRegistrationData*&gt; registry_</span></span><br><span class="line"><span class="function">      <span class="title">TF_GUARDED_BY</span><span class="params">(mu_)</span></span>; <span class="comment">//op就是注册在这里了</span></span><br><span class="line">  <span class="function"><span class="keyword">mutable</span> <span class="type">bool</span> initialized_ <span class="title">TF_GUARDED_BY</span><span class="params">(mu_)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Registry watcher.</span></span><br><span class="line">  <span class="function"><span class="keyword">mutable</span> Watcher watcher_ <span class="title">TF_GUARDED_BY</span><span class="params">(mu_)</span></span>;</span><br><span class="line"></span><br><span class="line">  std::function&lt;Status(<span class="type">const</span> OpRegistryInterface&amp;)&gt; op_registry_validator_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>看这几个接口很简单，但是其参数OpDef, OpRegistrationData很复杂。</p>
<h2 id="OpDef"><a href="#OpDef" class="headerlink" title="OpDef"></a>OpDef</h2><p>一个op有多个输入参数，和多个输入属性，还有多个输出参数，多个控制输出。它们都是Tensor。</p>
<p>输入属性的值在构图时已经确定不变了。而输入参数是执行图时变化数据。</p>
<p><img src="https://zhuzhuzaiimgbed.oss-cn-hangzhou.aliyuncs.com/img/image-20240320181116772.png" alt="image-20240320181116772"></p>
<p>class OpDef 是定义在proto中的。tensorflow&#x2F;core&#x2F;framework&#x2F;op_def.proto</p>
<p>这个proto就声明了个OP.实际上就是把输入输出参数，OP名字等等元信息保存下来。</p>
<figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">message </span><span class="title class_">OpDef</span> &#123;</span><br><span class="line"></span><br><span class="line">  <span class="type">string</span> name = <span class="number">1</span>; <span class="comment">// op名字</span></span><br><span class="line">  <span class="keyword">message </span><span class="title class_">ArgDef</span> &#123; <span class="comment">// op输入输出参数</span></span><br><span class="line">    <span class="type">string</span> name = <span class="number">1</span>;</span><br><span class="line">    <span class="type">string</span> description = <span class="number">2</span>;</span><br><span class="line">    DataType type = <span class="number">3</span>;</span><br><span class="line">    <span class="type">string</span> type_attr = <span class="number">4</span>;    <span class="comment">// if specified, attr must have type &quot;type&quot;</span></span><br><span class="line">    <span class="type">string</span> number_attr = <span class="number">5</span>;  <span class="comment">// if specified, attr must have type &quot;int&quot;</span></span><br><span class="line">    <span class="type">string</span> type_list_attr = <span class="number">6</span>;</span><br><span class="line">    <span class="keyword">repeated</span> ResourceHandleProto.DtypeAndShape handle_data = <span class="number">7</span>;</span><br><span class="line">    <span class="type">bool</span> is_ref = <span class="number">16</span>;</span><br><span class="line">    FullTypeDef experimental_full_type = <span class="number">17</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">repeated</span> ArgDef input_arg = <span class="number">2</span>;</span><br><span class="line">  <span class="keyword">repeated</span> ArgDef output_arg = <span class="number">3</span>;</span><br><span class="line">  <span class="keyword">repeated</span> <span class="type">string</span> control_output = <span class="number">20</span>; <span class="comment">//控制参数</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">message </span><span class="title class_">AttrDef</span> &#123;   <span class="comment">//op属性，构图时已经确定不变</span></span><br><span class="line"></span><br><span class="line">    <span class="type">string</span> name = <span class="number">1</span>;</span><br><span class="line">    <span class="type">string</span> type = <span class="number">2</span>;</span><br><span class="line">    AttrValue default_value = <span class="number">3</span>;</span><br><span class="line">    <span class="type">string</span> description = <span class="number">4</span>;</span><br><span class="line">    <span class="type">bool</span> has_minimum = <span class="number">5</span>;</span><br><span class="line">    <span class="type">int64</span> minimum = <span class="number">6</span>;</span><br><span class="line"></span><br><span class="line">    AttrValue allowed_values = <span class="number">7</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">repeated</span> AttrDef attr = <span class="number">4</span>; <span class="comment">//属性</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">message </span><span class="title class_">OpDeprecation</span> &#123;</span><br><span class="line">  <span class="type">int32</span> version = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">  <span class="type">string</span> explanation = <span class="number">2</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">message </span><span class="title class_">OpList</span> &#123;  <span class="comment">//一组op</span></span><br><span class="line">  <span class="keyword">repeated</span> OpDef op = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="OpDefBuilder来生成OP"><a href="#OpDefBuilder来生成OP" class="headerlink" title="OpDefBuilder来生成OP"></a>OpDefBuilder来生成OP</h2><p>Builder可以通过特定语法格式的字符串来添加 输入参数，输出参数等。添加完成后调用Finalize(OpRegistrationData* op_reg_data)生成了OpRegistrationData. OpRegistrationData有OpDef</p>
<p>tensorflow&#x2F;core&#x2F;framework&#x2F;op_def_builder.h</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">// Builder class passed to the REGISTER_OP() macro.</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">OpDefBuilder</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">OpDefBuilder</span><span class="params">(std::string op_name)</span></span>;</span><br><span class="line">  <span class="comment">//定义属性</span></span><br><span class="line">  <span class="function">OpDefBuilder&amp; <span class="title">Attr</span><span class="params">(std::string spec)</span></span>;</span><br><span class="line">  <span class="comment">//定义输入输出</span></span><br><span class="line">  <span class="function">OpDefBuilder&amp; <span class="title">Input</span><span class="params">(std::string spec)</span></span>;</span><br><span class="line">  <span class="function">OpDefBuilder&amp; <span class="title">Output</span><span class="params">(std::string spec)</span></span>;</span><br><span class="line"></span><br><span class="line">  OpRegistrationData op_reg_data_;</span><br><span class="line">  std::vector&lt;string&gt; attrs_;</span><br><span class="line">  std::vector&lt;string&gt; inputs_;</span><br><span class="line">  std::vector&lt;string&gt; outputs_;</span><br><span class="line">  std::vector&lt;string&gt; control_outputs_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>Op注册原理</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">REGISTER_OP</span>(<span class="string">&quot;ZeroOut&quot;</span>)</span><br><span class="line">    .<span class="built_in">Input</span>(<span class="string">&quot;to_zero: int32&quot;</span>)</span><br><span class="line">    .<span class="built_in">Output</span>(<span class="string">&quot;zeroed: int32&quot;</span>)</span><br><span class="line">    .<span class="built_in">SetShapeFn</span>([](::tensorflow::shape_inference::InferenceContext* c) &#123;</span><br><span class="line">      c-&gt;<span class="built_in">set_output</span>(<span class="number">0</span>, c-&gt;<span class="built_in">input</span>(<span class="number">0</span>));</span><br><span class="line">      <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">    &#125;);</span><br></pre></td></tr></table></figure>

<p>REGISTER_OP宏，实际上定义了如下的OpDefBuilderWrapper的对象。</p>
<p>后续调用的.Input, .Output,等都是对此对象中的Input, Output的方法的调用。而Input里实现上转而调用了OpDefBuilder的Input。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> register_op &#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">OpDefBuilderWrapper</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">OpDefBuilderWrapper</span><span class="params">(<span class="type">const</span> <span class="type">char</span> name[])</span> : builder_(name) &#123;</span>&#125;</span><br><span class="line">  <span class="comment">//属性</span></span><br><span class="line">  <span class="function">OpDefBuilderWrapper&amp; <span class="title">Attr</span><span class="params">(std::string spec)</span> </span>&#123;</span><br><span class="line">    builder_.<span class="built_in">Attr</span>(std::<span class="built_in">move</span>(spec));</span><br><span class="line">    <span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">//输入</span></span><br><span class="line">  <span class="function">OpDefBuilderWrapper&amp; <span class="title">Input</span><span class="params">(std::string spec)</span> </span>&#123;</span><br><span class="line">    builder_.<span class="built_in">Input</span>(std::<span class="built_in">move</span>(spec));</span><br><span class="line">    <span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">//输出</span></span><br><span class="line">  <span class="function">OpDefBuilderWrapper&amp; <span class="title">Output</span><span class="params">(std::string spec)</span> </span>&#123;</span><br><span class="line">    builder_.<span class="built_in">Output</span>(std::<span class="built_in">move</span>(spec));</span><br><span class="line">    <span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//下文中提到的InitOnStartupMarker 中调用了这个</span></span><br><span class="line">  <span class="function">InitOnStartupMarker <span class="title">operator</span><span class="params">()</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="keyword">mutable</span> ::tensorflow::OpDefBuilder builder_;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">&#125;  </span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> REGISTER_OP_IMPL(ctr, name, is_system_op)                         \</span></span><br><span class="line"><span class="meta">  static ::tensorflow::InitOnStartupMarker const register_op##ctr         \</span></span><br><span class="line"><span class="meta">      TF_ATTRIBUTE_UNUSED =                                               \</span></span><br><span class="line"><span class="meta">          TF_INIT_ON_STARTUP_IF(is_system_op || SHOULD_REGISTER_OP(name)) \</span></span><br><span class="line"><span class="meta">          &lt;&lt; ::tensorflow::register_op::OpDefBuilderWrapper(name)</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> REGISTER_OP(name)        \</span></span><br><span class="line"><span class="meta">  TF_ATTRIBUTE_ANNOTATE(<span class="string">&quot;tf:op&quot;</span>) \</span></span><br><span class="line"><span class="meta">  TF_NEW_ID_FOR_INIT(REGISTER_OP_IMPL, name, false)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> REGISTER_SYSTEM_OP(name)        \</span></span><br><span class="line"><span class="meta">  TF_ATTRIBUTE_ANNOTATE(<span class="string">&quot;tf:op&quot;</span>)        \</span></span><br><span class="line"><span class="meta">  TF_ATTRIBUTE_ANNOTATE(<span class="string">&quot;tf:op:system&quot;</span>) \</span></span><br><span class="line"><span class="meta">  TF_NEW_ID_FOR_INIT(REGISTER_OP_IMPL, name, true)</span></span><br><span class="line"></span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure>

<ul>
<li>REGISTER_OP这个宏调用TF_NEW_ID_FOR_INIT. 会使用__COUNTER__宏生成唯一ID.</li>
<li>调用REGISTER_OP_IMPLE时，参数ctr就是counter。</li>
<li>REGISTER_OP_IMPLE所有定义了一个static变量。变量类型是 tensorlfow::InitOnStartUpMarker。变量名是register_op##ctr,实际上就是register_op0, register_op1, ….</li>
<li>TF_INIT_ON_STARTUP_IF宏如果参数是false,则什么也不做，否则 调用后边的&lt;&lt; OpeDefBuilder。这个宏根相当于：!cond ? InitOnStartupMarker{} : (InitOnStartupMarker{} &lt;&lt; f);  f就是::tensorflow::register_op::OpDefBuilderWrapper(name)。因为InitOnStartUpmarker重载了operator&lt;&lt;。</li>
<li>在下图代码InitOpStartupMarker里调用了OpDefBuilderWrapper的Operator()方法。</li>
</ul>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">InitOnStartupMarker</span> &#123;</span><br><span class="line">  <span class="keyword">constexpr</span> InitOnStartupMarker <span class="keyword">operator</span>&lt;&lt;(InitOnStartupMarker) <span class="type">const</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line">  <span class="keyword">constexpr</span> InitOnStartupMarker <span class="keyword">operator</span>&lt;&lt;(T&amp;&amp; v) <span class="type">const</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> std::forward&lt;T&gt;(v)();  #相当于调用OpDefBuilderWrapper对像的<span class="built_in">operator</span>()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 是否在启动时就注册</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> TF_INIT_ON_STARTUP_IF(cond)                \</span></span><br><span class="line"><span class="meta">  (::std::integral_constant<span class="string">&lt;bool, !(cond)&gt;</span>::value) \</span></span><br><span class="line"><span class="meta">      ? ::tensorflow::InitOnStartupMarker&#123;&#125;        \</span></span><br><span class="line"><span class="meta">      : ::tensorflow::InitOnStartupMarker &#123;&#125;</span></span><br></pre></td></tr></table></figure>

<p>真正注册在这里：通过builder获取全局注册中心，实际上是不台OP的构建器function保存下来，在需要的时候就可以通过它来new出新的OP对象了。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">arduino复制代码<span class="function">InitOnStartupMarker <span class="title">OpDefBuilderWrapper::operator</span><span class="params">()</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  OpRegistry::<span class="built_in">Global</span>()-&gt;<span class="built_in">Register</span>(</span><br><span class="line">      [builder =</span><br><span class="line">           std::<span class="built_in">move</span>(builder_)](OpRegistrationData* op_reg_data) -&gt; Status &#123;</span><br><span class="line">        <span class="keyword">return</span> builder.<span class="built_in">Finalize</span>(op_reg_data);</span><br><span class="line">      &#125;);</span><br><span class="line">  <span class="keyword">return</span> &#123;&#125;;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// static,单例</span></span><br><span class="line"><span class="function">OpRegistry* <span class="title">OpRegistry::Global</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">static</span> OpRegistry* global_op_registry = <span class="keyword">new</span> OpRegistry;</span><br><span class="line">  <span class="keyword">return</span> global_op_registry;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">OpRegistry::Register</span><span class="params">(<span class="type">const</span> OpRegistrationDataFactory&amp; op_data_factory)</span> </span>&#123;</span><br><span class="line">  <span class="function">mutex_lock <span class="title">lock</span><span class="params">(mu_)</span></span>;</span><br><span class="line">  <span class="keyword">if</span> (initialized_) &#123;</span><br><span class="line">    <span class="built_in">TF_QCHECK_OK</span>(<span class="built_in">RegisterAlreadyLocked</span>(op_data_factory));</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    deferred_.<span class="built_in">push_back</span>(op_data_factory);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> std::function&lt;Status(OpRegistrationData*)&gt; OpRegistrationDataFactory;</span><br></pre></td></tr></table></figure>

<p>最终把构建好的op,其实就是OpRegistrationData插入到map&lt;op_name, OpRegistrationData*&gt; OpRegistry::registry_中。</p>
<h1 id="KERNEL源码部分"><a href="#KERNEL源码部分" class="headerlink" title="KERNEL源码部分"></a>KERNEL源码部分</h1><p>tensorflow图结点叫OP(operator)。OP是C++写的可以由使用者任意扩展的。扩展OP分两步，1是OP的声明，也就OP注册，使用REGISTER_OP来完成。2是OP的实现，叫op_kernel。KERNEL也需要注册，叫REGISTER_KERNEL_BUILDER。OP在实现时需要继承OpKernel类。</p>
<p>构图时只需要OP声明即可。运行时才需要查找并实例化Kernel。一个OP在不同的设备上可以有不同的实现。下面的例子是官网最简单的ZeroOut OP声明和Kernel的实现。实际上，声明和实现完全可以独立在不同的文件。本文则着重分析Kernel</p>
<p>Kernel是真正实现计算功能的。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;tensorflow/core/framework/op.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;tensorflow/core/framework/shape_inference.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;tensorflow/core/framework/op_kernel.h&quot;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> tensorflow;</span><br><span class="line"><span class="comment">//OP的声明</span></span><br><span class="line"><span class="built_in">REGISTER_OP</span>(<span class="string">&quot;ZeroOut&quot;</span>)</span><br><span class="line">    .<span class="built_in">Input</span>(<span class="string">&quot;to_zero: int32&quot;</span>)</span><br><span class="line">    .<span class="built_in">Output</span>(<span class="string">&quot;zeroed: int32&quot;</span>)</span><br><span class="line">    .<span class="built_in">SetShapeFn</span>([](::tensorflow::shape_inference::InferenceContext* c) &#123;</span><br><span class="line">      c-&gt;<span class="built_in">set_output</span>(<span class="number">0</span>, c-&gt;<span class="built_in">input</span>(<span class="number">0</span>));</span><br><span class="line">      <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">    &#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">//OP实现</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ZeroOutOp</span> : <span class="keyword">public</span> OpKernel &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">ZeroOutOp</span><span class="params">(OpKernelConstruction* context)</span> : OpKernel(context) &#123;</span>&#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">Compute</span><span class="params">(OpKernelContext* context)</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">    <span class="comment">// Grab the input tensor</span></span><br><span class="line">    <span class="type">const</span> Tensor&amp; input_tensor = context-&gt;<span class="built_in">input</span>(<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">auto</span> input = input_tensor.<span class="built_in">flat</span>&lt;int32&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Create an output tensor</span></span><br><span class="line">    Tensor* output_tensor = <span class="literal">NULL</span>;</span><br><span class="line">    <span class="built_in">OP_REQUIRES_OK</span>(context, context-&gt;<span class="built_in">allocate_output</span>(<span class="number">0</span>, input_tensor.<span class="built_in">shape</span>(),</span><br><span class="line">                                                     &amp;output_tensor));</span><br><span class="line">    <span class="keyword">auto</span> output_flat = output_tensor-&gt;<span class="built_in">flat</span>&lt;int32&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Set all but the first element of the output tensor to 0.</span></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> N = input.<span class="built_in">size</span>();</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt; N; i++) &#123;</span><br><span class="line">      <span class="built_in">output_flat</span>(i) = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Preserve the first input value if possible.</span></span><br><span class="line">    <span class="keyword">if</span> (N &gt; <span class="number">0</span>) <span class="built_in">output_flat</span>(<span class="number">0</span>) = <span class="built_in">input</span>(<span class="number">0</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">//注册KERNEL</span></span><br><span class="line"><span class="built_in">REGISTER_KERNEL_BUILDER</span>(<span class="built_in">Name</span>(<span class="string">&quot;ZeroOut&quot;</span>).<span class="built_in">Device</span>(DEVICE_CPU), ZeroOutOp);</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="Kernel"><a href="#Kernel" class="headerlink" title="Kernel"></a>Kernel</h2><p>tensorflow&#x2F;core&#x2F;framework&#x2F;op_kernel.h</p>
<h2 id="同步计算-Compute方法"><a href="#同步计算-Compute方法" class="headerlink" title="同步计算 Compute方法"></a>同步计算 Compute方法</h2><ol>
<li>kernel计算可以是同步也可以是异步。Compute必须是线程安全。大多数是同步。</li>
<li>同步 kernel 绝不能用锁，条件变量等阻塞当前线程，试图在其他kernel里解锁。有</li>
<li>因为executor可能只有固定数量的线程，都阻塞就会死锁</li>
<li>如果真想加锁，如RecvOp, DequeueOp,必须继承OpKernel的子类AsyncOpKernel。</li>
<li>大多数情况下，AsyncOpKerenl应当使用cancellation机制：context-&gt;cancellation_manager()</li>
<li>op的输入输出都要通过参数OpKernelContext context来获得。返回状态也通过ctx-&gt;SetStatus()</li>
<li>同步计算中，context可以保证函数返回前直存在。</li>
</ol>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//构造与析构</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">OpKernel</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="comment">//kernel不会在调度器中初始化，所以可以在子类中实现重逻辑</span></span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">OpKernel</span><span class="params">(OpKernelConstruction* context)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//允许延时OP. executor会使用OpKernelContext::inc_num_deferred_ops_function()` and</span></span><br><span class="line">  <span class="comment">// `OpKernelContext::dec_num_deferred_ops_function()` methods at run-time.</span></span><br><span class="line">  <span class="built_in">OpKernel</span>(OpKernelConstruction* context, <span class="type">bool</span> is_deferred);</span><br><span class="line">  <span class="comment">//能请允许子类自定义NodeDef</span></span><br><span class="line">  <span class="built_in">OpKernel</span>(OpKernelConstruction* context, NodeDef&amp;&amp; custom_def,</span><br><span class="line">           <span class="type">bool</span> is_deferred);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">virtual</span> ~<span class="built_in">OpKernel</span>();</span><br><span class="line">     </span><br><span class="line">  <span class="comment">//核心计算函数，子类重写它来实现自己的功能</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">Compute</span><span class="params">(OpKernelContext* context)</span> </span>= <span class="number">0</span>;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> AsyncOpKernel* <span class="title">AsAsync</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> <span class="literal">nullptr</span>; &#125;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">bool</span> <span class="title">IsExpensive</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> expensive_; &#125;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">const</span> Tensor* <span class="title">const_tensor</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> <span class="literal">nullptr</span>; &#125;</span><br><span class="line">  <span class="comment">// Accessors. 能返回结点定义，结点名字，</span></span><br><span class="line">  <span class="function"><span class="type">const</span> NodeDef&amp; <span class="title">def</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> props_-&gt;node_def; &#125;</span><br><span class="line">  <span class="function"><span class="type">const</span> std::string&amp; <span class="title">name</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> props_-&gt;node_def.<span class="built_in">name</span>(); &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="异步计算：AsyncOpKernel"><a href="#异步计算：AsyncOpKernel" class="headerlink" title="异步计算：AsyncOpKernel"></a>异步计算：AsyncOpKernel</h2><p>异步也就是computeAsync要立即返回。当然tensorflow会一直保持context存在，直到done被调用。一但done被调用，不应当再使用context。否则会core。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">AsyncOpKernel</span> : <span class="keyword">public</span> OpKernel &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="keyword">using</span> OpKernel::OpKernel;  <span class="comment">// Lift OpKernel constructors.</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">//异步计算完成后要调用此回调函数通知调度器。</span></span><br><span class="line">  <span class="comment">//只能调用一次，一旦调用，context, 和this都可能已经销毁了</span></span><br><span class="line">  <span class="keyword">typedef</span> std::function&lt;<span class="type">void</span>()&gt; DoneCallback;</span><br><span class="line">  <span class="comment">//异步计算就重写此接口</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">ComputeAsync</span><span class="params">(OpKernelContext* context, DoneCallback done)</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="function">AsyncOpKernel* <span class="title">AsAsync</span><span class="params">()</span> <span class="keyword">override</span> </span>&#123; <span class="keyword">return</span> <span class="keyword">this</span>; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">Compute</span><span class="params">(OpKernelContext* context)</span> <span class="keyword">override</span></span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="Kernel构造时的OpKernelConstruction"><a href="#Kernel构造时的OpKernelConstruction" class="headerlink" title="Kernel构造时的OpKernelConstruction"></a>Kernel构造时的OpKernelConstruction</h2><p>传入了</p>
<ol>
<li>设备:device</li>
<li>分配器Allocator</li>
<li>资源管理器：ResourceMgr</li>
<li>Node</li>
<li>Env</li>
<li>FunctionLib</li>
</ol>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//创建OP时由tensorflow框架创建此类，并传入给OP的构建函数。</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">OpKernelConstruction</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line"></span><br><span class="line">  <span class="comment">//环境，访问操作系统如文件系统，线程创建要使用此env.</span></span><br><span class="line">  <span class="function">Env* <span class="title">env</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> device_-&gt;<span class="built_in">env</span>(); &#125;</span><br><span class="line"> </span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">SetStatus</span><span class="params">(<span class="type">const</span> Status&amp; status)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">const</span> Status&amp; <span class="title">status</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> *status_; &#125;</span><br><span class="line">  <span class="comment">//属性时在构图时确定了的，所以在没有运行图时就能获取值。</span></span><br><span class="line">  <span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line">  <span class="function">Status <span class="title">GetAttr</span><span class="params">(StringPiece attr_name, T* value)</span> <span class="type">const</span></span>;</span><br><span class="line">  <span class="function"><span class="type">const</span> DeviceType&amp; <span class="title">device_type</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> device_type_; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function">FunctionLibraryRuntime* <span class="title">function_library</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> flib_; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Shared resources accessible to this kernel.</span></span><br><span class="line">  <span class="function">ResourceMgr* <span class="title">resource_manager</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> resource_mgr_; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// The GraphDef version whose behavior we should follow.</span></span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">graph_def_version</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> graph_def_version_; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//获取设备</span></span><br><span class="line">  <span class="function">DeviceBase* <span class="title">device</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> device_; &#125;</span><br><span class="line"></span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="OP输入输出参数帮助类"><a href="#OP输入输出参数帮助类" class="headerlink" title="OP输入输出参数帮助类"></a>OP输入输出参数帮助类</h2><p>有的输入是个List,用一个名字，代表了同类型的多个输入。 可以认为是Tensor tensors[N].输出也有这种情况。</p>
<ol>
<li>OpInputList</li>
<li>OpMutableInputList</li>
<li>OpOutputList</li>
</ol>
<h2 id="Compute的参数OpKernelContext"><a href="#Compute的参数OpKernelContext" class="headerlink" title="Compute的参数OpKernelContext"></a>Compute的参数OpKernelContext</h2><p>这个类十分巨大，内容丰富。这个Context提供了Op Compute时所需要的一切。从逻辑上讲，可分为以下几类</p>
<h3 id="输入输出参数获取"><a href="#输入输出参数获取" class="headerlink" title="输入输出参数获取"></a>输入输出参数获取</h3><p>Input, Output. 至于Attr,是在构图时获得，OpKernelConstruction里就能获取</p>
<p>输出还涉及到Tensor内存分配</p>
<h3 id="执行环境"><a href="#执行环境" class="headerlink" title="执行环境"></a>执行环境</h3><p>env, device, resource_mgr, node, graph, session, step_id, function_library, allocator, session</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">OpKernelContext</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="comment">//基本信息</span></span><br><span class="line">   <span class="type">const</span> SessionMetadata* session_metadata = <span class="literal">nullptr</span>;</span><br><span class="line">   TensorStore* tensor_store = <span class="literal">nullptr</span>;</span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">OpKernelContext</span><span class="params">(Params* params)</span></span>;</span><br><span class="line">  <span class="built_in">OpKernelContext</span>(Params* params, <span class="type">int</span> num_outputs);</span><br><span class="line">  ~<span class="built_in">OpKernelContext</span>();</span><br><span class="line">  <span class="function">Env* <span class="title">env</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> params_-&gt;device-&gt;<span class="built_in">env</span>(); &#125;</span><br><span class="line">  <span class="function"><span class="type">int64_t</span> <span class="title">step_id</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> params_-&gt;step_id; &#125;</span><br><span class="line">  <span class="function"><span class="type">int64_t</span> <span class="title">start_time_usecs</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> params_-&gt;start_time_usecs; &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 操作op的输入，可以按id,或者名字，只读取或者读写Input</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">const</span> Tensor&amp; <span class="title">input</span><span class="params">(<span class="type">int</span> index)</span> <span class="type">const</span></span>;</span><br><span class="line">  <span class="function">Status <span class="title">input</span><span class="params">(StringPiece name, <span class="type">const</span> Tensor** tensor)</span></span>;</span><br><span class="line">  <span class="function">Status <span class="title">input_list</span><span class="params">(StringPiece name, OpInputList* list)</span></span>;</span><br><span class="line">  <span class="function">Status <span class="title">input_ref_mutex</span><span class="params">(StringPiece name, mutex** out_mutex)</span></span>;</span><br><span class="line">  <span class="function">Tensor <span class="title">mutable_input</span><span class="params">(<span class="type">int</span> index, <span class="type">bool</span> lock_held)</span></span>;</span><br><span class="line">  <span class="function">Status <span class="title">mutable_input</span><span class="params">(StringPiece name, Tensor* tensor, <span class="type">bool</span> lock_held)</span></span>;</span><br><span class="line">  <span class="function">Status <span class="title">mutable_input_list</span><span class="params">(StringPiece name, OpMutableInputList* list)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">replace_ref_input</span><span class="params">(<span class="type">int</span> index, <span class="type">const</span> Tensor&amp; tensor, <span class="type">bool</span> lock_held)</span></span>;</span><br><span class="line">  <span class="function">Status <span class="title">replace_ref_input</span><span class="params">(StringPiece name, <span class="type">const</span> Tensor&amp; tensor,</span></span></span><br><span class="line"><span class="params"><span class="function">                           <span class="type">bool</span> lock_held)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">delete_ref_input</span><span class="params">(<span class="type">int</span> input_index, <span class="type">bool</span> lock_held)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">has_input</span><span class="params">(<span class="type">int</span> index)</span> <span class="type">const</span></span>;</span><br><span class="line"></span><br><span class="line"> <span class="comment">// 操作op的输输出，可以按id,或者名字，只读取或者读写output. 同时可以给output分配内存</span></span><br><span class="line">  <span class="function">Status <span class="title">output_list</span><span class="params">(StringPiece name, OpOutputList* list)</span></span>;</span><br><span class="line">  <span class="function">Status <span class="title">allocate_output</span><span class="params">(<span class="type">int</span> index, <span class="type">const</span> TensorShape&amp; shape,</span></span></span><br><span class="line"><span class="params"><span class="function">                         Tensor** tensor)</span> TF_MUST_USE_RESULT</span>;</span><br><span class="line">  <span class="function">Status <span class="title">allocate_output</span><span class="params">(StringPiece name, <span class="type">const</span> TensorShape&amp; shape,</span></span></span><br><span class="line"><span class="params"><span class="function">  Status allocate_output(<span class="type">int</span> index, <span class="type">const</span> TensorShape&amp; shape, Tensor** tensor,</span></span></span><br><span class="line"><span class="params"><span class="function">                         AllocatorAttributes attr) TF_MUST_USE_RESULT;</span></span></span><br><span class="line"><span class="params"><span class="function">  Status allocate_output(StringPiece name, <span class="type">const</span> TensorShape&amp; shape,</span></span></span><br><span class="line"><span class="params"><span class="function">                         Tensor** tensor,</span></span></span><br><span class="line"><span class="params"><span class="function">                         AllocatorAttributes attr) TF_MUST_USE_RESULT;</span></span></span><br><span class="line"><span class="params"><span class="function">  <span class="comment">//分配一个临时tensor变量</span></span></span></span><br><span class="line"><span class="params"><span class="function">  Status allocate_temp(DataType type, <span class="type">const</span> TensorShape&amp; shape,</span></span></span><br><span class="line"><span class="params"><span class="function">                       Tensor* out_temp, AllocatorAttributes allocator_attr,</span></span></span><br><span class="line"><span class="params"><span class="function">                       <span class="type">const</span> AllocationAttributes&amp; allocation_attr);</span></span></span><br><span class="line"><span class="params"><span class="function">  Status allocate_temp(DataType type, <span class="type">const</span> TensorShape&amp; shape,</span></span></span><br><span class="line"><span class="params"><span class="function">                       Tensor* out_temp, AllocatorAttributes allocator_attr) &#123;</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">return</span> allocate_temp(type, shape, out_temp, allocator_attr,</span></span></span><br><span class="line"><span class="params"><span class="function">                         AllocationAttributes());</span></span></span><br><span class="line"><span class="params"><span class="function">  &#125;</span></span></span><br><span class="line"><span class="params"><span class="function">  Status allocate_temp(DataType type, <span class="type">const</span> TensorShape&amp; shape,</span></span></span><br><span class="line"><span class="params"><span class="function">                       Tensor* out_temp) &#123;</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">return</span> allocate_temp(type, shape, out_temp, AllocatorAttributes());</span></span></span><br><span class="line"><span class="params"><span class="function">  &#125;</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">&#125;;</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br></pre></td></tr></table></figure>

<h2 id="kernel实例化"><a href="#kernel实例化" class="headerlink" title="kernel实例化"></a>kernel实例化</h2><p>运行时调用如下方法创建Kernel</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">std::unique_ptr&lt;OpKernel&gt; <span class="title">CreateOpKernel</span><span class="params">(DeviceType device_type,</span></span></span><br><span class="line"><span class="params"><span class="function">                                         DeviceBase* device,</span></span></span><br><span class="line"><span class="params"><span class="function">                                         Allocator* allocator,</span></span></span><br><span class="line"><span class="params"><span class="function">                                         <span class="type">const</span> NodeDef&amp; node_def,</span></span></span><br><span class="line"><span class="params"><span class="function">                                         <span class="type">int</span> graph_def_version, Status* status)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function">std::unique_ptr&lt;OpKernel&gt; <span class="title">CreateOpKernel</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    DeviceType device_type, DeviceBase* device, Allocator* allocator,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> std::shared_ptr&lt;<span class="type">const</span> NodeProperties&gt;&amp; props, <span class="type">int</span> graph_def_version,</span></span></span><br><span class="line"><span class="params"><span class="function">    Status* status)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function">Status <span class="title">CreateOpKernel</span><span class="params">(DeviceType device_type, DeviceBase* device,</span></span></span><br><span class="line"><span class="params"><span class="function">                      Allocator* allocator, FunctionLibraryRuntime* flib,</span></span></span><br><span class="line"><span class="params"><span class="function">                      <span class="type">const</span> std::shared_ptr&lt;<span class="type">const</span> NodeProperties&gt;&amp; props,</span></span></span><br><span class="line"><span class="params"><span class="function">                      <span class="type">int</span> graph_def_version, OpKernel** kernel)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function">Status <span class="title">CreateOpKernel</span><span class="params">(DeviceType device_type, DeviceBase* device,</span></span></span><br><span class="line"><span class="params"><span class="function">                      Allocator* allocator, FunctionLibraryRuntime* flib,</span></span></span><br><span class="line"><span class="params"><span class="function">                      ResourceMgr* resource_mgr,</span></span></span><br><span class="line"><span class="params"><span class="function">                      <span class="type">const</span> std::shared_ptr&lt;<span class="type">const</span> NodeProperties&gt;&amp; props,</span></span></span><br><span class="line"><span class="params"><span class="function">                      <span class="type">int</span> graph_def_version, OpKernel** kernel)</span></span>;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>Kernel注册同样使用了宏，工厂等</p>
<h3 id="REGISTER-KERNEL-BUILDER流程分析"><a href="#REGISTER-KERNEL-BUILDER流程分析" class="headerlink" title="REGISTER_KERNEL_BUILDER流程分析"></a>REGISTER_KERNEL_BUILDER流程分析</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//REGISTER_KERNEL_BUILDER 调用了REGISTER_KERNEL_BUILDER_IMPL 调用了TF_EXTRACT_KERNEL_NAME 调用了TF_EXTRACT_KERNEL_NAME_IMPL 调用了REGISTER_KERNEL_BUILDER_IMPL_2 调用了TF_NEW_ID_FOR_INIT调用了REGISTER_KERNEL_BUILDER_IMPL_3</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// REGISTER_KERNEL_BUILDER_IMPL_2, with a unique &#x27;ctr&#x27; as the first argument.</span></span><br><span class="line"><span class="comment">// TODO(dodgen): There are some uses of this macro inside functions, where</span></span><br><span class="line"><span class="comment">// kernel_builder refers to (non-const) locals (they should be fixed). To</span></span><br><span class="line"><span class="comment">// accommodate those, kernel_builder.Build() appears as an argument to an</span></span><br><span class="line"><span class="comment">// immediately-called lambda (not in the lambda itself).</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> REGISTER_KERNEL_BUILDER_IMPL_3(ctr, op_name, kernel_builder_expr,   \</span></span><br><span class="line"><span class="meta">                                       is_system_kernel, ...)               \</span></span><br><span class="line"><span class="meta">  static ::tensorflow::InitOnStartupMarker const register_kernel_##ctr      \</span></span><br><span class="line"><span class="meta">      TF_ATTRIBUTE_UNUSED =                                                 \</span></span><br><span class="line"><span class="meta">          TF_INIT_ON_STARTUP_IF(is_system_kernel ||                         \</span></span><br><span class="line"><span class="meta">                                (SHOULD_REGISTER_OP_KERNEL(#__VA_ARGS__) &amp;&amp; \</span></span><br><span class="line"><span class="meta">                                 SHOULD_REGISTER_OP(op_name)))              \</span></span><br><span class="line"><span class="meta">          &lt;&lt; ([](::tensorflow::KernelDef const* kernel_def) &#123;               \</span></span><br><span class="line"><span class="meta">               也就是到这里了，使用kernel_factory来注册了一个lambda函数      \</span></span><br><span class="line"><span class="meta">               ::tensorflow::kernel_factory::OpKernelRegistrar registrar(   \</span></span><br><span class="line"><span class="meta">                   kernel_def, #__VA_ARGS__,                                \</span></span><br><span class="line"><span class="meta">                   [](::tensorflow::OpKernelConstruction* context)          \</span></span><br><span class="line"><span class="meta">                       -&gt; ::tensorflow::OpKernel* &#123;                         \</span></span><br><span class="line"><span class="meta">                     return new __VA_ARGS__(context); 这里就是在new ZeroOut               \</span></span><br><span class="line"><span class="meta">                   &#125;);                                                      \</span></span><br><span class="line"><span class="meta">               (void)registrar;                                             \</span></span><br><span class="line"><span class="meta">               return ::tensorflow::InitOnStartupMarker&#123;&#125;;                  \</span></span><br><span class="line"><span class="meta">             &#125;)(kernel_builder_expr.Build()); <span class="comment">//这里的kernel_builder_expr就是KernelDefBuilder,其实就是Name(&quot;ZeroOut&quot;).Device(DEVICE_CPU).Build(); 而且这里是对lambda函数的调用，所以会立即进入函数内</span></span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>REGISTER_KERNEL_BUILDER(Name(“ZeroOut”).Device(DEVICE_CPU), ZeroOutOp);这个定义中，Name实际上是KernelDefBuilder. Device就是KernelDefBuilder::Device. </p>
<p>REGISTER_KERNEL_BUILDER( KernelDefBuilder对象， ZeroOut这个类)。</p>
<p>OpkernelRegistrar的构建函数里最终调用到这个GlobalKernelRegistry的Reigster</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span>* <span class="title">GlobalKernelRegistry</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">static</span> KernelRegistry* global_kernel_registry = []() &#123;</span><br><span class="line">    KernelRegistry* registry = <span class="keyword">new</span> KernelRegistry;</span><br><span class="line">    OpRegistry::<span class="built_in">Global</span>()-&gt;<span class="built_in">RegisterValidator</span>(ValidateKernelRegistrations);</span><br><span class="line">    <span class="keyword">return</span> registry;</span><br><span class="line">  &#125;();</span><br><span class="line">  <span class="keyword">return</span> global_kernel_registry;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">KernelRegistry</span> &#123;</span><br><span class="line">  mutex mu;</span><br><span class="line">  std::unordered_multimap&lt;string, KernelRegistration&gt; registry <span class="comment">//就是放在这个map里了</span></span><br><span class="line">      <span class="built_in">TF_GUARDED_BY</span>(mu);</span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="从动态库加载kernel"><a href="#从动态库加载kernel" class="headerlink" title="从动态库加载kernel"></a>从动态库加载kernel</h2><p>tensorflow&#x2F;core&#x2F;framework&#x2F;op_kernel.cc</p>
<p>加载目录:tensorflow&#x2F;core&#x2F;kernels目录中的所有so。实际上使用了Env-&gt;LoadDynamicLibrary 这种方式是我们扩展tensorflow kernel的方式。直接自己打包成独立的动态库，由tf加载即可。无须与tf源码编译到一起。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">LoadDynamicKernelsInternal</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  Env* env = Env::<span class="built_in">Default</span>();</span><br><span class="line">  env-&gt;<span class="built_in">LoadDynamicLibrary</span>(fullpath.<span class="built_in">c_str</span>(), &amp;unused_filehandle)); <span class="comment">//加载动态库。不同环境不现。比较linux上是加载so文件。windows是加载dll文件。</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">LoadDynamicKernels</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">//只调用一次</span></span><br><span class="line">  <span class="type">static</span> absl::once_flag dll_loader_flag;</span><br><span class="line">  absl::<span class="built_in">call_once</span>(dll_loader_flag, LoadDynamicKernelsInternal);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Kernel从context中获取输入，分配输出时返回错误"><a href="#Kernel从context中获取输入，分配输出时返回错误" class="headerlink" title="Kernel从context中获取输入，分配输出时返回错误"></a>Kernel从context中获取输入，分配输出时返回错误</h2><p>tensorflow&#x2F;core&#x2F;framework&#x2F;op_requires.h中定义了大量的宏，帮助我们实现这些功能。这些宏能根据需要返回错误。这宏非常实用，避免我们写大量的if判断，return返回之类的代码</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> OP_REQUIRES_OK(CTX, ...)                             \</span></span><br><span class="line"><span class="meta">  do &#123;                                                       \</span></span><br><span class="line"><span class="meta">    ::tensorflow::Status _s(__VA_ARGS__);                    \</span></span><br><span class="line"><span class="meta">    <span class="keyword">if</span> (!TF_PREDICT_TRUE(_s.ok())) &#123;                         \</span></span><br><span class="line"><span class="meta">      CheckNotInComputeAsync((CTX), <span class="string">&quot;OP_REQUIRES_OK_ASYNC&quot;</span>); \</span></span><br><span class="line"><span class="meta">      (CTX)-&gt;CtxFailureWithWarning(__FILE__, __LINE__, _s);  \</span></span><br><span class="line"><span class="meta">      return;                                                \</span></span><br><span class="line"><span class="meta">    &#125;                                                        \</span></span><br><span class="line"><span class="meta">  &#125; while (0)</span></span><br></pre></td></tr></table></figure>
    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/gpu/" rel="tag"># gpu</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2023/09/22/note/Tensorflow-lite%20source%20code%20analysis/" rel="prev" title="Tensorflow lite源码分析(Tensorflow 2.14)">
                  <i class="fa fa-angle-left"></i> Tensorflow lite源码分析(Tensorflow 2.14)
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2025/07/14/Researches/" rel="next" title="Personal works">
                  Personal works <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Zhuzhuzai</span>
  </div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

  <a href="https://github.com/unsatisfying" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>
  

      
        <script async src=https://cdn.jsdelivr.net/npm/hexo-next-mouse-effect@latest/click/fireWorks.js></script>
      

      s
        <script async src=https://cdn.jsdelivr.net/npm/hexo-next-mouse-effect@latest/move/fairyDustCursor.js></script>
      
    
</body>
</html>
