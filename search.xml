<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Personal works</title>
    <url>/2025/07/14/Researches/</url>
    <content><![CDATA[<h1 id="Secure-AI-Systems-A-Layered-Perspective"><a href="#Secure-AI-Systems-A-Layered-Perspective" class="headerlink" title="Secure AI Systems: A Layered Perspective"></a>Secure AI Systems: A Layered Perspective</h1><p>My Ph.D. research focuses on <strong>AI system security</strong>, from high-level application risks, through AI framework-level vulnerabilities, to low-level hardware exploitation. This layered exploration reveals systemic threats that span across the full AI software stack.</p>
<p><img src="https://zhuzhuzaiimgbed.oss-cn-hangzhou.aliyuncs.com/img/image-20250718095603049.png" alt="image-20250718095603049"></p>
<hr>
<h2 id="🧩-Layer-1-Application-Level-—-Python-Module-Conflicts"><a href="#🧩-Layer-1-Application-Level-—-Python-Module-Conflicts" class="headerlink" title="🧩 Layer 1: Application-Level — Python Module Conflicts"></a>🧩 Layer 1: Application-Level — Python Module Conflicts</h2><p><strong>Paper:</strong> <em>ModuleGuard: Understanding and Detecting Module Conflicts in Python Ecosystem</em> (ICSE 2024)<br><strong>Link:</strong> <a href="https://doi.org/10.1145/3597503.3639221">DOI: 10.1145&#x2F;3597503.3639221</a></p>
<p>Python has become the most important language for AI development. However, the ecosystem suffers from <strong>module conflicts</strong> (MCs), where different packages accidentally override or confuse module imports. These conflicts can cause runtime failures and make model deployment errors.</p>
<ul>
<li>Module overwriting at install time</li>
<li>Import confusion at runtime</li>
</ul>
<p><img src="https://zhuzhuzaiimgbed.oss-cn-hangzhou.aliyuncs.com/img/image-20250718100609973.png" alt="image-20250718100609973"></p>
<p>We systematically studied MCs across 4.2M PyPI packages and 3.7k GitHub projects. Our tool <strong>ModuleGuard</strong> leverages semantic-aware static analysis and installation simulation to detect:</p>
<blockquote>
<p>🔧 We proposed <code>ModuleGuard</code> and analyzed the ecosystem at scale, uncovering thousands of silent module-level module conflict issues in real-world projects.</p>
</blockquote>
<hr>
<h2 id="🧠-Layer-2-Framework-Level-—-Framework’s-API-based-Malicious-Models"><a href="#🧠-Layer-2-Framework-Level-—-Framework’s-API-based-Malicious-Models" class="headerlink" title="🧠 Layer 2: Framework-Level — Framework’s API-based Malicious Models"></a>🧠 Layer 2: Framework-Level — Framework’s API-based Malicious Models</h2><p><strong>Paper:</strong> <em>My Model is Malware to You: Transforming AI Models into Malware by Abusing TensorFlow APIs</em> (S&amp;P25)<br><strong>Link:</strong> <a href="https://github.com/ZJU-SEC/TensorAbuse">GitHub: TensorAbuse</a></p>
<p>Model sharing enables innovation — but also risk. We proposed the <strong>TensorAbuse</strong> attack, which abuses <strong>legitimate TensorFlow APIs</strong> (like <code>tf.io.matching_files</code>, <code>tf.raw_ops.DebugIdentityV3</code>) to:</p>
<ul>
<li>Read arbitrary files</li>
<li>Leak IPs</li>
<li>Send data to external servers</li>
<li>Get shell</li>
</ul>
<p><img src="https://zhuzhuzaiimgbed.oss-cn-hangzhou.aliyuncs.com/img/image-20250718101049930.png" alt="image-20250718101049930"></p>
<p>These <strong>attacks are embedded in the model graph</strong>, and get executed silently during inference — <strong>Users cannot be aware of them</strong>.</p>
<blockquote>
<p>🚨 We found 1,083 persistent TensorFlow APIs. 20 APIs in them can be abused to cause malicious behaviours. None of the current model hubs (e.g., Hugging Face, TensorFlow Hub) or scanners (e.g., ModelScan) could detect our synthetic malware.</p>
</blockquote>
<hr>
<h2 id="🔍-Layer-3-Hardware-Level-—-GPU-ASLR-Weakness"><a href="#🔍-Layer-3-Hardware-Level-—-GPU-ASLR-Weakness" class="headerlink" title="🔍 Layer 3: Hardware-Level — GPU ASLR Weakness"></a>🔍 Layer 3: Hardware-Level — GPU ASLR Weakness</h2><p><strong>Paper:</strong> <em>Demystifying and Exploiting ASLR on NVIDIA GPUs</em><br><strong>Status:</strong> Under submission </p>
<p>Modern AI workloads run on GPUs, but their memory layout is opaque. We reverse-engineered <strong>NVIDIA GPU’s ASLR implementation</strong>, uncovering multiple critical flaws:</p>
<ul>
<li>GPU heap is entirely <strong>unrandomized</strong></li>
<li><strong>Correlated offsets</strong> between GPU and CPU ASLR undermine both</li>
<li>Some regions are shared across all CUDA processes, enabling <strong>covert channels</strong></li>
</ul>
<p>We built two tools:</p>
<ul>
<li><strong>FlagProbe</strong> to recover memory segment semantics</li>
<li><strong>AnchorTrace</strong> to trace randomized addresses recursively and infer ASLR entropy</li>
</ul>
<blockquote>
<p>🧪 We showed that GPU memory layout leaks can be exploited to infer CPU glibc addresses — undermining fundamental ASLR protections.</p>
</blockquote>
<p><img src="https://zhuzhuzaiimgbed.oss-cn-hangzhou.aliyuncs.com/img/image-20250718103738923.png" alt="image-20250718103738923"></p>
<hr>
<h2 id="📫-Contact"><a href="#📫-Contact" class="headerlink" title="📫 Contact"></a>📫 Contact</h2><p>If you’re interested in collaboration, feel free to reach out:</p>
<ul>
<li>📧 Email: <a href="mailto:&#122;&#104;&#117;&#x72;&#x75;&#x6f;&#x66;&#97;&#x6e;&#64;&#122;&#106;&#117;&#x2e;&#101;&#x64;&#117;&#x2e;&#99;&#x6e;">zhuruofan@zju.edu.cn</a></li>
<li>🔗 GitHub: <a href="https://github.com/unsatisfying">ZJU-SEC</a></li>
</ul>
]]></content>
      <categories>
        <category>note</category>
      </categories>
      <tags>
        <tag>gpu</tag>
      </tags>
  </entry>
  <entry>
    <title>内存管理2</title>
    <url>/2025/09/19/note/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%862/</url>
    <content><![CDATA[<h1 id="内存管理"><a href="#内存管理" class="headerlink" title="内存管理"></a>内存管理</h1><p>Linux的内存管理实际上非常复杂，包括物理内存的管理，设备内存的管理以及虚拟内存的管理，我们就一点点来分析呗。首先是Linux的可访问的内存并不仅仅指的是内存条上的物理内存，也包括很多设备的内存和设备寄存器的映射，这些内存会通过MMIO映射到Linux的物理内存进行管理。</p>
<h1 id="物理内存管理"><a href="#物理内存管理" class="headerlink" title="物理内存管理"></a>物理内存管理</h1><p>我们先来看看物理内存是怎么管理的。</p>
<p>首先现代处理器基本都是NUMA架构，这意味着处理器通过增加了内存访问控制器来提高了内存访问带宽，但是不同的core在访问不同内存区域时会存在一定的速度差异，这是由于内存的组织和接口分布在不同位置决定的。因此，物理内存会被分为多个node来进行划分。</p>
<p>Linux中物理内存的管理大致可以分为Node-&gt;Zone-&gt;Page.</p>
<ul>
<li><p><strong>Node（pglist_data）</strong>：在 NUMA（非一致内存访问）系统中，每个 CPU 节点都有自己独立的内存区域。每个这样的节点由一个 <code>pglist_data</code> 结构体管理。</p>
</li>
<li><p><strong>Zone（zone）</strong>：节点内部又分为不同“类型”的内存区域（例如 DMA 区、普通区、HighMem 区等）。</p>
</li>
<li><p><strong>Page（struct page）</strong>：Zone 内部的最小管理单位，即页框。</p>
</li>
</ul>
<h2 id="Node"><a href="#Node" class="headerlink" title="Node"></a>Node</h2><p>在内核源码中，用pglist_data结构体来表示一个node结点的上内存相关数据。在UMA架构下只有一个pglist_data结构体，而在numa架构下会有多个。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">//arch/x86/mm/numa.c</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">pglist_data</span> *<span class="title">node_data</span>[<span class="title">MAX_NUMNODES</span>] __<span class="title">read_mostly</span>;</span></span><br><span class="line">EXPORT_SYMBOL(node_data);</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">pglist_data</span> &#123;</span></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * node_zones contains just the zones for THIS node. Not all of the</span></span><br><span class="line"><span class="comment">	 * zones may be populated, but it is the full list. It is referenced by</span></span><br><span class="line"><span class="comment">	 * this node&#x27;s node_zonelists as well as other node&#x27;s node_zonelists.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">zone</span> <span class="title">node_zones</span>[<span class="title">MAX_NR_ZONES</span>];</span> <span class="comment">//一个节点包含多个内存区（zone）例如: ZONE_DMA,ZONE_DMA32,ZONE_NORMAL,ZONE_HIGHMEM（在x86 32bit）.每个 struct zone 管理该区域的页框分配、回收、空闲页、伙伴系统等。</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * node_zonelists contains references to all zones in all nodes.</span></span><br><span class="line"><span class="comment">	 * Generally the first zones will be references to this node&#x27;s</span></span><br><span class="line"><span class="comment">	 * node_zones.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">zonelist</span> <span class="title">node_zonelists</span>[<span class="title">MAX_ZONELISTS</span>];</span></span><br><span class="line"></span><br><span class="line">	<span class="type">int</span> nr_zones; <span class="comment">/* number of populated zones in this node */</span> <span class="comment">//当前节点上实际被初始化的 zone 数量。</span></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_FLATMEM	<span class="comment">/* means !SPARSEMEM */</span></span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">page</span> *<span class="title">node_mem_map</span>;</span>  <span class="comment">//这是节点的 struct page 数组（即 “mem_map”），每个物理页框对应一个 struct page。</span></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_PAGE_EXTENSION</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">page_ext</span> *<span class="title">node_page_ext</span>;</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">......</span><br><span class="line">&#125; <span class="type">pg_data_t</span>;</span><br></pre></td></tr></table></figure>

<p>具体连接的方式参考图。还有其他一些结构是锁和数据统计，以及和热插拔相关的，这里就不做细说</p>
<p><img src="https://zhuzhuzaiimgbed.oss-cn-hangzhou.aliyuncs.com/img/image-20251005211616201.png" alt="image-20251005211616201"></p>
<h2 id="Zone"><a href="#Zone" class="headerlink" title="Zone"></a>Zone</h2><p>首先是Zone的类型有以下几种,具体每一种Zone的用法看注释即可。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">enum</span> <span class="title">zone_type</span> &#123;</span></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * ZONE_DMA and ZONE_DMA32 are used when there are peripherals not able</span></span><br><span class="line"><span class="comment">	 * to DMA to all of the addressable memory (ZONE_NORMAL).</span></span><br><span class="line"><span class="comment">	 * On architectures where this area covers the whole 32 bit address</span></span><br><span class="line"><span class="comment">	 * space ZONE_DMA32 is used. ZONE_DMA is left for the ones with smaller</span></span><br><span class="line"><span class="comment">	 * DMA addressing constraints. This distinction is important as a 32bit</span></span><br><span class="line"><span class="comment">	 * DMA mask is assumed when ZONE_DMA32 is defined. Some 64-bit</span></span><br><span class="line"><span class="comment">	 * platforms may need both zones as they support peripherals with</span></span><br><span class="line"><span class="comment">	 * different DMA addressing limitations.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_ZONE_DMA</span></span><br><span class="line">	ZONE_DMA, <span class="comment">//低端 DMA 可达内存区（通常为 &lt;16MB 或 &lt;32MB）</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_ZONE_DMA32</span></span><br><span class="line">	ZONE_DMA32, <span class="comment">//低端 DMA 可达内存区（通常为 &lt;16MB 或 &lt;32MB）</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * Normal addressable memory is in ZONE_NORMAL. DMA operations can be</span></span><br><span class="line"><span class="comment">	 * performed on pages in ZONE_NORMAL if the DMA devices support</span></span><br><span class="line"><span class="comment">	 * transfers to all addressable memory.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	ZONE_NORMAL,<span class="comment">//普通的、内核直接线性映射的物理内存区。</span></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_HIGHMEM</span></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * A memory area that is only addressable by the kernel through</span></span><br><span class="line"><span class="comment">	 * mapping portions into its own address space. This is for example</span></span><br><span class="line"><span class="comment">	 * used by i386 to allow the kernel to address the memory beyond</span></span><br><span class="line"><span class="comment">	 * 900MB. The kernel will set up special mappings (page</span></span><br><span class="line"><span class="comment">	 * table entries on i386) for each page that the kernel needs to</span></span><br><span class="line"><span class="comment">	 * access.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	ZONE_HIGHMEM, <span class="comment">//高端内存区：CPU 不能直接线性映射访问的物理内存。</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * ZONE_MOVABLE is similar to ZONE_NORMAL, except that it contains</span></span><br><span class="line"><span class="comment">	 * movable pages with few exceptional cases described below. Main use</span></span><br><span class="line"><span class="comment">	 * cases for ZONE_MOVABLE are to make memory offlining/unplug more</span></span><br><span class="line"><span class="comment">	 * likely to succeed, and to locally limit unmovable allocations - e.g.,</span></span><br><span class="line"><span class="comment">	 * to increase the number of THP/huge pages. Notable special cases are:</span></span><br><span class="line"><span class="comment">	 *</span></span><br><span class="line"><span class="comment">	 * 1. Pinned pages: (long-term) pinning of movable pages might</span></span><br><span class="line"><span class="comment">	 *    essentially turn such pages unmovable. Therefore, we do not allow</span></span><br><span class="line"><span class="comment">	 *    pinning long-term pages in ZONE_MOVABLE. When pages are pinned and</span></span><br><span class="line"><span class="comment">	 *    faulted, they come from the right zone right away. However, it is</span></span><br><span class="line"><span class="comment">	 *    still possible that address space already has pages in</span></span><br><span class="line"><span class="comment">	 *    ZONE_MOVABLE at the time when pages are pinned (i.e. user has</span></span><br><span class="line"><span class="comment">	 *    touches that memory before pinning). In such case we migrate them</span></span><br><span class="line"><span class="comment">	 *    to a different zone. When migration fails - pinning fails.</span></span><br><span class="line"><span class="comment">	 * 2. memblock allocations: kernelcore/movablecore setups might create</span></span><br><span class="line"><span class="comment">	 *    situations where ZONE_MOVABLE contains unmovable allocations</span></span><br><span class="line"><span class="comment">	 *    after boot. Memory offlining and allocations fail early.</span></span><br><span class="line"><span class="comment">	 * 3. Memory holes: kernelcore/movablecore setups might create very rare</span></span><br><span class="line"><span class="comment">	 *    situations where ZONE_MOVABLE contains memory holes after boot,</span></span><br><span class="line"><span class="comment">	 *    for example, if we have sections that are only partially</span></span><br><span class="line"><span class="comment">	 *    populated. Memory offlining and allocations fail early.</span></span><br><span class="line"><span class="comment">	 * 4. PG_hwpoison pages: while poisoned pages can be skipped during</span></span><br><span class="line"><span class="comment">	 *    memory offlining, such pages cannot be allocated.</span></span><br><span class="line"><span class="comment">	 * 5. Unmovable PG_offline pages: in paravirtualized environments,</span></span><br><span class="line"><span class="comment">	 *    hotplugged memory blocks might only partially be managed by the</span></span><br><span class="line"><span class="comment">	 *    buddy (e.g., via XEN-balloon, Hyper-V balloon, virtio-mem). The</span></span><br><span class="line"><span class="comment">	 *    parts not manged by the buddy are unmovable PG_offline pages. In</span></span><br><span class="line"><span class="comment">	 *    some cases (virtio-mem), such pages can be skipped during</span></span><br><span class="line"><span class="comment">	 *    memory offlining, however, cannot be moved/allocated. These</span></span><br><span class="line"><span class="comment">	 *    techniques might use alloc_contig_range() to hide previously</span></span><br><span class="line"><span class="comment">	 *    exposed pages from the buddy again (e.g., to implement some sort</span></span><br><span class="line"><span class="comment">	 *    of memory unplug in virtio-mem).</span></span><br><span class="line"><span class="comment">	 * 6. ZERO_PAGE(0), kernelcore/movablecore setups might create</span></span><br><span class="line"><span class="comment">	 *    situations where ZERO_PAGE(0) which is allocated differently</span></span><br><span class="line"><span class="comment">	 *    on different platforms may end up in a movable zone. ZERO_PAGE(0)</span></span><br><span class="line"><span class="comment">	 *    cannot be migrated.</span></span><br><span class="line"><span class="comment">	 * 7. Memory-hotplug: when using memmap_on_memory and onlining the</span></span><br><span class="line"><span class="comment">	 *    memory to the MOVABLE zone, the vmemmap pages are also placed in</span></span><br><span class="line"><span class="comment">	 *    such zone. Such pages cannot be really moved around as they are</span></span><br><span class="line"><span class="comment">	 *    self-stored in the range, but they are treated as movable when</span></span><br><span class="line"><span class="comment">	 *    the range they describe is about to be offlined.</span></span><br><span class="line"><span class="comment">	 *</span></span><br><span class="line"><span class="comment">	 * In general, no unmovable allocations that degrade memory offlining</span></span><br><span class="line"><span class="comment">	 * should end up in ZONE_MOVABLE. Allocators (like alloc_contig_range())</span></span><br><span class="line"><span class="comment">	 * have to expect that migrating pages in ZONE_MOVABLE can fail (even</span></span><br><span class="line"><span class="comment">	 * if has_unmovable_pages() states that there are no unmovable pages,</span></span><br><span class="line"><span class="comment">	 * there can be false negatives).</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	ZONE_MOVABLE, <span class="comment">//可迁移内存区，主要用于内存热插拔和大页管理。</span></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_ZONE_DEVICE</span></span><br><span class="line">	ZONE_DEVICE, <span class="comment">//设备专用内存区（非标准 DRAM 页），如持久内存（NVDIMM）、GPU BAR、CXL Memory。</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">	__MAX_NR_ZONES</span><br><span class="line"></span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">物理地址空间</span></span><br><span class="line"><span class="comment">┌──────────────────────────────┐</span></span><br><span class="line"><span class="comment">│ ZONE_DMA        (&lt;16MB)      │ → legacy ISA DMA</span></span><br><span class="line"><span class="comment">├──────────────────────────────┤</span></span><br><span class="line"><span class="comment">│ ZONE_DMA32      (&lt;4GB)       │ → 32-bit PCIe DMA</span></span><br><span class="line"><span class="comment">├──────────────────────────────┤</span></span><br><span class="line"><span class="comment">│ ZONE_NORMAL     (&gt;=4GB)      │ → kernel, user, pagecache</span></span><br><span class="line"><span class="comment">├──────────────────────────────┤</span></span><br><span class="line"><span class="comment">│ ZONE_MOVABLE                │ → movable pages, hotplug</span></span><br><span class="line"><span class="comment">├──────────────────────────────┤</span></span><br><span class="line"><span class="comment">│ ZONE_DEVICE                 │ → device memory (PMEM, GPU)</span></span><br><span class="line"><span class="comment">└──────────────────────────────┘</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p>看完了不同种类的Zone，我们来看看Zone结构体</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">zone</span> &#123;</span></span><br><span class="line">	<span class="comment">/* Read-mostly fields */</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">/* zone watermarks, access with *_wmark_pages(zone) macros */</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> _watermark[NR_WMARK]; <span class="comment">//本内存区域的三个水线，高中低</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> watermark_boost;</span><br><span class="line"></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> nr_reserved_highatomic;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * We don&#x27;t know if the memory that we&#x27;re going to allocate will be</span></span><br><span class="line"><span class="comment">	 * freeable or/and it will be released eventually, so to avoid totally</span></span><br><span class="line"><span class="comment">	 * wasting several GB of ram we must reserve some of the lower zone</span></span><br><span class="line"><span class="comment">	 * memory (otherwise we risk to run OOM on the lower zones despite</span></span><br><span class="line"><span class="comment">	 * there being tons of freeable ram on the higher zones).  This array is</span></span><br><span class="line"><span class="comment">	 * recalculated at runtime if the sysctl_lowmem_reserve_ratio sysctl</span></span><br><span class="line"><span class="comment">	 * changes.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="type">long</span> lowmem_reserve[MAX_NR_ZONES]; <span class="comment">//为各内存与指定若干页面，用于无论如何都不能失败的内存分配</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_NUMA</span></span><br><span class="line">	<span class="type">int</span> node; <span class="comment">//本Zone所属Node的id</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">pglist_data</span>	*<span class="title">zone_pgdat</span>;</span> <span class="comment">//指向对应Node的pglist_data结构体</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">per_cpu_pages</span>	__<span class="title">percpu</span> *<span class="title">per_cpu_pageset</span>;</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">per_cpu_zonestat</span>	__<span class="title">percpu</span> *<span class="title">per_cpu_zonestats</span>;</span></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * the high and batch values are copied to individual pagesets for</span></span><br><span class="line"><span class="comment">	 * faster access</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="type">int</span> pageset_high_min;</span><br><span class="line">	<span class="type">int</span> pageset_high_max;</span><br><span class="line">	<span class="type">int</span> pageset_batch;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifndef</span> CONFIG_SPARSEMEM</span></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * Flags for a pageblock_nr_pages block. See pageblock-flags.h.</span></span><br><span class="line"><span class="comment">	 * In SPARSEMEM, this map is stored in struct mem_section</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span>		*pageblock_flags;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span> <span class="comment">/* CONFIG_SPARSEMEM */</span></span></span><br><span class="line"></span><br><span class="line">	<span class="comment">/* zone_start_pfn == zone_start_paddr &gt;&gt; PAGE_SHIFT */</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span>		zone_start_pfn; <span class="comment">//起始页帧号</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * spanned_pages is the total pages spanned by the zone, including</span></span><br><span class="line"><span class="comment">	 * holes, which is calculated as:</span></span><br><span class="line"><span class="comment">	 * 	spanned_pages = zone_end_pfn - zone_start_pfn;</span></span><br><span class="line"><span class="comment">	 *</span></span><br><span class="line"><span class="comment">	 * present_pages is physical pages existing within the zone, which</span></span><br><span class="line"><span class="comment">	 * is calculated as:</span></span><br><span class="line"><span class="comment">	 *	present_pages = spanned_pages - absent_pages(pages in holes);</span></span><br><span class="line"><span class="comment">	 *</span></span><br><span class="line"><span class="comment">	 * present_early_pages is present pages existing within the zone</span></span><br><span class="line"><span class="comment">	 * located on memory available since early boot, excluding hotplugged</span></span><br><span class="line"><span class="comment">	 * memory.</span></span><br><span class="line"><span class="comment">	 *</span></span><br><span class="line"><span class="comment">	 * managed_pages is present pages managed by the buddy system, which</span></span><br><span class="line"><span class="comment">	 * is calculated as (reserved_pages includes pages allocated by the</span></span><br><span class="line"><span class="comment">	 * bootmem allocator):</span></span><br><span class="line"><span class="comment">	 *	managed_pages = present_pages - reserved_pages;</span></span><br><span class="line"><span class="comment">	 *</span></span><br><span class="line"><span class="comment">	 * cma pages is present pages that are assigned for CMA use</span></span><br><span class="line"><span class="comment">	 * (MIGRATE_CMA).</span></span><br><span class="line"><span class="comment">	 *</span></span><br><span class="line"><span class="comment">	 * So present_pages may be used by memory hotplug or memory power</span></span><br><span class="line"><span class="comment">	 * management logic to figure out unmanaged pages by checking</span></span><br><span class="line"><span class="comment">	 * (present_pages - managed_pages). And managed_pages should be used</span></span><br><span class="line"><span class="comment">	 * by page allocator and vm scanner to calculate all kinds of watermarks</span></span><br><span class="line"><span class="comment">	 * and thresholds.</span></span><br><span class="line"><span class="comment">	 *</span></span><br><span class="line"><span class="comment">	 * Locking rules:</span></span><br><span class="line"><span class="comment">	 *</span></span><br><span class="line"><span class="comment">	 * zone_start_pfn and spanned_pages are protected by span_seqlock.</span></span><br><span class="line"><span class="comment">	 * It is a seqlock because it has to be read outside of zone-&gt;lock,</span></span><br><span class="line"><span class="comment">	 * and it is done in the main allocator path.  But, it is written</span></span><br><span class="line"><span class="comment">	 * quite infrequently.</span></span><br><span class="line"><span class="comment">	 *</span></span><br><span class="line"><span class="comment">	 * The span_seq lock is declared along with zone-&gt;lock because it is</span></span><br><span class="line"><span class="comment">	 * frequently read in proximity to zone-&gt;lock.  It&#x27;s good to</span></span><br><span class="line"><span class="comment">	 * give them a chance of being in the same cacheline.</span></span><br><span class="line"><span class="comment">	 *</span></span><br><span class="line"><span class="comment">	 * Write access to present_pages at runtime should be protected by</span></span><br><span class="line"><span class="comment">	 * mem_hotplug_begin/done(). Any reader who can&#x27;t tolerant drift of</span></span><br><span class="line"><span class="comment">	 * present_pages should use get_online_mems() to get a stable value.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="type">atomic_long_t</span>		managed_pages; <span class="comment">//也即 managed_pages 是这个 zone 被伙伴系统管理的所有的 page 数目。</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span>		spanned_pages; <span class="comment">// 指的是不管中间有没有物理内存空洞，反正就是最后的页号减去起始的页号，即spanned_pages包含内存空洞区域页。</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span>		present_pages; <span class="comment">//也即 present_pages 是这个 zone 在物理内存中真实存在的所有 page 数目。</span></span><br><span class="line"><span class="meta">#<span class="keyword">if</span> defined(CONFIG_MEMORY_HOTPLUG)</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span>		present_early_pages;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_CMA</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span>		cma_pages;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">	<span class="type">const</span> <span class="type">char</span>		*name;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_MEMORY_ISOLATION</span></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * Number of isolated pageblock. It is used to solve incorrect</span></span><br><span class="line"><span class="comment">	 * freepage counting problem due to racy retrieving migratetype</span></span><br><span class="line"><span class="comment">	 * of pageblock. Protected by zone-&gt;lock.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span>		nr_isolate_pageblock;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_MEMORY_HOTPLUG</span></span><br><span class="line">	<span class="comment">/* see spanned/present_pages for more description */</span></span><br><span class="line">	<span class="type">seqlock_t</span>		span_seqlock;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">	<span class="type">int</span> initialized;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/* Write-intensive fields used from the page allocator */</span></span><br><span class="line">	CACHELINE_PADDING(_pad1_);</span><br><span class="line"></span><br><span class="line">	<span class="comment">/* free areas of different sizes */</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">free_area</span>	<span class="title">free_area</span>[<span class="title">NR_PAGE_ORDERS</span>];</span> <span class="comment">//Buddy伙伴系统的核心数据结构，管理空闲页块链表的数组。</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_UNACCEPTED_MEMORY</span></span><br><span class="line">	<span class="comment">/* Pages to be accepted. All pages on the list are MAX_PAGE_ORDER */</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">list_head</span>	<span class="title">unaccepted_pages</span>;</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">	<span class="comment">/* zone flags, see below */</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span>		flags;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/* Primarily protects free_area */</span></span><br><span class="line">	<span class="type">spinlock_t</span>		lock;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/* Write-intensive fields used by compaction and vmstats. */</span></span><br><span class="line">	CACHELINE_PADDING(_pad2_);</span><br><span class="line"></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * When free pages are below this point, additional steps are taken</span></span><br><span class="line"><span class="comment">	 * when reading the number of free pages to avoid per-cpu counter</span></span><br><span class="line"><span class="comment">	 * drift allowing watermarks to be breached</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> percpu_drift_mark;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">if</span> defined CONFIG_COMPACTION || defined CONFIG_CMA</span></span><br><span class="line">	<span class="comment">/* pfn where compaction free scanner should start */</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span>		compact_cached_free_pfn;</span><br><span class="line">	<span class="comment">/* pfn where compaction migration scanner should start */</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span>		compact_cached_migrate_pfn[ASYNC_AND_SYNC];</span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span>		compact_init_migrate_pfn;</span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span>		compact_init_free_pfn;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_COMPACTION</span></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * On compaction failure, 1&lt;&lt;compact_defer_shift compactions</span></span><br><span class="line"><span class="comment">	 * are skipped before trying again. The number attempted since</span></span><br><span class="line"><span class="comment">	 * last failure is tracked with compact_considered.</span></span><br><span class="line"><span class="comment">	 * compact_order_failed is the minimum compaction failed order.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">int</span>		compact_considered;</span><br><span class="line">	<span class="type">unsigned</span> <span class="type">int</span>		compact_defer_shift;</span><br><span class="line">	<span class="type">int</span>			compact_order_failed;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">if</span> defined CONFIG_COMPACTION || defined CONFIG_CMA</span></span><br><span class="line">	<span class="comment">/* Set to true when the PG_migrate_skip bits should be cleared */</span></span><br><span class="line">	<span class="type">bool</span>			compact_blockskip_flush;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">	<span class="type">bool</span>			contiguous;</span><br><span class="line"></span><br><span class="line">	CACHELINE_PADDING(_pad3_);</span><br><span class="line">	<span class="comment">/* Zone statistics */</span></span><br><span class="line">	<span class="type">atomic_long_t</span>		vm_stat[NR_VM_ZONE_STAT_ITEMS];</span><br><span class="line">	<span class="type">atomic_long_t</span>		vm_numa_event[NR_VM_NUMA_EVENT_ITEMS];</span><br><span class="line">&#125; ____cacheline_internodealigned_in_smp;</span><br></pre></td></tr></table></figure>

<h2 id="Page"><a href="#Page" class="headerlink" title="Page"></a>Page</h2><p>看完了结点和内存域之后，我们来讨论内存管理的核心元素，页帧。每个物理页帧都有一个struct page结构来表示.</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">page</span> &#123;</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> flags;		<span class="comment">/* Atomic flags, some possibly</span></span><br><span class="line"><span class="comment">					 * updated asynchronously */</span></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * Five words (20/40 bytes) are available in this union.</span></span><br><span class="line"><span class="comment">	 * WARNING: bit 0 of the first word is used for PageTail(). That</span></span><br><span class="line"><span class="comment">	 * means the other users of this union MUST NOT use the bit to</span></span><br><span class="line"><span class="comment">	 * avoid collision and false-positive PageTail().</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="class"><span class="keyword">union</span> &#123;</span></span><br><span class="line">		<span class="class"><span class="keyword">struct</span> &#123;</span>	<span class="comment">/* Page cache and anonymous pages */</span></span><br><span class="line">			<span class="comment">/**</span></span><br><span class="line"><span class="comment">			 * @lru: Pageout list, eg. active_list protected by</span></span><br><span class="line"><span class="comment">			 * lruvec-&gt;lru_lock.  Sometimes used as a generic list</span></span><br><span class="line"><span class="comment">			 * by the page owner.</span></span><br><span class="line"><span class="comment">			 */</span></span><br><span class="line">			<span class="class"><span class="keyword">union</span> &#123;</span></span><br><span class="line">				<span class="class"><span class="keyword">struct</span> <span class="title">list_head</span> <span class="title">lru</span>;</span></span><br><span class="line"></span><br><span class="line">				<span class="comment">/* Or, for the Unevictable &quot;LRU list&quot; slot */</span></span><br><span class="line">				<span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">					<span class="comment">/* Always even, to negate PageTail */</span></span><br><span class="line">					<span class="type">void</span> *__filler;</span><br><span class="line">					<span class="comment">/* Count page&#x27;s or folio&#x27;s mlocks */</span></span><br><span class="line">					<span class="type">unsigned</span> <span class="type">int</span> mlock_count;</span><br><span class="line">				&#125;;</span><br><span class="line"></span><br><span class="line">				<span class="comment">/* Or, free page */</span></span><br><span class="line">				<span class="class"><span class="keyword">struct</span> <span class="title">list_head</span> <span class="title">buddy_list</span>;</span></span><br><span class="line">				<span class="class"><span class="keyword">struct</span> <span class="title">list_head</span> <span class="title">pcp_list</span>;</span></span><br><span class="line">			&#125;;</span><br><span class="line">			<span class="comment">/* See page-flags.h for PAGE_MAPPING_FLAGS */</span></span><br><span class="line">			<span class="class"><span class="keyword">struct</span> <span class="title">address_space</span> *<span class="title">mapping</span>;</span></span><br><span class="line">			<span class="class"><span class="keyword">union</span> &#123;</span></span><br><span class="line">				<span class="type">pgoff_t</span> index;		<span class="comment">/* Our offset within mapping. */</span></span><br><span class="line">				<span class="type">unsigned</span> <span class="type">long</span> share;	<span class="comment">/* share count for fsdax */</span></span><br><span class="line">			&#125;;</span><br><span class="line">			<span class="comment">/**</span></span><br><span class="line"><span class="comment">			 * @private: Mapping-private opaque data.</span></span><br><span class="line"><span class="comment">			 * Usually used for buffer_heads if PagePrivate.</span></span><br><span class="line"><span class="comment">			 * Used for swp_entry_t if PageSwapCache.</span></span><br><span class="line"><span class="comment">			 * Indicates order in the buddy system if PageBuddy.</span></span><br><span class="line"><span class="comment">			 */</span></span><br><span class="line">			<span class="type">unsigned</span> <span class="type">long</span> private;</span><br><span class="line">		&#125;;</span><br><span class="line">		<span class="class"><span class="keyword">struct</span> &#123;</span>	<span class="comment">/* page_pool used by netstack */</span></span><br><span class="line">			<span class="comment">/**</span></span><br><span class="line"><span class="comment">			 * @pp_magic: magic value to avoid recycling non</span></span><br><span class="line"><span class="comment">			 * page_pool allocated pages.</span></span><br><span class="line"><span class="comment">			 */</span></span><br><span class="line">			<span class="type">unsigned</span> <span class="type">long</span> pp_magic;</span><br><span class="line">			<span class="class"><span class="keyword">struct</span> <span class="title">page_pool</span> *<span class="title">pp</span>;</span></span><br><span class="line">			<span class="type">unsigned</span> <span class="type">long</span> _pp_mapping_pad;</span><br><span class="line">			<span class="type">unsigned</span> <span class="type">long</span> dma_addr;</span><br><span class="line">			<span class="type">atomic_long_t</span> pp_ref_count;</span><br><span class="line">		&#125;;</span><br><span class="line">		<span class="class"><span class="keyword">struct</span> &#123;</span>	<span class="comment">/* Tail pages of compound page */</span></span><br><span class="line">			<span class="type">unsigned</span> <span class="type">long</span> compound_head;	<span class="comment">/* Bit zero is set */</span></span><br><span class="line">		&#125;;</span><br><span class="line">		<span class="class"><span class="keyword">struct</span> &#123;</span>	<span class="comment">/* ZONE_DEVICE pages */</span></span><br><span class="line">			<span class="comment">/** @pgmap: Points to the hosting device page map. */</span></span><br><span class="line">			<span class="class"><span class="keyword">struct</span> <span class="title">dev_pagemap</span> *<span class="title">pgmap</span>;</span></span><br><span class="line">			<span class="type">void</span> *zone_device_data;</span><br><span class="line">			<span class="comment">/*</span></span><br><span class="line"><span class="comment">			 * ZONE_DEVICE private pages are counted as being</span></span><br><span class="line"><span class="comment">			 * mapped so the next 3 words hold the mapping, index,</span></span><br><span class="line"><span class="comment">			 * and private fields from the source anonymous or</span></span><br><span class="line"><span class="comment">			 * page cache page while the page is migrated to device</span></span><br><span class="line"><span class="comment">			 * private memory.</span></span><br><span class="line"><span class="comment">			 * ZONE_DEVICE MEMORY_DEVICE_FS_DAX pages also</span></span><br><span class="line"><span class="comment">			 * use the mapping, index, and private fields when</span></span><br><span class="line"><span class="comment">			 * pmem backed DAX files are mapped.</span></span><br><span class="line"><span class="comment">			 */</span></span><br><span class="line">		&#125;;</span><br><span class="line"></span><br><span class="line">		<span class="comment">/** @rcu_head: You can use this to free a page by RCU. */</span></span><br><span class="line">		<span class="class"><span class="keyword">struct</span> <span class="title">rcu_head</span> <span class="title">rcu_head</span>;</span></span><br><span class="line">	&#125;;</span><br><span class="line"></span><br><span class="line">	<span class="class"><span class="keyword">union</span> &#123;</span>		<span class="comment">/* This union is 4 bytes in size. */</span></span><br><span class="line">		<span class="comment">/*</span></span><br><span class="line"><span class="comment">		 * For head pages of typed folios, the value stored here</span></span><br><span class="line"><span class="comment">		 * allows for determining what this page is used for. The</span></span><br><span class="line"><span class="comment">		 * tail pages of typed folios will not store a type</span></span><br><span class="line"><span class="comment">		 * (page_type == _mapcount == -1).</span></span><br><span class="line"><span class="comment">		 *</span></span><br><span class="line"><span class="comment">		 * See page-flags.h for a list of page types which are currently</span></span><br><span class="line"><span class="comment">		 * stored here.</span></span><br><span class="line"><span class="comment">		 *</span></span><br><span class="line"><span class="comment">		 * Owners of typed folios may reuse the lower 16 bit of the</span></span><br><span class="line"><span class="comment">		 * head page page_type field after setting the page type,</span></span><br><span class="line"><span class="comment">		 * but must reset these 16 bit to -1 before clearing the</span></span><br><span class="line"><span class="comment">		 * page type.</span></span><br><span class="line"><span class="comment">		 */</span></span><br><span class="line">		<span class="type">unsigned</span> <span class="type">int</span> page_type;</span><br><span class="line"></span><br><span class="line">		<span class="comment">/*</span></span><br><span class="line"><span class="comment">		 * For pages that are part of non-typed folios for which mappings</span></span><br><span class="line"><span class="comment">		 * are tracked via the RMAP, encodes the number of times this page</span></span><br><span class="line"><span class="comment">		 * is directly referenced by a page table.</span></span><br><span class="line"><span class="comment">		 *</span></span><br><span class="line"><span class="comment">		 * Note that the mapcount is always initialized to -1, so that</span></span><br><span class="line"><span class="comment">		 * transitions both from it and to it can be tracked, using</span></span><br><span class="line"><span class="comment">		 * atomic_inc_and_test() and atomic_add_negative(-1).</span></span><br><span class="line"><span class="comment">		 */</span></span><br><span class="line">		<span class="type">atomic_t</span> _mapcount;</span><br><span class="line">	&#125;;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/* Usage count. *DO NOT USE DIRECTLY*. See page_ref.h */</span></span><br><span class="line">	<span class="type">atomic_t</span> _refcount;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_MEMCG</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> memcg_data;</span><br><span class="line"><span class="meta">#<span class="keyword">elif</span> defined(CONFIG_SLAB_OBJ_EXT)</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> _unused_slab_obj_exts;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * On machines where all RAM is mapped into kernel address space,</span></span><br><span class="line"><span class="comment">	 * we can simply calculate the virtual address. On machines with</span></span><br><span class="line"><span class="comment">	 * highmem some memory is mapped into kernel virtual memory</span></span><br><span class="line"><span class="comment">	 * dynamically, so we need a place to store that address.</span></span><br><span class="line"><span class="comment">	 * Note that this field could be 16 bits on x86 ... ;)</span></span><br><span class="line"><span class="comment">	 *</span></span><br><span class="line"><span class="comment">	 * Architectures with slow multiplication can define</span></span><br><span class="line"><span class="comment">	 * WANT_PAGE_VIRTUAL in asm/page.h</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line"><span class="meta">#<span class="keyword">if</span> defined(WANT_PAGE_VIRTUAL)</span></span><br><span class="line">	<span class="type">void</span> *virtual;			<span class="comment">/* Kernel virtual address (NULL if</span></span><br><span class="line"><span class="comment">					   not kmapped, ie. highmem) */</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span> <span class="comment">/* WANT_PAGE_VIRTUAL */</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> LAST_CPUPID_NOT_IN_PAGE_FLAGS</span></span><br><span class="line">	<span class="type">int</span> _last_cpupid;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_KMSAN</span></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * KMSAN metadata for this page:</span></span><br><span class="line"><span class="comment">	 *  - shadow page: every bit indicates whether the corresponding</span></span><br><span class="line"><span class="comment">	 *    bit of the original page is initialized (0) or not (1);</span></span><br><span class="line"><span class="comment">	 *  - origin page: every 4 bytes contain an id of the stack trace</span></span><br><span class="line"><span class="comment">	 *    where the uninitialized value was created.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">page</span> *<span class="title">kmsan_shadow</span>;</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">page</span> *<span class="title">kmsan_origin</span>;</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">&#125; _struct_page_alignment;</span><br></pre></td></tr></table></figure>

<p>看着非常复杂，其实就是两个union加几个数据，换个方式就能够明白了</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">page</span></span></span><br><span class="line"><span class="class">├─ <span class="title">flags</span>                // 页标志位 (<span class="title">PG_locked</span>, <span class="title">PG_dirty</span>, <span class="title">etc</span>.)</span></span><br><span class="line"><span class="class">├─ <span class="title">union</span> &#123;</span>              <span class="comment">// 主要根据页类型复用</span></span><br><span class="line">│   ├─ Page cache / anon page</span><br><span class="line">│   │   ├─ lru / buddy_list / pcp_list / mlock_count</span><br><span class="line">│   │   ├─ mapping       → <span class="class"><span class="keyword">struct</span> <span class="title">address_space</span>* //如果页帧与文件相关，指向<span class="title">address_space</span>对象，且最低位为0</span></span><br><span class="line"><span class="class">│   │   ├─ <span class="title">index</span>/<span class="title">share</span> // 页在 <span class="title">mapping</span> 中的偏移 (<span class="title">file</span> <span class="title">offset</span> / <span class="title">page</span> <span class="title">index</span>)</span></span><br><span class="line"><span class="class">│   │   └─ <span class="title">private</span></span></span><br><span class="line"><span class="class">│   │</span></span><br><span class="line"><span class="class">│   ├─ <span class="title">page_pool</span> (网络栈专用)</span></span><br><span class="line"><span class="class">│   │   ├─ <span class="title">pp_magic</span></span></span><br><span class="line"><span class="class">│   │   ├─ <span class="title">pp</span></span></span><br><span class="line"><span class="class">│   │   ├─ <span class="title">dma_addr</span></span></span><br><span class="line"><span class="class">│   │   └─ <span class="title">pp_ref_count</span></span></span><br><span class="line"><span class="class">│   │</span></span><br><span class="line"><span class="class">│   ├─ <span class="title">Tail</span> <span class="title">page</span></span></span><br><span class="line"><span class="class">│   │   └─ <span class="title">compound_head</span> (<span class="title">bit0</span>=</span><span class="number">1</span> 指向 head)</span><br><span class="line">│   │</span><br><span class="line">│   ├─ ZONE_DEVICE</span><br><span class="line">│   │   ├─ pgmap → <span class="class"><span class="keyword">struct</span> <span class="title">dev_pagemap</span>*</span></span><br><span class="line"><span class="class">│   │   └─ <span class="title">zone_device_data</span></span></span><br><span class="line"><span class="class">│   │</span></span><br><span class="line"><span class="class">│   └─ <span class="title">rcu_head</span></span></span><br><span class="line"><span class="class">│</span></span><br><span class="line"><span class="class">├─ <span class="title">union</span> &#123;</span> page_type / _mapcount &#125;   <span class="comment">// 页类型或映射计数(被多少个页表项映射（PTE 引用数）) </span></span><br><span class="line">├─ _refcount                         <span class="comment">// 引用计数（核心字段）,表示内核是否仍持有该页（缓存、IO、LRU等）。</span></span><br><span class="line">├─ memcg_data / _unused_slab_obj_exts</span><br><span class="line">├─ (optional) virtual                <span class="comment">// 高端内存虚拟地址（高端内存）</span></span><br><span class="line">├─ (optional) _last_cpupid           <span class="comment">// 最近访问CPU</span></span><br><span class="line">└─ (optional) kmsan_shadow/origin    <span class="comment">// KMSAN 元数据</span></span><br></pre></td></tr></table></figure>



<p>以下给出几个常用的page struct的去除union之后的成员</p>
<ul>
<li><p>普通页缓存&#x2F;匿名页</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">page</span> &#123;</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> flags;          <span class="comment">// PG_locked, PG_uptodate, PG_dirty...</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span> <span class="title">lru</span>;</span>         <span class="comment">// 在 zone-&gt;lruvec 的链表上</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">address_space</span> *<span class="title">mapping</span>;</span><span class="comment">// 所属的文件或 anon_vma</span></span><br><span class="line">    <span class="type">pgoff_t</span> index;                <span class="comment">// 页在 mapping 中的偏移 (file offset / page index)</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> private;        <span class="comment">// 私有数据: buffer_head, swap entry, 等</span></span><br><span class="line">    <span class="type">atomic_t</span> _mapcount;           <span class="comment">// 被多少个页表项映射（PTE 引用数）</span></span><br><span class="line">    <span class="type">atomic_t</span> _refcount;           <span class="comment">// 内核总引用计数</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>


</li>
<li><p>复合页（Compound Page，Hugepage或order&gt;0页）</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">[Head page] <span class="class"><span class="keyword">struct</span> <span class="title">page</span></span></span><br><span class="line"><span class="class">   ├─ <span class="title">flags</span> (标记为 <span class="title">head</span>)</span></span><br><span class="line"><span class="class">   ├─ <span class="title">private</span> (<span class="title">order</span>)</span></span><br><span class="line"><span class="class">   ├─ ...</span></span><br><span class="line"><span class="class">   └─ <span class="title">compound_mapcount</span>, <span class="title">refcount</span></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">[<span class="title">Tail</span> <span class="title">page</span>] <span class="keyword">struct</span> <span class="title">page</span></span></span><br><span class="line"><span class="class">   ├─ <span class="title">compound_head</span> =</span> (head | <span class="number">1</span>)</span><br><span class="line">   └─ 其他字段未使用</span><br></pre></td></tr></table></figure>


</li>
<li><p>伙伴系统空闲页（当页处于空闲状态时，它并不属于文件映射，而是链在 <code>zone-&gt;free_area[order].free_list</code> 上）</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">page</span> &#123;</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> flags;          <span class="comment">// PG_buddy</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span> <span class="title">buddy_list</span>;</span>  <span class="comment">// 连接到 buddy freelist</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> private;        <span class="comment">// 存储页阶 (order)</span></span><br><span class="line">    <span class="type">atomic_t</span> _refcount = <span class="number">0</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>


</li>
<li><p>网络页池，作为内核高速回收 DMA buffer。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">page</span> &#123;</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> pp_magic;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">page_pool</span> *<span class="title">pp</span>;</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> dma_addr;</span><br><span class="line">    <span class="type">atomic_long_t</span> pp_ref_count;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>


</li>
<li><p>Zone_device页（这些页并非普通 RAM，而是设备内存（如 GPU 显存或持久内存）。它们通过 <code>struct dev_pagemap</code> 管理。）</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">page</span> &#123;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">dev_pagemap</span> *<span class="title">pgmap</span>;</span>   <span class="comment">// 设备页映射信息</span></span><br><span class="line">    <span class="type">void</span> *zone_device_data;      <span class="comment">// 驱动自定义</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">address_space</span> *<span class="title">mapping</span>;</span></span><br><span class="line">    <span class="type">pgoff_t</span> index;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> private;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="伙伴系统"><a href="#伙伴系统" class="headerlink" title="伙伴系统"></a>伙伴系统</h2><p>前面说过每个Zone结构内部都有一个free_area字段, 那我们看看free_area到底是什么东西。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">//include/linux/mmzone.h</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">zone</span>&#123;</span></span><br><span class="line">	...</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">free_area</span>	<span class="title">free_area</span>[<span class="title">NR_PAGE_ORDERS</span>];</span></span><br><span class="line">	...</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">free_area</span> &#123;</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">list_head</span>	<span class="title">free_list</span>[<span class="title">MIGRATE_TYPES</span>];</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span>		nr_free;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>大致结构如图所示，第一个free_area[0]表示页面大小为4K的空闲页，第二个free_area[1]表示页面大小为8K的空闲块，依次类推。而每个free_area之间又有多个free_list，这是由于不同的页有不同的属性，例如<code>MIGRATE_UNMOVABLE</code>,<code>MIGRATE_MOVABLE</code>,<code>MIGRATE_RECLAIMABLE</code>,<code>MIGRATE_PCPTYPES</code>等，因此就弄了多个list, 但是总数记录在nr_free中。<br><img src="https://zhuzhuzaiimgbed.oss-cn-hangzhou.aliyuncs.com/img/image-20251006010750662.png" alt="image-20251006010750662"></p>
<p>对于不同结点上不同的zone的组织方式就简化成如下图：</p>
<p><img src="https://zhuzhuzaiimgbed.oss-cn-hangzhou.aliyuncs.com/img/image-20251006011505993.png" alt="image-20251006011505993"></p>
<h1 id="虚拟内存管理"><a href="#虚拟内存管理" class="headerlink" title="虚拟内存管理"></a>虚拟内存管理</h1><p>讲完了物理内存管理，接下来讲讲Linux最核心的机制，虚拟内存，即地址映射和页表相关的内容。</p>
<p>在x86架构下，实际有三个地址，逻辑地址，线性地址和物理地址，逻辑地址经过分段管理单元转化成线性地址，线性地址经过分页页表和MMU转化成物理地址。虽然听着比较复杂，但是实际上x86和x86_64采用的是平坦内存模型，也就是绕过了逻辑地址到线性地址的这层翻译。具体来说就是虽然还是用了段寄存器和段选择子等机制来分段，但是所有段都是从物理地址0开始，且界限都一样，也就是说虽然有用户代码段，数据段，内核代码段，数据段之分，但是指向的都是同一段，只是使用了它们的特权级作为特权控制。</p>
<h2 id="五级页表地址翻译"><a href="#五级页表地址翻译" class="headerlink" title="五级页表地址翻译"></a>五级页表地址翻译</h2><p>五级页表的内容相信都耳熟能详了，这里便不再过多叙述。PGD,P4D,PUD,PMD,PTE。</p>
<p>具体就贴两个网上blog里截的图把。</p>
<p><img src="https://zhuzhuzaiimgbed.oss-cn-hangzhou.aliyuncs.com/img/image-20251006125155971.png" alt="image-20251006125155971"></p>
<p><img src="https://zhuzhuzaiimgbed.oss-cn-hangzhou.aliyuncs.com/img/image-20251006125218150.png" alt="image-20251006125218150"></p>
<p><img src="https://zhuzhuzaiimgbed.oss-cn-hangzhou.aliyuncs.com/img/image-20251006125228549.png" alt="image-20251006125228549"></p>
<h2 id="进程如何管理地址空间与页表"><a href="#进程如何管理地址空间与页表" class="headerlink" title="进程如何管理地址空间与页表"></a>进程如何管理地址空间与页表</h2><h3 id="task-struct"><a href="#task-struct" class="headerlink" title="task_struct"></a>task_struct</h3><p>我们首先了解一下Linux 中task_struct结构，也就是所谓的PCB</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">task_struct</span> &#123;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">thread_info</span>		<span class="title">thread_info</span>;</span></span><br><span class="line">    <span class="type">void</span>				*<span class="built_in">stack</span>;<span class="comment">//内核栈地址</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 进程打开的文件信息</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">files_struct</span>  *<span class="title">files</span>;</span></span><br><span class="line">    <span class="comment">// 内存描述符表示进程虚拟地址空间</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">mm_struct</span>  *<span class="title">mm</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">mm_struct</span>		*<span class="title">active_mm</span>;</span> <span class="comment">//内核线程用的是上一个线程的mm，内核线程和用户态线程的区别就是内核线程没有相关的内存描述符 mm_struct ，内核线程对应的 task_struct 结构中的 mm 域指向 Null，所以内核线程之间调度是不涉及地址空间切换的。当一个内核线程被调度时，它会发现自己的虚拟地址空间为 Null，虽然它不会访问用户态的内存，但是它会访问内核内存，聪明的内核会将调度之前的上一个用户态进程的虚拟内存空间 mm_struct 直接赋值给内核线程，因为内核线程不会访问用户空间的内存，它仅仅只会访问内核空间的内存，所以直接复用上一个用户态进程的虚拟地址空间就可以避免为内核线程分配 mm_struct 和相关页表的开销，以及避免内核线程之间调度时地址空间的切换开销。</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 进程id</span></span><br><span class="line">	<span class="type">pid_t</span>    pid;</span><br><span class="line">    <span class="comment">// 用于标识线程所属的进程 pid</span></span><br><span class="line">	<span class="type">pid_t</span>    tgid;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/* Real parent process: */</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">task_struct</span> __<span class="title">rcu</span>	*<span class="title">real_parent</span>;</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">/* Recipient of SIGCHLD, wait4() reports: */</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">task_struct</span> __<span class="title">rcu</span>	*<span class="title">parent</span>;</span></span><br><span class="line"></span><br><span class="line">        ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="mm-struct"><a href="#mm-struct" class="headerlink" title="mm_struct"></a>mm_struct</h3><p>其中最重要的一个结构就是mm_struct，用来表示内存地址空间结构，我们看看它包含了什么</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">mm_struct</span> &#123;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">maple_tree</span> <span class="title">mm_mt</span>;</span> <span class="comment">//枫树！这个用来代替红黑树，是5.13之后加入的新特性</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> mmap_base;	<span class="comment">/* base of mmap area */</span> <span class="comment">//现版本内核从上往下，从高地址往低地址增长</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> mmap_legacy_base;	<span class="comment">/* base of mmap area in bottom-up allocations */</span> <span class="comment">//早版本内核mmap从下往上，从低地址到高地址增长</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> task_size;	<span class="comment">/* size of task vm space */</span> <span class="comment">//task_size是表明内核空间的起始地址，x86架构下为`0xC000 000`, x86_64架构下为`0x0000 7FFF FFFF F000`</span></span><br><span class="line">	<span class="type">pgd_t</span> * pgd; <span class="comment">//页表基址，这是虚拟地址，也就是物理地址在directmapping下记录的虚拟地址</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> start_code, end_code, start_data, end_data;</span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> start_brk, brk, start_stack;</span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> arg_start, arg_end, env_start, env_end;</span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>其中有一个关键的结构<code> struct maple_tree mm_mt;</code>,这个是用来代替红黑树的，通过这个枫树，能够快速找到不同的vm_area_struct结构。这里替换的主要原因是，红黑树还需要用链表来辅助，在多线程中mmap&#x2F;unmap存在以下问题</p>
<table>
<thead>
<tr>
<th>问题</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>cache locality 差</td>
<td>红黑树节点分散，cache miss 高</td>
</tr>
<tr>
<td>链表 + 树双维护</td>
<td>维护两种结构复杂</td>
</tr>
<tr>
<td>mmap_lock 粗粒度</td>
<td>读写 mmap_lock 导致全局竞争</td>
</tr>
<tr>
<td>RCU 不友好</td>
<td>查找时需要加锁或引用计数</td>
</tr>
</tbody></table>
<p>而maple_tree有以下优点</p>
<ul>
<li><p>使用「块状节点」存储多个 VMA 指针；</p>
</li>
<li><p>节点内连续数组便于缓存；</p>
</li>
<li><p>支持 RCU 安全遍历；</p>
</li>
<li><p>极大减少锁冲突。</p>
</li>
</ul>
<h3 id="vm-area-struct"><a href="#vm-area-struct" class="headerlink" title="vm_area_struct"></a>vm_area_struct</h3><p>先看看结构体里有哪些东西, 可以发现已经没有之前的rb_node成员了，之前老版本会有一个<code>struct rb_node vm_rb;</code>,现在已经删除了，但是别的东西还是很明了的，就是表明一个区域的起始和结尾，以及文件映射相关的内容，还有一些权限什么的，具体看注释都能知道什么意思。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">vm_area_struct</span> &#123;</span></span><br><span class="line">	<span class="comment">/* The first cache line has the info for VMA tree walking. */</span></span><br><span class="line"></span><br><span class="line">	<span class="class"><span class="keyword">union</span> &#123;</span></span><br><span class="line">		<span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">			<span class="comment">/* VMA covers [vm_start; vm_end) addresses within mm */</span></span><br><span class="line">			<span class="type">unsigned</span> <span class="type">long</span> vm_start;</span><br><span class="line">			<span class="type">unsigned</span> <span class="type">long</span> vm_end;</span><br><span class="line">		&#125;;</span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_PER_VMA_LOCK</span></span><br><span class="line">		<span class="class"><span class="keyword">struct</span> <span class="title">rcu_head</span> <span class="title">vm_rcu</span>;</span>	<span class="comment">/* Used for deferred freeing. */</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">	&#125;;</span><br><span class="line"></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">mm_struct</span> *<span class="title">vm_mm</span>;</span>	<span class="comment">/* The address space we belong to. */</span></span><br><span class="line">	<span class="type">pgprot_t</span> vm_page_prot;          <span class="comment">/* Access permissions of this VMA. */</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * Flags, see mm.h.</span></span><br><span class="line"><span class="comment">	 * To modify use vm_flags_&#123;init|reset|set|clear|mod&#125; functions.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="class"><span class="keyword">union</span> &#123;</span></span><br><span class="line">		<span class="type">const</span> <span class="type">vm_flags_t</span> vm_flags;</span><br><span class="line">		<span class="type">vm_flags_t</span> __private __vm_flags;</span><br><span class="line">	&#125;;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_PER_VMA_LOCK</span></span><br><span class="line">	<span class="comment">/* Flag to indicate areas detached from the mm-&gt;mm_mt tree */</span></span><br><span class="line">	<span class="type">bool</span> detached;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * Can only be written (using WRITE_ONCE()) while holding both:</span></span><br><span class="line"><span class="comment">	 *  - mmap_lock (in write mode)</span></span><br><span class="line"><span class="comment">	 *  - vm_lock-&gt;lock (in write mode)</span></span><br><span class="line"><span class="comment">	 * Can be read reliably while holding one of:</span></span><br><span class="line"><span class="comment">	 *  - mmap_lock (in read or write mode)</span></span><br><span class="line"><span class="comment">	 *  - vm_lock-&gt;lock (in read or write mode)</span></span><br><span class="line"><span class="comment">	 * Can be read unreliably (using READ_ONCE()) for pessimistic bailout</span></span><br><span class="line"><span class="comment">	 * while holding nothing (except RCU to keep the VMA struct allocated).</span></span><br><span class="line"><span class="comment">	 *</span></span><br><span class="line"><span class="comment">	 * This sequence counter is explicitly allowed to overflow; sequence</span></span><br><span class="line"><span class="comment">	 * counter reuse can only lead to occasional unnecessary use of the</span></span><br><span class="line"><span class="comment">	 * slowpath.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="type">int</span> vm_lock_seq;</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">vma_lock</span> *<span class="title">vm_lock</span>;</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * For areas with an address space and backing store,</span></span><br><span class="line"><span class="comment">	 * linkage into the address_space-&gt;i_mmap interval tree.</span></span><br><span class="line"><span class="comment">	 *</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">		<span class="class"><span class="keyword">struct</span> <span class="title">rb_node</span> <span class="title">rb</span>;</span></span><br><span class="line">		<span class="type">unsigned</span> <span class="type">long</span> rb_subtree_last;</span><br><span class="line">	&#125; shared;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * A file&#x27;s MAP_PRIVATE vma can be in both i_mmap tree and anon_vma</span></span><br><span class="line"><span class="comment">	 * list, after a COW of one of the file pages.	A MAP_SHARED vma</span></span><br><span class="line"><span class="comment">	 * can only be in the i_mmap tree.  An anonymous MAP_PRIVATE, stack</span></span><br><span class="line"><span class="comment">	 * or brk vma (with NULL file) can only be in an anon_vma list.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">list_head</span> <span class="title">anon_vma_chain</span>;</span> <span class="comment">/* Serialized by mmap_lock &amp;</span></span><br><span class="line"><span class="comment">					  * page_table_lock */</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">anon_vma</span> *<span class="title">anon_vma</span>;</span>	<span class="comment">/* Serialized by page_table_lock */</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">/* Function pointers to deal with this struct. */</span></span><br><span class="line">	<span class="type">const</span> <span class="class"><span class="keyword">struct</span> <span class="title">vm_operations_struct</span> *<span class="title">vm_ops</span>;</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">/* Information about our backing store: */</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> vm_pgoff;		<span class="comment">/* Offset (within vm_file) in PAGE_SIZE</span></span><br><span class="line"><span class="comment">					   units */</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">file</span> * <span class="title">vm_file</span>;</span>		<span class="comment">/* File we map to (can be NULL). */</span></span><br><span class="line">	<span class="type">void</span> * vm_private_data;		<span class="comment">/* was vm_pte (shared mem) */</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_ANON_VMA_NAME</span></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * For private and shared anonymous mappings, a pointer to a null</span></span><br><span class="line"><span class="comment">	 * terminated string containing the name given to the vma, or NULL if</span></span><br><span class="line"><span class="comment">	 * unnamed. Serialized by mmap_lock. Use anon_vma_name to access.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">anon_vma_name</span> *<span class="title">anon_name</span>;</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_SWAP</span></span><br><span class="line">	<span class="type">atomic_long_t</span> swap_readahead_info;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">ifndef</span> CONFIG_MMU</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">vm_region</span> *<span class="title">vm_region</span>;</span>	<span class="comment">/* NOMMU mapping region */</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_NUMA</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">mempolicy</span> *<span class="title">vm_policy</span>;</span>	<span class="comment">/* NUMA policy for the VMA */</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_NUMA_BALANCING</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">vma_numab_state</span> *<span class="title">numab_state</span>;</span>	<span class="comment">/* NUMA Balancing state */</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">vm_userfaultfd_ctx</span> <span class="title">vm_userfaultfd_ctx</span>;</span></span><br><span class="line">&#125; __randomize_layout;</span><br></pre></td></tr></table></figure>

<h3 id="Maple-Tree-枫树"><a href="#Maple-Tree-枫树" class="headerlink" title="Maple Tree 枫树"></a>Maple Tree 枫树</h3><p>既然都看到这了，就学习一下枫树吧，顺便把B树什么都一起看了，这个应该全网没啥教程，只能自己看源码。</p>
<p>首先是maple树的一个定义，具体如下</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * If the tree contains a single entry at index 0, it is usually stored in</span></span><br><span class="line"><span class="comment"> * tree-&gt;ma_root.  To optimise for the page cache, an entry which ends in &#x27;00&#x27;,</span></span><br><span class="line"><span class="comment"> * &#x27;01&#x27; or &#x27;11&#x27; is stored in the root, but an entry which ends in &#x27;10&#x27; will be</span></span><br><span class="line"><span class="comment"> * stored in a node.  Bits 3-6 are used to store enum maple_type.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * The flags are used both to store some immutable information about this tree</span></span><br><span class="line"><span class="comment"> * (set at tree creation time) and dynamic information set under the spinlock.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Another use of flags are to indicate global states of the tree.  This is the</span></span><br><span class="line"><span class="comment"> * case with the MAPLE_USE_RCU flag, which indicates the tree is currently in</span></span><br><span class="line"><span class="comment"> * RCU mode.  This mode was added to allow the tree to reuse nodes instead of</span></span><br><span class="line"><span class="comment"> * re-allocating and RCU freeing nodes when there is a single user.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">maple_tree</span> &#123;</span></span><br><span class="line">	<span class="class"><span class="keyword">union</span> &#123;</span></span><br><span class="line">        <span class="comment">//写操作（例如插入、删除 VMA）时通常需要持有这个锁。</span></span><br><span class="line">		<span class="type">spinlock_t</span>	ma_lock;  <span class="comment">//如果本结构体需要加锁则使用这个写锁，读结构一般不加锁，所以可以RCU支持。RCU（read-copy update）,指的是要写指针的时候拷贝一份再更新，因此读写不用互斥，仅有写写需要互斥。</span></span><br><span class="line">		lockdep_map_p	ma_external_lock; <span class="comment">//或者使用外部代码的锁，这里可以忽略。当外部代码（例如 mmap_lock）负责保护整个树时，Maple Tree 就可以复用外部锁的 lockdep 信息，而不用自己的 spinlock。lockdep_map_p 是一个 “lockdep 伪锁” 类型，用来让 lockdep 工具追踪锁顺序，而不实际参与加锁。</span></span><br><span class="line">	&#125;;</span><br><span class="line">	<span class="type">unsigned</span> <span class="type">int</span>	ma_flags; <span class="comment">//用于记录树的全局状态与配置选项，至于maple_flags看下面定义</span></span><br><span class="line">	<span class="type">void</span> __rcu      *ma_root; <span class="comment">//这个是 Maple Tree 的根指针（root pointer），但它是一个 “encoded pointer”（即 maple_enode 类型），带有位域信息。</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * DOC: Maple tree flags</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * * MT_FLAGS_ALLOC_RANGE	- Track gaps in this tree</span></span><br><span class="line"><span class="comment"> * * MT_FLAGS_USE_RCU		- Operate in RCU mode</span></span><br><span class="line"><span class="comment"> * * MT_FLAGS_HEIGHT_OFFSET	- The position of the tree height in the flags</span></span><br><span class="line"><span class="comment"> * * MT_FLAGS_HEIGHT_MASK	- The mask for the maple tree height value</span></span><br><span class="line"><span class="comment"> * * MT_FLAGS_LOCK_MASK		- How the mt_lock is used</span></span><br><span class="line"><span class="comment"> * * MT_FLAGS_LOCK_IRQ		- Acquired irq-safe</span></span><br><span class="line"><span class="comment"> * * MT_FLAGS_LOCK_BH		- Acquired bh-safe</span></span><br><span class="line"><span class="comment"> * * MT_FLAGS_LOCK_EXTERN	- mt_lock is not used</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * MAPLE_HEIGHT_MAX	The largest height that can be stored</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> MT_FLAGS_ALLOC_RANGE	0x01</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> MT_FLAGS_USE_RCU	0x02</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> MT_FLAGS_HEIGHT_OFFSET	0x02</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> MT_FLAGS_HEIGHT_MASK	0x7C</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> MT_FLAGS_LOCK_MASK	0x300</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> MT_FLAGS_LOCK_IRQ	0x100</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> MT_FLAGS_LOCK_BH	0x200</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> MT_FLAGS_LOCK_EXTERN	0x300</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> MT_FLAGS_ALLOC_WRAPPED	0x0800</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * The Maple Tree squeezes various bits in at various points which aren&#x27;t</span></span><br><span class="line"><span class="comment"> * necessarily obvious.  Usually, this is done by observing that pointers are</span></span><br><span class="line"><span class="comment"> * N-byte aligned and thus the bottom log_2(N) bits are available for use.  We</span></span><br><span class="line"><span class="comment"> * don&#x27;t use the high bits of pointers to store additional information because</span></span><br><span class="line"><span class="comment"> * we don&#x27;t know what bits are unused on any given architecture.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Nodes are 256 bytes in size and are also aligned to 256 bytes, giving us 8</span></span><br><span class="line"><span class="comment"> * low bits for our own purposes.  Nodes are currently of 4 types:</span></span><br><span class="line"><span class="comment"> * 1. Single pointer (Range is 0-0)</span></span><br><span class="line"><span class="comment"> * 2. Non-leaf Allocation Range nodes</span></span><br><span class="line"><span class="comment"> * 3. Non-leaf Range nodes</span></span><br><span class="line"><span class="comment"> * 4. Leaf Range nodes All nodes consist of a number of node slots,</span></span><br><span class="line"><span class="comment"> *    pivots, and a parent pointer.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">maple_node</span> &#123;</span></span><br><span class="line">	<span class="class"><span class="keyword">union</span> &#123;</span></span><br><span class="line">		<span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">			<span class="class"><span class="keyword">struct</span> <span class="title">maple_pnode</span> *<span class="title">parent</span>;</span></span><br><span class="line">			<span class="type">void</span> __rcu *slot[MAPLE_NODE_SLOTS];</span><br><span class="line">		&#125;;</span><br><span class="line">		<span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">			<span class="type">void</span> *pad;</span><br><span class="line">			<span class="class"><span class="keyword">struct</span> <span class="title">rcu_head</span> <span class="title">rcu</span>;</span></span><br><span class="line">			<span class="class"><span class="keyword">struct</span> <span class="title">maple_enode</span> *<span class="title">piv_parent</span>;</span></span><br><span class="line">			<span class="type">unsigned</span> <span class="type">char</span> parent_slot;</span><br><span class="line">			<span class="class"><span class="keyword">enum</span> <span class="title">maple_type</span> <span class="title">type</span>;</span></span><br><span class="line">			<span class="type">unsigned</span> <span class="type">char</span> slot_len;</span><br><span class="line">			<span class="type">unsigned</span> <span class="type">int</span> ma_flags;</span><br><span class="line">		&#125;;</span><br><span class="line">		<span class="class"><span class="keyword">struct</span> <span class="title">maple_range_64</span> <span class="title">mr64</span>;</span></span><br><span class="line">		<span class="class"><span class="keyword">struct</span> <span class="title">maple_arange_64</span> <span class="title">ma64</span>;</span></span><br><span class="line">		<span class="class"><span class="keyword">struct</span> <span class="title">maple_alloc</span> <span class="title">alloc</span>;</span></span><br><span class="line">	&#125;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>OK了，看完了树的定义，其实核心结构都在ma_root这个指针里。我们来看看不同情况下该指针包含的内容。当树为空时，ma_root存放的值即为NULL，非常好理解。当树只有一个结点时，根据注释可知，其指针最低几位，即bit0,bit1,bit2作为类型信息，如果该单元素的地址低两位模式为 <code>00</code> &#x2F; <code>01</code> &#x2F; <code>11</code>，则直接存在 <code>ma_root</code>；如果是 <code>10</code>（即 <code>0b10</code>），那会与内部编码规则冲突，所以这种情况会强制放进一个 node 里。</p>
<p>然后我们再来看一下树的状态机，用来标识树的一个状态的</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Maple State Status</span></span><br><span class="line"><span class="comment"> * ma_active means the maple state is pointing to a node and offset and can</span></span><br><span class="line"><span class="comment"> * continue operating on the tree.</span></span><br><span class="line"><span class="comment"> * ma_start means we have not searched the tree.</span></span><br><span class="line"><span class="comment"> * ma_root means we have searched the tree and the entry we found lives in</span></span><br><span class="line"><span class="comment"> * the root of the tree (ie it has index 0, length 1 and is the only entry in</span></span><br><span class="line"><span class="comment"> * the tree).</span></span><br><span class="line"><span class="comment"> * ma_none means we have searched the tree and there is no node in the</span></span><br><span class="line"><span class="comment"> * tree for this entry.  For example, we searched for index 1 in an empty</span></span><br><span class="line"><span class="comment"> * tree.  Or we have a tree which points to a full leaf node and we</span></span><br><span class="line"><span class="comment"> * searched for an entry which is larger than can be contained in that</span></span><br><span class="line"><span class="comment"> * leaf node.</span></span><br><span class="line"><span class="comment"> * ma_pause means the data within the maple state may be stale, restart the</span></span><br><span class="line"><span class="comment"> * operation</span></span><br><span class="line"><span class="comment"> * ma_overflow means the search has reached the upper limit of the search</span></span><br><span class="line"><span class="comment"> * ma_underflow means the search has reached the lower limit of the search</span></span><br><span class="line"><span class="comment"> * ma_error means there was an error, check the node for the error number.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">enum</span> <span class="title">maple_status</span> &#123;</span></span><br><span class="line">	ma_active,  <span class="comment">//指向一个node，可以继续对树进行操作</span></span><br><span class="line">	ma_start, <span class="comment">//还没开始搜索树</span></span><br><span class="line">	ma_root,  <span class="comment">//树已经开始搜索了，但是目前只有一个根节点</span></span><br><span class="line">	ma_none, <span class="comment">//树已经开始搜索了，但是目前没有这个节点</span></span><br><span class="line">	ma_pause,</span><br><span class="line">	ma_overflow,</span><br><span class="line">	ma_underflow,</span><br><span class="line">	ma_error,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>然后看看往一颗空树添加节点的操作，分为插入一个值和插入一个range</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">mtree_insert</span><span class="params">(<span class="keyword">struct</span> maple_tree *mt, <span class="type">unsigned</span> <span class="type">long</span> index, <span class="type">void</span> *entry,</span></span><br><span class="line"><span class="params">		 <span class="type">gfp_t</span> gfp)</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="keyword">return</span> mtree_insert_range(mt, index, index, entry, gfp);</span><br><span class="line">&#125;</span><br><span class="line">EXPORT_SYMBOL(mtree_insert);</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * mtree_insert_range() - Insert an entry at a given range if there is no value.</span></span><br><span class="line"><span class="comment"> * @mt: The maple tree</span></span><br><span class="line"><span class="comment"> * @first: The start of the range</span></span><br><span class="line"><span class="comment"> * @last: The end of the range</span></span><br><span class="line"><span class="comment"> * @entry: The entry to store</span></span><br><span class="line"><span class="comment"> * @gfp: The GFP_FLAGS to use for allocations.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Return: 0 on success, -EEXISTS if the range is occupied, -EINVAL on invalid</span></span><br><span class="line"><span class="comment"> * request, -ENOMEM if memory could not be allocated.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">mtree_insert_range</span><span class="params">(<span class="keyword">struct</span> maple_tree *mt, <span class="type">unsigned</span> <span class="type">long</span> first,</span></span><br><span class="line"><span class="params">		<span class="type">unsigned</span> <span class="type">long</span> last, <span class="type">void</span> *entry, <span class="type">gfp_t</span> gfp)</span></span><br><span class="line">&#123;</span><br><span class="line">	MA_STATE(ms, mt, first, last);</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> (WARN_ON_ONCE(xa_is_advanced(entry)))</span><br><span class="line">		<span class="keyword">return</span> -EINVAL;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> (first &gt; last)</span><br><span class="line">		<span class="keyword">return</span> -EINVAL;</span><br><span class="line"></span><br><span class="line">	mtree_lock(mt);</span><br><span class="line">retry:</span><br><span class="line">	mas_insert(&amp;ms, entry);</span><br><span class="line">	<span class="keyword">if</span> (mas_nomem(&amp;ms, gfp))</span><br><span class="line">		<span class="keyword">goto</span> retry;</span><br><span class="line"></span><br><span class="line">	mtree_unlock(mt);</span><br><span class="line">	<span class="keyword">if</span> (mas_is_err(&amp;ms))</span><br><span class="line">		<span class="keyword">return</span> xa_err(ms.node);</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line">EXPORT_SYMBOL(mtree_insert_range);</span><br></pre></td></tr></table></figure>

<p>可以看到核心在于声明了一个ms变量，即ma_state结构体,</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> MA_STATE(name, mt, first, end)					\</span></span><br><span class="line"><span class="meta">	struct ma_state name = &#123;					\</span></span><br><span class="line"><span class="meta">		.tree = mt,						\</span></span><br><span class="line"><span class="meta">		.index = first,						\</span></span><br><span class="line"><span class="meta">		.last = end,						\</span></span><br><span class="line"><span class="meta">		.node = NULL,						\ <span class="comment">//初始状态树没有任何节点</span></span></span><br><span class="line">		.status = ma_start,					\</span><br><span class="line">		.min = <span class="number">0</span>,						\</span><br><span class="line">		.max = ULONG_MAX,					\</span><br><span class="line">		.alloc = <span class="literal">NULL</span>,						\  </span><br><span class="line">		.mas_flags = <span class="number">0</span>,						\</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> ma_state &#123;</span><br><span class="line">	<span class="keyword">struct</span> maple_tree *tree;	<span class="comment">/* The tree we&#x27;re operating in */</span><span class="comment">// 指向目标树</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> index;		<span class="comment">// 当前操作的起始index（first）</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> last;		<span class="comment">// 当前操作的终止index（last）</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">maple_enode</span> *<span class="title">node</span>;</span>	<span class="comment">/* The node containing this entry */</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> min;		<span class="comment">/* The minimum index - implied pivot min */</span><span class="comment">// 当前节点管理的index区间</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> max;		<span class="comment">/* The maximum index - implied pivot max */</span><span class="comment">// 当前节点管理的index区间</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">maple_alloc</span> *<span class="title">alloc</span>;</span>	<span class="comment">/* Allocated nodes for this operation */</span> <span class="comment">// 若需要分配新节点，指向预分配页</span></span><br><span class="line">	<span class="class"><span class="keyword">enum</span> <span class="title">maple_status</span> <span class="title">status</span>;</span>	<span class="comment">/* The status of the state (active, start, none, etc) */</span> <span class="comment">// 状态机标记（ma_start, ma_none, ma_data等）</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">char</span> depth;		<span class="comment">/* depth of tree descent during write */</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">char</span> offset;</span><br><span class="line">	<span class="type">unsigned</span> <span class="type">char</span> mas_flags;</span><br><span class="line">	<span class="type">unsigned</span> <span class="type">char</span> end;		<span class="comment">/* The end of the node */</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>然后调用mas_insert(&amp;ms, entry);那我们来看看mas_insert相关代码, 在该函数中，同样用宏声明了一个MA_WR_STATE，</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * mas_insert() - Internal call to insert a value</span></span><br><span class="line"><span class="comment"> * @mas: The maple state</span></span><br><span class="line"><span class="comment"> * @entry: The entry to store</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Return: %NULL or the contents that already exists at the requested index</span></span><br><span class="line"><span class="comment"> * otherwise.  The maple state needs to be checked for error conditions.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="type">static</span> <span class="keyword">inline</span> <span class="type">void</span> *<span class="title function_">mas_insert</span><span class="params">(<span class="keyword">struct</span> ma_state *mas, <span class="type">void</span> *entry)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">    #define MA_WR_STATE(name, ma_state, wr_entry)				\</span></span><br><span class="line"><span class="comment">	struct ma_wr_state name = &#123;					\</span></span><br><span class="line"><span class="comment">		.mas = ma_state,					\</span></span><br><span class="line"><span class="comment">		.content = NULL,					\</span></span><br><span class="line"><span class="comment">		.entry = wr_entry,					\</span></span><br><span class="line"><span class="comment">	&#125;</span></span><br><span class="line"><span class="comment">	这里进来首先创建一个mas_state上下文，</span></span><br><span class="line"><span class="comment">	struct ma_wr_state &#123;</span></span><br><span class="line"><span class="comment">    	struct ma_state *mas;  // 指向当前 ma_state</span></span><br><span class="line"><span class="comment">    	void *content;         // 现有内容（如果已存在）</span></span><br><span class="line"><span class="comment">    	void *entry;           // 要插入的新 entry</span></span><br><span class="line"><span class="comment">	&#125;;</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">	MA_WR_STATE(wr_mas, mas, entry);</span><br><span class="line"></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * Inserting a new range inserts either 0, 1, or 2 pivots within the</span></span><br><span class="line"><span class="comment">	 * tree.  If the insert fits exactly into an existing gap with a value</span></span><br><span class="line"><span class="comment">	 * of NULL, then the slot only needs to be written with the new value.</span></span><br><span class="line"><span class="comment">	 * If the range being inserted is adjacent to another range, then only a</span></span><br><span class="line"><span class="comment">	 * single pivot needs to be inserted (as well as writing the entry).  If</span></span><br><span class="line"><span class="comment">	 * the new range is within a gap but does not touch any other ranges,</span></span><br><span class="line"><span class="comment">	 * then two pivots need to be inserted: the start - 1, and the end.  As</span></span><br><span class="line"><span class="comment">	 * usual, the entry must be written.  Most operations require a new node</span></span><br><span class="line"><span class="comment">	 * to be allocated and replace an existing node to ensure RCU safety,</span></span><br><span class="line"><span class="comment">	 * when in RCU mode.  The exception to requiring a newly allocated node</span></span><br><span class="line"><span class="comment">	 * is when inserting at the end of a node (appending).  When done</span></span><br><span class="line"><span class="comment">	 * carefully, appending can reuse the node in place.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	wr_mas.content = mas_start(mas);</span><br><span class="line">	<span class="keyword">if</span> (wr_mas.content)</span><br><span class="line">		<span class="keyword">goto</span> exists; <span class="comment">//已存在，不允许重复插入</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> (mas_is_none(mas) || mas_is_ptr(mas)) &#123;</span><br><span class="line">		mas_store_root(mas, entry);  <span class="comment">//如果是空树，直接在root插入entry</span></span><br><span class="line">		<span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/* spanning writes always overwrite something */</span></span><br><span class="line">	<span class="keyword">if</span> (!mas_wr_walk(&amp;wr_mas))</span><br><span class="line">		<span class="keyword">goto</span> exists;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/* At this point, we are at the leaf node that needs to be altered. */</span></span><br><span class="line">	wr_mas.offset_end = mas-&gt;offset;</span><br><span class="line">	wr_mas.end_piv = wr_mas.r_max;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> (wr_mas.content || (mas-&gt;last &gt; wr_mas.r_max))</span><br><span class="line">		<span class="keyword">goto</span> exists;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> (!entry)</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">	mas_wr_modify(&amp;wr_mas);</span><br><span class="line">	<span class="keyword">return</span> wr_mas.content;</span><br><span class="line"></span><br><span class="line">exists:</span><br><span class="line">	mas_set_err(mas, -EEXIST);</span><br><span class="line">	<span class="keyword">return</span> wr_mas.content;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>也就是说如果是空树，则到mas_store_root函数中进行处理。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">static</span> <span class="keyword">inline</span> <span class="type">void</span> <span class="title function_">mas_store_root</span><span class="params">(<span class="keyword">struct</span> ma_state *mas, <span class="type">void</span> *entry)</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="keyword">if</span> (likely((mas-&gt;last != <span class="number">0</span>) || (mas-&gt;index != <span class="number">0</span>)))  <span class="comment">//插入是一个范围</span></span><br><span class="line">		mas_root_expand(mas, entry);</span><br><span class="line">	<span class="keyword">else</span> <span class="keyword">if</span> (((<span class="type">unsigned</span> <span class="type">long</span>) (entry) &amp; <span class="number">3</span>) == <span class="number">2</span>)  <span class="comment">//低两位是10</span></span><br><span class="line">		mas_root_expand(mas, entry); <span class="comment">//将根扩大</span></span><br><span class="line">	<span class="keyword">else</span> &#123;</span><br><span class="line">		rcu_assign_pointer(mas-&gt;tree-&gt;ma_root, entry);  <span class="comment">//如果是插入单独一个数字，则直接把该entry作为根</span></span><br><span class="line">		mas-&gt;status = ma_start; <span class="comment">//状态改成还没开始搜索树</span></span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * mas_root_expand() - Expand a root to a node</span></span><br><span class="line"><span class="comment"> * @mas: The maple state</span></span><br><span class="line"><span class="comment"> * @entry: The entry to store into the tree</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="type">static</span> <span class="keyword">inline</span> <span class="type">int</span> <span class="title function_">mas_root_expand</span><span class="params">(<span class="keyword">struct</span> ma_state *mas, <span class="type">void</span> *entry)</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="type">void</span> *contents = mas_root_locked(mas);</span><br><span class="line">	<span class="class"><span class="keyword">enum</span> <span class="title">maple_type</span> <span class="title">type</span> =</span> maple_leaf_64;</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">maple_node</span> *<span class="title">node</span>;</span></span><br><span class="line">	<span class="type">void</span> __rcu **slots;</span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> *pivots;</span><br><span class="line">	<span class="type">int</span> slot = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">	mas_node_count(mas, <span class="number">1</span>); <span class="comment">//确保allocated数量要大于1，不然就多预分配几个</span></span><br><span class="line">	<span class="keyword">if</span> (unlikely(mas_is_err(mas)))</span><br><span class="line">		<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">	node = mas_pop_node(mas);  <span class="comment">// 分配一个新的 maple_node</span></span><br><span class="line">	pivots = ma_pivots(node, type);</span><br><span class="line">	slots = ma_slots(node, type);</span><br><span class="line">	node-&gt;parent = ma_parent_ptr(mas_tree_parent(mas));</span><br><span class="line">	mas-&gt;node = mt_mk_node(node, type);</span><br><span class="line">	mas-&gt;status = ma_active;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> (mas-&gt;index) &#123;</span><br><span class="line">		<span class="keyword">if</span> (contents) &#123;</span><br><span class="line">			rcu_assign_pointer(slots[slot], contents);</span><br><span class="line">			<span class="keyword">if</span> (likely(mas-&gt;index &gt; <span class="number">1</span>))</span><br><span class="line">				slot++;</span><br><span class="line">		&#125;</span><br><span class="line">		pivots[slot++] = mas-&gt;index - <span class="number">1</span>;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	rcu_assign_pointer(slots[slot], entry); <span class="comment">//slots成员用于存储entry,也就是vm_area_struct</span></span><br><span class="line">	mas-&gt;offset = slot;</span><br><span class="line">	pivots[slot] = mas-&gt;last;</span><br><span class="line">	<span class="keyword">if</span> (mas-&gt;last != ULONG_MAX)</span><br><span class="line">		pivots[++slot] = ULONG_MAX;</span><br><span class="line"></span><br><span class="line">	mas-&gt;depth = <span class="number">1</span>;</span><br><span class="line">	mas_set_height(mas);</span><br><span class="line">	ma_set_meta(node, maple_leaf_64, <span class="number">0</span>, slot);</span><br><span class="line">	<span class="comment">/* swap the new root into the tree */</span></span><br><span class="line">	rcu_assign_pointer(mas-&gt;tree-&gt;ma_root, mte_mk_root(mas-&gt;node));</span><br><span class="line">	<span class="keyword">return</span> slot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<p>最后给一个完整的vm_area_struct是如何组织成maple_tree的，这个网上资料太少了，找到一篇论文里的图，能够很好地说明各个节点和内容。具体来说pivot来表示各个vm_area_struct的范围，slots 用来存储vm_area_struct（叶子节点）或者下一级slots（非叶子节点）的地址。这样看就非常了然了。</p>
<p><img src="https://zhuzhuzaiimgbed.oss-cn-hangzhou.aliyuncs.com/img/image-20251006215530853.png" alt="image-20251006215530853"></p>
<p>可以看到非leaf node用的是maple_arange_64结构体，其slots存储的都是下一级slots的指针，而leaf node使用的是maple_range_64结构体，其slots存储user data。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Leaf nodes do not store pointers to nodes, they store user data.  Users may</span></span><br><span class="line"><span class="comment"> * store almost any bit pattern.  As noted above, the optimisation of storing an</span></span><br><span class="line"><span class="comment"> * entry at 0 in the root pointer cannot be done for data which have the bottom</span></span><br><span class="line"><span class="comment"> * two bits set to &#x27;10&#x27;.  We also reserve values with the bottom two bits set to</span></span><br><span class="line"><span class="comment"> * &#x27;10&#x27; which are below 4096 (ie 2, 6, 10 .. 4094) for internal use.  Some APIs</span></span><br><span class="line"><span class="comment"> * return errnos as a negative errno shifted right by two bits and the bottom</span></span><br><span class="line"><span class="comment"> * two bits set to &#x27;10&#x27;, and while choosing to store these values in the array</span></span><br><span class="line"><span class="comment"> * is not an error, it may lead to confusion if you&#x27;re testing for an error with</span></span><br><span class="line"><span class="comment"> * mas_is_err().</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Non-leaf nodes store the type of the node pointed to (enum maple_type in bits</span></span><br><span class="line"><span class="comment"> * 3-6), bit 2 is reserved.  That leaves bits 0-1 unused for now.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * In regular B-Tree terms, pivots are called keys.  The term pivot is used to</span></span><br><span class="line"><span class="comment"> * indicate that the tree is specifying ranges,  Pivots may appear in the</span></span><br><span class="line"><span class="comment"> * subtree with an entry attached to the value whereas keys are unique to a</span></span><br><span class="line"><span class="comment"> * specific position of a B-tree.  Pivot values are inclusive of the slot with</span></span><br><span class="line"><span class="comment"> * the same index.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">maple_range_64</span> &#123;</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">maple_pnode</span> *<span class="title">parent</span>;</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> pivot[MAPLE_RANGE64_SLOTS - <span class="number">1</span>];</span><br><span class="line">	<span class="class"><span class="keyword">union</span> &#123;</span></span><br><span class="line">		<span class="type">void</span> __rcu *slot[MAPLE_RANGE64_SLOTS];</span><br><span class="line">		<span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">			<span class="type">void</span> __rcu *pad[MAPLE_RANGE64_SLOTS - <span class="number">1</span>];</span><br><span class="line">			<span class="class"><span class="keyword">struct</span> <span class="title">maple_metadata</span> <span class="title">meta</span>;</span></span><br><span class="line">		&#125;;</span><br><span class="line">	&#125;;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * At tree creation time, the user can specify that they&#x27;re willing to trade off</span></span><br><span class="line"><span class="comment"> * storing fewer entries in a tree in return for storing more information in</span></span><br><span class="line"><span class="comment"> * each node.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * The maple tree supports recording the largest range of NULL entries available</span></span><br><span class="line"><span class="comment"> * in this node, also called gaps.  This optimises the tree for allocating a</span></span><br><span class="line"><span class="comment"> * range.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">maple_arange_64</span> &#123;</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">maple_pnode</span> *<span class="title">parent</span>;</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> pivot[MAPLE_ARANGE64_SLOTS - <span class="number">1</span>];</span><br><span class="line">	<span class="type">void</span> __rcu *slot[MAPLE_ARANGE64_SLOTS];</span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> gap[MAPLE_ARANGE64_SLOTS];</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">maple_metadata</span> <span class="title">meta</span>;</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>





<h1 id="内核中一些内存分配函数的细节与区别"><a href="#内核中一些内存分配函数的细节与区别" class="headerlink" title="内核中一些内存分配函数的细节与区别"></a>内核中一些内存分配函数的细节与区别</h1><h2 id="伙伴系统分配函数"><a href="#伙伴系统分配函数" class="headerlink" title="伙伴系统分配函数"></a>伙伴系统分配函数</h2><p>首先是前面说过的伙伴系统，主要分配函数有<code>alloc_page</code>,<code>alloc_pages</code></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">//include/linux/gfp.h</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> alloc_page(gfp_mask) alloc_pages(gfp_mask, 0)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> alloc_pages(...)			alloc_hooks(alloc_pages_noprof(__VA_ARGS__))</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//NUMA架构</span></span><br><span class="line"><span class="keyword">struct</span> page *<span class="title function_">alloc_pages_noprof</span><span class="params">(<span class="type">gfp_t</span> gfp, <span class="type">unsigned</span> <span class="type">int</span> order)</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">mempolicy</span> *<span class="title">pol</span> =</span> &amp;default_policy;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * No reference counting needed for current-&gt;mempolicy</span></span><br><span class="line"><span class="comment">	 * nor system default_policy</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="keyword">if</span> (!in_interrupt() &amp;&amp; !(gfp &amp; __GFP_THISNODE))</span><br><span class="line">		pol = get_task_policy(current);</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> alloc_pages_mpol_noprof(gfp, order, pol, NO_INTERLEAVE_INDEX,</span><br><span class="line">				       numa_node_id());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//非NUMA架构</span></span><br><span class="line"><span class="type">static</span> <span class="keyword">inline</span> <span class="keyword">struct</span> page *<span class="title function_">alloc_pages_noprof</span><span class="params">(<span class="type">gfp_t</span> gfp_mask, <span class="type">unsigned</span> <span class="type">int</span> order)</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="keyword">return</span> alloc_pages_node_noprof(numa_node_id(), gfp_mask, order);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>然后可以看到就是分为NUMA架构和非NUMA架构的区别了，这里我们分别来看，因为调用的是不同函数</p>
<h3 id="NUMA架构"><a href="#NUMA架构" class="headerlink" title="NUMA架构"></a>NUMA架构</h3><p>NUMA架构是从内存池中获取<code>1&lt;&lt;order</code>个页面。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> page *<span class="title function_">alloc_pages_mpol_noprof</span><span class="params">(<span class="type">gfp_t</span> gfp, <span class="type">unsigned</span> <span class="type">int</span> order,</span></span><br><span class="line"><span class="params">		<span class="keyword">struct</span> mempolicy *pol, <span class="type">pgoff_t</span> ilx, <span class="type">int</span> nid)</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="type">nodemask_t</span> *nodemask; <span class="comment">//准备node掩码</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">page</span> *<span class="title">page</span>;</span> <span class="comment">//准备return value</span></span><br><span class="line"></span><br><span class="line">	nodemask = policy_nodemask(gfp, pol, ilx, &amp;nid);  <span class="comment">//根据mempool的策略，分析可以从哪些node上分配页面。</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> (pol-&gt;mode == MPOL_PREFERRED_MANY) <span class="comment">//当策略允许多个“首选节点”时，跳过后续逻辑，用专门路径分配。</span></span><br><span class="line">		<span class="keyword">return</span> alloc_pages_preferred_many(gfp, order, nid, nodemask);</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> (IS_ENABLED(CONFIG_TRANSPARENT_HUGEPAGE) &amp;&amp;</span><br><span class="line">	    <span class="comment">/* filter &quot;hugepage&quot; allocation, unless from alloc_pages() */</span></span><br><span class="line">	    order == HPAGE_PMD_ORDER &amp;&amp; ilx != NO_INTERLEAVE_INDEX) &#123; <span class="comment">//分配透明大页，优先从本节点获取</span></span><br><span class="line">		<span class="comment">/*</span></span><br><span class="line"><span class="comment">		 * For hugepage allocation and non-interleave policy which</span></span><br><span class="line"><span class="comment">		 * allows the current node (or other explicitly preferred</span></span><br><span class="line"><span class="comment">		 * node) we only try to allocate from the current/preferred</span></span><br><span class="line"><span class="comment">		 * node and don&#x27;t fall back to other nodes, as the cost of</span></span><br><span class="line"><span class="comment">		 * remote accesses would likely offset THP benefits.</span></span><br><span class="line"><span class="comment">		 *</span></span><br><span class="line"><span class="comment">		 * If the policy is interleave or does not allow the current</span></span><br><span class="line"><span class="comment">		 * node in its nodemask, we allocate the standard way.</span></span><br><span class="line"><span class="comment">		 */</span></span><br><span class="line">		<span class="keyword">if</span> (pol-&gt;mode != MPOL_INTERLEAVE &amp;&amp;</span><br><span class="line">		    pol-&gt;mode != MPOL_WEIGHTED_INTERLEAVE &amp;&amp;</span><br><span class="line">		    (!nodemask || node_isset(nid, *nodemask))) &#123;</span><br><span class="line">			<span class="comment">/*</span></span><br><span class="line"><span class="comment">			 * First, try to allocate THP only on local node, but</span></span><br><span class="line"><span class="comment">			 * don&#x27;t reclaim unnecessarily, just compact.</span></span><br><span class="line"><span class="comment">			 */</span></span><br><span class="line">			page = __alloc_pages_node_noprof(nid,</span><br><span class="line">				gfp | __GFP_THISNODE | __GFP_NORETRY, order); <span class="comment">//尝试先在本地节点路径上快速分配，不触发内存回收</span></span><br><span class="line">			<span class="keyword">if</span> (page || !(gfp &amp; __GFP_DIRECT_RECLAIM))</span><br><span class="line">				<span class="keyword">return</span> page;</span><br><span class="line">			<span class="comment">/*</span></span><br><span class="line"><span class="comment">			 * If hugepage allocations are configured to always</span></span><br><span class="line"><span class="comment">			 * synchronous compact or the vma has been madvised</span></span><br><span class="line"><span class="comment">			 * to prefer hugepage backing, retry allowing remote</span></span><br><span class="line"><span class="comment">			 * memory with both reclaim and compact as well.</span></span><br><span class="line"><span class="comment">			 */</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	page = __alloc_pages_noprof(gfp, order, nid, nodemask);  <span class="comment">//如果前面失败了，就调用正常路径分配，可以跨节点，可能触发内存回收，会根据nodemask限制分配节点</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> (unlikely(pol-&gt;mode == MPOL_INTERLEAVE) &amp;&amp; page) &#123;</span><br><span class="line">		<span class="comment">/* skip NUMA_INTERLEAVE_HIT update if numa stats is disabled */</span></span><br><span class="line">		<span class="keyword">if</span> (static_branch_likely(&amp;vm_numa_stat_key) &amp;&amp;</span><br><span class="line">		    page_to_nid(page) == nid) &#123;</span><br><span class="line">			preempt_disable();</span><br><span class="line">			__count_numa_event(page_zone(page), NUMA_INTERLEAVE_HIT);</span><br><span class="line">			preempt_enable();</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> page;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这里函数不会触发内存回收，因为设置了gfp_mask，后续慢速路径使用原来的mask</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">static</span> <span class="keyword">inline</span> <span class="class"><span class="keyword">struct</span> <span class="title">page</span> *</span></span><br><span class="line"><span class="class">__<span class="title">alloc_pages_node_noprof</span>(<span class="title">int</span> <span class="title">nid</span>, <span class="title">gfp_t</span> <span class="title">gfp_mask</span>, <span class="title">unsigned</span> <span class="title">int</span> <span class="title">order</span>)</span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">	VM_BUG_ON(nid &lt; <span class="number">0</span> || nid &gt;= MAX_NUMNODES);</span><br><span class="line">	warn_if_node_offline(nid, gfp_mask); <span class="comment">//检查节点没有下线，是否合法</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> __alloc_pages_noprof(gfp_mask, order, nid, <span class="literal">NULL</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * This is the &#x27;heart&#x27; of the zoned buddy allocator.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">page</span> *__<span class="title">alloc_pages_noprof</span>(<span class="title">gfp_t</span> <span class="title">gfp</span>, <span class="title">unsigned</span> <span class="title">int</span> <span class="title">order</span>,</span></span><br><span class="line"><span class="class">				      <span class="title">int</span> <span class="title">preferred_nid</span>, <span class="title">nodemask_t</span> *<span class="title">nodemask</span>)</span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">page</span> *<span class="title">page</span>;</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">int</span> alloc_flags = ALLOC_WMARK_LOW; <span class="comment">//低水位线</span></span><br><span class="line">	<span class="type">gfp_t</span> alloc_gfp; <span class="comment">/* The gfp_t that was actually used for allocation */</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">alloc_context</span> <span class="title">ac</span> =</span> &#123; &#125;;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * There are several places where we assume that the order value is sane</span></span><br><span class="line"><span class="comment">	 * so bail out early if the request is out of bound.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="keyword">if</span> (WARN_ON_ONCE_GFP(order &gt; MAX_PAGE_ORDER, gfp)) <span class="comment">//防止分配过大的页面 这里指的是大于2^10</span></span><br><span class="line">		<span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">	gfp &amp;= gfp_allowed_mask;</span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * Apply scoped allocation constraints. This is mainly about GFP_NOFS</span></span><br><span class="line"><span class="comment">	 * resp. GFP_NOIO which has to be inherited for all allocation requests</span></span><br><span class="line"><span class="comment">	 * from a particular context which has been marked by</span></span><br><span class="line"><span class="comment">	 * memalloc_no&#123;fs,io&#125;_&#123;save,restore&#125;. And PF_MEMALLOC_PIN which ensures</span></span><br><span class="line"><span class="comment">	 * movable zones are not used during allocation.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	gfp = current_gfp_context(gfp);</span><br><span class="line">	alloc_gfp = gfp;</span><br><span class="line">	<span class="keyword">if</span> (!prepare_alloc_pages(gfp, order, preferred_nid, nodemask, &amp;ac,</span><br><span class="line">			&amp;alloc_gfp, &amp;alloc_flags)) <span class="comment">//做一些准备工作，比如确定目标Zone，调整gfp，检查CPUSET相关等。</span></span><br><span class="line">		<span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * Forbid the first pass from falling back to types that fragment</span></span><br><span class="line"><span class="comment">	 * memory until all local zones are considered.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	alloc_flags |= alloc_flags_nofragment(ac.preferred_zoneref-&gt;zone, gfp);</span><br><span class="line"></span><br><span class="line">	<span class="comment">/* First allocation attempt */</span></span><br><span class="line">	page = get_page_from_freelist(alloc_gfp, order, alloc_flags, &amp;ac); <span class="comment">//快速路径尝试，最后调用rmqueue() 从伙伴系统取页</span></span><br><span class="line">	<span class="keyword">if</span> (likely(page))</span><br><span class="line">		<span class="keyword">goto</span> out;</span><br><span class="line"></span><br><span class="line">	alloc_gfp = gfp;</span><br><span class="line">	ac.spread_dirty_pages = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * Restore the original nodemask if it was potentially replaced with</span></span><br><span class="line"><span class="comment">	 * &amp;cpuset_current_mems_allowed to optimize the fast-path attempt.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	ac.nodemask = nodemask;</span><br><span class="line"></span><br><span class="line">	page = __alloc_pages_slowpath(alloc_gfp, order, &amp;ac); <span class="comment">//执行满速分配，会执行内存压缩，会触发OOM等。</span></span><br><span class="line"></span><br><span class="line">out:</span><br><span class="line">	<span class="keyword">if</span> (memcg_kmem_online() &amp;&amp; (gfp &amp; __GFP_ACCOUNT) &amp;&amp; page &amp;&amp;</span><br><span class="line">	    unlikely(__memcg_kmem_charge_page(page, gfp, order) != <span class="number">0</span>)) &#123;</span><br><span class="line">		__free_pages(page, order);</span><br><span class="line">		page = <span class="literal">NULL</span>;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	trace_mm_page_alloc(page, order, alloc_gfp, ac.migratetype);</span><br><span class="line">	kmsan_alloc_page(page, order, alloc_gfp);</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> page;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="非NUMA架构"><a href="#非NUMA架构" class="headerlink" title="非NUMA架构"></a>非NUMA架构</h3><p>非NUMA架构其实也是调用的以上函数，只是调用的参数不太一样，这里就不详细说明了</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">static</span> <span class="keyword">inline</span> <span class="keyword">struct</span> page *<span class="title function_">alloc_pages_node_noprof</span><span class="params">(<span class="type">int</span> nid, <span class="type">gfp_t</span> gfp_mask,</span></span><br><span class="line"><span class="params">						   <span class="type">unsigned</span> <span class="type">int</span> order)</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="keyword">if</span> (nid == NUMA_NO_NODE)</span><br><span class="line">		nid = numa_mem_id();</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> __alloc_pages_node_noprof(nid, gfp_mask, order);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="其他buddy之上的分配函数"><a href="#其他buddy之上的分配函数" class="headerlink" title="其他buddy之上的分配函数"></a>其他buddy之上的分配函数</h2><p>get_free_page</p>
<p>get_dma_pages</p>
<p>alloc_pages_exact</p>
<p>get_zerod_page</p>
<p>最后都会调用__get_free_pages, 然后再调用底层的buddy函数。</p>
]]></content>
      <categories>
        <category>note</category>
      </categories>
      <tags>
        <tag>os</tag>
      </tags>
  </entry>
  <entry>
    <title>文件系统</title>
    <url>/2025/09/19/note/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[<h1 id="Linux-文件系统详解"><a href="#Linux-文件系统详解" class="headerlink" title="Linux 文件系统详解"></a>Linux 文件系统详解</h1><p>要讲文件系统主要有三个方面的内容需要了解：</p>
<ul>
<li>用户视角下的文件系统，即一个树状的目录结构，包括各个不同磁盘的mount关系，各个文件的属性和权限以及文件本身（一个数组形状的字节合集）。</li>
<li>Linux系统下的文件系统，即内核中文件相关的数据结构，包括super block， inode， dentry等，还有磁盘上文件的页缓存。</li>
<li>磁盘上物理组织文件的视角，磁盘上的各个块之间的关系以及各个inode等。</li>
</ul>
<h1 id="用户视角下的文件系统"><a href="#用户视角下的文件系统" class="headerlink" title="用户视角下的文件系统"></a>用户视角下的文件系统</h1><p>用户视角下文件系统其实就是一个树状的目录，如图所示。其中主磁盘即rootfs，在系统启动阶段被装载在根目录，而其他文件系统例如U盘或者移动硬盘固态等，就会装载在一个特定的节点上，例如图中home和usb1就是两个挂载点，挂在了两个文件系统。整体形成一棵目录树。</p>
<p><img src="https://zhuzhuzaiimgbed.oss-cn-hangzhou.aliyuncs.com/img/20251002221915949.png" alt="image-20251002220629047"></p>
<h1 id="进程视角下的文件系统"><a href="#进程视角下的文件系统" class="headerlink" title="进程视角下的文件系统"></a>进程视角下的文件系统</h1><h2 id="task-struct中和文件相关内容"><a href="#task-struct中和文件相关内容" class="headerlink" title="task_struct中和文件相关内容"></a>task_struct中和文件相关内容</h2><p>进程在Linux kernel中主要是用task_struct这个结构来表示，一个进程有一个task_struct，即操作系统中所谓的TCB。在task_struct中有很多字段和文件相关，这里只列出几个关键的：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// include/linux/sched.h</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">task_struct</span> &#123;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">/* Filesystem information: */</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">fs_struct</span>		*<span class="title">fs</span>;</span> <span class="comment">//存放进程的文件系统上下文：当前目录 (cwd)、根目录 (root)、umask、chdir 等信息。</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">/* Open file information: */</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">files_struct</span>		*<span class="title">files</span>;</span> <span class="comment">//指向进程的打开文件表（fd table）。包含 fd 数组、close_on_exec 位图、引用计数等（在 fdtable.h 定义）</span></span><br><span class="line">    </span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">nameidata</span>		*<span class="title">nameidata</span>;</span> <span class="comment">//与路径查找（lookup）相关的临时结构（lookup 操作时使用）。</span></span><br><span class="line">    </span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>首先每个进程会有自己的进程上下文，即当前的工作目录和根目录，记录在fs_struct结构体中。同时会打开多个文件，记录在files_struct结构体中。此外还有一个<code>nameidata</code>字段，<em>struct nameidata</em> 是 Linux 内核中用于路径查找的辅助结构体。它在文件系统中起着关键作用，帮助根据路径名找到目标节点的 dentry 和 inode。</p>
<h2 id="fs-struct结构体"><a href="#fs-struct结构体" class="headerlink" title="fs_struct结构体"></a>fs_struct结构体</h2><p>前面说到了一个进程内有一个fs_struct结构体，我们来看看它包含什么</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// include/linux/fs_struct.h</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">fs_struct</span> &#123;</span></span><br><span class="line">	<span class="type">int</span> users;  <span class="comment">//被共享（引用）的次数，即共享该fs_struct的进程数目，当该计数归0，该结构体会被释放</span></span><br><span class="line">	<span class="type">spinlock_t</span> lock; <span class="comment">//保护该结构的自旋锁</span></span><br><span class="line">	<span class="type">seqcount_spinlock_t</span> seq; <span class="comment">//读写相关的序列锁，用于对 root、pwd 的并发访问提供“乐观读取”机制。读者不加锁，只是读取并检查序号是否一致；写者需要持有 lock 并更新 seq。这样减少了对频繁读操作的锁竞争。</span></span><br><span class="line">	<span class="type">int</span> umask; <span class="comment">//进程创建文件时默认的访问权限</span></span><br><span class="line">	<span class="type">int</span> in_exec;<span class="comment">//当进程调用 execve() 执行新程序时设置，用来防止并发修改 fs_struct（比如别的线程在 exec 时改工作目录）。</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">path</span> <span class="title">root</span>, <span class="title">pwd</span>;</span> <span class="comment">//根目录和当前目录</span></span><br><span class="line">&#125; __randomize_layout;  <span class="comment">//随机化成员，在编译阶段随机化部分成员的顺序</span></span><br></pre></td></tr></table></figure>

<h2 id="files-struct结构体"><a href="#files-struct结构体" class="headerlink" title="files_struct结构体"></a>files_struct结构体</h2><p>内核中还有一个files_struct结构体，同样看看里面包含了哪些内容</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// include/linux/fdtable.h</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Open file table structure</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">files_struct</span> &#123;</span></span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">   * read mostly part</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">	<span class="type">atomic_t</span> count; <span class="comment">//被共享引用的次数，多个进程（例如通过 clone(CLONE_FILES)）可以共享同一个文件描述符表，count 表示有多少进程在共享。为 0 时释放。</span></span><br><span class="line">	<span class="type">bool</span> resize_in_progress; <span class="comment">//文件描述符表是否正在扩容。当打开的文件数超过当前表大小时，需要扩展 fdtable。这个标志用来防止并发扩展（resize race）。</span></span><br><span class="line">	<span class="type">wait_queue_head_t</span> resize_wait; <span class="comment">//等待队列，如果有多个线程同时触发扩容，只有一个执行 resize，其余在此队列等待，避免重复扩展。</span></span><br><span class="line"></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">fdtable</span> __<span class="title">rcu</span> *<span class="title">fdt</span>;</span> <span class="comment">//当前正在使用的文件描述符表，指针带有 RCU 保护。存放文件描述符（fd）与文件对象的映射表，指针可能在扩展时切换到新的 fdtable。</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">fdtable</span> <span class="title">fdtab</span>;</span> <span class="comment">//内嵌的一个小 fdtable。初始时进程直接使用这个内嵌表，避免频繁 kmalloc。通常能容纳少量 fd（比如 NR_OPEN_DEFAULT 个）。只有打开的文件数超过默认大小才会分配新的大表。</span></span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">   * written part on a separate cache line in SMP</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">	<span class="type">spinlock_t</span> file_lock ____cacheline_aligned_in_smp; <span class="comment">//保护文件描述符表的自旋锁。控制对文件描述符（打开、关闭、dup 等）的并发修改。</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">int</span> next_fd; <span class="comment">//下一个可用的文件描述符号。提高分配 fd 的效率，每次分配时从 next_fd 开始搜索。</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> close_on_exec_init[<span class="number">1</span>]; <span class="comment">//位图（初始内嵌部分），对应 FD_CLOEXEC 标志。记录哪些 fd 在 execve() 时需要自动关闭。超出范围时在 fdtable 的动态部分里扩展。</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> open_fds_init[<span class="number">1</span>]; <span class="comment">//位图（初始内嵌部分），记录哪些 fd 当前是打开状态。</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> full_fds_bits_init[<span class="number">1</span>]; <span class="comment">//位图（初始内嵌部分），辅助位图，用于加速 fd 分配（快速判断哪些 fd 已用/空闲）。</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">file</span> __<span class="title">rcu</span> * <span class="title">fd_array</span>[<span class="title">NR_OPEN_DEFAULT</span>];</span> <span class="comment">//文件指针数组（初始内嵌部分）。存放默认数量的 struct file * 指针（例如前 32 个 fd）。超过时会切换到动态分配的 fdtable。</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>具体如图所示</p>
<p><img src="https://zhuzhuzaiimgbed.oss-cn-hangzhou.aliyuncs.com/img/20251003130434537.png" alt="image-20251003130430704"></p>
<h2 id="struct-fdtable结构体"><a href="#struct-fdtable结构体" class="headerlink" title="struct fdtable结构体"></a>struct fdtable结构体</h2><p>上面files_struct结构体中有一个关键数据结构fdtable,即文件描述符表，其在结构体内部有一个内嵌的fdtable结构体fdtab，同时还有一个指针fdt指向一个fdtable结构体。初始化时候fdt指针是指向内嵌在结构体files_struct中的fdtab成员的，并且该结构用了RCU同步保护机制。具体结构定义如下</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// include/linux/fdtable.h</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">fdtable</span> &#123;</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">int</span> max_fds;</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">file</span> __<span class="title">rcu</span> **<span class="title">fd</span>;</span>      <span class="comment">/* current fd array */</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> *close_on_exec;</span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> *open_fds;</span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> *full_fds_bits;</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">rcu_head</span> <span class="title">rcu</span>;</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">//ps 这里介绍一下RCU同步机制，因为有些指针使用了__rcu标志来标识，实际上该标志告诉了静态分析工具和编译器，这个指针读得多，写得少，且读的时候不需要加锁。__rcu 是一个 sparse 注解宏（静态分析工具用的标记，不影响编译出的代码），它告诉内核开发者和静态分析器：1. 这个指针只能通过 RCU 安全地读/写。2. 读它的时候要用 rcu_dereference()，而不是直接解引用。3. 改它的时候要用 rcu_assign_pointer()，而不是直接赋值。</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">读取该指针：</span></span><br><span class="line"><span class="comment">rcu_read_lock();</span></span><br><span class="line"><span class="comment">struct fdtable *fdt = rcu_dereference(files-&gt;fdt);</span></span><br><span class="line"><span class="comment">struct file *filp = rcu_dereference(fdt-&gt;fd[fd]);</span></span><br><span class="line"><span class="comment">if (filp)</span></span><br><span class="line"><span class="comment">    get_file(filp); // 增加引用计数，保证不会被释放</span></span><br><span class="line"><span class="comment">rcu_read_unlock();</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">写入该指针：</span></span><br><span class="line"><span class="comment">spin_lock(&amp;files-&gt;file_lock);</span></span><br><span class="line"><span class="comment">rcu_assign_pointer(fdt-&gt;fd[fd], new_filp);</span></span><br><span class="line"><span class="comment">spin_unlock(&amp;files-&gt;file_lock);</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<p>同时类似，初始时内嵌成员fdtab中<code>struct file __rcu **fd</code>就指向files_struct中的fd_array成员等，具体看图，这样做的好处是不用kmalloc这样耗时的操作，先预先分配NR_OPEN_DEFAULT个。</p>
<h2 id="struct-file-结构体"><a href="#struct-file-结构体" class="headerlink" title="struct file 结构体"></a>struct file 结构体</h2><p>最后就是内核视角的文件结构，即file结构体，在用户视角下一个文件其实就是一个int值，也叫文件描述符fd，但是对应内核数据结构其实就是file结构体数组的一个下表，真实的file结构体如下</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * f_&#123;lock,count,pos_lock&#125; members can be highly contended and share</span></span><br><span class="line"><span class="comment"> * the same cacheline. f_&#123;lock,mode&#125; are very frequently used together</span></span><br><span class="line"><span class="comment"> * and so share the same cacheline as well. The read-mostly</span></span><br><span class="line"><span class="comment"> * f_&#123;path,inode,op&#125; are kept on a separate cacheline.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">file</span> &#123;</span></span><br><span class="line">	<span class="class"><span class="keyword">union</span> &#123;</span></span><br><span class="line">		<span class="comment">/* fput() uses task work when closing and freeing file (default). */</span></span><br><span class="line">		<span class="class"><span class="keyword">struct</span> <span class="title">callback_head</span> 	<span class="title">f_task_work</span>;</span></span><br><span class="line">		<span class="comment">/* fput() must use workqueue (most kernel threads).在内核线程中，不能使用 task work，所以改用 workqueue + lockless list。 */</span></span><br><span class="line">		<span class="class"><span class="keyword">struct</span> <span class="title">llist_node</span>	<span class="title">f_llist</span>;</span></span><br><span class="line">		<span class="type">unsigned</span> <span class="type">int</span> 		f_iocb_flags; <span class="comment">//有时此字段存储异步 IO 控制块 (iocb) 的标志。</span></span><br><span class="line">	&#125;; <span class="comment">//这块表示关闭和回收文件时候使用的一个union。</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * Protects f_ep, f_flags.</span></span><br><span class="line"><span class="comment">	 * Must not be taken from IRQ context.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="type">spinlock_t</span>		f_lock <span class="comment">//保护 f_ep 和 f_flags，避免并发修改。</span></span><br><span class="line">	<span class="type">fmode_t</span>			f_mode; <span class="comment">//文件打开模式（读/写/追加等），对应用户空间的 O_RDONLY/O_WRONLY/O_RDWR。</span></span><br><span class="line">	<span class="type">atomic_long_t</span>		f_count; <span class="comment">//文件对象的引用计数,每个 dup()、fork(CLONE_FILES) 都会增加计数，close() 时减少。为 0 时释放。</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">mutex</span>		<span class="title">f_pos_lock</span>;</span> <span class="comment">//保护f_pos的锁</span></span><br><span class="line">	<span class="type">loff_t</span>			f_pos; <span class="comment">//文件的当前偏移量（相当于用户空间的 file pointer）。不同进程如果独立 open 同一个 inode，会有不同的 f_pos。</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">int</span>		f_flags; <span class="comment">//文件打开时候的flag</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">fown_struct</span>	<span class="title">f_owner</span>;</span> <span class="comment">//记录信号所有者（F_SETOWN/F_SETFL 用于异步 IO/信号）。</span></span><br><span class="line">	<span class="type">const</span> <span class="class"><span class="keyword">struct</span> <span class="title">cred</span>	*<span class="title">f_cred</span>;</span> <span class="comment">//打开文件时的凭据（UID/GID/capabilities）。即使进程之后提权/降权，这里仍保持当时的 cred。</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">file_ra_state</span>	<span class="title">f_ra</span>;</span> <span class="comment">//readahead 状态（预读优化），内核读文件时可能会提前加载后续页。</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">path</span>		<span class="title">f_path</span>;</span> <span class="comment">//记录该文件所在的 vfsmount + dentry（即路径位置）。</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">inode</span>		*<span class="title">f_inode</span>;</span>	<span class="comment">/* cached value, 缓存的 inode 指针，加快访问速度。 */</span></span><br><span class="line">	<span class="type">const</span> <span class="class"><span class="keyword">struct</span> <span class="title">file_operations</span>	*<span class="title">f_op</span>;</span> <span class="comment">//文件操作函数表（open/read/write/mmap/ioctl 等）。</span></span><br><span class="line"></span><br><span class="line">	u64			f_version; <span class="comment">//文件版本号，用于支持 NFS 等网络文件系统的 cache consistency。</span></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_SECURITY</span></span><br><span class="line">	<span class="type">void</span>			*f_security;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">	<span class="comment">/* needed for tty driver, and maybe others */</span></span><br><span class="line">	<span class="type">void</span>			*private_data;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_EPOLL</span></span><br><span class="line">	<span class="comment">/* Used by fs/eventpoll.c to link all the hooks to this file, epoll 用来跟踪哪些 epoll_fd 正在监听此文件。 */</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">hlist_head</span>	*<span class="title">f_ep</span>;</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span> <span class="comment">/* #ifdef CONFIG_EPOLL */</span></span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">address_space</span>	*<span class="title">f_mapping</span>;</span> <span class="comment">//文件的页缓存映射，用于读写页缓存、mmap 等。通常指向 inode-&gt;i_mapping，但特殊文件（如 pipes、sockets）可能不同。</span></span><br><span class="line">	<span class="type">errseq_t</span>		f_wb_err;</span><br><span class="line">	<span class="type">errseq_t</span>		f_sb_err; <span class="comment">/* for syncfs */</span></span><br><span class="line">&#125; __randomize_layout</span><br><span class="line">  __attribute__((aligned(<span class="number">4</span>)));	<span class="comment">/* lest something weird decides that 2 is OK */</span></span><br></pre></td></tr></table></figure>

<p>OK了，我们现在大概知道一个文件在用户视角和在内核视角的区别与联系了，接下来我们就可以看VFS的实现了。首先用户进程要操作文件，首先需要使用open函数对其打开，然后通过read和write对其进行处理。（这里的read, write都是库函数，也可以直接调用系统调用进行处理）</p>
<h1 id="VFS虚拟文件系统"><a href="#VFS虚拟文件系统" class="headerlink" title="VFS虚拟文件系统"></a>VFS虚拟文件系统</h1><p>VFS其实作用其实就是隐藏了底层不同文件系统的差异，向上提供统一的数据结构和接口。就比如用户执行cp命令，把U盘的文件拷贝到本地，其无需考虑U盘的文件系统格式和操作函数，也无需考虑本地根目录或者安装的硬盘的文件系统格式和操作函数，而是统一地用write，read这样的操作来实现，极大地方便了用户。</p>
<p>VFS实现主要抽象出了四大组件对象，包括文件（file）,目录（dentry）,索引结点（inode），超级块（super block）。</p>
<ul>
<li>文件：struct file，存放进程已经打开的文件信息和对其进行操作的函数，类似户口，并不能直接看到文件数据。<ul>
<li>表示一个<strong>打开的文件实例</strong>，包含偏移量 (<code>f_pos</code>)、打开标志 (<code>f_flags</code>)、所属进程的 cred 等。</li>
<li>每次 <code>open()</code>（或 <code>dup()</code>）都会产生&#x2F;引用一个新的 <code>struct file</code>。</li>
<li>即使两个 file 指针指向同一个 dentry，它们的偏移量、flags 可以不同。</li>
</ul>
</li>
<li>目录项：存在文件的特定识别名和关联信息。用来记录文件的名字、索引节点指针以及与其他目录项的层级关联关系。 多个目录项关联起来，就会形成目录结构，但它与索引节点不同的是，目录项是由内核维护的一个数据结构，不存放于磁盘，而是缓存在内存。<strong>简单来说说目录项纪录了已访问过的文件和目录的内存影像，是整个文件系统树结构的一个子集</strong>。<ul>
<li>表示一个目录项（名字和 inode 的映射关系）。</li>
<li>同一个文件路径对应一个唯一的 dentry（dcache 缓存）。</li>
<li>多个 dentry 可以指向同一个 inode（硬链接）。</li>
</ul>
</li>
<li>索引结点：每个索引结点的编号可以唯一地标识本文件系统中的文件，不同文件系统上可以有相同的索引号。它纪录了文件的名字、索引节点指针以及与其他目录项的层级关联关系。 多个目录项关联起来，就会形成目录结构，因为目录也是一个特殊的文件。且索引节点其是磁盘上索引节点的内存影像和拓展。<ul>
<li>表示一个文件系统对象（文件&#x2F;目录&#x2F;设备节点）的元数据（权限、大小、时间戳等）。</li>
<li>在内存中是唯一的：一个 inode number 在一个超级块里只有一个 <code>struct inode</code>。</li>
</ul>
</li>
<li>超级块：存放安装和挂载的文件系统基本信息。超级块是磁盘上超级块的内存影像和拓展。</li>
</ul>
<p>具体关系如图所示，并且都是多对一的关系，即多个文件描述符可以指向相同的文件对象（不同进程打开相同的文件），多个文件对象可以指向相同的目录项（比如同一个文件被打开多次，会产生多个struct file（fd）, 但是dentry相同）和inode节点，多个目录项可以指向相同的索引节点（硬链接）：</p>
<blockquote>
<p>PS: 这里顺便说一下软链接，软链接是一个单独的文件，里面存放路径字符串。软链接文件有自己的 inode（类型 <code>S_IFLNK</code>），存放目标路径。软链接有独立的 dentry，<code>dentry-&gt;d_inode</code> 指向软链接自己的 inode。<code>open(&quot;symlink&quot;)</code> 通常触发路径解析，VFS 调用 <code>-&gt;follow_link</code>（旧 API，内核新版本改为 <code>-&gt;get_link</code>），解析目标路径，再返回目标文件的 dentry&#x2F;inode。</p>
</blockquote>
<p><img src="https://zhuzhuzaiimgbed.oss-cn-hangzhou.aliyuncs.com/img/20251003135609606.png" alt="image-20251003135608114"></p>
<p>对于查找一个文件，我们以下图作为例子，假设需要找<code>/home/lqm/file1</code>,先在磁盘上找到<code>/</code>根目录对应的索引节点和内容，取到内存构造dentry，和inode的内存映像，然后找到下一级目录l2的索引节点，这样依次类推。</p>
<ul>
<li><strong>起点</strong>：内核通过进程的 <code>fs_struct</code> 知道当前根目录（可能是 <code>/</code>，也可能是 chroot&#x2F;jail 的某个子目录）和当前工作目录 <code>pwd</code>。<br> 对于绝对路径 <code>/home/lqm/file1</code>，查找从根目录 inode 开始。</li>
<li><strong>第一级 <code>/</code></strong>：<ul>
<li>找到根目录 inode（假设编号 <code>0</code> 或 <code>1</code>），把它读入内存形成 <code>struct inode</code>。</li>
<li>内核为 <code>/</code> 目录项建立一个 <code>struct dentry</code>，并与 inode 关联。</li>
<li>读出root的目录页，到page_cache, 然后用look_up查看对应下一级是否存在</li>
</ul>
</li>
<li><strong>第二级 <code>home</code></strong>：<ul>
<li>在根目录数据块中找到 <code>home</code> 这个目录项（dentry 名字 -&gt; inode 号）。</li>
<li>读出 <code>home</code> 的 inode，建立 <code>dentry(&quot;home&quot;)</code>，挂到 <code>/</code> 的 dentry 树下。</li>
</ul>
</li>
<li><strong>第三级 <code>lqm</code></strong>：同样，找到 inode <code>X3</code>，建立 <code>dentry(&quot;lqm&quot;)</code>。</li>
<li><strong>第四级 <code>file1</code></strong>：<ul>
<li>在 <code>lqm</code> 目录数据里找到 <code>file1</code> → inode <code>Y4</code>。</li>
<li>读出 <code>Y4</code> 的 inode，建立 <code>dentry(&quot;file1&quot;)</code>。</li>
</ul>
</li>
</ul>
<p>此时路径解析完成，<code>dentry(&quot;file1&quot;)</code> + <code>inode(Y4)</code> 已经在内核内存里。</p>
<p><img src="https://zhuzhuzaiimgbed.oss-cn-hangzhou.aliyuncs.com/img/20251003141120967.png" alt="image-20251003141119081"></p>
<h1 id="打开文件的源码解析"><a href="#打开文件的源码解析" class="headerlink" title="打开文件的源码解析"></a>打开文件的源码解析</h1><p>看了那么多理论，show me the code，我们就看看进程调用open之后，创建file_struct等过程</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">//include/linux/syscalls.h</span></span><br><span class="line"><span class="comment">//首先syscall表处理函数跳转到sys_open，具体看文件arch/x86/entry/syscalls/syscall_64.tbl中</span></span><br><span class="line"><span class="comment">//2	 common	 open			sys_open</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">// 然后sys_open 调用一个宏嵌套</span></span><br><span class="line"></span><br><span class="line">SYSCALL_DEFINE3(open, <span class="type">const</span> <span class="type">char</span> __user *, filename, <span class="type">int</span>, flags, <span class="type">umode_t</span>, mode)</span><br><span class="line">&#123;</span><br><span class="line">	<span class="keyword">if</span> (force_o_largefile())</span><br><span class="line">		flags |= O_LARGEFILE;</span><br><span class="line">	<span class="keyword">return</span> do_sys_open(AT_FDCWD, filename, flags, mode);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//SYSCALL_DEFINEx(3, open, const char __user *, filename, int, flags, umode_t, mode)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> SYSCALL_DEFINE3(name, ...) SYSCALL_DEFINEx(3, _##name, __VA_ARGS__)</span></span><br><span class="line"><span class="comment">//__SYSCALL_DEFINEx(3, _open, const char __user *, filename, int, flags, umode_t, mode)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> SYSCALL_DEFINEx(x, sname, ...)				\</span></span><br><span class="line"><span class="meta">	SYSCALL_METADATA(sname, x, __VA_ARGS__)			\ <span class="comment">//这个宏定义是空，直接看下面这一行</span></span></span><br><span class="line">	__SYSCALL_DEFINEx(x, sname, __VA_ARGS__)</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"><span class="comment">/*生成一个别名函数asmlinkage long sys_open(const char __user * filename, int flags, umode_t mode)</span></span><br><span class="line"><span class="comment">    __attribute__((alias(&quot;__se_sys_open&quot;))); </span></span><br><span class="line"><span class="comment">声明一个函数static inline long __do_sys_open(const char __user * filename, int flags, umode_t mode);</span></span><br><span class="line"><span class="comment">声明一个函数并实现</span></span><br><span class="line"><span class="comment">	asmlinkage long __se_sys_open(const char __user * filename, int flags, umode_t mode);	\</span></span><br><span class="line"><span class="comment">	asmlinkage long __se_sys_open(const char __user * filename, int flags, umode_t mode)	\</span></span><br><span class="line"><span class="comment">	&#123;								\</span></span><br><span class="line"><span class="comment">		long ret = __do_sys_open(const char __user * filename, int flags, umode_t mode);\</span></span><br><span class="line"><span class="comment">		做一些参数检查</span></span><br><span class="line"><span class="comment">		return ret;						\</span></span><br><span class="line"><span class="comment">	&#125;			</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> __SYSCALL_DEFINEx(x, name, ...)					\</span></span><br><span class="line"><span class="meta">	__diag_push();							\</span></span><br><span class="line"><span class="meta">	__diag_ignore(GCC, 8, <span class="string">&quot;-Wattribute-alias&quot;</span>,			\</span></span><br><span class="line"><span class="meta">		      <span class="string">&quot;Type aliasing is used to sanitize syscall arguments&quot;</span>);\</span></span><br><span class="line"><span class="meta">	asmlinkage long sys##name(__MAP(x,__SC_DECL,__VA_ARGS__))	\</span></span><br><span class="line"><span class="meta">		__attribute__((alias(__stringify(__se_sys##name))));	\</span></span><br><span class="line"><span class="meta">	ALLOW_ERROR_INJECTION(sys##name, ERRNO);			\</span></span><br><span class="line"><span class="meta">	static inline long __do_sys##name(__MAP(x,__SC_DECL,__VA_ARGS__));\</span></span><br><span class="line"><span class="meta">	asmlinkage long __se_sys##name(__MAP(x,__SC_LONG,__VA_ARGS__));	\</span></span><br><span class="line"><span class="meta">	asmlinkage long __se_sys##name(__MAP(x,__SC_LONG,__VA_ARGS__))	\</span></span><br><span class="line"><span class="meta">	&#123;								\</span></span><br><span class="line"><span class="meta">		long ret = __do_sys##name(__MAP(x,__SC_CAST,__VA_ARGS__));\</span></span><br><span class="line"><span class="meta">		__MAP(x,__SC_TEST,__VA_ARGS__);				\</span></span><br><span class="line"><span class="meta">		__PROTECT(x, ret,__MAP(x,__SC_ARGS,__VA_ARGS__));	\</span></span><br><span class="line"><span class="meta">		return ret;						\</span></span><br><span class="line"><span class="meta">	&#125;								\</span></span><br><span class="line"><span class="meta">	__diag_pop();							\</span></span><br><span class="line"><span class="meta">	static inline long __do_sys##name(__MAP(x,__SC_DECL,__VA_ARGS__))</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span> <span class="comment">/* __SYSCALL_DEFINEx */</span></span></span><br><span class="line">        </span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">最后跑到了static inline long __do_sys##name(__MAP(x,__SC_DECL,__VA_ARGS__))，再加上最开始的声明部分，实际__do_sys_open函数内容就是如下：</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="type">static</span> <span class="keyword">inline</span> <span class="type">long</span> __do_sys_open(<span class="type">int</span> dfd, <span class="type">const</span> <span class="type">char</span> __user *filename,</span><br><span class="line">                                 <span class="type">int</span> flags, <span class="type">umode_t</span> mode)</span><br><span class="line">&#123;</span><br><span class="line">	<span class="keyword">if</span> (force_o_largefile())</span><br><span class="line">		flags |= O_LARGEFILE;</span><br><span class="line">	<span class="keyword">return</span> do_sys_open(AT_FDCWD, filename, flags, mode);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>经过上面分析这些宏，其实最终是到do_sys_open函数，我们来看看这个函数</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// fs/open.c</span></span><br><span class="line"><span class="comment">//dfd：目录文件描述符（通常是 AT_FDCWD 表示当前目录）。</span></span><br><span class="line"><span class="type">long</span> <span class="title function_">do_sys_open</span><span class="params">(<span class="type">int</span> dfd, <span class="type">const</span> <span class="type">char</span> __user *filename, <span class="type">int</span> flags, <span class="type">umode_t</span> mode)</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">open_how</span> <span class="title">how</span> =</span> build_open_how(flags, mode); <span class="comment">//把老式 flags + mode 参数转换成统一的 struct open_how，为 openat2 接口服务。</span></span><br><span class="line">	<span class="keyword">return</span> do_sys_openat2(dfd, filename, &amp;how);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="type">long</span> <span class="title function_">do_sys_openat2</span><span class="params">(<span class="type">int</span> dfd, <span class="type">const</span> <span class="type">char</span> __user *filename,</span></span><br><span class="line"><span class="params">			   <span class="keyword">struct</span> open_how *how)</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">open_flags</span> <span class="title">op</span>;</span></span><br><span class="line">	<span class="type">int</span> fd = build_open_flags(how, &amp;op); <span class="comment">//解析用户传进来的 flags（如 O_CREAT, O_TRUNC, O_APPEND），填充成 open_flags 结构。成功会return 0. 不然返回-EINVAL; 这个fd命名也忒。。。</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">filename</span> *<span class="title">tmp</span>;</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> (fd)</span><br><span class="line">		<span class="keyword">return</span> fd;</span><br><span class="line"></span><br><span class="line">	tmp = getname(filename); <span class="comment">//从用户空间拷贝文件名到内核空间，得到一个 struct filename 对象。用户态指针 const char __user *filename → 内核安全的 filename。</span></span><br><span class="line">	<span class="keyword">if</span> (IS_ERR(tmp))</span><br><span class="line">		<span class="keyword">return</span> PTR_ERR(tmp);</span><br><span class="line"></span><br><span class="line">	fd = get_unused_fd_flags(how-&gt;flags); <span class="comment">//从当前进程的 fd 表里找一个空闲的 fd slot。</span></span><br><span class="line">	<span class="keyword">if</span> (fd &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">		<span class="class"><span class="keyword">struct</span> <span class="title">file</span> *<span class="title">f</span> =</span> do_filp_open(dfd, tmp, &amp;op);</span><br><span class="line">		<span class="keyword">if</span> (IS_ERR(f)) &#123;</span><br><span class="line">			put_unused_fd(fd);</span><br><span class="line">			fd = PTR_ERR(f);</span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			fd_install(fd, f);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	putname(tmp);</span><br><span class="line">	<span class="keyword">return</span> fd;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>先关注如何获取空闲fd的，即<code>get_unused_fd_flags(how-&gt;flags)</code>，就是前面说的利用file_struct结构体中的字段来获取到一个空闲的fd的。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">get_unused_fd_flags</span><span class="params">(<span class="type">unsigned</span> flags)</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="keyword">return</span> __get_unused_fd_flags(flags, rlimit(RLIMIT_NOFILE));</span><br><span class="line">&#125;</span><br><span class="line">EXPORT_SYMBOL(get_unused_fd_flags);</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> __get_unused_fd_flags(<span class="type">unsigned</span> flags, <span class="type">unsigned</span> <span class="type">long</span> nofile)</span><br><span class="line">&#123;</span><br><span class="line">	<span class="keyword">return</span> alloc_fd(<span class="number">0</span>, nofile, flags);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="type">int</span> <span class="title function_">alloc_fd</span><span class="params">(<span class="type">unsigned</span> start, <span class="type">unsigned</span> end, <span class="type">unsigned</span> flags)</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">files_struct</span> *<span class="title">files</span> =</span> current-&gt;files; <span class="comment">//获取到当前task_struct中的files_struct，即所有打开的files相关内容，里面有fdtable表。</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">int</span> fd;</span><br><span class="line">	<span class="type">int</span> error;</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">fdtable</span> *<span class="title">fdt</span>;</span></span><br><span class="line"></span><br><span class="line">	spin_lock(&amp;files-&gt;file_lock); <span class="comment">//加锁</span></span><br><span class="line">repeat:</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">    #define files_fdtable(files) \</span></span><br><span class="line"><span class="comment">	rcu_dereference_check_fdtable((files), (files)-&gt;fdt)</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">	fdt = files_fdtable(files); <span class="comment">//RCU读锁，读fdt指针</span></span><br><span class="line">	fd = start; <span class="comment">//fd从0开始</span></span><br><span class="line">	<span class="keyword">if</span> (fd &lt; files-&gt;next_fd)  <span class="comment">//从next_fd开始搜索</span></span><br><span class="line">		fd = files-&gt;next_fd;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> (fd &lt; fdt-&gt;max_fds)  <span class="comment">//如果找到就找到了，不然需要扩展fdt。</span></span><br><span class="line">		fd = find_next_fd(fdt, fd);  <span class="comment">//根据位图寻找</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * N.B. For clone tasks sharing a files structure, this test</span></span><br><span class="line"><span class="comment">	 * will limit the total number of files that can be opened.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	error = -EMFILE;</span><br><span class="line">	<span class="keyword">if</span> (fd &gt;= end)</span><br><span class="line">		<span class="keyword">goto</span> out;</span><br><span class="line"></span><br><span class="line">	error = expand_files(files, fd);</span><br><span class="line">	<span class="keyword">if</span> (error &lt; <span class="number">0</span>)</span><br><span class="line">		<span class="keyword">goto</span> out;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * If we needed to expand the fs array we</span></span><br><span class="line"><span class="comment">	 * might have blocked - try again.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="keyword">if</span> (error)</span><br><span class="line">		<span class="keyword">goto</span> repeat;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> (start &lt;= files-&gt;next_fd)</span><br><span class="line">		files-&gt;next_fd = fd + <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">	__set_open_fd(fd, fdt);</span><br><span class="line">	<span class="keyword">if</span> (flags &amp; O_CLOEXEC)</span><br><span class="line">		__set_close_on_exec(fd, fdt);</span><br><span class="line">	<span class="keyword">else</span></span><br><span class="line">		__clear_close_on_exec(fd, fdt);</span><br><span class="line">	error = fd;</span><br><span class="line"><span class="meta">#<span class="keyword">if</span> 1</span></span><br><span class="line">	<span class="comment">/* Sanity check */</span></span><br><span class="line">	<span class="keyword">if</span> (rcu_access_pointer(fdt-&gt;fd[fd]) != <span class="literal">NULL</span>) &#123;</span><br><span class="line">		printk(KERN_WARNING <span class="string">&quot;alloc_fd: slot %d not NULL!\n&quot;</span>, fd);</span><br><span class="line">		rcu_assign_pointer(fdt-&gt;fd[fd], <span class="literal">NULL</span>);</span><br><span class="line">	&#125;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">out:</span><br><span class="line">	spin_unlock(&amp;files-&gt;file_lock);</span><br><span class="line">	<span class="keyword">return</span> error;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>得到空闲fd号之后，构建对应的struct file结构体</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">file</span> *<span class="title">f</span> =</span> do_filp_open(dfd, tmp, &amp;op);</span><br><span class="line"><span class="keyword">if</span> (IS_ERR(f)) &#123;</span><br><span class="line">			put_unused_fd(fd); <span class="comment">//失败：释放刚刚预留的 fd slot。</span></span><br><span class="line">			fd = PTR_ERR(f);</span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			fd_install(fd, f); <span class="comment">//成功则调用 fd_install(fd, f)，把 struct file * 安装到当前进程的文件描述符表里。</span></span><br><span class="line">		&#125;</span><br></pre></td></tr></table></figure>

<p>那么关键就是构建file struct这个结构体的函数do_filp_open, 然后核心就是使用kmem_cache_zalloc去分配一个结构体，这个是一个slab cache，再初始化相应字段，最后就返回了。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> file *<span class="title function_">do_filp_open</span><span class="params">(<span class="type">int</span> dfd, <span class="keyword">struct</span> filename *pathname,</span></span><br><span class="line"><span class="params">		<span class="type">const</span> <span class="keyword">struct</span> open_flags *op)</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">nameidata</span> <span class="title">nd</span>;</span></span><br><span class="line">	<span class="type">int</span> flags = op-&gt;lookup_flags;</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">file</span> *<span class="title">filp</span>;</span></span><br><span class="line"></span><br><span class="line">	set_nameidata(&amp;nd, dfd, pathname, <span class="literal">NULL</span>); <span class="comment">//填充nameidata数据结构</span></span><br><span class="line">	filp = path_openat(&amp;nd, op, flags | LOOKUP_RCU);</span><br><span class="line">	<span class="keyword">if</span> (unlikely(filp == ERR_PTR(-ECHILD)))</span><br><span class="line">		filp = path_openat(&amp;nd, op, flags);</span><br><span class="line">	<span class="keyword">if</span> (unlikely(filp == ERR_PTR(-ESTALE)))</span><br><span class="line">		filp = path_openat(&amp;nd, op, flags | LOOKUP_REVAL);</span><br><span class="line">	restore_nameidata();</span><br><span class="line">	<span class="keyword">return</span> filp;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="type">void</span> __set_nameidata(<span class="keyword">struct</span> nameidata *p, <span class="type">int</span> dfd, <span class="keyword">struct</span> filename *name)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">nameidata</span> *<span class="title">old</span> =</span> current-&gt;nameidata;</span><br><span class="line">    p-&gt;<span class="built_in">stack</span> = p-&gt;internal;</span><br><span class="line">    p-&gt;depth = <span class="number">0</span>;</span><br><span class="line">    p-&gt;dfd = dfd;</span><br><span class="line">    p-&gt;name = name;</span><br><span class="line">    p-&gt;path.mnt = <span class="literal">NULL</span>;</span><br><span class="line">    p-&gt;path.dentry = <span class="literal">NULL</span>;</span><br><span class="line">    p-&gt;total_link_count = old ? old-&gt;total_link_count : <span class="number">0</span>;</span><br><span class="line">    p-&gt;saved = old;</span><br><span class="line">    current-&gt;nameidata = p;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="keyword">struct</span> file *<span class="title function_">path_openat</span><span class="params">(<span class="keyword">struct</span> nameidata *nd,</span></span><br><span class="line"><span class="params">                                <span class="type">const</span> <span class="keyword">struct</span> open_flags *op, <span class="type">unsigned</span> flags)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">file</span> *<span class="title">file</span>;</span></span><br><span class="line">    <span class="type">int</span> error;</span><br><span class="line"></span><br><span class="line">    file = alloc_empty_file(op-&gt;open_flag, current_cred());</span><br><span class="line">    <span class="keyword">if</span> (IS_ERR(file))</span><br><span class="line">        <span class="keyword">return</span> file;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (unlikely(file-&gt;f_flags &amp; __O_TMPFILE)) &#123;</span><br><span class="line">        error = do_tmpfile(nd, flags, op, file); <span class="comment">//open(..., O_TMPFILE, ...)，表示创建匿名临时文件（不会出现在目录树中）。交给 do_tmpfile 处理。</span></span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (unlikely(file-&gt;f_flags &amp; O_PATH)) &#123;</span><br><span class="line">        error = do_o_path(nd, flags, file); <span class="comment">//open(..., O_PATH)，表示只获取一个路径句柄，不真正打开文件（不能读写）。交给 do_o_path 处理。</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="type">const</span> <span class="type">char</span> *s = path_init(nd, flags); <span class="comment">//初始化路径起点是root还是pwd，返回下一个需要解析的路径字符串</span></span><br><span class="line">        <span class="keyword">while</span> (!(error = link_path_walk(s, nd)) &amp;&amp; <span class="comment">//逐级解析路径分量，例如 /home/lqm/file1 就会依次解析 home → lqm → file1，在内存中找到相应的 dentry 和 inode。</span></span><br><span class="line">               (s = open_last_lookups(nd, file, op)) != <span class="literal">NULL</span>) <span class="comment">//处理路径的最后一部分（可能是文件本身，或者符号链接）。</span></span><br><span class="line">            ;</span><br><span class="line">        <span class="keyword">if</span> (!error)</span><br><span class="line">            error = do_open(nd, file, op); <span class="comment">//检查文件是否存在，不存在就创建。检查权限，最后调用文件系统的open函数</span></span><br><span class="line">        terminate_walk(nd); <span class="comment">//结束路径遍历，释放临时资源（比如 nameidata 里保存的路径栈）。</span></span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">&#125;      </span><br><span class="line"><span class="keyword">struct</span> file *<span class="title function_">alloc_empty_file</span><span class="params">(<span class="type">int</span> flags, <span class="type">const</span> <span class="keyword">struct</span> cred *cred)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">file</span> *<span class="title">f</span>;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (get_nr_files() &gt;= files_stat.max_files &amp;&amp; !capable(CAP_SYS_ADMIN)) &#123;</span><br><span class="line">        <span class="keyword">if</span> (percpu_counter_sum_positive(&amp;nr_files) &gt;= files_stat.max_files)</span><br><span class="line">            <span class="keyword">goto</span> over;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    f = kmem_cache_zalloc(filp_cachep, GFP_KERNEL);</span><br><span class="line">	...</span><br><span class="line">    <span class="keyword">return</span> f;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>note</category>
      </categories>
      <tags>
        <tag>os</tag>
      </tags>
  </entry>
  <entry>
    <title>x86_64系统调用</title>
    <url>/2025/09/19/note/%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/</url>
    <content><![CDATA[<h1 id="系统调用"><a href="#系统调用" class="headerlink" title="系统调用"></a>系统调用</h1><p>本文专注于x86_64架构的系统调用，与x86架构不同的是，32位使用的是int80中断来处理的系统调用，具体看<code>arch/x86/entry/entry_32.S</code>文件。 而x86_64架构对应的kernel入口在entry_64.S中，其直接使用syscall指令。二者的区别在于，</p>
<ul>
<li><p>直接使用syscall需要保存的寄存器数量更少。x86 的 <code>int 0x80</code>需要保存更多寄存器（如 <code>CS:EIP</code>、<code>SS:ESP</code>、<code>EFLAGS</code>等），而 <code>syscall</code>仅保存 <code>RFLAGS</code>和 <code>CS:RIP</code>，因此减少了上下文切换的开销。此外x86_64还避免了中断处理的开销。</p>
</li>
<li><p>参数传递的寄存器不同。<strong>x86</strong>：前6个参数依次通过 <code>ebx</code>、<code>ecx</code>、<code>edx</code>、<code>esi</code>、<code>edi</code>、<code>ebp</code>传递，超出部分通过栈传递。<strong>x86_64</strong>：前6个参数通过 <code>rdi</code>、<code>rsi</code>、<code>rdx</code>、<code>r10</code>、<code>r8</code>、<code>r9</code>传递，且第四个参数（原 <code>ecx</code>）改为 <code>r10</code>，以避免与返回地址冲突。<strong>关键区别</strong>在于x86_64 的 <code>rcx</code>寄存器用于保存返回地址，因此参数传递需避开该寄存器。</p>
</li>
<li><p>错误码返回不同。两者均通过 <code>eax/rax</code>返回结果，但 x86_64 的错误码以负数形式（范围 <code>-4095</code>至 <code>-1</code>）表示，而 x86 使用正数错误码。</p>
</li>
</ul>
<h2 id="系统调用的初始化"><a href="#系统调用的初始化" class="headerlink" title="系统调用的初始化"></a>系统调用的初始化</h2><p>在系统启动之初的CPU_init阶段，会对CPU上一些MSR寄存器进行初始化，而对于syscall_init部分的初始化在syscall_init函数中。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// file: arch/x86/kernel/cpu/common.c</span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">syscall_init</span><span class="params">(<span class="type">void</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="comment">/* The default user and kernel segments */</span></span><br><span class="line">	wrmsr(MSR_STAR, <span class="number">0</span>, (__USER32_CS &lt;&lt; <span class="number">16</span>) | __KERNEL_CS);</span><br><span class="line"></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * Except the IA32_STAR MSR, there is NO need to setup SYSCALL and</span></span><br><span class="line"><span class="comment">	 * SYSENTER MSRs for FRED, because FRED uses the ring 3 FRED</span></span><br><span class="line"><span class="comment">	 * entrypoint for SYSCALL and SYSENTER, and ERETU is the only legit</span></span><br><span class="line"><span class="comment">	 * instruction to return to ring 3 (both sysexit and sysret cause</span></span><br><span class="line"><span class="comment">	 * #UD when FRED is enabled).</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="keyword">if</span> (!cpu_feature_enabled(X86_FEATURE_FRED))</span><br><span class="line">		idt_syscall_init();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="keyword">inline</span> <span class="type">void</span> <span class="title function_">idt_syscall_init</span><span class="params">(<span class="type">void</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">	wrmsrl(MSR_LSTAR, (<span class="type">unsigned</span> <span class="type">long</span>)entry_SYSCALL_64);</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> (ia32_enabled()) &#123;</span><br><span class="line">		wrmsrl_cstar((<span class="type">unsigned</span> <span class="type">long</span>)entry_SYSCALL_compat);</span><br><span class="line">		<span class="comment">/*</span></span><br><span class="line"><span class="comment">		 * This only works on Intel CPUs.</span></span><br><span class="line"><span class="comment">		 * On AMD CPUs these MSRs are 32-bit, CPU truncates MSR_IA32_SYSENTER_EIP.</span></span><br><span class="line"><span class="comment">		 * This does not cause SYSENTER to jump to the wrong location, because</span></span><br><span class="line"><span class="comment">		 * AMD doesn&#x27;t allow SYSENTER in long mode (either 32- or 64-bit).</span></span><br><span class="line"><span class="comment">		 */</span></span><br><span class="line">		wrmsrl_safe(MSR_IA32_SYSENTER_CS, (u64)__KERNEL_CS);</span><br><span class="line">		wrmsrl_safe(MSR_IA32_SYSENTER_ESP,</span><br><span class="line">			    (<span class="type">unsigned</span> <span class="type">long</span>)(cpu_entry_stack(smp_processor_id()) + <span class="number">1</span>));</span><br><span class="line">		wrmsrl_safe(MSR_IA32_SYSENTER_EIP, (u64)entry_SYSENTER_compat);</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">		wrmsrl_cstar((<span class="type">unsigned</span> <span class="type">long</span>)entry_SYSCALL32_ignore);</span><br><span class="line">		wrmsrl_safe(MSR_IA32_SYSENTER_CS, (u64)GDT_ENTRY_INVALID_SEG);</span><br><span class="line">		wrmsrl_safe(MSR_IA32_SYSENTER_ESP, <span class="number">0ULL</span>);</span><br><span class="line">		wrmsrl_safe(MSR_IA32_SYSENTER_EIP, <span class="number">0ULL</span>);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * Flags to clear on syscall; clear as much as possible</span></span><br><span class="line"><span class="comment">	 * to minimize user space-kernel interference.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	wrmsrl(MSR_SYSCALL_MASK,</span><br><span class="line">	       X86_EFLAGS_CF|X86_EFLAGS_PF|X86_EFLAGS_AF|</span><br><span class="line">	       X86_EFLAGS_ZF|X86_EFLAGS_SF|X86_EFLAGS_TF|</span><br><span class="line">	       X86_EFLAGS_IF|X86_EFLAGS_DF|X86_EFLAGS_OF|</span><br><span class="line">	       X86_EFLAGS_IOPL|X86_EFLAGS_NT|X86_EFLAGS_RF|</span><br><span class="line">	       X86_EFLAGS_AC|X86_EFLAGS_ID);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>其中在第6行，将User段的cs和kernel段的cs写入MSR_STAR寄存器。第一个特殊模块集寄存器- <code>MSR_STAR</code> 的 <code>63:48</code> 为用户代码的代码段。这些数据将加载至 <code>CS</code> 和 <code>SS</code> 段选择符，由提供将系统调用返回至相应特权级的用户代码功能的 <code>sysret</code> 指令使用。 同时从内核代码来看， 当用户空间应用程序执行系统调用时，<code>MSR_STAR</code> 的 <code>47:32</code> 将作为 <code>CS</code> and <code>SS</code>段选择寄存器的基地址。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* The default user and kernel segments */</span></span><br><span class="line">	wrmsr(MSR_STAR, <span class="number">0</span>, (__USER32_CS &lt;&lt; <span class="number">16</span>) | __KERNEL_CS);</span><br></pre></td></tr></table></figure>

<p>然后在第21行写入entry_SYSCALL_64函数的地址，即kernel entry的入口地址。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">wrmsrl(MSR_LSTAR, (<span class="type">unsigned</span> <span class="type">long</span>)entry_SYSCALL_64);</span><br></pre></td></tr></table></figure>

<p>设置好系统调用入口后，需要以下特殊模式的寄存器进行操作，以方便64位CPU能够执行32位的程序。</p>
<ul>
<li><code>MSR_CSTAR</code> - target <code>rip</code> for the compability mode callers;</li>
<li><code>MSR_IA32_SYSENTER_CS</code> - target <code>cs</code> for the <code>sysenter</code> instruction;</li>
<li><code>MSR_IA32_SYSENTER_ESP</code> - target <code>esp</code> for the <code>sysenter</code> instruction;</li>
<li><code>MSR_IA32_SYSENTER_EIP</code> - target <code>eip</code> for the <code>sysenter</code> instruction.</li>
</ul>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (ia32_enabled()) &#123;</span><br><span class="line">		wrmsrl_cstar((<span class="type">unsigned</span> <span class="type">long</span>)entry_SYSCALL_compat);</span><br><span class="line">		<span class="comment">/*</span></span><br><span class="line"><span class="comment">		 * This only works on Intel CPUs.</span></span><br><span class="line"><span class="comment">		 * On AMD CPUs these MSRs are 32-bit, CPU truncates MSR_IA32_SYSENTER_EIP.</span></span><br><span class="line"><span class="comment">		 * This does not cause SYSENTER to jump to the wrong location, because</span></span><br><span class="line"><span class="comment">		 * AMD doesn&#x27;t allow SYSENTER in long mode (either 32- or 64-bit).</span></span><br><span class="line"><span class="comment">		 */</span></span><br><span class="line">		wrmsrl_safe(MSR_IA32_SYSENTER_CS, (u64)__KERNEL_CS);</span><br><span class="line">		wrmsrl_safe(MSR_IA32_SYSENTER_ESP,</span><br><span class="line">			    (<span class="type">unsigned</span> <span class="type">long</span>)(cpu_entry_stack(smp_processor_id()) + <span class="number">1</span>));</span><br><span class="line">		wrmsrl_safe(MSR_IA32_SYSENTER_EIP, (u64)entry_SYSENTER_compat);</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">		wrmsrl_cstar((<span class="type">unsigned</span> <span class="type">long</span>)entry_SYSCALL32_ignore);</span><br><span class="line">		wrmsrl_safe(MSR_IA32_SYSENTER_CS, (u64)GDT_ENTRY_INVALID_SEG);</span><br><span class="line">		wrmsrl_safe(MSR_IA32_SYSENTER_ESP, <span class="number">0ULL</span>);</span><br><span class="line">		wrmsrl_safe(MSR_IA32_SYSENTER_EIP, <span class="number">0ULL</span>);</span><br><span class="line">	&#125;</span><br><span class="line">	wrmsrl(MSR_SYSCALL_MASK,</span><br><span class="line">	       X86_EFLAGS_CF|X86_EFLAGS_PF|X86_EFLAGS_AF|</span><br><span class="line">	       X86_EFLAGS_ZF|X86_EFLAGS_SF|X86_EFLAGS_TF|</span><br><span class="line">	       X86_EFLAGS_IF|X86_EFLAGS_DF|X86_EFLAGS_OF|</span><br><span class="line">	       X86_EFLAGS_IOPL|X86_EFLAGS_NT|X86_EFLAGS_RF|</span><br><span class="line">	       X86_EFLAGS_AC|X86_EFLAGS_ID);  <span class="comment">//禁止中断和一些别的掩码位，最重要的是禁止中断。也就是说syscall是不允许中断的</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这里需要了解一下几个寄存器的作用</p>
<ul>
<li><code>esp </code>- 当前栈顶</li>
<li><code>eip</code> - 下一条指令地址</li>
<li><code>ebp</code> - 当前栈底</li>
<li><code>cs</code> - 代码段地址</li>
</ul>
<p>这里代码就是比较明了，就是把32位程序的使用的一些MSR寄存器等进行设置，把64位下的值给他们。不过这是关于64位程序运行32位的部分，因此我们先跳过这块，直接看具体的入口函数，即<code>entry_SYSCALL_64</code>，该函数地址被写入MSR_LSTAR寄存器，一旦用户态执行syscall指令，就会跳转到该地址进行执行。</p>
<p>syscall指令主要做了以下几件事：</p>
<ul>
<li><p>把<code>syscall</code>指令的下一条指令（也就是返回地址）存入 <code>%rcx</code> 寄存，然后把指令指针寄存器 <code>%rip</code> 替换成IA32_LSTAR MSR寄存器里的值。</p>
</li>
<li><p>把 rflags 标志寄存器的值保存到 <code>%r11</code>，然后把 rflags 的值与 IA32_FMASK MSR 里的值做掩码运算。</p>
</li>
<li><p>把 IA32_STAR MSR寄存器里第32~47位加载到 CS 和 SS 段寄存器。</p>
</li>
</ul>
<h2 id="真正系统调用"><a href="#真正系统调用" class="headerlink" title="真正系统调用"></a>真正系统调用</h2><h3 id="进入内核态运行代码之前需要的一些准备工作（切换段寄存器和CR3等）"><a href="#进入内核态运行代码之前需要的一些准备工作（切换段寄存器和CR3等）" class="headerlink" title="进入内核态运行代码之前需要的一些准备工作（切换段寄存器和CR3等）"></a>进入内核态运行代码之前需要的一些准备工作（切换段寄存器和CR3等）</h3><p>然后我们来看真正的内核入口的汇编代码</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SYM_CODE_START(entry_SYSCALL_64)</span><br><span class="line">	UNWIND_HINT_ENTRY</span><br><span class="line">	ENDBR</span><br><span class="line">	</span><br><span class="line">	swapgs </span><br><span class="line">	/* tss.sp2 is scratch space. */</span><br><span class="line">	movq	%rsp, PER_CPU_VAR(cpu_tss_rw + TSS_sp2)</span><br><span class="line">	SWITCH_TO_KERNEL_CR3 scratch_reg=%rsp</span><br><span class="line">	movq	PER_CPU_VAR(pcpu_hot + X86_top_of_stack), %rsp</span><br><span class="line"></span><br><span class="line">SYM_INNER_LABEL(entry_SYSCALL_64_safe_stack, SYM_L_GLOBAL)</span><br><span class="line">	ANNOTATE_NOENDBR</span><br><span class="line"></span><br><span class="line">	/* Construct struct pt_regs on stack */</span><br><span class="line">	pushq	$__USER_DS				/* pt_regs-&gt;ss */</span><br><span class="line">	pushq	PER_CPU_VAR(cpu_tss_rw + TSS_sp2)	/* pt_regs-&gt;sp */</span><br><span class="line">	pushq	%r11					/* pt_regs-&gt;flags */</span><br><span class="line">	pushq	$__USER_CS				/* pt_regs-&gt;cs */</span><br><span class="line">	pushq	%rcx					/* pt_regs-&gt;ip */</span><br><span class="line">SYM_INNER_LABEL(entry_SYSCALL_64_after_hwframe, SYM_L_GLOBAL)</span><br><span class="line">	pushq	%rax					/* pt_regs-&gt;orig_ax */</span><br><span class="line"></span><br><span class="line">	PUSH_AND_CLEAR_REGS rax=$-ENOSYS</span><br><span class="line"></span><br><span class="line">	/* IRQs are off. */</span><br><span class="line">	movq	%rsp, %rdi</span><br><span class="line">	/* Sign extend the lower 32bit as syscall numbers are treated as int */</span><br><span class="line">	movslq	%eax, %rsi</span><br><span class="line"></span><br><span class="line">	/* clobbers %rax, make sure it is after saving the syscall nr */</span><br><span class="line">	IBRS_ENTER</span><br><span class="line">	UNTRAIN_RET</span><br><span class="line">	CLEAR_BRANCH_HISTORY</span><br><span class="line"></span><br><span class="line">	call	do_syscall_64		/* returns with IRQs disabled */</span><br></pre></td></tr></table></figure>

<p>首先前两行，第一行是处理ftrace,kprobe等关于内核栈调用和调试信息相关的部分，我们不关心，因此跳过，第二行是x86开启CET保护后，函数call过来必须跳转的指令，不然会异常，所以我们也不关心。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">UNWIND_HINT_ENTRY</span><br><span class="line">ENDBR</span><br></pre></td></tr></table></figure>

<p>然后是切换GS段基址，从用户态切换到内核态。因为x86-64上有一个per CPU数据区域，是需要通过GS寄存器访问的，在用户态下GS 指向用户线程的 TLS；内核态下，GS 指向内核的 <code>per_cpu</code> 数据。这一步是从用户态的段切换到内核态的段。<code>PS：其实这里切换来切换去都是同一个段，因为平坦内存模型，在GDT表中，所有的段的基址都是0，只是不同段的idx不同，比如12 - kernel code segment， 13 - kernel data segment， 14 - default user CS （具体看文件arch/x86/include/asm/segment.h中的注释）所以这里只是一个历史遗留问题，为了保证早期只支持段的设备做的。</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">swapgs </span><br></pre></td></tr></table></figure>

<p>然后把当前用户态的栈指针<code>%RSP</code>临时存储的TSS段，注释已经告诉我们这个段的sp2字段是空的。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/* tss.sp2 is scratch space. */</span><br><span class="line">movq	%rsp, PER_CPU_VAR(cpu_tss_rw + TSS_sp2)</span><br></pre></td></tr></table></figure>

<p>然后是切换页表到内核页表，即修改CR3寄存器。这个宏把rsp当作一个临时寄存器，因为rsp的值已经存储过的。然后是一个处理CPU特性的宏，判断CPU支不支持PTI（Page Table Isolation），如果不支持就直接跳转到末尾<code>.Lend_\@</code>, 支持的话就接着执行下面的语句，当前语句是空<code>&quot;&quot;</code>.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SWITCH_TO_KERNEL_CR3 scratch_reg=%rsp</span><br><span class="line"></span><br><span class="line">.macro SWITCH_TO_KERNEL_CR3 scratch_reg:req</span><br><span class="line">	ALTERNATIVE &quot;jmp .Lend_\@&quot;, &quot;&quot;, X86_FEATURE_PTI</span><br><span class="line">	mov	%cr3, \scratch_reg</span><br><span class="line">	ADJUST_KERNEL_CR3 \scratch_reg</span><br><span class="line">	mov	\scratch_reg, %cr3</span><br><span class="line">.Lend_\@:</span><br><span class="line">.endm</span><br><span class="line"></span><br><span class="line">.macro ADJUST_KERNEL_CR3 reg:req</span><br><span class="line">	ALTERNATIVE &quot;&quot;, &quot;SET_NOFLUSH_BIT \reg&quot;, X86_FEATURE_PCID</span><br><span class="line">	/* Clear PCID and &quot;MITIGATION_PAGE_TABLE_ISOLATION bit&quot;, point CR3 at kernel pagetables: */</span><br><span class="line">	andq    $(~PTI_USER_PGTABLE_AND_PCID_MASK), \reg</span><br><span class="line">.endm</span><br><span class="line"></span><br><span class="line">#define PTI_USER_PGTABLE_BIT		PAGE_SHIFT</span><br><span class="line">#define PTI_USER_PGTABLE_MASK		(1 &lt;&lt; PTI_USER_PGTABLE_BIT)</span><br><span class="line">#define PTI_USER_PCID_BIT		X86_CR3_PTI_PCID_USER_BIT</span><br><span class="line">#define PTI_USER_PCID_MASK		(1 &lt;&lt; PTI_USER_PCID_BIT)</span><br><span class="line">#define PTI_USER_PGTABLE_AND_PCID_MASK  (PTI_USER_PCID_MASK | PTI_USER_PGTABLE_MASK)</span><br></pre></td></tr></table></figure>

<p>然后上面的宏第四行把CR3寄存器临时存到rsp寄存器里，然后又是一个宏，这里判断CPU支不支持PCID(Process Context ID)，如果支持就不需要flush TLB。同时把用户态CR3的PTI_USER_PCID_MASK和PTI_USER_PGTABLE_MASK清空，然后再将其写回CR3寄存器中。这里其实关键的地方在于，用户态的CR3和内核态的CR3只差了一页。用一张网上的图就是如下所示，所以这里把PTI_USER_PGTABLE_MASK，即1&lt;&lt;12这里变成了0，表明是kernel的CR3了。这里其实就是为了防护熔断和幽灵漏洞设置的KPTI部分。<br><img src="https://zhuzhuzaiimgbed.oss-cn-hangzhou.aliyuncs.com/img/image-20251001204334700.png" alt="image-20251001204334700"></p>
<p>最后就是切换到内核栈了,即把per-cpu变量中的栈顶写入RSP。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">movq PER_CPU_VAR(pcpu_hot + X86_top_of_stack), %rsp</span><br></pre></td></tr></table></figure>



<h3 id="保存用户态寄存器值"><a href="#保存用户态寄存器值" class="headerlink" title="保存用户态寄存器值"></a>保存用户态寄存器值</h3><p>前面已经设置好内核栈和内核态页表了之后，就开始保存一些寄存器的值了，我们一行行来看</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SYM_INNER_LABEL(entry_SYSCALL_64_safe_stack, SYM_L_GLOBAL)</span><br><span class="line">	ANNOTATE_NOENDBR #标记这个地址没有endbr指令，并不做什么关键的事情。</span><br><span class="line"></span><br><span class="line">	/* Construct struct pt_regs on stack */</span><br><span class="line">	pushq	$__USER_DS				/* pt_regs-&gt;ss */</span><br><span class="line">	pushq	PER_CPU_VAR(cpu_tss_rw + TSS_sp2)	/* pt_regs-&gt;sp */</span><br><span class="line">	pushq	%r11					/* pt_regs-&gt;flags */</span><br><span class="line">	pushq	$__USER_CS				/* pt_regs-&gt;cs */</span><br><span class="line">	pushq	%rcx					/* pt_regs-&gt;ip */</span><br><span class="line">SYM_INNER_LABEL(entry_SYSCALL_64_after_hwframe, SYM_L_GLOBAL)</span><br><span class="line">	pushq	%rax					/* pt_regs-&gt;orig_ax */</span><br><span class="line"></span><br><span class="line">	PUSH_AND_CLEAR_REGS rax=$-ENOSYS</span><br><span class="line">	</span><br><span class="line">.macro PUSH_AND_CLEAR_REGS rdx=%rdx rcx=%rcx rax=%rax save_ret=0 clear_bp=1 unwind_hint=1</span><br><span class="line">	PUSH_REGS rdx=\rdx, rcx=\rcx, rax=\rax, save_ret=\save_ret unwind_hint=\unwind_hint</span><br><span class="line">	CLEAR_REGS clear_bp=\clear_bp</span><br><span class="line">.endm</span><br><span class="line"></span><br><span class="line">.macro PUSH_REGS rdx=%rdx rcx=%rcx rax=%rax save_ret=0 unwind_hint=1</span><br><span class="line">	.if \save_ret</span><br><span class="line">	pushq	%rsi		/* pt_regs-&gt;si */  # 有些情况栈上已经会存在返回地址，例如call指令压入的，如果直接push会导致返回地址被破坏，因此先把返回地址保存一下，</span><br><span class="line">	movq	8(%rsp), %rsi	/* temporarily store the return address in %rsi */</span><br><span class="line">	movq	%rdi, 8(%rsp)	/* pt_regs-&gt;di (overwriting original return address) */</span><br><span class="line">	.else</span><br><span class="line">	pushq   %rdi		/* pt_regs-&gt;di */</span><br><span class="line">	pushq   %rsi		/* pt_regs-&gt;si */</span><br><span class="line">	.endif</span><br><span class="line">	pushq	\rdx		/* pt_regs-&gt;dx */</span><br><span class="line">	pushq   \rcx		/* pt_regs-&gt;cx */</span><br><span class="line">	pushq   \rax		/* pt_regs-&gt;ax */</span><br><span class="line">	pushq   %r8		/* pt_regs-&gt;r8 */</span><br><span class="line">	pushq   %r9		/* pt_regs-&gt;r9 */</span><br><span class="line">	pushq   %r10		/* pt_regs-&gt;r10 */</span><br><span class="line">	pushq   %r11		/* pt_regs-&gt;r11 */</span><br><span class="line">	pushq	%rbx		/* pt_regs-&gt;rbx */</span><br><span class="line">	pushq	%rbp		/* pt_regs-&gt;rbp */</span><br><span class="line">	pushq	%r12		/* pt_regs-&gt;r12 */</span><br><span class="line">	pushq	%r13		/* pt_regs-&gt;r13 */</span><br><span class="line">	pushq	%r14		/* pt_regs-&gt;r14 */</span><br><span class="line">	pushq	%r15		/* pt_regs-&gt;r15 */</span><br><span class="line"></span><br><span class="line">	.if \unwind_hint</span><br><span class="line">	UNWIND_HINT_REGS</span><br><span class="line">	.endif</span><br><span class="line"></span><br><span class="line">	.if \save_ret</span><br><span class="line">	pushq	%rsi		/* return address on top of stack */ # 最后再写入rsi，即返回地址</span><br><span class="line">	.endif</span><br><span class="line">.endm</span><br><span class="line"></span><br><span class="line">.macro CLEAR_REGS clear_bp=1</span><br><span class="line">	/*</span><br><span class="line">	 * Sanitize registers of values that a speculation attack might</span><br><span class="line">	 * otherwise want to exploit. The lower registers are likely clobbered</span><br><span class="line">	 * well before they could be put to use in a speculative execution</span><br><span class="line">	 * gadget.</span><br><span class="line">	 */</span><br><span class="line">	xorl	%esi,  %esi	/* nospec si  */</span><br><span class="line">	xorl	%edx,  %edx	/* nospec dx  */</span><br><span class="line">	xorl	%ecx,  %ecx	/* nospec cx  */</span><br><span class="line">	xorl	%r8d,  %r8d	/* nospec r8  */</span><br><span class="line">	xorl	%r9d,  %r9d	/* nospec r9  */</span><br><span class="line">	xorl	%r10d, %r10d	/* nospec r10 */</span><br><span class="line">	xorl	%r11d, %r11d	/* nospec r11 */</span><br><span class="line">	xorl	%ebx,  %ebx	/* nospec rbx */</span><br><span class="line">	.if \clear_bp</span><br><span class="line">	xorl	%ebp,  %ebp	/* nospec rbp */</span><br><span class="line">	.endif</span><br><span class="line">	xorl	%r12d, %r12d	/* nospec r12 */</span><br><span class="line">	xorl	%r13d, %r13d	/* nospec r13 */</span><br><span class="line">	xorl	%r14d, %r14d	/* nospec r14 */</span><br><span class="line">	xorl	%r15d, %r15d	/* nospec r15 */</span><br><span class="line"></span><br><span class="line">.endm</span><br></pre></td></tr></table></figure>

<p>然后开始push寄存器到pt_regs结构体</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">	/* Construct struct pt_regs on stack */</span><br><span class="line">	pushq	$__USER_DS				/* pt_regs-&gt;ss  用户段DS*/</span><br><span class="line">	pushq	PER_CPU_VAR(cpu_tss_rw + TSS_sp2)	/* pt_regs-&gt;sp 之前保存到tss段的用户态rsp寄存器*/</span><br><span class="line">	pushq	%r11					/* pt_regs-&gt;flags syscall指令自动存储的rflags寄存器*/</span><br><span class="line">	pushq	$__USER_CS				/* pt_regs-&gt;cs 用户段CS寄存器*/</span><br><span class="line">	pushq	%rcx					/* pt_regs-&gt;ip 用户态的下一条指令，是由syscall指令执行时候CPU自动存储到rcx寄存器中的*/</span><br><span class="line">SYM_INNER_LABEL(entry_SYSCALL_64_after_hwframe, SYM_L_GLOBAL)</span><br><span class="line">	pushq	%rax					/* pt_regs-&gt;orig_ax 把rax寄存器压入栈，也就是系统调用号*/</span><br></pre></td></tr></table></figure>

<p>然后是一个宏调用, 就是按顺序压入</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">PUSH_AND_CLEAR_REGS rax=$-ENOSYS</span><br><span class="line">.macro PUSH_AND_CLEAR_REGS rdx=%rdx rcx=%rcx rax=%rax save_ret=0 clear_bp=1 unwind_hint=1</span><br><span class="line">	PUSH_REGS rdx=\rdx, rcx=\rcx, rax=\rax, save_ret=\save_ret unwind_hint=\unwind_hint</span><br><span class="line">	CLEAR_REGS clear_bp=\clear_bp</span><br><span class="line">.endm</span><br><span class="line"></span><br><span class="line">.macro PUSH_REGS rdx=%rdx rcx=%rcx rax=%rax save_ret=0 unwind_hint=1</span><br><span class="line">	.if \save_ret</span><br><span class="line">	pushq	%rsi		/* pt_regs-&gt;si */</span><br><span class="line">	movq	8(%rsp), %rsi	/* temporarily store the return address in %rsi */</span><br><span class="line">	movq	%rdi, 8(%rsp)	/* pt_regs-&gt;di (overwriting original return address) */</span><br><span class="line">	.else</span><br><span class="line">	pushq   %rdi		/* pt_regs-&gt;di */</span><br><span class="line">	pushq   %rsi		/* pt_regs-&gt;si */</span><br><span class="line">	.endif</span><br><span class="line">	pushq	\rdx		/* pt_regs-&gt;dx */</span><br><span class="line">	pushq   \rcx		/* pt_regs-&gt;cx */</span><br><span class="line">	pushq   \rax		/* pt_regs-&gt;ax */</span><br><span class="line">	pushq   %r8		/* pt_regs-&gt;r8 */</span><br><span class="line">	pushq   %r9		/* pt_regs-&gt;r9 */</span><br><span class="line">	pushq   %r10		/* pt_regs-&gt;r10 */</span><br><span class="line">	pushq   %r11		/* pt_regs-&gt;r11 */</span><br><span class="line">	pushq	%rbx		/* pt_regs-&gt;rbx */</span><br><span class="line">	pushq	%rbp		/* pt_regs-&gt;rbp */</span><br><span class="line">	pushq	%r12		/* pt_regs-&gt;r12 */</span><br><span class="line">	pushq	%r13		/* pt_regs-&gt;r13 */</span><br><span class="line">	pushq	%r14		/* pt_regs-&gt;r14 */</span><br><span class="line">	pushq	%r15		/* pt_regs-&gt;r15 */</span><br><span class="line"></span><br><span class="line">	.if \unwind_hint</span><br><span class="line">	UNWIND_HINT_REGS</span><br><span class="line">	.endif</span><br><span class="line"></span><br><span class="line">	.if \save_ret</span><br><span class="line">	pushq	%rsi		/* return address on top of stack */</span><br><span class="line">	.endif</span><br><span class="line">.endm</span><br></pre></td></tr></table></figure>

<p>在看这一部分的时候可以结合pt_regs结构体一起来看, 因为压入栈的顺序与pt_regs的顺序相反。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">struct pt_regs &#123;</span><br><span class="line">	/*</span><br><span class="line">	 * C ABI says these regs are callee-preserved. They aren&#x27;t saved on</span><br><span class="line">	 * kernel entry unless syscall needs a complete, fully filled</span><br><span class="line">	 * &quot;struct pt_regs&quot;.</span><br><span class="line">	 */</span><br><span class="line">	unsigned long r15;</span><br><span class="line">	unsigned long r14;</span><br><span class="line">	unsigned long r13;</span><br><span class="line">	unsigned long r12;</span><br><span class="line">	unsigned long bp;</span><br><span class="line">	unsigned long bx;</span><br><span class="line"></span><br><span class="line">	/* These regs are callee-clobbered. Always saved on kernel entry. */</span><br><span class="line">	unsigned long r11;</span><br><span class="line">	unsigned long r10;</span><br><span class="line">	unsigned long r9;</span><br><span class="line">	unsigned long r8;</span><br><span class="line">	unsigned long ax;</span><br><span class="line">	unsigned long cx;</span><br><span class="line">	unsigned long dx;</span><br><span class="line">	unsigned long si;</span><br><span class="line">	unsigned long di;</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * orig_ax is used on entry for:</span><br><span class="line">	 * - the syscall number (syscall, sysenter, int80)</span><br><span class="line">	 * - error_code stored by the CPU on traps and exceptions</span><br><span class="line">	 * - the interrupt number for device interrupts</span><br><span class="line">	 *</span><br><span class="line">	 * A FRED stack frame starts here:</span><br><span class="line">	 *   1) It _always_ includes an error code;</span><br><span class="line">	 *</span><br><span class="line">	 *   2) The return frame for ERET[US] starts here, but</span><br><span class="line">	 *      the content of orig_ax is ignored.</span><br><span class="line">	 */</span><br><span class="line">	unsigned long orig_ax;</span><br><span class="line"></span><br><span class="line">	/* The IRETQ return frame starts here */</span><br><span class="line">	unsigned long ip;</span><br><span class="line"></span><br><span class="line">	union &#123;</span><br><span class="line">		/* CS selector */</span><br><span class="line">		u16		cs;</span><br><span class="line">		/* The extended 64-bit data slot containing CS */</span><br><span class="line">		u64		csx;</span><br><span class="line">		/* The FRED CS extension */</span><br><span class="line">		struct fred_cs	fred_cs;</span><br><span class="line">	&#125;;</span><br><span class="line"></span><br><span class="line">	unsigned long flags;</span><br><span class="line">	unsigned long sp;</span><br><span class="line"></span><br><span class="line">	union &#123;</span><br><span class="line">		/* SS selector */</span><br><span class="line">		u16		ss;</span><br><span class="line">		/* The extended 64-bit data slot containing SS */</span><br><span class="line">		u64		ssx;</span><br><span class="line">		/* The FRED SS extension */</span><br><span class="line">		struct fred_ss	fred_ss;</span><br><span class="line">	&#125;;</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * Top of stack on IDT systems, while FRED systems have extra fields</span><br><span class="line">	 * defined above for storing exception related information, e.g. CR2 or</span><br><span class="line">	 * DR6.</span><br><span class="line">	 */</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>把以上两个结合起来其实就是以下这张图：</p>
<p><img src="https://zhuzhuzaiimgbed.oss-cn-hangzhou.aliyuncs.com/img/image-20251001220608653.png" alt="image-20251001220608653"></p>
<p>然后仔细观察会发现，rax其实被压入栈了两次，</p>
<ul>
<li><p><code>orig_ax</code> 用于 restart_syscall &#x2F; ptrace &#x2F; syscall trace：可以知道用户最初调用哪个 syscall。</p>
</li>
<li><p><code>ax</code> 是常规用户寄存器快照，和其他通用寄存器一样，用于 pt_regs 完整保存，虽然两个值一样，但是这里需要给返回值一个占位。</p>
</li>
</ul>
<p>另外还有%rdi并没有被清除，这是因为rdi是syscall的第一个参数，因为会直接被用，所以就不清0了。</p>
<p>OK 到这里就已经把所有寄存器的值保存到内核栈上了，然后就可以调用真正的系统调用了。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/* IRQs are off. */</span><br><span class="line">	movq	%rsp, %rdi</span><br><span class="line">	/* Sign extend the lower 32bit as syscall numbers are treated as int */</span><br><span class="line">	movslq	%eax, %rsi</span><br><span class="line"></span><br><span class="line">	/* clobbers %rax, make sure it is after saving the syscall nr */</span><br><span class="line">	IBRS_ENTER  # 限制间接分支预测</span><br><span class="line">	UNTRAIN_RET # 清理返回栈预测器</span><br><span class="line">	CLEAR_BRANCH_HISTORY # 清分支历史，防止 spec leak</span><br><span class="line">	</span><br><span class="line">	call	do_syscall_64		/* returns with IRQs disabled */</span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">__visible noinstr bool do_syscall_64(struct pt_regs *regs, int nr)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>我们先看这个函数有两个参数，第一个是pt_regs地址，第二个是系统调用号，所以这里汇编将rsp的值，也就是pt_regs的地址给rdi寄存器，也就是ABI规约里的第一个参数，然后把eax，也就是系统调用号给rsi，也就是ABI规约里的第二个参数。然后做了一些防止幽灵攻击的措施。（这里就不详细了解了，可以具体查看相关幽灵和熔断漏洞<a href="https://events19.linuxfoundation.cn/wp-content/uploads/2017/11/Understanding-Spectre-v2-and-How-the-Vulnerability-Impact-the-Cloud-Security_Gavin-Guo.pdf">Understanding-Spectre-v2-and-How-the-Vulnerability-Impact-the-Cloud-Security_Gavin-Guo.pdf</a>）</p>
<h3 id="do-syscall-64"><a href="#do-syscall-64" class="headerlink" title="do_syscall_64"></a>do_syscall_64</h3><p>终于我们跳出了汇编的函数，来到了看得明白一点的C函数，我先贴个完整的代码，然后我们再一点点看</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">__visible noinstr <span class="type">bool</span> <span class="title function_">do_syscall_64</span><span class="params">(<span class="keyword">struct</span> pt_regs *regs, <span class="type">int</span> nr)</span></span><br><span class="line">&#123;</span><br><span class="line">	add_random_kstack_offset(); <span class="comment">//给内核栈加一个随机偏移</span></span><br><span class="line">	nr = syscall_enter_from_user_mode(regs, nr); <span class="comment">// 做一些限制检查，比如syscall 过滤/限制（seccomp 等），然后可能要调整syscall的编号，最终nr才是需要调用的编号。</span></span><br><span class="line"></span><br><span class="line">	instrumentation_begin(); <span class="comment">//用于kprobe, ftrace的跟踪</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> (!do_syscall_x64(regs, nr) &amp;&amp; !do_syscall_x32(regs, nr) &amp;&amp; nr != <span class="number">-1</span>) &#123;</span><br><span class="line">		<span class="comment">/* Invalid system call, but still a system call. */</span></span><br><span class="line">		regs-&gt;ax = __x64_sys_ni_syscall(regs);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	instrumentation_end();</span><br><span class="line">	syscall_exit_to_user_mode(regs);</span><br><span class="line"></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * Check that the register state is valid for using SYSRET to exit</span></span><br><span class="line"><span class="comment">	 * to userspace.  Otherwise use the slower but fully capable IRET</span></span><br><span class="line"><span class="comment">	 * exit path.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">/* XEN PV guests always use the IRET path */</span></span><br><span class="line">	<span class="keyword">if</span> (cpu_feature_enabled(X86_FEATURE_XENPV))</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/* SYSRET requires RCX == RIP and R11 == EFLAGS */</span></span><br><span class="line">	<span class="keyword">if</span> (unlikely(regs-&gt;cx != regs-&gt;ip || regs-&gt;r11 != regs-&gt;flags))</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/* CS and SS must match the values set in MSR_STAR */</span></span><br><span class="line">	<span class="keyword">if</span> (unlikely(regs-&gt;cs != __USER_CS || regs-&gt;ss != __USER_DS))</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * On Intel CPUs, SYSRET with non-canonical RCX/RIP will #GP</span></span><br><span class="line"><span class="comment">	 * in kernel space.  This essentially lets the user take over</span></span><br><span class="line"><span class="comment">	 * the kernel, since userspace controls RSP.</span></span><br><span class="line"><span class="comment">	 *</span></span><br><span class="line"><span class="comment">	 * TASK_SIZE_MAX covers all user-accessible addresses other than</span></span><br><span class="line"><span class="comment">	 * the deprecated vsyscall page.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="keyword">if</span> (unlikely(regs-&gt;ip &gt;= TASK_SIZE_MAX))</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * SYSRET cannot restore RF.  It can restore TF, but unlike IRET,</span></span><br><span class="line"><span class="comment">	 * restoring TF results in a trap from userspace immediately after</span></span><br><span class="line"><span class="comment">	 * SYSRET.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="keyword">if</span> (unlikely(regs-&gt;flags &amp; (X86_EFLAGS_RF | X86_EFLAGS_TF)))</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/* Use SYSRET to exit to userspace */</span></span><br><span class="line">	<span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>关键在于调用系统调用的地方在以下代码片段。先尝试用64位，再尝试32位，如果实在都失败，就用一个ni（not implemented）的系统调用，这样不会挂内核。</p>
<ul>
<li><p><strong>do_syscall_x64(regs, nr)</strong> → 尝试调用 64-bit syscall</p>
</li>
<li><p><strong>do_syscall_x32(regs, nr)</strong> → 尝试调用 32-bit compatibility syscall</p>
</li>
<li><p>如果两者都失败，且 syscall 编号有效 (<code>nr != -1</code>)：</p>
<ul>
<li><p>调用 <code>__x64_sys_ni_syscall()</code> → <strong>“not implemented”</strong> syscall</p>
</li>
<li><p>将返回值存到 <code>regs-&gt;ax</code>，保证用户态看到正确的返回值（-ENOSYS）</p>
</li>
</ul>
</li>
</ul>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">	<span class="keyword">if</span> (!do_syscall_x64(regs, nr) &amp;&amp; !do_syscall_x32(regs, nr) &amp;&amp; nr != <span class="number">-1</span>) &#123;</span><br><span class="line">		<span class="comment">/* Invalid system call, but still a system call. */</span></span><br><span class="line">		regs-&gt;ax = __x64_sys_ni_syscall(regs);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">static</span> __always_inline <span class="type">bool</span> <span class="title function_">do_syscall_x64</span><span class="params">(<span class="keyword">struct</span> pt_regs *regs, <span class="type">int</span> nr)</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * Convert negative numbers to very high and thus out of range</span></span><br><span class="line"><span class="comment">	 * numbers for comparisons.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">int</span> unr = nr;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> (likely(unr &lt; NR_syscalls)) &#123;</span><br><span class="line">		unr = array_index_nospec(unr, NR_syscalls); <span class="comment">//防止幽灵攻击，比如传入一个nr=-1的值，然后转uint时候会变得很大。</span></span><br><span class="line">		regs-&gt;ax = x64_sys_call(regs, unr); <span class="comment">//根据unr的编号调用具体函数</span></span><br><span class="line">		<span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">static</span> __always_inline <span class="type">bool</span> <span class="title function_">do_syscall_x32</span><span class="params">(<span class="keyword">struct</span> pt_regs *regs, <span class="type">int</span> nr)</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * Adjust the starting offset of the table, and convert numbers</span></span><br><span class="line"><span class="comment">	 * &lt; __X32_SYSCALL_BIT to very high and thus out of range</span></span><br><span class="line"><span class="comment">	 * numbers for comparisons.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">int</span> xnr = nr - __X32_SYSCALL_BIT;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> (IS_ENABLED(CONFIG_X86_X32_ABI) &amp;&amp; likely(xnr &lt; X32_NR_syscalls)) &#123;</span><br><span class="line">		xnr = array_index_nospec(xnr, X32_NR_syscalls);</span><br><span class="line">		regs-&gt;ax = x32_sys_call(regs, xnr);</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>其实x64_sys_call的代码也很巧妙,就是一个简单的switch，然后中间用一个头文件弄了一个自动生成的syscall表，具体内容看文件<code>arch/x86/entry/syscalls/syscall_64.tbl</code></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">long</span> <span class="title function_">x64_sys_call</span><span class="params">(<span class="type">const</span> <span class="keyword">struct</span> pt_regs *regs, <span class="type">unsigned</span> <span class="type">int</span> nr)</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="keyword">switch</span> (nr) &#123;</span><br><span class="line">	<span class="meta">#<span class="keyword">include</span> <span class="string">&lt;asm/syscalls_64.h&gt;</span></span></span><br><span class="line">	<span class="keyword">default</span>: <span class="keyword">return</span> __x64_sys_ni_syscall(regs);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>OK到这里就大概清楚了具体的系统调用怎么调用的，怎么call到表里的表项的。</p>
<h3 id="系统调用的返回"><a href="#系统调用的返回" class="headerlink" title="系统调用的返回"></a>系统调用的返回</h3><p>先看看完整的代码路径, 执行完do_syscall_64之后，会把syscall返回的结果写入pt_regs-&gt;ax部分，然后do_syscall_64的返回值如果是true，则是使用sysret返回，是快速路径，如果是false，则使用iret满速路径。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">	call	do_syscall_64		/* returns with IRQs disabled */</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * Try to use SYSRET instead of IRET if we&#x27;re returning to</span><br><span class="line">	 * a completely clean 64-bit userspace context.  If we&#x27;re not,</span><br><span class="line">	 * go to the slow exit path.</span><br><span class="line">	 * In the Xen PV case we must use iret anyway.</span><br><span class="line">	 */</span><br><span class="line"></span><br><span class="line">	ALTERNATIVE &quot;testb %al, %al; jz swapgs_restore_regs_and_return_to_usermode&quot;, \</span><br><span class="line">		&quot;jmp swapgs_restore_regs_and_return_to_usermode&quot;, X86_FEATURE_XENPV</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * We win! This label is here just for ease of understanding</span><br><span class="line">	 * perf profiles. Nothing jumps here.</span><br><span class="line">	 */</span><br><span class="line">syscall_return_via_sysret:</span><br><span class="line">	IBRS_EXIT #清除IBRS相关寄存器</span><br><span class="line">	POP_REGS pop_rdi=0 # 把所有pt_regs寄存器弹出来，并且不弹出%rdi，因为本身没有压入过</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * Now all regs are restored except RSP and RDI.</span><br><span class="line">	 * Save old stack pointer and switch to trampoline stack.</span><br><span class="line">	 */</span><br><span class="line">	movq	%rsp, %rdi # 把当前栈顶%rsp 给 rdi寄存器</span><br><span class="line">	movq	PER_CPU_VAR(cpu_tss_rw + TSS_sp0), %rsp  #把trampoline的栈给rsp，这是一个固定的小栈</span><br><span class="line">	UNWIND_HINT_END_OF_STACK</span><br><span class="line"></span><br><span class="line">	pushq	RSP-RDI(%rdi)	/* RSP */  </span><br><span class="line">	pushq	(%rdi)		/* RDI */</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * We are on the trampoline stack.  All regs except RDI are live.</span><br><span class="line">	 * We can do future final exit work right here.</span><br><span class="line">	 */</span><br><span class="line">	STACKLEAK_ERASE_NOCLOBBER</span><br><span class="line"></span><br><span class="line">	SWITCH_TO_USER_CR3_STACK scratch_reg=%rdi</span><br><span class="line"></span><br><span class="line">	popq	%rdi</span><br><span class="line">	popq	%rsp</span><br><span class="line">SYM_INNER_LABEL(entry_SYSRETQ_unsafe_stack, SYM_L_GLOBAL)</span><br><span class="line">	ANNOTATE_NOENDBR</span><br><span class="line">	swapgs #把 GS 基址从内核的 per-cpu 基址交换回用户态 GS（TLS）的值。这一步必须在恢复用户寄存器并在最终 sysretq 之前执行，因为用户态的 GS/FS 必须是用户原值。</span><br><span class="line">	CLEAR_CPU_BUFFERS</span><br><span class="line">	sysretq #这里就返回用户态了，后续代码都不会被调用到。 sysretq：真正的、快速的返回到用户态（使用 RCX = RIP, R11 = RFLAGS，CS/SS 由 MSR_STAR 指定，且 RSP 已经被恢复为用户 RSP）。sysretq 之后 CPU 立即在用户态继续执行。</span><br><span class="line">SYM_INNER_LABEL(entry_SYSRETQ_end, SYM_L_GLOBAL)</span><br><span class="line">	ANNOTATE_NOENDBR</span><br><span class="line">	int3  # int3 是调试断点指令（如果控制流不该到这里却到这里，触发 oops / bugcheck）。在正确的系统里 sysretq 不会返回到下一条指令，这里的 int3 只是保险（&quot;should not reach&quot;）。</span><br><span class="line">SYM_CODE_END(entry_SYSCALL_64)</span><br></pre></td></tr></table></figure>

<p>然后有两行代码比较魔幻</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">	pushq	RSP-RDI(%rdi)	<span class="comment">/* RSP */</span>  </span><br><span class="line">	pushq	(%rdi)		<span class="comment">/* RDI */</span></span><br><span class="line">        </span><br><span class="line"><span class="meta">#<span class="keyword">define</span> DATA(offset)		(KEXEC_CONTROL_CODE_MAX_SIZE+(offset))</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* Minimal CPU state */</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> RSP			DATA(0x0)</span></span><br></pre></td></tr></table></figure>

<p>因为我们进入了trampoline栈，但是呢原本内核栈还有一些数据没有pop完，如下所示, 所以这两行总的作用就是复制原来旧内核栈上保存的 RSP 和 RDI 到当前 trampoline 栈以便恢复。那么以下这些寄存器就不pop了嘛，有人肯定会有疑问。这就有了iret和sysret的区别，iret要求栈上需要有ss sp这些东西，从而自动会pop，但是sysret不会，这些脏东西会留在内核栈上，但是无所谓，下次进来的时候会把这些覆盖。</p>
<p><img src="https://zhuzhuzaiimgbed.oss-cn-hangzhou.aliyuncs.com/img/image-20251001233147305.png" alt="image-20251001233147305"></p>
<p>具体一点就是</p>
<ul>
<li><p><strong><code>iretq</code></strong> 要求栈上有严格的 frame（SS, RSP, RFLAGS, CS, RIP），所以 CPU 会真正 pop 它们。</p>
</li>
<li><p><strong><code>sysretq</code></strong> 更轻量：它直接从 <code>%rcx</code> 取返回地址，从 <code>%r11</code> 取 RFLAGS，然后跳回用户态。它根本不会理会栈上的那一坨。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>note</category>
      </categories>
      <tags>
        <tag>os</tag>
      </tags>
  </entry>
  <entry>
    <title>红黑树</title>
    <url>/2025/09/19/note/%E7%BA%A2%E9%BB%91%E6%A0%91/</url>
    <content><![CDATA[<h1 id="红黑树"><a href="#红黑树" class="headerlink" title="红黑树"></a>红黑树</h1><h2 id="红黑树特点"><a href="#红黑树特点" class="headerlink" title="红黑树特点"></a>红黑树特点</h2><p>红黑树和别的树的优势在于：</p>
<ul>
<li>首先它是一个二叉树，这意味着二叉树的插入，查找和删除的平均复杂度在最快情况下都是<code>O(logN)</code>，因此在频繁插入删除和查找的情况下效率非常高。</li>
<li>那为什么不采用二叉搜索树呢，这是因为二叉搜索树在插入的时候可能会导致树变成链表（比如按顺序插入从小到大的结点，一直插入到右子树），这样查找的效率就变成<code>O(N)</code>了。</li>
<li>既然二叉搜索树太弱了，那为什么不用二叉平衡树呢，即AVL。这是因为二叉平衡树需要左右子树高度差&lt;&#x3D;1, 而红黑树允许左右子树高度差大于1，只是限定了路径上黑色结点数目相同，并且不存在连续的红色结点（最长路径为最短路径的两倍，最长路径是红黑交替的，最短路径为全黑的）。这样通过放宽平衡条件可以换取更少的旋转操作，更少的旋转操作意味着在频繁插入删除的场景下比AVL更高效。</li>
</ul>
<p>总的来说，红黑树具备以下特点</p>
<ul>
<li>它是一棵二叉搜索树</li>
<li>每一个节点都会被着色，不是<strong>黑色</strong>就是<strong>红色</strong></li>
<li><strong>根节点必须为黑色</strong></li>
<li>对于一个红色节点，它的孩子或为空，或是黑色。也就是说<strong>路径上不能有连续红色节点</strong></li>
<li>从根节点到NULL节点的所有路径上，<strong>黑色节点的数量都相同</strong></li>
</ul>
<h2 id="Linux中红黑树的实现"><a href="#Linux中红黑树的实现" class="headerlink" title="Linux中红黑树的实现"></a>Linux中红黑树的实现</h2><p>OK有了以上直观的观念后，咱们来看看Linux中实现红黑树的源码。</p>
<p>首先是红黑树的定义（Linux 6.11版本）, 在内核文件<code>include/linux/rbtree_types.h</code>中，可以看到其实就是一个传统的数据结构，三个指针，分别指向父节点，两个左右子树，但是这个父节点这个值（<code>__rb_parent_color</code>）做了一个优化，具体看注释：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">rb_node</span> &#123;</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span>  __rb_parent_color; <span class="comment">//父节点地址&amp;0b00, 这是因为父节点的指针都是8字节对齐的（即后面代码所示__attribute__((aligned(sizeof(long))));），所以低位肯定是0，那么就用低位来存储对应当前节点的颜色即可。</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">rb_node</span> *<span class="title">rb_right</span>;</span> <span class="comment">//右子树</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">rb_node</span> *<span class="title">rb_left</span>;</span>  <span class="comment">//左子树</span></span><br><span class="line">&#125; __attribute__((aligned(<span class="keyword">sizeof</span>(<span class="type">long</span>))));</span><br><span class="line"><span class="comment">/* The alignment might seem pointless, but allegedly CRIS needs it */</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">rb_root</span> &#123;</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">rb_node</span> *<span class="title">rb_node</span>;</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>有了数据结构定义之后，我们再来看看相关的一些宏定义用来操作这个数据结构的。主要代码在文件在<code>include/linux/rbtree.h</code>中</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// include/linux/rbtree.h</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> rb_parent(r)   ((struct rb_node *)((r)-&gt;__rb_parent_color &amp; ~3)) <span class="comment">//这里就是获取到parent的指针，把__rb_parent_color成员的低位置0。</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span>	rb_entry(ptr, type, member) container_of(ptr, type, member) <span class="comment">//</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> RB_EMPTY_ROOT(root)  (READ_ONCE((root)-&gt;rb_node) == NULL) <span class="comment">//判断root是不是空</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* &#x27;empty&#x27; nodes are nodes that are known not to be inserted in an rbtree */</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> RB_EMPTY_NODE(node)  \</span></span><br><span class="line"><span class="meta">	((node)-&gt;__rb_parent_color == (unsigned long)(node)) <span class="comment">//判断RBnode的父节点是不是自己</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> RB_CLEAR_NODE(node)  \</span></span><br><span class="line"><span class="meta">	((node)-&gt;__rb_parent_color = (unsigned long)(node))</span></span><br></pre></td></tr></table></figure>



<p>然后再来看看第二个比较重要的宏定义 <code>contain_of</code>,  这是因为Linux的数据结构，例如链表和红黑树，都是嵌入到结构体里面的，因此指针指向的也是rb_node结构，并不是包含该rbnode的结构体(例如mm_struct)，要提取真实的mm_struct结构体，则需要使用类似这种container_of宏。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// include/linux/container_of.h</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> container_of(ptr, type, member) (&#123;				\</span></span><br><span class="line"><span class="meta">	void *__mptr = (void *)(ptr);					\ <span class="comment">//把ptr指针强转成void*， 防止类型警告。</span></span></span><br><span class="line">	<span class="keyword">static_assert</span>(__same_type(*(ptr), ((type *)<span class="number">0</span>)-&gt;member) ||	\ <span class="comment">//__same_type  GCC内置宏，确保*(ptr)和((type *)0)-&gt;member类型相同，这里用了一个技巧写法，即假设0是(type *)类型的指针，从而取其member成员。</span></span><br><span class="line">		      __same_type(*(ptr), <span class="type">void</span>),			\  <span class="comment">//允许 ptr是 void*（某些特殊情况，如 list_head可能是 void*）。</span></span><br><span class="line">		      <span class="string">&quot;pointer type mismatch in container_of()&quot;</span>);	\  <span class="comment">//编译时检查</span></span><br><span class="line">	((type *)(__mptr - offsetof(type, member))); &#125;) <span class="comment">// offsetof(type, member)：计算 member在 type结构体中的偏移量（字节）。然后把当前的rbnode减去偏移就是真实的</span></span><br><span class="line">        </span><br><span class="line"><span class="comment">// include/linux/stddef.h        </span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> offsetof(TYPE, MEMBER)	__builtin_offsetof(TYPE, MEMBER) <span class="comment">// GCC函数，</span></span></span><br></pre></td></tr></table></figure>

<p>假设有一个结构体</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">person</span> &#123;</span></span><br><span class="line">    <span class="type">int</span> age;</span><br><span class="line">    <span class="type">char</span> name[<span class="number">20</span>];</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">rb_node</span> <span class="title">rb</span>;</span>  <span class="comment">// 假设这是一个红黑树节点</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>并且假设我们现在有一个<code>struct rb_node* node</code>指针,我们使用如下语句就能获取到该结构体：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">person</span> *<span class="title">p</span> =</span> container_of(node, <span class="keyword">struct</span> person, rb);</span><br></pre></td></tr></table></figure>



<p>此外还有一些比较常用的函数：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// lib/rbtree.c  </span></span><br><span class="line">  <span class="keyword">struct</span> rb_node *<span class="title function_">rb_first</span><span class="params">(<span class="keyword">struct</span> rb_root *tree)</span>;</span><br><span class="line">  <span class="keyword">struct</span> rb_node *<span class="title function_">rb_last</span><span class="params">(<span class="keyword">struct</span> rb_root *tree)</span>;</span><br><span class="line">  <span class="keyword">struct</span> rb_node *<span class="title function_">rb_next</span><span class="params">(<span class="keyword">struct</span> rb_node *node)</span>;</span><br><span class="line">  <span class="keyword">struct</span> rb_node *<span class="title function_">rb_prev</span><span class="params">(<span class="keyword">struct</span> rb_node *node)</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> rb_node *<span class="title function_">rb_first</span><span class="params">(<span class="type">const</span> <span class="keyword">struct</span> rb_root *root)</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">rb_node</span>	*<span class="title">n</span>;</span></span><br><span class="line"></span><br><span class="line">	n = root-&gt;rb_node;</span><br><span class="line">	<span class="keyword">if</span> (!n)</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">	<span class="keyword">while</span> (n-&gt;rb_left) <span class="comment">// 一直取最左边的结点</span></span><br><span class="line">		n = n-&gt;rb_left;</span><br><span class="line">	<span class="keyword">return</span> n;</span><br><span class="line">&#125; </span><br><span class="line">EXPORT_SYMBOL(rb_first);</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> rb_node *<span class="title function_">rb_last</span><span class="params">(<span class="type">const</span> <span class="keyword">struct</span> rb_root *root)</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">rb_node</span>	*<span class="title">n</span>;</span></span><br><span class="line"></span><br><span class="line">	n = root-&gt;rb_node;</span><br><span class="line">	<span class="keyword">if</span> (!n)</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">	<span class="keyword">while</span> (n-&gt;rb_right)	<span class="comment">// 一直取最右边的结点</span></span><br><span class="line">		n = n-&gt;rb_right;</span><br><span class="line">	<span class="keyword">return</span> n;</span><br><span class="line">&#125;</span><br><span class="line">EXPORT_SYMBOL(rb_last);</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> rb_node *<span class="title function_">rb_next</span><span class="params">(<span class="type">const</span> <span class="keyword">struct</span> rb_node *node)</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">rb_node</span> *<span class="title">parent</span>;</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> (RB_EMPTY_NODE(node)) <span class="comment">// 判断当前node的parent是不是指向自己，如果是说明该node没有被插入rb_root中，所以返回NULL。</span></span><br><span class="line">		<span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * If we have a right-hand child, go down and then left as far</span></span><br><span class="line"><span class="comment">	 * as we can.  如果有右子树，则取右子树的最左结点</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="keyword">if</span> (node-&gt;rb_right) &#123;</span><br><span class="line">		node = node-&gt;rb_right;</span><br><span class="line">		<span class="keyword">while</span> (node-&gt;rb_left)</span><br><span class="line">			node = node-&gt;rb_left;</span><br><span class="line">		<span class="keyword">return</span> (<span class="keyword">struct</span> rb_node *)node;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * No right-hand children. Everything down and left is smaller than us,</span></span><br><span class="line"><span class="comment">	 * so any &#x27;next&#x27; node must be in the general direction of our parent.</span></span><br><span class="line"><span class="comment">	 * Go up the tree; any time the ancestor is a right-hand child of its</span></span><br><span class="line"><span class="comment">	 * parent, keep going up. First time it&#x27;s a left-hand child of its</span></span><br><span class="line"><span class="comment">	 * parent, said parent is our &#x27;next&#x27; node.  如果没有右子树，则一直递归往上取。不过这里有个疑问，如果本身是最后一个结点了，那最后一个结点的最后一个结点是什么？</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="keyword">while</span> ((parent = rb_parent(node)) &amp;&amp; node == parent-&gt;rb_right)</span><br><span class="line">		node = parent;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> parent;</span><br><span class="line">&#125;</span><br><span class="line">EXPORT_SYMBOL(rb_next);</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> rb_node *<span class="title function_">rb_prev</span><span class="params">(<span class="type">const</span> <span class="keyword">struct</span> rb_node *node)</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">rb_node</span> *<span class="title">parent</span>;</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> (RB_EMPTY_NODE(node))</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * If we have a left-hand child, go down and then right as far</span></span><br><span class="line"><span class="comment">	 * as we can.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="keyword">if</span> (node-&gt;rb_left) &#123;</span><br><span class="line">		node = node-&gt;rb_left;</span><br><span class="line">		<span class="keyword">while</span> (node-&gt;rb_right)</span><br><span class="line">			node = node-&gt;rb_right;</span><br><span class="line">		<span class="keyword">return</span> (<span class="keyword">struct</span> rb_node *)node;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * No left-hand children. Go up till we find an ancestor which</span></span><br><span class="line"><span class="comment">	 * is a right-hand child of its parent.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="keyword">while</span> ((parent = rb_parent(node)) &amp;&amp; node == parent-&gt;rb_left)</span><br><span class="line">		node = parent;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> parent;</span><br><span class="line">&#125;</span><br><span class="line">EXPORT_SYMBOL(rb_prev);</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="增删改查"><a href="#增删改查" class="headerlink" title="增删改查"></a>增删改查</h2><p>我们最为关心的增删改查。</p>
<h3 id="在rb-tree中增加一个node"><a href="#在rb-tree中增加一个node" class="headerlink" title="在rb_tree中增加一个node"></a>在rb_tree中增加一个node</h3><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// include/linux/rbtree.h</span></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * rb_add() - insert @node into @tree</span></span><br><span class="line"><span class="comment"> * @node: node to insert</span></span><br><span class="line"><span class="comment"> * @tree: tree to insert @node into</span></span><br><span class="line"><span class="comment"> * @less: operator defining the (partial) node order</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="type">static</span> __always_inline <span class="type">void</span></span><br><span class="line"><span class="title function_">rb_add</span><span class="params">(<span class="keyword">struct</span> rb_node *node, <span class="keyword">struct</span> rb_root *tree,</span></span><br><span class="line"><span class="params">       <span class="type">bool</span> (*less)(<span class="keyword">struct</span> rb_node *, <span class="type">const</span> <span class="keyword">struct</span> rb_node *))</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">rb_node</span> **<span class="title">link</span> =</span> &amp;tree-&gt;rb_node;</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">rb_node</span> *<span class="title">parent</span> =</span> <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">while</span> (*link) &#123;</span><br><span class="line">		parent = *link;</span><br><span class="line">		<span class="keyword">if</span> (less(node, parent))</span><br><span class="line">			link = &amp;parent-&gt;rb_left;</span><br><span class="line">		<span class="keyword">else</span></span><br><span class="line">			link = &amp;parent-&gt;rb_right;</span><br><span class="line">	&#125; <span class="comment">//这里先找到对应parent和link，即node要插入的位置的parent。</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//下面两个函数才是增加结点和平衡的关键</span></span><br><span class="line">	rb_link_node(node, parent, link);</span><br><span class="line">	rb_insert_color(node, tree);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>我们先来看看rb_link_node函数。其实就是把link的值改成node。原本link是null。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">//  include/linux/rbtree.h</span></span><br><span class="line"><span class="type">static</span> <span class="keyword">inline</span> <span class="type">void</span> <span class="title function_">rb_link_node</span><span class="params">(<span class="keyword">struct</span> rb_node *node, <span class="keyword">struct</span> rb_node *parent,</span></span><br><span class="line"><span class="params">				<span class="keyword">struct</span> rb_node **rb_link)</span></span><br><span class="line">&#123;</span><br><span class="line">	node-&gt;__rb_parent_color = (<span class="type">unsigned</span> <span class="type">long</span>)parent;</span><br><span class="line">	node-&gt;rb_left = node-&gt;rb_right = <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">	*rb_link = node;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>然后是rb_insert_color函数, 内核代码里都写了很好的注释。其中很关键的点都画图了，这里注释小写证明红色（n, p, g, u），大写证明黑色(N,P,G,U)</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">//  lib/rbtree.c</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">rb_insert_color</span><span class="params">(<span class="keyword">struct</span> rb_node *node, <span class="keyword">struct</span> rb_root *root)</span></span><br><span class="line">&#123;</span><br><span class="line">	__rb_insert(node, root, dummy_rotate);</span><br><span class="line">&#125;</span><br><span class="line">EXPORT_SYMBOL(rb_insert_color);</span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="keyword">inline</span> <span class="type">void</span> <span class="title function_">dummy_rotate</span><span class="params">(<span class="keyword">struct</span> rb_node *old, <span class="keyword">struct</span> rb_node *new)</span> &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="keyword">inline</span> <span class="keyword">struct</span> rb_node *<span class="title function_">rb_red_parent</span><span class="params">(<span class="keyword">struct</span> rb_node *red)</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="keyword">return</span> (<span class="keyword">struct</span> rb_node *)red-&gt;__rb_parent_color;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">static</span> __always_inline <span class="type">void</span></span><br><span class="line">__rb_insert(<span class="keyword">struct</span> rb_node *node, <span class="keyword">struct</span> rb_root *root,</span><br><span class="line">	    <span class="type">void</span> (*augment_rotate)(<span class="keyword">struct</span> rb_node *old, <span class="keyword">struct</span> rb_node *new))</span><br><span class="line">&#123;</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">rb_node</span> *<span class="title">parent</span> =</span> rb_red_parent(node), *gparent, *tmp; <span class="comment">//插入的结点必定是红色的</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">		<span class="comment">/*</span></span><br><span class="line"><span class="comment">		 * Loop invariant: node is red.</span></span><br><span class="line"><span class="comment">		 */</span></span><br><span class="line">		<span class="keyword">if</span> (unlikely(!parent)) &#123;</span><br><span class="line">			<span class="comment">/*</span></span><br><span class="line"><span class="comment">			 * The inserted node is root. Either this is the</span></span><br><span class="line"><span class="comment">			 * first node, or we recursed at Case 1 below and</span></span><br><span class="line"><span class="comment">			 * are no longer violating 4). 如果插入的结点就是root，就把当前结点设置成黑色，又由于是root，也就是没有父结点，所以父结点是NULL。</span></span><br><span class="line"><span class="comment">			 * static inline void rb_set_parent_color(struct rb_node *rb,</span></span><br><span class="line"><span class="comment">			 *        struct rb_node *p, int color)</span></span><br><span class="line"><span class="comment">             *  &#123;</span></span><br><span class="line"><span class="comment">             *      rb-&gt;__rb_parent_color = (unsigned long)p + color;</span></span><br><span class="line"><span class="comment">             *  &#125;</span></span><br><span class="line"><span class="comment">			 */</span></span><br><span class="line">			rb_set_parent_color(node, <span class="literal">NULL</span>, RB_BLACK);</span><br><span class="line">			<span class="keyword">break</span>;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="comment">/*</span></span><br><span class="line"><span class="comment">		 * If there is a black parent, we are done.</span></span><br><span class="line"><span class="comment">		 * Otherwise, take some corrective action as,</span></span><br><span class="line"><span class="comment">		 * per 4), we don&#x27;t want a red root or two</span></span><br><span class="line"><span class="comment">		 * consecutive red nodes.  如果父亲是黑色，那么直接插入即可，因为不会打破平衡。</span></span><br><span class="line"><span class="comment">		 */</span></span><br><span class="line">		<span class="keyword">if</span>(rb_is_black(parent))</span><br><span class="line">			<span class="keyword">break</span>;</span><br><span class="line"></span><br><span class="line">		gparent = rb_red_parent(parent);  <span class="comment">//获取父亲的父亲 grandparent</span></span><br><span class="line"></span><br><span class="line">		tmp = gparent-&gt;rb_right;  <span class="comment">//尝试获取uncle结点。</span></span><br><span class="line">		<span class="keyword">if</span> (parent != tmp) &#123;	<span class="comment">/* parent == gparent-&gt;rb_left */</span> <span class="comment">//说明是左子树， uncle是g的右子树</span></span><br><span class="line">			<span class="keyword">if</span> (tmp &amp;&amp; rb_is_red(tmp)) &#123; <span class="comment">//其实就是从底部往上，因为当前结点是红的，并且uncle是红的，把parent和uncle都变成黑的，再把grandparent变成红的，然后往上递归。</span></span><br><span class="line">				<span class="comment">/*</span></span><br><span class="line"><span class="comment">				 * Case 1 - node&#x27;s uncle is red (color flips).</span></span><br><span class="line"><span class="comment">				 *</span></span><br><span class="line"><span class="comment">				 *       G            g</span></span><br><span class="line"><span class="comment">				 *      / \          / \</span></span><br><span class="line"><span class="comment">				 *     p   u  --&gt;   P   U</span></span><br><span class="line"><span class="comment">				 *    /            /</span></span><br><span class="line"><span class="comment">				 *   n            n</span></span><br><span class="line"><span class="comment">				 *</span></span><br><span class="line"><span class="comment">				 * However, since g&#x27;s parent might be red, and</span></span><br><span class="line"><span class="comment">				 * 4) does not allow this, we need to recurse</span></span><br><span class="line"><span class="comment">				 * at g.</span></span><br><span class="line"><span class="comment">				 */</span></span><br><span class="line">				rb_set_parent_color(tmp, gparent, RB_BLACK);</span><br><span class="line">				rb_set_parent_color(parent, gparent, RB_BLACK);</span><br><span class="line">				node = gparent;</span><br><span class="line">				parent = rb_parent(node);</span><br><span class="line">				rb_set_parent_color(node, parent, RB_RED);</span><br><span class="line">				<span class="keyword">continue</span>;</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			tmp = parent-&gt;rb_right; </span><br><span class="line">			<span class="keyword">if</span> (node == tmp) &#123;</span><br><span class="line">				<span class="comment">/* 说明当前node就是parent的右子树，就旋转</span></span><br><span class="line"><span class="comment">				 * Case 2 - node&#x27;s uncle is black and node is</span></span><br><span class="line"><span class="comment">				 * the parent&#x27;s right child (left rotate at parent).</span></span><br><span class="line"><span class="comment">				 *</span></span><br><span class="line"><span class="comment">				 *      G             G</span></span><br><span class="line"><span class="comment">				 *     / \           / \</span></span><br><span class="line"><span class="comment">				 *    p   U  --&gt;    n   U</span></span><br><span class="line"><span class="comment">				 *     \           /</span></span><br><span class="line"><span class="comment">				 *      n         p</span></span><br><span class="line"><span class="comment">				 *</span></span><br><span class="line"><span class="comment">				 * This still leaves us in violation of 4), the</span></span><br><span class="line"><span class="comment">				 * continuation into Case 3 will fix that.</span></span><br><span class="line"><span class="comment">				 */</span></span><br><span class="line">				tmp = node-&gt;rb_left;</span><br><span class="line">				WRITE_ONCE(parent-&gt;rb_right, tmp);</span><br><span class="line">				WRITE_ONCE(node-&gt;rb_left, parent);</span><br><span class="line">				<span class="keyword">if</span> (tmp)</span><br><span class="line">					rb_set_parent_color(tmp, parent,</span><br><span class="line">							    RB_BLACK);</span><br><span class="line">				rb_set_parent_color(parent, node, RB_RED);</span><br><span class="line">				augment_rotate(parent, node);</span><br><span class="line">				parent = node;</span><br><span class="line">				tmp = node-&gt;rb_right;</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			<span class="comment">/*</span></span><br><span class="line"><span class="comment">			 * Case 3 - node&#x27;s uncle is black and node is</span></span><br><span class="line"><span class="comment">			 * the parent&#x27;s left child (right rotate at gparent).</span></span><br><span class="line"><span class="comment">			 *</span></span><br><span class="line"><span class="comment">			 *        G           P</span></span><br><span class="line"><span class="comment">			 *       / \         / \</span></span><br><span class="line"><span class="comment">			 *      p   U  --&gt;  n   g</span></span><br><span class="line"><span class="comment">			 *     /                 \</span></span><br><span class="line"><span class="comment">			 *    n                   U</span></span><br><span class="line"><span class="comment">			 */</span></span><br><span class="line">			WRITE_ONCE(gparent-&gt;rb_left, tmp); <span class="comment">/* == parent-&gt;rb_right */</span></span><br><span class="line">			WRITE_ONCE(parent-&gt;rb_right, gparent);</span><br><span class="line">			<span class="keyword">if</span> (tmp)</span><br><span class="line">				rb_set_parent_color(tmp, gparent, RB_BLACK);</span><br><span class="line">			__rb_rotate_set_parents(gparent, parent, root, RB_RED);</span><br><span class="line">			augment_rotate(gparent, parent);</span><br><span class="line">			<span class="keyword">break</span>;</span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			tmp = gparent-&gt;rb_left;</span><br><span class="line">			<span class="keyword">if</span> (tmp &amp;&amp; rb_is_red(tmp)) &#123;</span><br><span class="line">				<span class="comment">/* Case 1 - color flips */</span></span><br><span class="line">				rb_set_parent_color(tmp, gparent, RB_BLACK);</span><br><span class="line">				rb_set_parent_color(parent, gparent, RB_BLACK);</span><br><span class="line">				node = gparent;</span><br><span class="line">				parent = rb_parent(node);</span><br><span class="line">				rb_set_parent_color(node, parent, RB_RED);</span><br><span class="line">				<span class="keyword">continue</span>;</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			tmp = parent-&gt;rb_left;</span><br><span class="line">			<span class="keyword">if</span> (node == tmp) &#123;</span><br><span class="line">				<span class="comment">/* Case 2 - right rotate at parent */</span></span><br><span class="line">				tmp = node-&gt;rb_right;</span><br><span class="line">				WRITE_ONCE(parent-&gt;rb_left, tmp);</span><br><span class="line">				WRITE_ONCE(node-&gt;rb_right, parent);</span><br><span class="line">				<span class="keyword">if</span> (tmp)</span><br><span class="line">					rb_set_parent_color(tmp, parent,</span><br><span class="line">							    RB_BLACK);</span><br><span class="line">				rb_set_parent_color(parent, node, RB_RED);</span><br><span class="line">				augment_rotate(parent, node);</span><br><span class="line">				parent = node;</span><br><span class="line">				tmp = node-&gt;rb_left;</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			<span class="comment">/* Case 3 - left rotate at gparent */</span></span><br><span class="line">			WRITE_ONCE(gparent-&gt;rb_right, tmp); <span class="comment">/* == parent-&gt;rb_left */</span></span><br><span class="line">			WRITE_ONCE(parent-&gt;rb_left, gparent);</span><br><span class="line">			<span class="keyword">if</span> (tmp)</span><br><span class="line">				rb_set_parent_color(tmp, gparent, RB_BLACK);</span><br><span class="line">			__rb_rotate_set_parents(gparent, parent, root, RB_RED);</span><br><span class="line">			augment_rotate(gparent, parent);</span><br><span class="line">			<span class="keyword">break</span>;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>这里看着代码比较复杂，其实就是利用递归来做旋转和变色，具体如下：</p>
<h4 id="场景1：红黑树为空树"><a href="#场景1：红黑树为空树" class="headerlink" title="场景1：红黑树为空树"></a>场景1：红黑树为空树</h4><p>直接把插入结点作为根节点就可以了</p>
<p>另外：根据红黑树性质 2根节点是黑色的。还需要把插入节点设置为黑色</p>
<h4 id="场景2：插入节点的Key已经存在"><a href="#场景2：插入节点的Key已经存在" class="headerlink" title="场景2：插入节点的Key已经存在"></a>场景2：插入节点的Key已经存在</h4><p>更新当前节点的值，为插入节点的值。</p>
<p><img src="https://zhuzhuzaiimgbed.oss-cn-hangzhou.aliyuncs.com/img/image-20250930190317643.png" alt="image-20250930190317643"></p>
<h4 id="情景3：插入节点的父节点为黑色"><a href="#情景3：插入节点的父节点为黑色" class="headerlink" title="情景3：插入节点的父节点为黑色"></a>情景3：插入节点的父节点为黑色</h4><p>由于插入的节点是红色的，当插入节点的父节点是黑色时，不会影响红黑树的平衡，</p>
<p>所以： <strong>直接插入无需做自平衡</strong>。</p>
<p><img src="https://zhuzhuzaiimgbed.oss-cn-hangzhou.aliyuncs.com/img/image-20250930190359749.png" alt="image-20250930190359749"></p>
<h4 id="情景4：插入节点的父节点为红色"><a href="#情景4：插入节点的父节点为红色" class="headerlink" title="情景4：插入节点的父节点为红色"></a>情景4：插入节点的父节点为红色</h4><p>根据性质2：根节点是黑色。</p>
<p>如果插入节点的父节点为红色节点，那么该父节点不可能为根节点，所以插入节点总是存在祖父节点(三代关系)。</p>
<p>根据性质4：每个<strong>红色</strong>节点的两个子节点一定是<strong>黑色</strong>的。不能有<strong>两个红色节点相连</strong>。</p>
<p>此时会出现两种状态：</p>
<ul>
<li>父亲和叔叔为红色</li>
<li>父亲为红色，叔叔为黑色</li>
</ul>
<p><img src="https://zhuzhuzaiimgbed.oss-cn-hangzhou.aliyuncs.com/img/image-20250930190427233.png" alt="image-20250930190427233"></p>
<h5 id="场景4-1：父亲和叔叔为红色节点"><a href="#场景4-1：父亲和叔叔为红色节点" class="headerlink" title="场景4.1：父亲和叔叔为红色节点"></a>场景4.1：父亲和叔叔为红色节点</h5><p>根据性质4：<strong>红色节点不能相连 &#x3D;&#x3D;》祖父节点肯定为黑色节点：</strong></p>
<p>父亲为红色，那么此时该插入子树的红黑树层数的情况是：黑红红。</p>
<p>因为不可能同时存在两个相连的红色节点，需要进行 变色， 显然处理方式是把其改为：红黑红</p>
<p><strong>变色 处理</strong>：黑红红 &#x3D;&#x3D;&gt; 红黑红</p>
<p>1.将F和V节点改为黑色</p>
<p>2.将P改为红色</p>
<p>3.将P设置为当前节点，进行后续处理</p>
<p><img src="https://zhuzhuzaiimgbed.oss-cn-hangzhou.aliyuncs.com/img/image-20250930190513948.png" alt="image-20250930190513948"></p>
<p>将P设置为红色了，</p>
<p>如果<strong>P的父节点是黑色</strong>，那么无需做处理；</p>
<p>但如果P的父节点是红色，则违反红黑树性质了，所以需要将P设置为当前节点，继续插入操作, 作自平衡处理，直到整体平衡为止。</p>
<h5 id="场景4-2：叔叔为黑色，父亲为红色，并且插在父亲的左节点"><a href="#场景4-2：叔叔为黑色，父亲为红色，并且插在父亲的左节点" class="headerlink" title="场景4.2：叔叔为黑色，父亲为红色，并且插在父亲的左节点"></a>场景4.2：叔叔为黑色，父亲为红色，并且插在父亲的左节点</h5><p>分为两种情况，当前结点是左节点和当前结点是右结点</p>
<ul>
<li>场景4.2.1 LL型失衡</li>
</ul>
<p>把F设置成黑色，P设置成红色，然后右旋。</p>
<p><img src="https://zhuzhuzaiimgbed.oss-cn-hangzhou.aliyuncs.com/img/image-20250930190759084.png" alt="image-20250930190759084"></p>
<ul>
<li>场景4.2.2 LR型失衡</li>
</ul>
<p>把K和F进行左旋，转换成4.2.1</p>
<p><img src="https://zhuzhuzaiimgbed.oss-cn-hangzhou.aliyuncs.com/img/image-20250930190824711.png" alt="image-20250930190824711"></p>
<p>同理RR失衡和RL失衡则不再重复。</p>
]]></content>
      <categories>
        <category>note</category>
      </categories>
      <tags>
        <tag>os</tag>
      </tags>
  </entry>
  <entry>
    <title>Tensorflow OP 代码分析</title>
    <url>/2023/09/22/note/Tensorflow%20C++%20op/</url>
    <content><![CDATA[<h1 id="Tensorflow-OP-代码分析"><a href="#Tensorflow-OP-代码分析" class="headerlink" title="Tensorflow OP 代码分析"></a>Tensorflow OP 代码分析</h1><p>[TOC]</p>
<h2 id="增加一个新的op"><a href="#增加一个新的op" class="headerlink" title="增加一个新的op"></a>增加一个新的op</h2><p>增加一个新的op需要通过<code>REGISTER_OP</code> 宏进行注册，如下代码所示。宏中定义了这个OP的输入，输出，attr属性等。创建文件<code>tensorflow/core/user_ops/zero_out.cc</code>并输入如下代码</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;tensorflow/core/framework/op.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="built_in">REGISTER_OP</span>(<span class="string">&quot;ZeroOut&quot;</span>)</span><br><span class="line">    .<span class="built_in">Input</span>(<span class="string">&quot;to_zero: int32&quot;</span>)</span><br><span class="line">    .<span class="built_in">Output</span>(<span class="string">&quot;zeroed: int32&quot;</span>);</span><br></pre></td></tr></table></figure>

<blockquote>
<p>ZeroOut这个op名字必须是唯一的，而以下划线<code>_</code>开头的名字一般是保留内部使用的</p>
</blockquote>
<h2 id="增加OP的实现"><a href="#增加OP的实现" class="headerlink" title="增加OP的实现"></a>增加OP的实现</h2><p>OP仅仅是定义了一个接口，而一个OP可以有很多个实现，包括<code>CPU</code>, <code>GPU</code>等的实现，可以通过继承一个<code>OpKernel </code>的类，并且重写<code>Compute</code>函数来实现一个tensorflow OP implement. <code>Compute</code>函数接收一个<code>OpKernelContext</code>类型的参数，能够通过它获取相关的op上下文，例如输入，然后对其进行处理。如下是一个例子：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;tensorflow/core/framework/op_kernel.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> tensorflow;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ZeroOutOp</span> : <span class="keyword">public</span> OpKernel &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">ZeroOutOp</span><span class="params">(OpKernelConstruction* context)</span> : OpKernel(context) &#123;</span>&#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">Compute</span><span class="params">(OpKernelContext* context)</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">    <span class="comment">// Grab the input tensor</span></span><br><span class="line">    <span class="type">const</span> Tensor&amp; input_tensor = context-&gt;<span class="built_in">input</span>(<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">auto</span> input = input_tensor.<span class="built_in">flat</span>&lt;int32&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Create an output tensor</span></span><br><span class="line">    Tensor* output_tensor = <span class="literal">NULL</span>;</span><br><span class="line">    <span class="built_in">OP_REQUIRES_OK</span>(context, context-&gt;<span class="built_in">allocate_output</span>(<span class="number">0</span>, input_tensor.<span class="built_in">shape</span>(),</span><br><span class="line">                                                     &amp;output_tensor));</span><br><span class="line">    <span class="keyword">auto</span> output = output_tensor-&gt;<span class="built_in">flat</span>&lt;int32&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Set all but the first element of the output tensor to 0.</span></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> N = input.<span class="built_in">size</span>();</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt; N; i++) &#123;</span><br><span class="line">      <span class="built_in">output</span>(i) = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Preserve the first input value if possible.</span></span><br><span class="line">    <span class="keyword">if</span> (N &gt; <span class="number">0</span>) <span class="built_in">output</span>(<span class="number">0</span>) = <span class="built_in">input</span>(<span class="number">0</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意Compute函数需要保证线程安全的，否则可能会有竞争。</p>
</blockquote>
<p>在实现内核之后，将其注册到TensorFlow系统。在注册中，您可以指定运行该内核的不同约束。例如，您可能有一个用于cpu的内核，另一个用于gpu的内核。需要使用如下宏到<code>zero_out.cc</code>文件中：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">REGISTER_KERNEL_BUILDER</span>(<span class="built_in">Name</span>(<span class="string">&quot;ZeroOut&quot;</span>).<span class="built_in">Device</span>(DEVICE_CPU), ZeroOutOp);</span><br></pre></td></tr></table></figure>

<h2 id="Build-OP-库"><a href="#Build-OP-库" class="headerlink" title="Build OP 库"></a>Build OP 库</h2><p>需要本地安装有g++，然后对<code>zero_out.cc</code>进行编译，找到<code>zero_out.cc</code>文件，对其进行编译</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">TF_CFLAGS=( $(python -c &#x27;import tensorflow as tf; print(&quot; &quot;.join(tf.sysconfig.get_compile_flags()))&#x27;) )</span><br><span class="line">TF_LFLAGS=( $(python -c &#x27;import tensorflow as tf; print(&quot; &quot;.join(tf.sysconfig.get_link_flags()))&#x27;) )</span><br><span class="line">g++ -std=c++11 -shared zero_out.cc -o zero_out.so -fPIC $&#123;TF_CFLAGS[@]&#125; $&#123;TF_LFLAGS[@]&#125; -O2</span><br></pre></td></tr></table></figure>

<p><code>zero_out.cc</code>全部内容如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;tensorflow/core/framework/op.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;tensorflow/core/framework/op_kernel.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="built_in">REGISTER_OP</span>(<span class="string">&quot;ZeroOutzrf&quot;</span>).<span class="built_in">Input</span>(<span class="string">&quot;to_zero: int32&quot;</span>).<span class="built_in">Output</span>(<span class="string">&quot;zeroed: int32&quot;</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> tensorflow;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ZeroOutOpZRF</span> : <span class="keyword">public</span> OpKernel &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">ZeroOutOpZRF</span><span class="params">(OpKernelConstruction* context)</span> : OpKernel(context) &#123;</span>&#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">Compute</span><span class="params">(OpKernelContext* context)</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">    <span class="comment">// Grab the input tensor</span></span><br><span class="line">    <span class="type">const</span> Tensor&amp; input_tensor = context-&gt;<span class="built_in">input</span>(<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">auto</span> input = input_tensor.<span class="built_in">flat</span>&lt;int32&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Create an output tensor</span></span><br><span class="line">    Tensor* output_tensor = <span class="literal">NULL</span>;</span><br><span class="line">    <span class="built_in">OP_REQUIRES_OK</span>(context, context-&gt;<span class="built_in">allocate_output</span>(<span class="number">0</span>, input_tensor.<span class="built_in">shape</span>(),</span><br><span class="line">                                                     &amp;output_tensor));</span><br><span class="line">    <span class="keyword">auto</span> output = output_tensor-&gt;<span class="built_in">flat</span>&lt;int32&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Set all but the first element of the output tensor to 0.</span></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> N = input.<span class="built_in">size</span>();</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt; N; i++) &#123;</span><br><span class="line">      <span class="built_in">output</span>(i) = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Preserve the first input value if possible.</span></span><br><span class="line">    <span class="keyword">if</span> (N &gt; <span class="number">0</span>) <span class="built_in">output</span>(<span class="number">0</span>) = <span class="built_in">input</span>(<span class="number">0</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="built_in">REGISTER_KERNEL_BUILDER</span>(<span class="built_in">Name</span>(<span class="string">&quot;ZeroOutzrf&quot;</span>).<span class="built_in">Device</span>(DEVICE_CPU), ZeroOutOpZRF);</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="使用bazel编译操作"><a href="#使用bazel编译操作" class="headerlink" title="使用bazel编译操作"></a>使用bazel编译操作</h2><p>如果你安装了 TensorFlow 源码，则你可以利用 TensorFLow 的构建系统来编译你的操作。把一个 BUILD 文件放在<br><a href="https://www.tensorflow.org/code/tensorflow/core/user_ops/"><code>tensorflow/core/user_ops</code></a> 目录中，其中包含 Bazel 的构建规则，内容如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">load</span>(<span class="string">&quot;//tensorflow:tensorflow.bzl&quot;</span>, <span class="string">&quot;tf_custom_op_library&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">tf_custom_op_library</span>(</span><br><span class="line">    name = <span class="string">&quot;zero_out.so&quot;</span>,</span><br><span class="line">    srcs = [<span class="string">&quot;zero_out.cc&quot;</span>],</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>运行下列命令来构建 <code>zero_out.so</code>.</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">bazel build --config opt //tensorflow/core/user_ops:zero_out.so</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意：虽然你可以用标准 <code>cc_library</code> 规则来生成一个共享库文件（<code>.so</code> 文件），我们还是强烈推荐使用 <code>tf_custom_op_library</code> 宏。这个宏加了一些必要的依赖项，而且还包含一些检查，以确保输出的共享库文件与 TensorFlow 的插件加载机制兼容。</p>
</blockquote>
<h2 id="条件检查和验证"><a href="#条件检查和验证" class="headerlink" title="条件检查和验证"></a>条件检查和验证</h2><p>上述示例假定操作适用于任意形状的张量。但如果我们只处理矢量呢？那么我们就需要在 OpKernel 的实现中加入一个检查：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">Compute</span><span class="params">(OpKernelContext* context)</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 获得输入张量</span></span><br><span class="line">  <span class="type">const</span> Tensor&amp; input_tensor = context-&gt;<span class="built_in">input</span>(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">OP_REQUIRES</span>(context, TensorShapeUtils::<span class="built_in">IsVector</span>(input_tensor.<span class="built_in">shape</span>()),</span><br><span class="line">              errors::<span class="built_in">InvalidArgument</span>(<span class="string">&quot;ZeroOut expects a 1-D vector.&quot;</span>));</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这里我们加了一个断言，它要求输入是一个矢量，否则将设置 <code>InvalidArgument</code> 状态。<a href="https://www.tensorflow.org/code/tensorflow/core/lib/core/errors.h"><code>OP_REQUIRES</code> 宏</a> 有三个参数：</p>
<ul>
<li>上下文 <code>context</code>：既可以是一个 <code>OpKernelContext</code>，也可以是一个 <code>OpKernelConstruction</code> 指针（参见<br> <a href="https://www.tensorflow.org/code/tensorflow/core/framework/op_kernel.h"><code>tensorflow/core/framework/op_kernel.h</code></a> 文件），用于其 <code>SetStatus()</code> 方法。</li>
<li>条件：关于验证张量形状的更多函数，参见文件<br> <a href="https://www.tensorflow.org/code/tensorflow/core/framework/tensor_shape.h"><code>tensorflow/core/framework/tensor_shape.h</code></a></li>
<li>错误本身：它由一个 <code>Status</code> 对象表示，参见文件<br> <a href="https://www.tensorflow.org/code/tensorflow/core/lib/core/status.h"><code>tensorflow/core/lib/core/status.h</code></a>。一个 <code>Status</code> 对象包含一个类型（常为 <code>InvalidArgument</code>，但能看到类型列表）和一条消息。构建一个错误的函数参见文件<br>  <a href="https://www.tensorflow.org/code/tensorflow/core/lib/core/errors.h"><code>tensorflow/core/lib/core/errors.h</code></a>。</li>
</ul>
<p>另外，如果你想测试从某个函数返回的 <code>Status</code> 对象是否为错误，则使用宏 <a href="https://www.tensorflow.org/code/tensorflow/core/lib/core/errors.h"><code>OP_REQUIRES_OK</code></a>。这两个宏都会在错误报错时返回错误对象。</p>
<h2 id="属性"><a href="#属性" class="headerlink" title="属性"></a>属性</h2><p>操作可以有属性，当一个操作被加到计算图中时，它的属性就会被赋值。这些属性用于配置此操作，它们的值既可以在内核实现中访问，也可以在操作注册时的输入输出类型中进行访问。相较于输入，参数的使用要尽量避免，因为输入更为灵活一些。这是因为属性是常数，<br>必须在计算图构造时定义。相反，输入作为张量，它的值是动态的；即输入的值在每一步都可以修改，比如使用 feed。属性主要用于无法使用输入的场合：任何影响特征（输入输出的数量和类型）的配置，或无法在每一步修改的时候。</p>
<p>你需要在注册操作时定义属性，定义时要指定名称和使用 <code>Attr</code> 方法的类型，此方法的参数规范如下：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>: <span class="tag">&lt;<span class="name">attr-type-expr</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>其中 <code>&lt;name&gt;</code> 以字母开头，由数字、字母和下划线组成，而 <code>&lt;attr-type-expr&gt;</code> 一个类型表达式（参见<a href="https://tensorflow.juejin.im/extend/adding_an_op.html#attr_types">下方</a>）。</p>
<p>比如，如果你想让 <code>ZeroOut</code> 操作保留用户指定的索引，而不是仅保留第 0 个元素，你可以按下面的方式来注册操作：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">REGISTER_OP</span>(<span class="string">&quot;ZeroOut&quot;</span>)</span><br><span class="line">    .<span class="built_in">Attr</span>(<span class="string">&quot;preserve_index: int&quot;</span>)</span><br><span class="line">    .<span class="built_in">Input</span>(<span class="string">&quot;to_zero: int32&quot;</span>)</span><br><span class="line">    .<span class="built_in">Output</span>(<span class="string">&quot;zeroed: int32&quot;</span>);</span><br></pre></td></tr></table></figure>

<p><a href="https://www.tensorflow.org/api_docs/python/tf/DType"><code>tf.DType</code></a></p>
<p>你实现的内核可以在构造函数中通过 <code>context</code> 参数来访问属性：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ZeroOutOp</span> : <span class="keyword">public</span> OpKernel &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">ZeroOutOp</span><span class="params">(OpKernelConstruction* context)</span> : OpKernel(context) &#123;</span></span><br><span class="line">    <span class="comment">// 获取待保存的索引值</span></span><br><span class="line">    <span class="built_in">OP_REQUIRES_OK</span>(context,</span><br><span class="line">                   context-&gt;<span class="built_in">GetAttr</span>(<span class="string">&quot;preserve_index&quot;</span>, &amp;preserve_index_));</span><br><span class="line">    <span class="comment">// 检查 preserve_index 是否为正值</span></span><br><span class="line">    <span class="built_in">OP_REQUIRES</span>(context, preserve_index_ &gt;= <span class="number">0</span>,</span><br><span class="line">                errors::<span class="built_in">InvalidArgument</span>(<span class="string">&quot;Need preserve_index &gt;= 0, got &quot;</span>,</span><br><span class="line">                                        preserve_index_));</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">Compute</span><span class="params">(OpKernelContext* context)</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">  &#125;</span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="type">int</span> preserve_index_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>还可以在 <code>Compute</code> 方法中使用这个参数：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">Compute</span><span class="params">(OpKernelContext* context)</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 我们用保存的属性来检查动态输入的合法性</span></span><br><span class="line">  <span class="comment">// 所以，我们检查 preserve_index 是否在允许的值域范围内</span></span><br><span class="line">  <span class="built_in">OP_REQUIRES</span>(context, preserve_index_ &lt; input.<span class="built_in">dimension</span>(<span class="number">0</span>),</span><br><span class="line">              errors::<span class="built_in">InvalidArgument</span>(<span class="string">&quot;preserve_index out of range&quot;</span>));</span><br><span class="line">  <span class="comment">// 将输出张量中所有元素设置为 0</span></span><br><span class="line">  <span class="type">const</span> <span class="type">int</span> N = input.<span class="built_in">size</span>();</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; i++) &#123;</span><br><span class="line">    <span class="built_in">output_flat</span>(i) = <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 保存指定位置的输入值</span></span><br><span class="line">  <span class="built_in">output_flat</span>(preserve_index_) = <span class="built_in">input</span>(preserve_index_);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="属性类型"><a href="#属性类型" class="headerlink" title="属性类型"></a>属性类型</h3><p>属性支持下列数据类型：</p>
<ul>
<li><code>string</code>：任意字节序列（不要求是 UTF8 编码）</li>
<li><code>int</code>：有符号整数</li>
<li><code>float</code>: 浮点数</li>
<li><code>bool</code>: True 或 false</li>
<li><code>type</code>： <a href="https://www.tensorflow.org/code/tensorflow/core/framework/types.cc"><code>DataType</code></a> 的其中一个（非引用）值</li>
<li><code>shape</code>：一个 <a href="https://www.tensorflow.org/code/tensorflow/core/framework/tensor_shape.proto"><code>TensorShapeProto</code></a></li>
<li><code>tensor</code>：一个 <a href="https://www.tensorflow.org/code/tensorflow/core/framework/tensor.proto"><code>TensorProto</code></a></li>
<li><code>list(&lt;type&gt;)</code>： <code>&lt;type&gt;</code> 的列表，其中 <code>&lt;type&gt;</code> 为其中一种上述类型<br> 注意： <code>list(list(&lt;type&gt;))</code> 是非法的。</li>
</ul>
<p>欲了解限定性列表，参见 <a href="https://www.tensorflow.org/code/tensorflow/core/framework/op_def_builder.cc"><code>op_def_builder.cc:FinalizeAttr</code></a>。</p>
<h3 id="默认值和约束"><a href="#默认值和约束" class="headerlink" title="默认值和约束"></a>默认值和约束</h3><p>属性可以有默认值，有一些属性则还可以有约束。为了定义一个有约束的属性，可以使用下列属性类型表达式（<code>&lt;attr-type-expr&gt;</code>）：</p>
<ul>
<li><p><code>{&#39;&lt;string1&gt;&#39;, &#39;&lt;string2&gt;&#39;}</code>：表示在 <code>&lt;string1&gt;</code> 或 <code>&lt;string2&gt;</code> 这两种取值中二选一。当你使用这种语法时，系统自动推断出属性类型为 <code>string</code>。这相当于模仿构造了一个枚举：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">REGISTER_OP</span>(<span class="string">&quot;EnumExample&quot;</span>)</span><br><span class="line">    .<span class="built_in">Attr</span>(<span class="string">&quot;e: &#123;&#x27;apple&#x27;, &#x27;orange&#x27;&#125;&quot;</span>);</span><br></pre></td></tr></table></figure>
</li>
<li><p><a href="https://www.tensorflow.org/api_docs/python/tf/DType"><code>tf.DType</code></a></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">REGISTER_OP</span>(<span class="string">&quot;RestrictedTypeExample&quot;</span>)</span><br><span class="line">    .<span class="built_in">Attr</span>(<span class="string">&quot;t: &#123;int32, float, bool&#125;&quot;</span>);</span><br></pre></td></tr></table></figure>
</li>
<li><p>常用的类型约束可以有如下别名：</p>
<ul>
<li><p><code>numbertype</code>：<code>type</code> 类型被限制为数值类型（不是字符串，也不是布尔类型）</p>
</li>
<li><p><code>realnumbertype</code>：类似于 <code>numbertype</code> 类型，但不包括复数类型</p>
</li>
<li><p><code>quantizedtype</code>：类型于 <code>numbertype</code> 类型，但只包括量化数值类型</p>
<p>属性所支持的类型列表可通过 <a href="https://www.tensorflow.org/code/tensorflow/core/framework/types.h"><code>tensorflow/core/framework/types.h</code></a> 中的一些函数来定义（比如 <code>NumberTypes()</code>）。在本例中，属性 <code>t</code> 必须是下面一种数值类型：</p>
</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">REGISTER_OP</span>(<span class="string">&quot;NumberType&quot;</span>)</span><br><span class="line">    .<span class="built_in">Attr</span>(<span class="string">&quot;t: numbertype&quot;</span>);</span><br></pre></td></tr></table></figure>

<p>  对于这个操作：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tf.number_type(t=tf.int32)  <span class="comment"># 合法</span></span><br><span class="line">tf.number_type(t=tf.<span class="built_in">bool</span>)   <span class="comment"># 不合法</span></span><br></pre></td></tr></table></figure>

<p>  列表可以和其他列表及单一类型组合。下面的操作允许属性 <code>t</code> 为任意数值类型或布尔类型：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">REGISTER_OP</span>(<span class="string">&quot;NumberOrBooleanType&quot;</span>)</span><br><span class="line">    .<span class="built_in">Attr</span>(<span class="string">&quot;t: &#123;numbertype, bool&#125;&quot;</span>);</span><br></pre></td></tr></table></figure>

<p>  对于这个操作：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tf.number_or_boolean_type(t=tf.int32)  <span class="comment"># 合法</span></span><br><span class="line">tf.number_or_boolean_type(t=tf.<span class="built_in">bool</span>)   <span class="comment"># 合法</span></span><br><span class="line">tf.number_or_boolean_type(t=tf.string) <span class="comment"># 不合法</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><code>int &gt;= &lt;n&gt;</code>：取值必须是整型，且要求大于等于 <code>&lt;n&gt;</code>，其中 <code>&lt;n&gt;</code> 是一个自然数。</p>
<p> 比如，下列操作注册中，指定了属性 <code>a</code> 必须为一个至少为 <code>2</code> 的值：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">REGISTER_OP</span>(<span class="string">&quot;MinIntExample&quot;</span>)</span><br><span class="line">    .<span class="built_in">Attr</span>(<span class="string">&quot;a: int &gt;= 2&quot;</span>);</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>list(&lt;type&gt;) &gt;= &lt;n&gt;</code>: 取值为<code>&lt;type&gt;</code> 类型的一个列表，其长度大于等于 <code>&lt;n&gt;</code>。</p>
<p> 比如，下列操作注册指定属性 <code>a</code> 是一个类型列表（要么是 <code>int32</code>，要么是 <code>float</code>），且要求长度大于等于 <code>3</code>：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">REGISTER_OP</span>(<span class="string">&quot;TypeListExample&quot;</span>)</span><br><span class="line">    .<span class="built_in">Attr</span>(<span class="string">&quot;a: list(&#123;int32, float&#125;) &gt;= 3&quot;</span>);</span><br></pre></td></tr></table></figure></li>
</ul>
<p>为设置一个属性的默认值（让它在生成代码中成为可选项），可以在最后加上 <code>= &lt;default&gt;</code>，如下面代码所示：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">REGISTER_OP</span>(<span class="string">&quot;AttrDefaultExample&quot;</span>)</span><br><span class="line">    .<span class="built_in">Attr</span>(<span class="string">&quot;i: int = 0&quot;</span>);</span><br></pre></td></tr></table></figure>

<p>这种默认值的支持语法正是计算图的 GraphDef 定义的协议缓存表达中所用的语法。</p>
<p>下面的示例展示如何为所有类型指定默认值：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">REGISTER_OP</span>(<span class="string">&quot;AttrDefaultExampleForAllTypes&quot;</span>)</span><br><span class="line">   .<span class="built_in">Attr</span>(<span class="string">&quot;s: string = &#x27;foo&#x27;&quot;</span>)</span><br><span class="line">   .<span class="built_in">Attr</span>(<span class="string">&quot;i: int = 0&quot;</span>)</span><br><span class="line">   .<span class="built_in">Attr</span>(<span class="string">&quot;f: float = 1.0&quot;</span>)</span><br><span class="line">   .<span class="built_in">Attr</span>(<span class="string">&quot;b: bool = true&quot;</span>)</span><br><span class="line">   .<span class="built_in">Attr</span>(<span class="string">&quot;ty: type = DT_INT32&quot;</span>)</span><br><span class="line">   .<span class="built_in">Attr</span>(<span class="string">&quot;sh: shape = &#123; dim &#123; size: 1 &#125; dim &#123; size: 2 &#125; &#125;&quot;</span>)</span><br><span class="line">   .<span class="built_in">Attr</span>(<span class="string">&quot;te: tensor = &#123; dtype: DT_INT32 int_val: 5 &#125;&quot;</span>)</span><br><span class="line">   .<span class="built_in">Attr</span>(<span class="string">&quot;l_empty: list(int) = []&quot;</span>)</span><br><span class="line">   .<span class="built_in">Attr</span>(<span class="string">&quot;l_int: list(int) = [2, 3, 5, 7]&quot;</span>);</span><br></pre></td></tr></table></figure>

<p><a href="https://www.tensorflow.org/api_docs/python/tf/DType"><code>tf.DType</code></a></p>
<h1 id="OP源码部分"><a href="#OP源码部分" class="headerlink" title="OP源码部分"></a>OP源码部分</h1><h2 id="REGISTER-OP"><a href="#REGISTER-OP" class="headerlink" title="REGISTER_OP"></a>REGISTER_OP</h2><p> operator(op)是tensorflow扩展功能的的方式。OP分为声明和定义。声明叫op,实现叫kernel.一个声明可以有多个实现。或者说在不同设备上的不同实现。OP需要注册。</p>
<p>时刻注意，OP只是一个声明。如同C++的函数声明。并不涉及这些OP如何实现。比如可以声明一个OP叫Add，其功能是可以做两个数的加法int Add(int a, int b); 而这个声明用一个proto message表示就是message OpDef。而图就是多个OP的输入输出首尾相接组成的有向无环图，这个图实际上表示了函数的调用关系。</p>
<h2 id="OP注册中心接口"><a href="#OP注册中心接口" class="headerlink" title="OP注册中心接口"></a>OP注册中心接口</h2><p>只提供了根据名字查找OP的接口。tensorflow&#x2F;core&#x2F;framework&#x2F;op.h</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">OpRegistryInterface</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="keyword">virtual</span> ~<span class="built_in">OpRegistryInterface</span>();</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Status <span class="title">LookUp</span><span class="params">(<span class="type">const</span> std::string&amp; op_type_name,</span></span></span><br><span class="line"><span class="params"><span class="function">                        <span class="type">const</span> OpRegistrationData** op_reg_data)</span> <span class="type">const</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="function">Status <span class="title">LookUpOpDef</span><span class="params">(<span class="type">const</span> std::string&amp; op_type_name,</span></span></span><br><span class="line"><span class="params"><span class="function">                     <span class="type">const</span> OpDef** op_def)</span> <span class="type">const</span></span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">//实际的一个实现</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">OpRegistry</span> : <span class="keyword">public</span> OpRegistryInterface &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="keyword">typedef</span> std::function&lt;Status(OpRegistrationData*)&gt; OpRegistrationDataFactory;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">OpRegistry</span>();</span><br><span class="line">  ~<span class="built_in">OpRegistry</span>() <span class="keyword">override</span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">Register</span><span class="params">(<span class="type">const</span> OpRegistrationDataFactory&amp; op_data_factory)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="function">Status <span class="title">LookUp</span><span class="params">(<span class="type">const</span> std::string&amp; op_type_name,</span></span></span><br><span class="line"><span class="params"><span class="function">                <span class="type">const</span> OpRegistrationData** op_reg_data)</span> <span class="type">const</span> <span class="keyword">override</span></span>;</span><br><span class="line">  <span class="keyword">mutable</span> mutex mu_;</span><br><span class="line">  <span class="comment">// Functions in deferred_ may only be called with mu_ held.</span></span><br><span class="line">  <span class="function"><span class="keyword">mutable</span> std::vector&lt;OpRegistrationDataFactory&gt; deferred_ <span class="title">TF_GUARDED_BY</span><span class="params">(mu_)</span></span>;</span><br><span class="line">  <span class="comment">// Values are owned.</span></span><br><span class="line">  <span class="function"><span class="keyword">mutable</span> std::unordered_map&lt;string, <span class="type">const</span> OpRegistrationData*&gt; registry_</span></span><br><span class="line"><span class="function">      <span class="title">TF_GUARDED_BY</span><span class="params">(mu_)</span></span>; <span class="comment">//op就是注册在这里了</span></span><br><span class="line">  <span class="function"><span class="keyword">mutable</span> <span class="type">bool</span> initialized_ <span class="title">TF_GUARDED_BY</span><span class="params">(mu_)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Registry watcher.</span></span><br><span class="line">  <span class="function"><span class="keyword">mutable</span> Watcher watcher_ <span class="title">TF_GUARDED_BY</span><span class="params">(mu_)</span></span>;</span><br><span class="line"></span><br><span class="line">  std::function&lt;Status(<span class="type">const</span> OpRegistryInterface&amp;)&gt; op_registry_validator_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>看这几个接口很简单，但是其参数OpDef, OpRegistrationData很复杂。</p>
<h2 id="OpDef"><a href="#OpDef" class="headerlink" title="OpDef"></a>OpDef</h2><p>一个op有多个输入参数，和多个输入属性，还有多个输出参数，多个控制输出。它们都是Tensor。</p>
<p>输入属性的值在构图时已经确定不变了。而输入参数是执行图时变化数据。</p>
<p><img src="https://zhuzhuzaiimgbed.oss-cn-hangzhou.aliyuncs.com/img/image-20240320181116772.png" alt="image-20240320181116772"></p>
<p>class OpDef 是定义在proto中的。tensorflow&#x2F;core&#x2F;framework&#x2F;op_def.proto</p>
<p>这个proto就声明了个OP.实际上就是把输入输出参数，OP名字等等元信息保存下来。</p>
<figure class="highlight protobuf"><table><tr><td class="code"><pre><span class="line"><span class="keyword">message </span><span class="title class_">OpDef</span> &#123;</span><br><span class="line"></span><br><span class="line">  <span class="type">string</span> name = <span class="number">1</span>; <span class="comment">// op名字</span></span><br><span class="line">  <span class="keyword">message </span><span class="title class_">ArgDef</span> &#123; <span class="comment">// op输入输出参数</span></span><br><span class="line">    <span class="type">string</span> name = <span class="number">1</span>;</span><br><span class="line">    <span class="type">string</span> description = <span class="number">2</span>;</span><br><span class="line">    DataType type = <span class="number">3</span>;</span><br><span class="line">    <span class="type">string</span> type_attr = <span class="number">4</span>;    <span class="comment">// if specified, attr must have type &quot;type&quot;</span></span><br><span class="line">    <span class="type">string</span> number_attr = <span class="number">5</span>;  <span class="comment">// if specified, attr must have type &quot;int&quot;</span></span><br><span class="line">    <span class="type">string</span> type_list_attr = <span class="number">6</span>;</span><br><span class="line">    <span class="keyword">repeated</span> ResourceHandleProto.DtypeAndShape handle_data = <span class="number">7</span>;</span><br><span class="line">    <span class="type">bool</span> is_ref = <span class="number">16</span>;</span><br><span class="line">    FullTypeDef experimental_full_type = <span class="number">17</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">repeated</span> ArgDef input_arg = <span class="number">2</span>;</span><br><span class="line">  <span class="keyword">repeated</span> ArgDef output_arg = <span class="number">3</span>;</span><br><span class="line">  <span class="keyword">repeated</span> <span class="type">string</span> control_output = <span class="number">20</span>; <span class="comment">//控制参数</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">message </span><span class="title class_">AttrDef</span> &#123;   <span class="comment">//op属性，构图时已经确定不变</span></span><br><span class="line"></span><br><span class="line">    <span class="type">string</span> name = <span class="number">1</span>;</span><br><span class="line">    <span class="type">string</span> type = <span class="number">2</span>;</span><br><span class="line">    AttrValue default_value = <span class="number">3</span>;</span><br><span class="line">    <span class="type">string</span> description = <span class="number">4</span>;</span><br><span class="line">    <span class="type">bool</span> has_minimum = <span class="number">5</span>;</span><br><span class="line">    <span class="type">int64</span> minimum = <span class="number">6</span>;</span><br><span class="line"></span><br><span class="line">    AttrValue allowed_values = <span class="number">7</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">repeated</span> AttrDef attr = <span class="number">4</span>; <span class="comment">//属性</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">message </span><span class="title class_">OpDeprecation</span> &#123;</span><br><span class="line">  <span class="type">int32</span> version = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">  <span class="type">string</span> explanation = <span class="number">2</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">message </span><span class="title class_">OpList</span> &#123;  <span class="comment">//一组op</span></span><br><span class="line">  <span class="keyword">repeated</span> OpDef op = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="OpDefBuilder来生成OP"><a href="#OpDefBuilder来生成OP" class="headerlink" title="OpDefBuilder来生成OP"></a>OpDefBuilder来生成OP</h2><p>Builder可以通过特定语法格式的字符串来添加 输入参数，输出参数等。添加完成后调用Finalize(OpRegistrationData* op_reg_data)生成了OpRegistrationData. OpRegistrationData有OpDef</p>
<p>tensorflow&#x2F;core&#x2F;framework&#x2F;op_def_builder.h</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">// Builder class passed to the REGISTER_OP() macro.</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">OpDefBuilder</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">OpDefBuilder</span><span class="params">(std::string op_name)</span></span>;</span><br><span class="line">  <span class="comment">//定义属性</span></span><br><span class="line">  <span class="function">OpDefBuilder&amp; <span class="title">Attr</span><span class="params">(std::string spec)</span></span>;</span><br><span class="line">  <span class="comment">//定义输入输出</span></span><br><span class="line">  <span class="function">OpDefBuilder&amp; <span class="title">Input</span><span class="params">(std::string spec)</span></span>;</span><br><span class="line">  <span class="function">OpDefBuilder&amp; <span class="title">Output</span><span class="params">(std::string spec)</span></span>;</span><br><span class="line"></span><br><span class="line">  OpRegistrationData op_reg_data_;</span><br><span class="line">  std::vector&lt;string&gt; attrs_;</span><br><span class="line">  std::vector&lt;string&gt; inputs_;</span><br><span class="line">  std::vector&lt;string&gt; outputs_;</span><br><span class="line">  std::vector&lt;string&gt; control_outputs_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>Op注册原理</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">REGISTER_OP</span>(<span class="string">&quot;ZeroOut&quot;</span>)</span><br><span class="line">    .<span class="built_in">Input</span>(<span class="string">&quot;to_zero: int32&quot;</span>)</span><br><span class="line">    .<span class="built_in">Output</span>(<span class="string">&quot;zeroed: int32&quot;</span>)</span><br><span class="line">    .<span class="built_in">SetShapeFn</span>([](::tensorflow::shape_inference::InferenceContext* c) &#123;</span><br><span class="line">      c-&gt;<span class="built_in">set_output</span>(<span class="number">0</span>, c-&gt;<span class="built_in">input</span>(<span class="number">0</span>));</span><br><span class="line">      <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">    &#125;);</span><br></pre></td></tr></table></figure>

<p>REGISTER_OP宏，实际上定义了如下的OpDefBuilderWrapper的对象。</p>
<p>后续调用的.Input, .Output,等都是对此对象中的Input, Output的方法的调用。而Input里实现上转而调用了OpDefBuilder的Input。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> register_op &#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">OpDefBuilderWrapper</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">OpDefBuilderWrapper</span><span class="params">(<span class="type">const</span> <span class="type">char</span> name[])</span> : builder_(name) &#123;</span>&#125;</span><br><span class="line">  <span class="comment">//属性</span></span><br><span class="line">  <span class="function">OpDefBuilderWrapper&amp; <span class="title">Attr</span><span class="params">(std::string spec)</span> </span>&#123;</span><br><span class="line">    builder_.<span class="built_in">Attr</span>(std::<span class="built_in">move</span>(spec));</span><br><span class="line">    <span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">//输入</span></span><br><span class="line">  <span class="function">OpDefBuilderWrapper&amp; <span class="title">Input</span><span class="params">(std::string spec)</span> </span>&#123;</span><br><span class="line">    builder_.<span class="built_in">Input</span>(std::<span class="built_in">move</span>(spec));</span><br><span class="line">    <span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">//输出</span></span><br><span class="line">  <span class="function">OpDefBuilderWrapper&amp; <span class="title">Output</span><span class="params">(std::string spec)</span> </span>&#123;</span><br><span class="line">    builder_.<span class="built_in">Output</span>(std::<span class="built_in">move</span>(spec));</span><br><span class="line">    <span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//下文中提到的InitOnStartupMarker 中调用了这个</span></span><br><span class="line">  <span class="function">InitOnStartupMarker <span class="title">operator</span><span class="params">()</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="keyword">mutable</span> ::tensorflow::OpDefBuilder builder_;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">&#125;  </span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> REGISTER_OP_IMPL(ctr, name, is_system_op)                         \</span></span><br><span class="line"><span class="meta">  static ::tensorflow::InitOnStartupMarker const register_op##ctr         \</span></span><br><span class="line"><span class="meta">      TF_ATTRIBUTE_UNUSED =                                               \</span></span><br><span class="line"><span class="meta">          TF_INIT_ON_STARTUP_IF(is_system_op || SHOULD_REGISTER_OP(name)) \</span></span><br><span class="line"><span class="meta">          &lt;&lt; ::tensorflow::register_op::OpDefBuilderWrapper(name)</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> REGISTER_OP(name)        \</span></span><br><span class="line"><span class="meta">  TF_ATTRIBUTE_ANNOTATE(<span class="string">&quot;tf:op&quot;</span>) \</span></span><br><span class="line"><span class="meta">  TF_NEW_ID_FOR_INIT(REGISTER_OP_IMPL, name, false)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> REGISTER_SYSTEM_OP(name)        \</span></span><br><span class="line"><span class="meta">  TF_ATTRIBUTE_ANNOTATE(<span class="string">&quot;tf:op&quot;</span>)        \</span></span><br><span class="line"><span class="meta">  TF_ATTRIBUTE_ANNOTATE(<span class="string">&quot;tf:op:system&quot;</span>) \</span></span><br><span class="line"><span class="meta">  TF_NEW_ID_FOR_INIT(REGISTER_OP_IMPL, name, true)</span></span><br><span class="line"></span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure>

<ul>
<li>REGISTER_OP这个宏调用TF_NEW_ID_FOR_INIT. 会使用__COUNTER__宏生成唯一ID.</li>
<li>调用REGISTER_OP_IMPLE时，参数ctr就是counter。</li>
<li>REGISTER_OP_IMPLE所有定义了一个static变量。变量类型是 tensorlfow::InitOnStartUpMarker。变量名是register_op##ctr,实际上就是register_op0, register_op1, ….</li>
<li>TF_INIT_ON_STARTUP_IF宏如果参数是false,则什么也不做，否则 调用后边的&lt;&lt; OpeDefBuilder。这个宏根相当于：!cond ? InitOnStartupMarker{} : (InitOnStartupMarker{} &lt;&lt; f);  f就是::tensorflow::register_op::OpDefBuilderWrapper(name)。因为InitOnStartUpmarker重载了operator&lt;&lt;。</li>
<li>在下图代码InitOpStartupMarker里调用了OpDefBuilderWrapper的Operator()方法。</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">InitOnStartupMarker</span> &#123;</span><br><span class="line">  <span class="keyword">constexpr</span> InitOnStartupMarker <span class="keyword">operator</span>&lt;&lt;(InitOnStartupMarker) <span class="type">const</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line">  <span class="keyword">constexpr</span> InitOnStartupMarker <span class="keyword">operator</span>&lt;&lt;(T&amp;&amp; v) <span class="type">const</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> std::forward&lt;T&gt;(v)();  #相当于调用OpDefBuilderWrapper对像的<span class="built_in">operator</span>()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 是否在启动时就注册</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> TF_INIT_ON_STARTUP_IF(cond)                \</span></span><br><span class="line"><span class="meta">  (::std::integral_constant<span class="string">&lt;bool, !(cond)&gt;</span>::value) \</span></span><br><span class="line"><span class="meta">      ? ::tensorflow::InitOnStartupMarker&#123;&#125;        \</span></span><br><span class="line"><span class="meta">      : ::tensorflow::InitOnStartupMarker &#123;&#125;</span></span><br></pre></td></tr></table></figure>

<p>真正注册在这里：通过builder获取全局注册中心，实际上是不台OP的构建器function保存下来，在需要的时候就可以通过它来new出新的OP对象了。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">arduino复制代码<span class="function">InitOnStartupMarker <span class="title">OpDefBuilderWrapper::operator</span><span class="params">()</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  OpRegistry::<span class="built_in">Global</span>()-&gt;<span class="built_in">Register</span>(</span><br><span class="line">      [builder =</span><br><span class="line">           std::<span class="built_in">move</span>(builder_)](OpRegistrationData* op_reg_data) -&gt; Status &#123;</span><br><span class="line">        <span class="keyword">return</span> builder.<span class="built_in">Finalize</span>(op_reg_data);</span><br><span class="line">      &#125;);</span><br><span class="line">  <span class="keyword">return</span> &#123;&#125;;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// static,单例</span></span><br><span class="line"><span class="function">OpRegistry* <span class="title">OpRegistry::Global</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">static</span> OpRegistry* global_op_registry = <span class="keyword">new</span> OpRegistry;</span><br><span class="line">  <span class="keyword">return</span> global_op_registry;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">OpRegistry::Register</span><span class="params">(<span class="type">const</span> OpRegistrationDataFactory&amp; op_data_factory)</span> </span>&#123;</span><br><span class="line">  <span class="function">mutex_lock <span class="title">lock</span><span class="params">(mu_)</span></span>;</span><br><span class="line">  <span class="keyword">if</span> (initialized_) &#123;</span><br><span class="line">    <span class="built_in">TF_QCHECK_OK</span>(<span class="built_in">RegisterAlreadyLocked</span>(op_data_factory));</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    deferred_.<span class="built_in">push_back</span>(op_data_factory);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> std::function&lt;Status(OpRegistrationData*)&gt; OpRegistrationDataFactory;</span><br></pre></td></tr></table></figure>

<p>最终把构建好的op,其实就是OpRegistrationData插入到map&lt;op_name, OpRegistrationData*&gt; OpRegistry::registry_中。</p>
<h1 id="KERNEL源码部分"><a href="#KERNEL源码部分" class="headerlink" title="KERNEL源码部分"></a>KERNEL源码部分</h1><p>tensorflow图结点叫OP(operator)。OP是C++写的可以由使用者任意扩展的。扩展OP分两步，1是OP的声明，也就OP注册，使用REGISTER_OP来完成。2是OP的实现，叫op_kernel。KERNEL也需要注册，叫REGISTER_KERNEL_BUILDER。OP在实现时需要继承OpKernel类。</p>
<p>构图时只需要OP声明即可。运行时才需要查找并实例化Kernel。一个OP在不同的设备上可以有不同的实现。下面的例子是官网最简单的ZeroOut OP声明和Kernel的实现。实际上，声明和实现完全可以独立在不同的文件。本文则着重分析Kernel</p>
<p>Kernel是真正实现计算功能的。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;tensorflow/core/framework/op.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;tensorflow/core/framework/shape_inference.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;tensorflow/core/framework/op_kernel.h&quot;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> tensorflow;</span><br><span class="line"><span class="comment">//OP的声明</span></span><br><span class="line"><span class="built_in">REGISTER_OP</span>(<span class="string">&quot;ZeroOut&quot;</span>)</span><br><span class="line">    .<span class="built_in">Input</span>(<span class="string">&quot;to_zero: int32&quot;</span>)</span><br><span class="line">    .<span class="built_in">Output</span>(<span class="string">&quot;zeroed: int32&quot;</span>)</span><br><span class="line">    .<span class="built_in">SetShapeFn</span>([](::tensorflow::shape_inference::InferenceContext* c) &#123;</span><br><span class="line">      c-&gt;<span class="built_in">set_output</span>(<span class="number">0</span>, c-&gt;<span class="built_in">input</span>(<span class="number">0</span>));</span><br><span class="line">      <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">    &#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">//OP实现</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ZeroOutOp</span> : <span class="keyword">public</span> OpKernel &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">ZeroOutOp</span><span class="params">(OpKernelConstruction* context)</span> : OpKernel(context) &#123;</span>&#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">Compute</span><span class="params">(OpKernelContext* context)</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">    <span class="comment">// Grab the input tensor</span></span><br><span class="line">    <span class="type">const</span> Tensor&amp; input_tensor = context-&gt;<span class="built_in">input</span>(<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">auto</span> input = input_tensor.<span class="built_in">flat</span>&lt;int32&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Create an output tensor</span></span><br><span class="line">    Tensor* output_tensor = <span class="literal">NULL</span>;</span><br><span class="line">    <span class="built_in">OP_REQUIRES_OK</span>(context, context-&gt;<span class="built_in">allocate_output</span>(<span class="number">0</span>, input_tensor.<span class="built_in">shape</span>(),</span><br><span class="line">                                                     &amp;output_tensor));</span><br><span class="line">    <span class="keyword">auto</span> output_flat = output_tensor-&gt;<span class="built_in">flat</span>&lt;int32&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Set all but the first element of the output tensor to 0.</span></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> N = input.<span class="built_in">size</span>();</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt; N; i++) &#123;</span><br><span class="line">      <span class="built_in">output_flat</span>(i) = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Preserve the first input value if possible.</span></span><br><span class="line">    <span class="keyword">if</span> (N &gt; <span class="number">0</span>) <span class="built_in">output_flat</span>(<span class="number">0</span>) = <span class="built_in">input</span>(<span class="number">0</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">//注册KERNEL</span></span><br><span class="line"><span class="built_in">REGISTER_KERNEL_BUILDER</span>(<span class="built_in">Name</span>(<span class="string">&quot;ZeroOut&quot;</span>).<span class="built_in">Device</span>(DEVICE_CPU), ZeroOutOp);</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="Kernel"><a href="#Kernel" class="headerlink" title="Kernel"></a>Kernel</h2><p>tensorflow&#x2F;core&#x2F;framework&#x2F;op_kernel.h</p>
<h2 id="同步计算-Compute方法"><a href="#同步计算-Compute方法" class="headerlink" title="同步计算 Compute方法"></a>同步计算 Compute方法</h2><ol>
<li>kernel计算可以是同步也可以是异步。Compute必须是线程安全。大多数是同步。</li>
<li>同步 kernel 绝不能用锁，条件变量等阻塞当前线程，试图在其他kernel里解锁。有</li>
<li>因为executor可能只有固定数量的线程，都阻塞就会死锁</li>
<li>如果真想加锁，如RecvOp, DequeueOp,必须继承OpKernel的子类AsyncOpKernel。</li>
<li>大多数情况下，AsyncOpKerenl应当使用cancellation机制：context-&gt;cancellation_manager()</li>
<li>op的输入输出都要通过参数OpKernelContext context来获得。返回状态也通过ctx-&gt;SetStatus()</li>
<li>同步计算中，context可以保证函数返回前直存在。</li>
</ol>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//构造与析构</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">OpKernel</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="comment">//kernel不会在调度器中初始化，所以可以在子类中实现重逻辑</span></span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">OpKernel</span><span class="params">(OpKernelConstruction* context)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//允许延时OP. executor会使用OpKernelContext::inc_num_deferred_ops_function()` and</span></span><br><span class="line">  <span class="comment">// `OpKernelContext::dec_num_deferred_ops_function()` methods at run-time.</span></span><br><span class="line">  <span class="built_in">OpKernel</span>(OpKernelConstruction* context, <span class="type">bool</span> is_deferred);</span><br><span class="line">  <span class="comment">//能请允许子类自定义NodeDef</span></span><br><span class="line">  <span class="built_in">OpKernel</span>(OpKernelConstruction* context, NodeDef&amp;&amp; custom_def,</span><br><span class="line">           <span class="type">bool</span> is_deferred);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">virtual</span> ~<span class="built_in">OpKernel</span>();</span><br><span class="line">     </span><br><span class="line">  <span class="comment">//核心计算函数，子类重写它来实现自己的功能</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">Compute</span><span class="params">(OpKernelContext* context)</span> </span>= <span class="number">0</span>;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> AsyncOpKernel* <span class="title">AsAsync</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> <span class="literal">nullptr</span>; &#125;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">bool</span> <span class="title">IsExpensive</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> expensive_; &#125;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">const</span> Tensor* <span class="title">const_tensor</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> <span class="literal">nullptr</span>; &#125;</span><br><span class="line">  <span class="comment">// Accessors. 能返回结点定义，结点名字，</span></span><br><span class="line">  <span class="function"><span class="type">const</span> NodeDef&amp; <span class="title">def</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> props_-&gt;node_def; &#125;</span><br><span class="line">  <span class="function"><span class="type">const</span> std::string&amp; <span class="title">name</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> props_-&gt;node_def.<span class="built_in">name</span>(); &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="异步计算：AsyncOpKernel"><a href="#异步计算：AsyncOpKernel" class="headerlink" title="异步计算：AsyncOpKernel"></a>异步计算：AsyncOpKernel</h2><p>异步也就是computeAsync要立即返回。当然tensorflow会一直保持context存在，直到done被调用。一但done被调用，不应当再使用context。否则会core。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">AsyncOpKernel</span> : <span class="keyword">public</span> OpKernel &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="keyword">using</span> OpKernel::OpKernel;  <span class="comment">// Lift OpKernel constructors.</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">//异步计算完成后要调用此回调函数通知调度器。</span></span><br><span class="line">  <span class="comment">//只能调用一次，一旦调用，context, 和this都可能已经销毁了</span></span><br><span class="line">  <span class="keyword">typedef</span> std::function&lt;<span class="type">void</span>()&gt; DoneCallback;</span><br><span class="line">  <span class="comment">//异步计算就重写此接口</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">ComputeAsync</span><span class="params">(OpKernelContext* context, DoneCallback done)</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="function">AsyncOpKernel* <span class="title">AsAsync</span><span class="params">()</span> <span class="keyword">override</span> </span>&#123; <span class="keyword">return</span> <span class="keyword">this</span>; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">Compute</span><span class="params">(OpKernelContext* context)</span> <span class="keyword">override</span></span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="Kernel构造时的OpKernelConstruction"><a href="#Kernel构造时的OpKernelConstruction" class="headerlink" title="Kernel构造时的OpKernelConstruction"></a>Kernel构造时的OpKernelConstruction</h2><p>传入了</p>
<ol>
<li>设备:device</li>
<li>分配器Allocator</li>
<li>资源管理器：ResourceMgr</li>
<li>Node</li>
<li>Env</li>
<li>FunctionLib</li>
</ol>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//创建OP时由tensorflow框架创建此类，并传入给OP的构建函数。</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">OpKernelConstruction</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line"></span><br><span class="line">  <span class="comment">//环境，访问操作系统如文件系统，线程创建要使用此env.</span></span><br><span class="line">  <span class="function">Env* <span class="title">env</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> device_-&gt;<span class="built_in">env</span>(); &#125;</span><br><span class="line"> </span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">SetStatus</span><span class="params">(<span class="type">const</span> Status&amp; status)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">const</span> Status&amp; <span class="title">status</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> *status_; &#125;</span><br><span class="line">  <span class="comment">//属性时在构图时确定了的，所以在没有运行图时就能获取值。</span></span><br><span class="line">  <span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line">  <span class="function">Status <span class="title">GetAttr</span><span class="params">(StringPiece attr_name, T* value)</span> <span class="type">const</span></span>;</span><br><span class="line">  <span class="function"><span class="type">const</span> DeviceType&amp; <span class="title">device_type</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> device_type_; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function">FunctionLibraryRuntime* <span class="title">function_library</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> flib_; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Shared resources accessible to this kernel.</span></span><br><span class="line">  <span class="function">ResourceMgr* <span class="title">resource_manager</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> resource_mgr_; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// The GraphDef version whose behavior we should follow.</span></span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">graph_def_version</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> graph_def_version_; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//获取设备</span></span><br><span class="line">  <span class="function">DeviceBase* <span class="title">device</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> device_; &#125;</span><br><span class="line"></span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="OP输入输出参数帮助类"><a href="#OP输入输出参数帮助类" class="headerlink" title="OP输入输出参数帮助类"></a>OP输入输出参数帮助类</h2><p>有的输入是个List,用一个名字，代表了同类型的多个输入。 可以认为是Tensor tensors[N].输出也有这种情况。</p>
<ol>
<li>OpInputList</li>
<li>OpMutableInputList</li>
<li>OpOutputList</li>
</ol>
<h2 id="Compute的参数OpKernelContext"><a href="#Compute的参数OpKernelContext" class="headerlink" title="Compute的参数OpKernelContext"></a>Compute的参数OpKernelContext</h2><p>这个类十分巨大，内容丰富。这个Context提供了Op Compute时所需要的一切。从逻辑上讲，可分为以下几类</p>
<h3 id="输入输出参数获取"><a href="#输入输出参数获取" class="headerlink" title="输入输出参数获取"></a>输入输出参数获取</h3><p>Input, Output. 至于Attr,是在构图时获得，OpKernelConstruction里就能获取</p>
<p>输出还涉及到Tensor内存分配</p>
<h3 id="执行环境"><a href="#执行环境" class="headerlink" title="执行环境"></a>执行环境</h3><p>env, device, resource_mgr, node, graph, session, step_id, function_library, allocator, session</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">OpKernelContext</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="comment">//基本信息</span></span><br><span class="line">   <span class="type">const</span> SessionMetadata* session_metadata = <span class="literal">nullptr</span>;</span><br><span class="line">   TensorStore* tensor_store = <span class="literal">nullptr</span>;</span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">OpKernelContext</span><span class="params">(Params* params)</span></span>;</span><br><span class="line">  <span class="built_in">OpKernelContext</span>(Params* params, <span class="type">int</span> num_outputs);</span><br><span class="line">  ~<span class="built_in">OpKernelContext</span>();</span><br><span class="line">  <span class="function">Env* <span class="title">env</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> params_-&gt;device-&gt;<span class="built_in">env</span>(); &#125;</span><br><span class="line">  <span class="function"><span class="type">int64_t</span> <span class="title">step_id</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> params_-&gt;step_id; &#125;</span><br><span class="line">  <span class="function"><span class="type">int64_t</span> <span class="title">start_time_usecs</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> params_-&gt;start_time_usecs; &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 操作op的输入，可以按id,或者名字，只读取或者读写Input</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">const</span> Tensor&amp; <span class="title">input</span><span class="params">(<span class="type">int</span> index)</span> <span class="type">const</span></span>;</span><br><span class="line">  <span class="function">Status <span class="title">input</span><span class="params">(StringPiece name, <span class="type">const</span> Tensor** tensor)</span></span>;</span><br><span class="line">  <span class="function">Status <span class="title">input_list</span><span class="params">(StringPiece name, OpInputList* list)</span></span>;</span><br><span class="line">  <span class="function">Status <span class="title">input_ref_mutex</span><span class="params">(StringPiece name, mutex** out_mutex)</span></span>;</span><br><span class="line">  <span class="function">Tensor <span class="title">mutable_input</span><span class="params">(<span class="type">int</span> index, <span class="type">bool</span> lock_held)</span></span>;</span><br><span class="line">  <span class="function">Status <span class="title">mutable_input</span><span class="params">(StringPiece name, Tensor* tensor, <span class="type">bool</span> lock_held)</span></span>;</span><br><span class="line">  <span class="function">Status <span class="title">mutable_input_list</span><span class="params">(StringPiece name, OpMutableInputList* list)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">replace_ref_input</span><span class="params">(<span class="type">int</span> index, <span class="type">const</span> Tensor&amp; tensor, <span class="type">bool</span> lock_held)</span></span>;</span><br><span class="line">  <span class="function">Status <span class="title">replace_ref_input</span><span class="params">(StringPiece name, <span class="type">const</span> Tensor&amp; tensor,</span></span></span><br><span class="line"><span class="params"><span class="function">                           <span class="type">bool</span> lock_held)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">delete_ref_input</span><span class="params">(<span class="type">int</span> input_index, <span class="type">bool</span> lock_held)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">has_input</span><span class="params">(<span class="type">int</span> index)</span> <span class="type">const</span></span>;</span><br><span class="line"></span><br><span class="line"> <span class="comment">// 操作op的输输出，可以按id,或者名字，只读取或者读写output. 同时可以给output分配内存</span></span><br><span class="line">  <span class="function">Status <span class="title">output_list</span><span class="params">(StringPiece name, OpOutputList* list)</span></span>;</span><br><span class="line">  <span class="function">Status <span class="title">allocate_output</span><span class="params">(<span class="type">int</span> index, <span class="type">const</span> TensorShape&amp; shape,</span></span></span><br><span class="line"><span class="params"><span class="function">                         Tensor** tensor)</span> TF_MUST_USE_RESULT</span>;</span><br><span class="line">  <span class="function">Status <span class="title">allocate_output</span><span class="params">(StringPiece name, <span class="type">const</span> TensorShape&amp; shape,</span></span></span><br><span class="line"><span class="params"><span class="function">  Status allocate_output(<span class="type">int</span> index, <span class="type">const</span> TensorShape&amp; shape, Tensor** tensor,</span></span></span><br><span class="line"><span class="params"><span class="function">                         AllocatorAttributes attr) TF_MUST_USE_RESULT;</span></span></span><br><span class="line"><span class="params"><span class="function">  Status allocate_output(StringPiece name, <span class="type">const</span> TensorShape&amp; shape,</span></span></span><br><span class="line"><span class="params"><span class="function">                         Tensor** tensor,</span></span></span><br><span class="line"><span class="params"><span class="function">                         AllocatorAttributes attr) TF_MUST_USE_RESULT;</span></span></span><br><span class="line"><span class="params"><span class="function">  <span class="comment">//分配一个临时tensor变量</span></span></span></span><br><span class="line"><span class="params"><span class="function">  Status allocate_temp(DataType type, <span class="type">const</span> TensorShape&amp; shape,</span></span></span><br><span class="line"><span class="params"><span class="function">                       Tensor* out_temp, AllocatorAttributes allocator_attr,</span></span></span><br><span class="line"><span class="params"><span class="function">                       <span class="type">const</span> AllocationAttributes&amp; allocation_attr);</span></span></span><br><span class="line"><span class="params"><span class="function">  Status allocate_temp(DataType type, <span class="type">const</span> TensorShape&amp; shape,</span></span></span><br><span class="line"><span class="params"><span class="function">                       Tensor* out_temp, AllocatorAttributes allocator_attr) &#123;</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">return</span> allocate_temp(type, shape, out_temp, allocator_attr,</span></span></span><br><span class="line"><span class="params"><span class="function">                         AllocationAttributes());</span></span></span><br><span class="line"><span class="params"><span class="function">  &#125;</span></span></span><br><span class="line"><span class="params"><span class="function">  Status allocate_temp(DataType type, <span class="type">const</span> TensorShape&amp; shape,</span></span></span><br><span class="line"><span class="params"><span class="function">                       Tensor* out_temp) &#123;</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">return</span> allocate_temp(type, shape, out_temp, AllocatorAttributes());</span></span></span><br><span class="line"><span class="params"><span class="function">  &#125;</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">&#125;;</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br></pre></td></tr></table></figure>

<h2 id="kernel实例化"><a href="#kernel实例化" class="headerlink" title="kernel实例化"></a>kernel实例化</h2><p>运行时调用如下方法创建Kernel</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">std::unique_ptr&lt;OpKernel&gt; <span class="title">CreateOpKernel</span><span class="params">(DeviceType device_type,</span></span></span><br><span class="line"><span class="params"><span class="function">                                         DeviceBase* device,</span></span></span><br><span class="line"><span class="params"><span class="function">                                         Allocator* allocator,</span></span></span><br><span class="line"><span class="params"><span class="function">                                         <span class="type">const</span> NodeDef&amp; node_def,</span></span></span><br><span class="line"><span class="params"><span class="function">                                         <span class="type">int</span> graph_def_version, Status* status)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function">std::unique_ptr&lt;OpKernel&gt; <span class="title">CreateOpKernel</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    DeviceType device_type, DeviceBase* device, Allocator* allocator,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> std::shared_ptr&lt;<span class="type">const</span> NodeProperties&gt;&amp; props, <span class="type">int</span> graph_def_version,</span></span></span><br><span class="line"><span class="params"><span class="function">    Status* status)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function">Status <span class="title">CreateOpKernel</span><span class="params">(DeviceType device_type, DeviceBase* device,</span></span></span><br><span class="line"><span class="params"><span class="function">                      Allocator* allocator, FunctionLibraryRuntime* flib,</span></span></span><br><span class="line"><span class="params"><span class="function">                      <span class="type">const</span> std::shared_ptr&lt;<span class="type">const</span> NodeProperties&gt;&amp; props,</span></span></span><br><span class="line"><span class="params"><span class="function">                      <span class="type">int</span> graph_def_version, OpKernel** kernel)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function">Status <span class="title">CreateOpKernel</span><span class="params">(DeviceType device_type, DeviceBase* device,</span></span></span><br><span class="line"><span class="params"><span class="function">                      Allocator* allocator, FunctionLibraryRuntime* flib,</span></span></span><br><span class="line"><span class="params"><span class="function">                      ResourceMgr* resource_mgr,</span></span></span><br><span class="line"><span class="params"><span class="function">                      <span class="type">const</span> std::shared_ptr&lt;<span class="type">const</span> NodeProperties&gt;&amp; props,</span></span></span><br><span class="line"><span class="params"><span class="function">                      <span class="type">int</span> graph_def_version, OpKernel** kernel)</span></span>;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>Kernel注册同样使用了宏，工厂等</p>
<h3 id="REGISTER-KERNEL-BUILDER流程分析"><a href="#REGISTER-KERNEL-BUILDER流程分析" class="headerlink" title="REGISTER_KERNEL_BUILDER流程分析"></a>REGISTER_KERNEL_BUILDER流程分析</h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//REGISTER_KERNEL_BUILDER 调用了REGISTER_KERNEL_BUILDER_IMPL 调用了TF_EXTRACT_KERNEL_NAME 调用了TF_EXTRACT_KERNEL_NAME_IMPL 调用了REGISTER_KERNEL_BUILDER_IMPL_2 调用了TF_NEW_ID_FOR_INIT调用了REGISTER_KERNEL_BUILDER_IMPL_3</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// REGISTER_KERNEL_BUILDER_IMPL_2, with a unique &#x27;ctr&#x27; as the first argument.</span></span><br><span class="line"><span class="comment">// TODO(dodgen): There are some uses of this macro inside functions, where</span></span><br><span class="line"><span class="comment">// kernel_builder refers to (non-const) locals (they should be fixed). To</span></span><br><span class="line"><span class="comment">// accommodate those, kernel_builder.Build() appears as an argument to an</span></span><br><span class="line"><span class="comment">// immediately-called lambda (not in the lambda itself).</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> REGISTER_KERNEL_BUILDER_IMPL_3(ctr, op_name, kernel_builder_expr,   \</span></span><br><span class="line"><span class="meta">                                       is_system_kernel, ...)               \</span></span><br><span class="line"><span class="meta">  static ::tensorflow::InitOnStartupMarker const register_kernel_##ctr      \</span></span><br><span class="line"><span class="meta">      TF_ATTRIBUTE_UNUSED =                                                 \</span></span><br><span class="line"><span class="meta">          TF_INIT_ON_STARTUP_IF(is_system_kernel ||                         \</span></span><br><span class="line"><span class="meta">                                (SHOULD_REGISTER_OP_KERNEL(#__VA_ARGS__) &amp;&amp; \</span></span><br><span class="line"><span class="meta">                                 SHOULD_REGISTER_OP(op_name)))              \</span></span><br><span class="line"><span class="meta">          &lt;&lt; ([](::tensorflow::KernelDef const* kernel_def) &#123;               \</span></span><br><span class="line"><span class="meta">               也就是到这里了，使用kernel_factory来注册了一个lambda函数      \</span></span><br><span class="line"><span class="meta">               ::tensorflow::kernel_factory::OpKernelRegistrar registrar(   \</span></span><br><span class="line"><span class="meta">                   kernel_def, #__VA_ARGS__,                                \</span></span><br><span class="line"><span class="meta">                   [](::tensorflow::OpKernelConstruction* context)          \</span></span><br><span class="line"><span class="meta">                       -&gt; ::tensorflow::OpKernel* &#123;                         \</span></span><br><span class="line"><span class="meta">                     return new __VA_ARGS__(context); 这里就是在new ZeroOut               \</span></span><br><span class="line"><span class="meta">                   &#125;);                                                      \</span></span><br><span class="line"><span class="meta">               (void)registrar;                                             \</span></span><br><span class="line"><span class="meta">               return ::tensorflow::InitOnStartupMarker&#123;&#125;;                  \</span></span><br><span class="line"><span class="meta">             &#125;)(kernel_builder_expr.Build()); <span class="comment">//这里的kernel_builder_expr就是KernelDefBuilder,其实就是Name(&quot;ZeroOut&quot;).Device(DEVICE_CPU).Build(); 而且这里是对lambda函数的调用，所以会立即进入函数内</span></span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>REGISTER_KERNEL_BUILDER(Name(“ZeroOut”).Device(DEVICE_CPU), ZeroOutOp);这个定义中，Name实际上是KernelDefBuilder. Device就是KernelDefBuilder::Device. </p>
<p>REGISTER_KERNEL_BUILDER( KernelDefBuilder对象， ZeroOut这个类)。</p>
<p>OpkernelRegistrar的构建函数里最终调用到这个GlobalKernelRegistry的Reigster</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span>* <span class="title">GlobalKernelRegistry</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">static</span> KernelRegistry* global_kernel_registry = []() &#123;</span><br><span class="line">    KernelRegistry* registry = <span class="keyword">new</span> KernelRegistry;</span><br><span class="line">    OpRegistry::<span class="built_in">Global</span>()-&gt;<span class="built_in">RegisterValidator</span>(ValidateKernelRegistrations);</span><br><span class="line">    <span class="keyword">return</span> registry;</span><br><span class="line">  &#125;();</span><br><span class="line">  <span class="keyword">return</span> global_kernel_registry;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">KernelRegistry</span> &#123;</span><br><span class="line">  mutex mu;</span><br><span class="line">  std::unordered_multimap&lt;string, KernelRegistration&gt; registry <span class="comment">//就是放在这个map里了</span></span><br><span class="line">      <span class="built_in">TF_GUARDED_BY</span>(mu);</span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="从动态库加载kernel"><a href="#从动态库加载kernel" class="headerlink" title="从动态库加载kernel"></a>从动态库加载kernel</h2><p>tensorflow&#x2F;core&#x2F;framework&#x2F;op_kernel.cc</p>
<p>加载目录:tensorflow&#x2F;core&#x2F;kernels目录中的所有so。实际上使用了Env-&gt;LoadDynamicLibrary 这种方式是我们扩展tensorflow kernel的方式。直接自己打包成独立的动态库，由tf加载即可。无须与tf源码编译到一起。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">LoadDynamicKernelsInternal</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  Env* env = Env::<span class="built_in">Default</span>();</span><br><span class="line">  env-&gt;<span class="built_in">LoadDynamicLibrary</span>(fullpath.<span class="built_in">c_str</span>(), &amp;unused_filehandle)); <span class="comment">//加载动态库。不同环境不现。比较linux上是加载so文件。windows是加载dll文件。</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">LoadDynamicKernels</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">//只调用一次</span></span><br><span class="line">  <span class="type">static</span> absl::once_flag dll_loader_flag;</span><br><span class="line">  absl::<span class="built_in">call_once</span>(dll_loader_flag, LoadDynamicKernelsInternal);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Kernel从context中获取输入，分配输出时返回错误"><a href="#Kernel从context中获取输入，分配输出时返回错误" class="headerlink" title="Kernel从context中获取输入，分配输出时返回错误"></a>Kernel从context中获取输入，分配输出时返回错误</h2><p>tensorflow&#x2F;core&#x2F;framework&#x2F;op_requires.h中定义了大量的宏，帮助我们实现这些功能。这些宏能根据需要返回错误。这宏非常实用，避免我们写大量的if判断，return返回之类的代码</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> OP_REQUIRES_OK(CTX, ...)                             \</span></span><br><span class="line"><span class="meta">  do &#123;                                                       \</span></span><br><span class="line"><span class="meta">    ::tensorflow::Status _s(__VA_ARGS__);                    \</span></span><br><span class="line"><span class="meta">    <span class="keyword">if</span> (!TF_PREDICT_TRUE(_s.ok())) &#123;                         \</span></span><br><span class="line"><span class="meta">      CheckNotInComputeAsync((CTX), <span class="string">&quot;OP_REQUIRES_OK_ASYNC&quot;</span>); \</span></span><br><span class="line"><span class="meta">      (CTX)-&gt;CtxFailureWithWarning(__FILE__, __LINE__, _s);  \</span></span><br><span class="line"><span class="meta">      return;                                                \</span></span><br><span class="line"><span class="meta">    &#125;                                                        \</span></span><br><span class="line"><span class="meta">  &#125; while (0)</span></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>note</category>
      </categories>
      <tags>
        <tag>gpu</tag>
      </tags>
  </entry>
  <entry>
    <title>Tensorflow lite源码分析(Tensorflow 2.14)</title>
    <url>/2023/09/22/note/Tensorflow-lite%20source%20code%20analysis/</url>
    <content><![CDATA[<h1 id="Tensorflow-lite源码分析-Tensorflow-2-14"><a href="#Tensorflow-lite源码分析-Tensorflow-2-14" class="headerlink" title="Tensorflow lite源码分析(Tensorflow 2.14)"></a>Tensorflow lite源码分析(Tensorflow 2.14)</h1><h2 id="装载现有模型"><a href="#装载现有模型" class="headerlink" title="装载现有模型"></a>装载现有模型</h2><p>​	首先Android app使用tensorflow api中的interpreter创建了一个解释器，该解释器有多种构造函数和继承，这里使用的是文件中读取模型，同时使用了一个委托(delegate)，但是我们最后再来看这个委托是什么。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> val tflite by lazy &#123;</span><br><span class="line">       Interpreter(</span><br><span class="line">           FileUtil.loadMappedFile(<span class="built_in">this</span>, MODEL_PATH),</span><br><span class="line">           Interpreter.Options().addDelegate(nnApiDelegate))</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">private</span> val detector by lazy &#123;</span><br><span class="line">       ObjectDetectionHelper(</span><br><span class="line">           tflite,</span><br><span class="line">           FileUtil.loadLabels(<span class="built_in">this</span>, LABELS_PATH)</span><br><span class="line">       )</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>

<p>​	该函数调用了<code>Interpreter</code>类，具体函数过程如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//tensorflow/lite/java/src/main/java/org/tensorflow/lite/NativeInterpreterWrapper.java</span></span><br><span class="line">NativeInterpreterWrapper(ByteBuffer buffer, InterpreterImpl.Options options) &#123;</span><br><span class="line">    TensorFlowLite.init();</span><br><span class="line">	......</span><br><span class="line">    <span class="built_in">this</span>.modelByteBuffer = buffer;</span><br><span class="line">    <span class="type">long</span> <span class="variable">errorHandle</span> <span class="operator">=</span> createErrorReporter(ERROR_BUFFER_SIZE);</span><br><span class="line">    <span class="type">long</span> <span class="variable">modelHandle</span> <span class="operator">=</span> createModelWithBuffer(modelByteBuffer, errorHandle);</span><br><span class="line">    init(errorHandle, modelHandle, options);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>​	核心在于第四行和第六行，第四行将buffer赋给this对象，第六行通过buffer创建模型。这里就接着调用了JNI跳转到C&#x2F;C++的实现。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//tensorflow/lite/java/src/main/native/nativeinterpreterwrapper_jni.cc</span></span><br><span class="line"><span class="function">JNIEXPORT jlong JNICALL</span></span><br><span class="line"><span class="function"><span class="title">Java_org_tensorflow_lite_NativeInterpreterWrapper_createModelWithBuffer</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    JNIEnv* env, jclass <span class="comment">/*clazz*/</span>, jobject model_buffer, jlong error_handle)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (!tflite::jni::<span class="built_in">CheckJniInitializedOrThrow</span>(env)) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  BufferErrorReporter* error_reporter =</span><br><span class="line">      <span class="built_in">convertLongToErrorReporter</span>(env, error_handle);</span><br><span class="line">  <span class="keyword">if</span> (error_reporter == <span class="literal">nullptr</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">  <span class="type">const</span> <span class="type">char</span>* buf =</span><br><span class="line">      <span class="built_in">static_cast</span>&lt;<span class="type">char</span>*&gt;(env-&gt;<span class="built_in">GetDirectBufferAddress</span>(model_buffer));</span><br><span class="line">  jlong capacity = env-&gt;<span class="built_in">GetDirectBufferCapacity</span>(model_buffer);</span><br><span class="line">  <span class="keyword">if</span> (!<span class="built_in">VerifyModel</span>(buf, capacity)) &#123;</span><br><span class="line">    <span class="built_in">ThrowException</span>(</span><br><span class="line">        env, tflite::jni::kIllegalArgumentException,</span><br><span class="line">        <span class="string">&quot;ByteBuffer is not a valid TensorFlow Lite model flatbuffer&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">auto</span> model = FlatBufferModel::<span class="built_in">BuildFromBuffer</span>(</span><br><span class="line">      buf, <span class="built_in">static_cast</span>&lt;<span class="type">size_t</span>&gt;(capacity), error_reporter);</span><br><span class="line">  <span class="keyword">if</span> (!model) &#123;</span><br><span class="line">    <span class="built_in">ThrowException</span>(env, tflite::jni::kIllegalArgumentException,</span><br><span class="line">                   <span class="string">&quot;ByteBuffer does not encode a valid model: %s&quot;</span>,</span><br><span class="line">                   error_reporter-&gt;<span class="built_in">CachedErrorMessage</span>());</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">reinterpret_cast</span>&lt;jlong&gt;(model.<span class="built_in">release</span>());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>​	在上面逻辑中，最核心的一行是第18行，从buffer创建模型。其调用的是<code>model_builder.cc</code>文件下的<code>BuildFromBuffer</code>函数.</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//tensorflow/lite/core/model_builder.cc</span></span><br><span class="line"><span class="function">std::unique_ptr&lt;FlatBufferModel&gt; <span class="title">FlatBufferModel::BuildFromBuffer</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">char</span>* caller_owned_buffer, <span class="type">size_t</span> buffer_size,</span></span></span><br><span class="line"><span class="params"><span class="function">    ErrorReporter* error_reporter)</span> </span>&#123;</span><br><span class="line"><span class="comment">//调用ValidateErrorReporter函数，检查error_reporter是否为nullptr，如果是，则返回默认的错误报告器，否则返回原来的error_reporter。</span></span><br><span class="line">  error_reporter = <span class="built_in">ValidateErrorReporter</span>(error_reporter);</span><br><span class="line"><span class="comment">//创建一个MemoryAllocation对象，它是Allocation类的子类，用于封装缓冲区的地址和大小，并提供读取和写入的接口。MemoryAllocation对象使用new操作符在堆上分配内存，并使用caller_owned_buffer, buffer_size, error_reporter作为构造函数的参数。</span></span><br><span class="line">  <span class="function">std::unique_ptr&lt;Allocation&gt; <span class="title">allocation</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">      <span class="keyword">new</span> MemoryAllocation(caller_owned_buffer, buffer_size, error_reporter))</span></span>;</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">BuildFromAllocation</span>(std::<span class="built_in">move</span>(allocation), error_reporter);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">ErrorReporter* <span class="title">ValidateErrorReporter</span><span class="params">(ErrorReporter* e)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> e ? e : <span class="built_in">DefaultErrorReporter</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">MemoryAllocation::<span class="built_in">MemoryAllocation</span>(<span class="type">const</span> <span class="type">void</span>* ptr, <span class="type">size_t</span> num_bytes, ErrorReporter* error_reporter)</span><br><span class="line">: <span class="built_in">Allocation</span>(error_reporter, Allocation::Type::kMemory) &#123;</span><br><span class="line">	......</span><br><span class="line">  buffer_ = ptr;</span><br><span class="line">  buffer_size_bytes_ = num_bytes;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>​	在做了一些错误检查和给buffer分配内存后转化成专门的Allocation类(这么做的原因还是为了抽象，把各种从文件读的模型，从内存buffer读的模型都转化成allocation类，最后进行统一处理)，然后进行核心的函数处理<code>BuildFromAllocation</code>:</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// tensorflow/lite/core/model_builder.cc</span></span><br><span class="line"><span class="function">std::unique_ptr&lt;FlatBufferModel&gt; <span class="title">FlatBufferModel::BuildFromAllocation</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    std::unique_ptr&lt;Allocation&gt; allocation, ErrorReporter* error_reporter)</span> </span>&#123;</span><br><span class="line">  <span class="function">std::unique_ptr&lt;FlatBufferModel&gt; <span class="title">model</span><span class="params">(<span class="keyword">new</span> FlatBufferModel(</span></span></span><br><span class="line"><span class="params"><span class="function">      std::move(allocation), ValidateErrorReporter(error_reporter)))</span></span>;</span><br><span class="line">  <span class="keyword">if</span> (!model-&gt;<span class="built_in">initialized</span>()) &#123;</span><br><span class="line">    model.<span class="built_in">reset</span>();</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    model-&gt;<span class="built_in">ValidateModelBuffers</span>(error_reporter);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> model;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// FlatBufferModel的构造函数实现</span></span><br><span class="line"><span class="comment">// 将model直接传递给类型model_成员变量</span></span><br><span class="line">FlatBufferModel::<span class="built_in">FlatBufferModel</span>(<span class="type">const</span> Model* model, ErrorReporter* error_reporter)</span><br><span class="line">    : <span class="built_in">model_</span>(model), <span class="built_in">error_reporter_</span>(<span class="built_in">ValidateErrorReporter</span>(error_reporter)) &#123;&#125;</span><br><span class="line"><span class="comment">//将allocation变量直接传递给allocation_变量，然后使用GetModel对allocation进行处理。</span></span><br><span class="line">FlatBufferModel::<span class="built_in">FlatBufferModel</span>(std::unique_ptr&lt;Allocation&gt; allocation, ErrorReporter* error_reporter)</span><br><span class="line">    : <span class="built_in">error_reporter_</span>(<span class="built_in">ValidateErrorReporter</span>(error_reporter)), <span class="built_in">allocation_</span>(std::<span class="built_in">move</span>(allocation)) &#123;</span><br><span class="line">  <span class="keyword">if</span> (!allocation_ || !allocation_-&gt;<span class="built_in">valid</span>() || !<span class="built_in">CheckModelIdentifier</span>()) &#123;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  model_ = ::tflite::<span class="built_in">GetModel</span>(allocation_-&gt;<span class="built_in">base</span>());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>​	它使用了<code>GetModel</code>方法：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// tensorflow/tensorflow/lite/core/model_builder.h</span></span><br><span class="line"><span class="function"><span class="type">const</span> tflite::Model* <span class="title">GetModel</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> model_; &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// tensorflow/tensorflow/lite/schema/schema_generated.h</span></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">const</span> tflite::Model *<span class="title">GetModel</span><span class="params">(<span class="type">const</span> <span class="type">void</span> *buf)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> ::flatbuffers::<span class="built_in">GetRoot</span>&lt;tflite::Model&gt;(buf);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>​	可以发现这里调用了google的<code>flatbuffer</code>库，具体源码参考<a href="https://github.com/google/flatbuffers/blob/d3e8cb60a133be5387008864d3fc212e31774b63/include/flatbuffers/buffer.h">flatbuffers&#x2F;include&#x2F;flatbuffers&#x2F;buffer.h at d3e8cb60a133be5387008864d3fc212e31774b63 · google&#x2F;flatbuffers (github.com)</a>。实际调用引入过程是<code>schema_generated.h</code> 代码中引入了头文件 <code>#include &quot;flatbuffers/flatbuffers.h&quot;</code> ，然后 <code>flatbuffers/flatbuffers.h</code> 引入头文件<code>flatbuffers/buffer.h</code>,最终得到<code>GetModel</code>的实现。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// https://github.com/google/flatbuffers/blob/d3e8cb60a133be5387008864d3fc212e31774b63/include/flatbuffers/buffer.h</span></span><br><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt; <span class="type">const</span> T *<span class="title">GetRoot</span><span class="params">(<span class="type">const</span> <span class="type">void</span> *buf)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">GetMutableRoot</span>&lt;T&gt;(<span class="built_in">const_cast</span>&lt;<span class="type">void</span> *&gt;(buf));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt; T *<span class="title">GetMutableRoot</span><span class="params">(<span class="type">void</span> *buf)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (!buf) <span class="keyword">return</span> <span class="literal">nullptr</span>;</span><br><span class="line">  <span class="built_in">EndianCheck</span>();</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">reinterpret_cast</span>&lt;T *&gt;(</span><br><span class="line">      <span class="built_in">reinterpret_cast</span>&lt;<span class="type">uint8_t</span> *&gt;(buf) +</span><br><span class="line">      <span class="built_in">EndianScalar</span>(*<span class="built_in">reinterpret_cast</span>&lt;<span class="type">uoffset_t</span> *&gt;(buf)));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>​	OK 到这一步为止，我们可以知道实际仅仅是吧flatbuffer格式的文件读进了内存，并用各种抽象进行管理，内存布局仍然是flatbuffer中定义的内存布局。并且最后的包装成了一个Model对象，<code>Model *_model</code>。</p>
<p>然后让我们来看看TFLite中模型具体是怎么定义的吧，这个涉及到的文件为<code>schema.fbs(tensorflow/tensorflow/lite/schema/schema.fbs)</code></p>
<ul>
<li><p>Model:</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">table Model &#123;</span><br><span class="line">  <span class="comment">// 一个int32类型的值，表示模型的版本号。目前最新的版本号是3</span></span><br><span class="line">  version:uint;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 一个OperatorCode类型的数组，表示模型中使用的算子的编码。每个算子有一个唯一的编码，用于标识算子的名称和版本。</span></span><br><span class="line">  operator_codes:[OperatorCode];</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 一个SubGraph类型的数组，表示模型中包含的子图。每个子图有一个输入张量列表、一个输出张量列表、一个状态张量列表、一个算子节点列表和一个名称。子图是模型执行的基本单元，可以理解为一个计算图. 0th子图为main图</span></span><br><span class="line">  subgraphs:[SubGraph];</span><br><span class="line"></span><br><span class="line">  <span class="comment">// A description of the model.</span></span><br><span class="line">  description:string;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 一个Buffer类型的数组，表示模型中所有张量数据的存储空间。每个缓冲区有一个字节数组和一个哈希值。通过缓冲区的索引，可以从字节数组中读取或写入张量的数据。0th的buffer必须是空buffer</span></span><br><span class="line">  <span class="comment">// Note the 0th entry of this array must be an empty buffer (sentinel).</span></span><br><span class="line">  <span class="comment">// This is a convention so that tensors without a buffer can provide 0 as</span></span><br><span class="line">  <span class="comment">// their buffer.</span></span><br><span class="line">  buffers:[Buffer];</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 一个int32类型的数组，表示模型中包含的元数据所在的缓冲区的索引。元数据是一种用于描述模型属性和关联文件等信息的结构，可以用于提高模型的可解释性和兼容性。</span></span><br><span class="line">  metadata_buffer:[<span class="type">int</span>];</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Metadata about the model. 包含name和buffer，即名字字段和该metadata所在的buffer</span></span><br><span class="line">  metadata:[Metadata];</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 一个SignatureDef类型的数组，表示模型中包含的签名定义。每个签名定义有一个输入映射、一个输出映射和一个方法名称。签名定义是一种用于描述模型输入和输出接口以及功能等信息的结构，可以用于提高模型的可用性和灵活性。</span></span><br><span class="line">  signature_defs:[SignatureDef];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>Subgraph:</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">table SubGraph &#123;</span><br><span class="line">  <span class="comment">// A list of all tensors used in this subgraph.</span></span><br><span class="line">  tensors:[Tensor];</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 子图的输入张量索引，例如inputs [0] 表示tensors数组中第0个张量表示输入张量</span></span><br><span class="line">  inputs:[<span class="type">int</span>];</span><br><span class="line">  <span class="comment">// 输出张量索引</span></span><br><span class="line">  outputs:[<span class="type">int</span>];</span><br><span class="line">  <span class="comment">// operators数组</span></span><br><span class="line">  operators:[Operator];</span><br><span class="line">  name:string;</span><br><span class="line">&#125;</span><br><span class="line">    </span><br></pre></td></tr></table></figure>
</li>
<li><p>Tensor: </p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">table Tensor &#123;</span><br><span class="line">  <span class="comment">// int 类型的数字，表示张量的形状，例如[1, 224, 224, 3],表示1个图片样本，224*224像素大小，RGB3个通道</span></span><br><span class="line">  shape:[<span class="type">int</span>];</span><br><span class="line">  <span class="comment">// 张量的数据类型，比如int32， float32， int8等等 ，也定义在该文件中的enum TensorType字段</span></span><br><span class="line">  type:TensorType;</span><br><span class="line">  <span class="comment">// buffer：一个int32类型的值，表示张量的数据所在的缓冲区的索引。缓冲区是一种存储模型中所有张量数据的结构，每个缓冲区有一个唯一的索引和一个字节数组。通过这个字段，可以从缓冲区中读取或写入张量的数据。</span></span><br><span class="line">  buffer:uint;</span><br><span class="line">  name:string;  <span class="comment">// 一个string类型的值，表示张量的名称。这个字段可以用于标识或描述张量的作用或来源，也可以用于调试或可视化。</span></span><br><span class="line">  quantization:QuantizationParameters;  <span class="comment">// Optional. 一个QuantizationParameters类型的表，表示张量的量化参数。量化是一种将浮点数转换为整数或低位数来减少模型大小和提高性能的技术。这个表中包含了一些用于反量化或重新量化张量数据的参数，如最小值、最大值、比例因子、零点等。</span></span><br><span class="line"></span><br><span class="line">  is_variable:<span class="type">bool</span> = <span class="literal">false</span>; <span class="comment">//一个bool类型的值，表示张量是否是变量。变量是一种可以在模型运行过程中改变值的张量，通常用于存储模型的参数或状态。如果这个字段为true，则表示张量是变量，否则表示张量是常量。</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 一个SparsityParameters类型的表，表示张量的稀疏性参数。稀疏性是一种将张量中大部分为零的元素压缩或省略来减少模型大小和提高性能的技术。这个表中包含了一些用于解压缩或重新压缩张量数据的参数，如稀疏维度、非零值索引、非零值块等。</span></span><br><span class="line">  sparsity:SparsityParameters;  <span class="comment">// Optional.</span></span><br><span class="line"></span><br><span class="line">  shape_signature:[<span class="type">int</span>]; <span class="comment">// Optional.</span></span><br><span class="line">  has_rank: <span class="type">bool</span> = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 用作嵌套张量类型字段</span></span><br><span class="line">  variant_tensors:[VariantSubType];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>Buffer:</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">table Buffer &#123;</span><br><span class="line">  data:[ubyte] (force_align: <span class="number">16</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// In a model that is larger than 2GB, then buffers instead uses the following</span></span><br><span class="line">  <span class="comment">// attributes to find stored data, which is outside of flatbuffers</span></span><br><span class="line">  <span class="comment">// the offset is calculated relative to the beginning of the file and is only</span></span><br><span class="line">  <span class="comment">// valid if &gt; 1.</span></span><br><span class="line">  offset: ulong;</span><br><span class="line">  size: ulong;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="处理模型"><a href="#处理模型" class="headerlink" title="处理模型"></a>处理模型</h2><p>​	接着上面的步骤，我们回到java包装器的地方，回顾一下代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//tensorflow/lite/java/src/main/java/org/tensorflow/lite/NativeInterpreterWrapper.java</span></span><br><span class="line">NativeInterpreterWrapper(ByteBuffer buffer, InterpreterImpl.Options options) &#123;</span><br><span class="line">    TensorFlowLite.init();</span><br><span class="line">	......</span><br><span class="line">    <span class="built_in">this</span>.modelByteBuffer = buffer;</span><br><span class="line">    <span class="type">long</span> <span class="variable">errorHandle</span> <span class="operator">=</span> createErrorReporter(ERROR_BUFFER_SIZE);</span><br><span class="line">    <span class="type">long</span> <span class="variable">modelHandle</span> <span class="operator">=</span> createModelWithBuffer(modelByteBuffer, errorHandle);</span><br><span class="line">    init(errorHandle, modelHandle, options);</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<p>​	这里将模型读入buffer后，接着运行了init函数，那么init函数里面干了什么事情呢？</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// tensorflow/tensorflow/lite/java/src/main/java/org/tensorflow/lite/NativeInterpreterWrapper.java</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// errorHandle：一个long类型的值，表示一个错误处理器的句柄，用于报告解释器运行过程中的错误信息。</span></span><br><span class="line"><span class="comment">// modelHandle：一个long类型的值，表示一个模型的句柄，用于加载和访问TensorFlow Lite模型的数据和元数据。</span></span><br><span class="line"><span class="comment">// options：一个InterpreterImpl.Options类型的对象，表示一些解释器的选项，如线程数、加速配置、精度控制等</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">init</span><span class="params">(<span class="type">long</span> errorHandle, <span class="type">long</span> modelHandle, InterpreterImpl.Options options)</span> &#123;</span><br><span class="line">	<span class="comment">// some error handle, 检查options是否为空，检查options中是否有加速配置</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// ......</span></span><br><span class="line">        </span><br><span class="line">    <span class="built_in">this</span>.errorHandle = errorHandle;</span><br><span class="line">    <span class="built_in">this</span>.modelHandle = modelHandle;</span><br><span class="line">    <span class="comment">// First create the interpreter without delegates.  We need an interpreter in order to figure</span></span><br><span class="line">    <span class="comment">// out whether the model contains any unresolved flex ops, and creating the interpreter with</span></span><br><span class="line">    <span class="comment">// delegates might fail if there are any unresolved flex ops.</span></span><br><span class="line">    <span class="comment">// (Alternatively, we could determine this without needing to recreate the interpreter</span></span><br><span class="line">    <span class="comment">// by passing the tflite::Model in to here, and then traversing that?)</span></span><br><span class="line">    <span class="comment">// 上面这段英文罗里吧嗦一大堆，实际就是先创建一个基本的解释器，如果后续有代理再进行处理。</span></span><br><span class="line">    ArrayList&lt;Long&gt; delegateHandles = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">    <span class="built_in">this</span>.interpreterHandle =</span><br><span class="line">        createInterpreter(</span><br><span class="line">            modelHandle,</span><br><span class="line">            errorHandle,</span><br><span class="line">            options.getNumThreads(),</span><br><span class="line">            options.getUseXNNPACK(),</span><br><span class="line">            delegateHandles);</span><br><span class="line">    <span class="comment">// 判断是否有上述interpreter没法处理的op，也就是说上面这个函数就是处理模型成op的真实过程</span></span><br><span class="line">    <span class="built_in">this</span>.originalGraphHasUnresolvedFlexOp = hasUnresolvedFlexOp(interpreterHandle);</span><br><span class="line">    <span class="comment">// 这里添加委托，委托就是一种可以提高模型执行效率和兼容性的机制，可以将模型中的一些操作交给特定的硬件或软件来执行。</span></span><br><span class="line">    addDelegates(options);</span><br><span class="line">    <span class="comment">// 初始化当前对象中包含InterpreterFactory接口的代理。InterpreterFactory接口是一种可以让代理自己创建解释器并管理其生命周期的机制。</span></span><br><span class="line">    initDelegatesWithInterpreterFactory();</span><br><span class="line">    delegateHandles.ensureCapacity(delegates.size());</span><br><span class="line">    <span class="keyword">for</span> (Delegate delegate : delegates) &#123;</span><br><span class="line">      delegateHandles.add(delegate.getNativeHandle());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 说明有代理需要处理，所以把之前创建的基本解释器删除，添加有代理的解释器</span></span><br><span class="line">    <span class="keyword">if</span> (!delegateHandles.isEmpty()) &#123;</span><br><span class="line">      <span class="comment">// If there are any delegates enabled, recreate the interpreter with those delegates.</span></span><br><span class="line">      delete(<span class="comment">/* errorHandle= */</span> <span class="number">0</span>, <span class="comment">/* modelHandle= */</span> <span class="number">0</span>, <span class="built_in">this</span>.interpreterHandle);</span><br><span class="line">      <span class="built_in">this</span>.interpreterHandle =</span><br><span class="line">          createInterpreter(</span><br><span class="line">              modelHandle,</span><br><span class="line">              errorHandle,</span><br><span class="line">              options.getNumThreads(),</span><br><span class="line">              options.getUseXNNPACK(),</span><br><span class="line">              delegateHandles);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// ......</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 创建两个TensorImpl类型的数组，分别赋值给当前对象的inputTensors和outputTensors成员变量。这两个数组用于存储模型的输入和输出张量的对象。数组的大小分别由调用getInputCount和getOutputCount方法得到。</span></span><br><span class="line">    <span class="built_in">this</span>.inputTensors = <span class="keyword">new</span> <span class="title class_">TensorImpl</span>[getInputCount(interpreterHandle)];</span><br><span class="line">    <span class="built_in">this</span>.outputTensors = <span class="keyword">new</span> <span class="title class_">TensorImpl</span>[getOutputCount(interpreterHandle)];</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// ......</span></span><br><span class="line">    <span class="comment">// 为模型的输入和输出张量分配内存</span></span><br><span class="line">    allocateTensors(interpreterHandle, errorHandle);</span><br><span class="line">    <span class="built_in">this</span>.isMemoryAllocated = <span class="literal">true</span>;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<p>​	很复杂，但是我们关注一个核心函数，<code>createInterpreter</code>。同样这里是一个JNI包装器，实际从java代码调用到了C++的API。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// tensorflow/tensorflow/lite/java/src/main/native/nativeinterpreterwrapper_jni.cc</span></span><br><span class="line"><span class="function">JNIEXPORT jlong JNICALL</span></span><br><span class="line"><span class="function"><span class="title">Java_org_tensorflow_lite_NativeInterpreterWrapper_createInterpreter</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    JNIEnv* env, jclass clazz, jlong model_handle, jlong error_handle,</span></span></span><br><span class="line"><span class="params"><span class="function">    jint num_threads, jboolean useXnnpack, jobject delegate_handle_list)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// some handler check for JNI</span></span><br><span class="line">  <span class="comment">// 获取两个调用的参数，应该是JNI调用过来的时候需要进行一个数据结构的转换。</span></span><br><span class="line">  FlatBufferModel* model = <span class="built_in">convertLongToModel</span>(env, model_handle);</span><br><span class="line">  <span class="keyword">if</span> (model == <span class="literal">nullptr</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  BufferErrorReporter* error_reporter =</span><br><span class="line">      <span class="built_in">convertLongToErrorReporter</span>(env, error_handle);</span><br><span class="line">  <span class="keyword">if</span> (error_reporter == <span class="literal">nullptr</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line">  std::unique_ptr&lt;OpResolver&gt; resolver =</span><br><span class="line">      std::<span class="built_in">make_unique</span>&lt;tflite::jni::OpResolverLazyDelegateProxy&gt;(</span><br><span class="line">          tflite::<span class="built_in">CreateOpResolver</span>(), useXnnpack != JNI_FALSE);</span><br><span class="line"></span><br><span class="line">  <span class="function">InterpreterBuilder <span class="title">interpreter_builder</span><span class="params">(*model, *resolver)</span></span>;</span><br><span class="line">  interpreter_builder.<span class="built_in">SetNumThreads</span>(<span class="built_in">static_cast</span>&lt;<span class="type">int</span>&gt;(num_threads));</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Add delegate_list to interpreter_builder.</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// Java: int size = delegate_list.size();</span></span><br><span class="line">  jint size = env-&gt;<span class="built_in">CallIntMethod</span>(delegate_handle_list, list_size_method);</span><br><span class="line">  <span class="keyword">for</span> (jint i = <span class="number">0</span>; i &lt; size; ++i) &#123;</span><br><span class="line">    <span class="comment">// Java: Long jdelegate_handle = delegate_handle_list-&gt;get(i);</span></span><br><span class="line">    jobject jdelegate_handle =</span><br><span class="line">        env-&gt;<span class="built_in">CallObjectMethod</span>(delegate_handle_list, list_get_method, i);</span><br><span class="line">    <span class="keyword">if</span> (jdelegate_handle == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">      <span class="keyword">if</span> (!env-&gt;<span class="built_in">ExceptionCheck</span>()) &#123;</span><br><span class="line">        <span class="built_in">ThrowException</span>(env, tflite::jni::kIllegalArgumentException,</span><br><span class="line">                       <span class="string">&quot;Internal error: null object in Delegate handle list&quot;</span>);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// Java: long delegate_handle = jdelegate_handle.longValue();</span></span><br><span class="line">    jlong delegate_handle =</span><br><span class="line">        env-&gt;<span class="built_in">CallLongMethod</span>(jdelegate_handle, long_value_method);</span><br><span class="line">    <span class="keyword">if</span> (delegate_handle == <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="keyword">if</span> (!env-&gt;<span class="built_in">ExceptionCheck</span>()) &#123;</span><br><span class="line">        <span class="built_in">ThrowException</span>(env, tflite::jni::kIllegalArgumentException,</span><br><span class="line">                       <span class="string">&quot;Internal error: Found invalid handle&quot;</span>);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">auto</span> delegate = <span class="built_in">reinterpret_cast</span>&lt;TfLiteOpaqueDelegate*&gt;(delegate_handle);</span><br><span class="line">    interpreter_builder.<span class="built_in">AddDelegate</span>(delegate);</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<p>看来核心就在第15行开始的函数。这一行是什么意思呢，把一些修饰符删去后可以知道，<code>resolver = OpResolverLazyDelegateProxy(CreateOpResolver(), useXnnpack != JNI_FALSE) </code> 所以我们先看看 <code>CreateOpResolver</code> 干了什么事情。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// tensorflow/tensorflow/lite/create_op_resolver_with_selected_ops.cc</span></span><br><span class="line"><span class="function">std::unique_ptr&lt;MutableOpResolver&gt; <span class="title">CreateOpResolver</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  std::unique_ptr&lt;MutableOpResolver&gt; resolver =</span><br><span class="line">      std::<span class="built_in">make_unique</span>&lt;MutableOpResolver&gt;();</span><br><span class="line">  <span class="built_in">RegisterSelectedOps</span>(resolver.<span class="built_in">get</span>());</span><br><span class="line">  <span class="keyword">return</span> resolver;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// tensorflow/tensorflow/lite/core/create_op_resolver_with_builtin_ops.cc</span></span><br><span class="line"><span class="function">std::unique_ptr&lt;MutableOpResolver&gt; <span class="title">CreateOpResolver</span><span class="params">()</span> </span>&#123;  <span class="comment">// NOLINT</span></span><br><span class="line">  <span class="keyword">return</span> std::<span class="built_in">unique_ptr</span>&lt;tflite::ops::builtin::BuiltinOpResolver&gt;(</span><br><span class="line">      <span class="keyword">new</span> tflite::ops::builtin::<span class="built_in">BuiltinOpResolverWithoutDefaultDelegates</span>());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">BuiltinOpResolver::<span class="built_in">BuiltinOpResolver</span>() &#123;</span><br><span class="line">  <span class="built_in">AddBuiltin</span>(BuiltinOperator_ABS, <span class="built_in">Register_ABS</span>(), <span class="comment">/* min_version = */</span> <span class="number">1</span>,</span><br><span class="line">             <span class="comment">/* max_version = */</span> <span class="number">5</span>);</span><br><span class="line">  <span class="built_in">AddBuiltin</span>(BuiltinOperator_HARD_SWISH, <span class="built_in">Register_HARD_SWISH</span>());</span><br><span class="line">  <span class="built_in">AddBuiltin</span>(BuiltinOperator_RELU, <span class="built_in">Register_RELU</span>(), <span class="comment">/* min_version = */</span> <span class="number">1</span>,</span><br><span class="line">             <span class="comment">/* max_version = */</span> <span class="number">3</span>);</span><br><span class="line">  <span class="built_in">AddBuiltin</span>(BuiltinOperator_RELU_N1_TO_1, <span class="built_in">Register_RELU_N1_TO_1</span>());</span><br><span class="line">  <span class="built_in">AddBuiltin</span>(BuiltinOperator_RELU_0_TO_1, <span class="built_in">Register_RELU_0_TO_1</span>());</span><br><span class="line">  <span class="built_in">AddBuiltin</span>(BuiltinOperator_RELU6, <span class="built_in">Register_RELU6</span>(), <span class="comment">/* min_version = */</span> <span class="number">1</span>,</span><br><span class="line">             <span class="comment">/* max_version = */</span> <span class="number">3</span>);</span><br><span class="line">  <span class="built_in">AddBuiltin</span>(BuiltinOperator_TANH, <span class="built_in">Register_TANH</span>(), <span class="comment">/* min_version = */</span> <span class="number">1</span>,</span><br><span class="line">             <span class="comment">/* max_version = */</span> <span class="number">3</span>);</span><br><span class="line">  <span class="built_in">AddBuiltin</span>(BuiltinOperator_LOGISTIC, <span class="built_in">Register_LOGISTIC</span>(),</span><br><span class="line">             <span class="comment">/* min_version = */</span> <span class="number">1</span>,</span><br><span class="line">             <span class="comment">/* max_version = */</span> <span class="number">3</span>);</span><br><span class="line">  <span class="built_in">AddBuiltin</span>(BuiltinOperator_AVERAGE_POOL_2D, <span class="built_in">Register_AVERAGE_POOL_2D</span>(),</span><br><span class="line">             <span class="comment">/* min_version */</span> <span class="number">1</span>,</span><br><span class="line">             <span class="comment">/* max_version */</span> <span class="number">3</span>);</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"> <span class="keyword">enum</span> <span class="title class_">BuiltinOperator</span> : <span class="type">int32_t</span> &#123;</span><br><span class="line">  BuiltinOperator_ADD = <span class="number">0</span>,</span><br><span class="line">  BuiltinOperator_AVERAGE_POOL_2D = <span class="number">1</span>,</span><br><span class="line">  BuiltinOperator_CONCATENATION = <span class="number">2</span>,</span><br><span class="line">  BuiltinOperator_CONV_2D = <span class="number">3</span>,</span><br><span class="line">  BuiltinOperator_DEPTHWISE_CONV_2D = <span class="number">4</span>,</span><br><span class="line">  BuiltinOperator_DEPTH_TO_SPACE = <span class="number">5</span>,</span><br><span class="line">  BuiltinOperator_DEQUANTIZE = <span class="number">6</span>,</span><br><span class="line">  BuiltinOperator_EMBEDDING_LOOKUP = <span class="number">7</span>,</span><br><span class="line">  BuiltinOperator_FLOOR = <span class="number">8</span>,</span><br><span class="line">     ...</span><br><span class="line">  BuiltinOperator_ABS = <span class="number">101</span>,</span><br><span class="line">     ...</span><br><span class="line">         </span><br><span class="line"><span class="comment">//tensorflow/tensorflow/lite/kernels/elementwise.cc   </span></span><br><span class="line"><span class="comment">// elementwise::ElementWiseQuantizedInit：这个函数用于初始化一个逐元素运算的算子，它会根据输入和输出张量的类型和量化参数，创建一个逐元素运算的上下文对象，并返回其指针。</span></span><br><span class="line"><span class="comment">// elementwise::ElementWiseQuantizedFree：这个函数用于释放一个逐元素运算的算子，它会删除之前创建的逐元素运算的上下文对象，并释放其内存空间。</span></span><br><span class="line"><span class="comment">// PrepareAbs：这个函数用于准备一个绝对值算子，它会检查输入和输出张量的形状是否一致，并根据输入和输出张量的类型和量化参数，计算出绝对值运算所需的乘法和偏移量，并保存在逐元素运算的上下文对象中。</span></span><br><span class="line"><span class="comment">// elementwise::AbsEval：这个函数用于执行一个绝对值算子，它会根据输入和输出张量的类型和量化参数，以及之前计算出的乘法和偏移量，对输入张量中的每个元素求其绝对值，并将结果写入输出张量中。</span></span><br><span class="line"><span class="built_in">GENERIC_PREPARE</span>(PrepareAbs, elementwise::IsAbsSupportedType,</span><br><span class="line">                elementwise::kAbsName)</span><br><span class="line">TfLiteRegistration* <span class="built_in">Register_ABS</span>() &#123;</span><br><span class="line">  <span class="type">static</span> TfLiteRegistration r = &#123;elementwise::ElementWiseQuantizedInit,</span><br><span class="line">                                 elementwise::ElementWiseQuantizedFree,</span><br><span class="line">                                 PrepareAbs, elementwise::AbsEval&#125;;</span><br><span class="line">  <span class="keyword">return</span> &amp;r;</span><br><span class="line">&#125;</span><br><span class="line">     </span><br><span class="line"><span class="function">TfLiteStatus <span class="title">AbsEval</span><span class="params">(TfLiteContext* context, TfLiteNode* node)</span> </span>&#123;</span><br><span class="line">  <span class="type">const</span> TfLiteTensor* input = <span class="built_in">GetInput</span>(context, node, <span class="number">0</span>);</span><br><span class="line">  <span class="type">const</span> TfLiteType type = input-&gt;type;</span><br><span class="line">  <span class="keyword">switch</span> (type) &#123;</span><br><span class="line">    <span class="keyword">case</span> kTfLiteFloat32:</span><br><span class="line">      <span class="keyword">return</span> <span class="built_in">EvalImpl</span>&lt;<span class="type">float</span>&gt;(context, node, std::abs&lt;<span class="type">float</span>&gt;, type);</span><br><span class="line">    <span class="keyword">case</span> kTfLiteInt8:</span><br><span class="line">      <span class="keyword">return</span> <span class="built_in">AbsEvalQuantized</span>&lt;<span class="type">int8_t</span>&gt;(context, node, type);</span><br><span class="line">    <span class="keyword">case</span> kTfLiteInt16:</span><br><span class="line">      <span class="keyword">return</span> input-&gt;quantization.type == kTfLiteNoQuantization</span><br><span class="line">                 ? <span class="built_in">AbsInt16EvalImpl</span>(context, node, type)</span><br><span class="line">                 : <span class="built_in">AbsEvalQuantized</span>&lt;<span class="type">int16_t</span>&gt;(context, node, type);</span><br><span class="line">    <span class="keyword">case</span> kTfLiteInt32:</span><br><span class="line">      <span class="keyword">return</span> <span class="built_in">EvalImpl</span>&lt;<span class="type">int32_t</span>&gt;(context, node, std::abs&lt;<span class="type">int32_t</span>&gt;, type);</span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">      <span class="built_in">TF_LITE_KERNEL_LOG</span>(context, <span class="string">&quot;Current data type %s is not supported.&quot;</span>,</span><br><span class="line">                         <span class="built_in">TfLiteTypeGetName</span>(type));</span><br><span class="line">      <span class="keyword">return</span> kTfLiteError;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">     </span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="function"><span class="keyword">inline</span> TfLiteStatus <span class="title">EvalImpl</span><span class="params">(TfLiteContext* context, TfLiteNode* node,</span></span></span><br><span class="line"><span class="params"><span class="function">                             std::function&lt;T(T)&gt; func,</span></span></span><br><span class="line"><span class="params"><span class="function">                             std::function&lt;TfLiteStatus(T)&gt; validate_input_func,</span></span></span><br><span class="line"><span class="params"><span class="function">                             TfLiteType expected_type)</span> </span>&#123;</span><br><span class="line">  <span class="type">const</span> TfLiteTensor* input;</span><br><span class="line">  <span class="built_in">TF_LITE_ENSURE_OK</span>(context, <span class="built_in">GetInputSafe</span>(context, node, <span class="number">0</span>, &amp;input));</span><br><span class="line">  TfLiteTensor* output;</span><br><span class="line">  <span class="built_in">TF_LITE_ENSURE_OK</span>(context, <span class="built_in">GetOutputSafe</span>(context, node, <span class="number">0</span>, &amp;output));</span><br><span class="line">  <span class="built_in">TF_LITE_ENSURE_TYPES_EQ</span>(context, input-&gt;type, expected_type);</span><br><span class="line">  <span class="type">const</span> <span class="type">int64_t</span> num_elements = <span class="built_in">NumElements</span>(input);</span><br><span class="line">  <span class="type">const</span> T* in_data = <span class="built_in">GetTensorData</span>&lt;T&gt;(input);</span><br><span class="line">  T* out_data = <span class="built_in">GetTensorData</span>&lt;T&gt;(output);</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int64_t</span> i = <span class="number">0</span>; i &lt; num_elements; ++i) &#123;</span><br><span class="line">    <span class="keyword">if</span> (validate_input_func) &#123;</span><br><span class="line">      <span class="built_in">TF_LITE_ENSURE_OK</span>(context, <span class="built_in">validate_input_func</span>(in_data[i]));</span><br><span class="line">    &#125;</span><br><span class="line">    out_data[i] = <span class="built_in">func</span>(in_data[i]);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> kTfLiteOk;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>​	可以发现注册了很多内置的算子。这些算子应该是tensorflow中实现的。实现都在tensorflow&#x2F;tensorflow&#x2F;lite&#x2F;kernels文件夹中。然后实际核心运算可以看到，使用的是std标准库中的<code>std::abs&lt;int32_t&gt;</code>, 这里就能够和内核驱动进行一个连接。</p>
<p>然后再回头来看看<code>InterpreterBuilder interpreter_builder(*model, *resolver);</code> 这个调用了以下构造函数，其中<code>options_experimental</code> 为默认的参数, 也就是进行一些赋值后返回。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// tensorflow/tensorflow/lite/core/interpreter_builder.h</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">InterpreterBuilder</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="comment">/// For this constructor, the ErrorReporter will be extracted from the</span></span><br><span class="line">  <span class="comment">/// FlatBufferModel.</span></span><br><span class="line">  <span class="comment">/// `options` object is copied during construction. So caller can release it</span></span><br><span class="line">  <span class="comment">// after calling the constructor.</span></span><br><span class="line">  <span class="built_in">InterpreterBuilder</span>(<span class="type">const</span> FlatBufferModel&amp; model,</span><br><span class="line">                     <span class="type">const</span> OpResolver&amp; op_resolver,</span><br><span class="line">                     <span class="type">const</span> InterpreterOptions* options_experimental = <span class="literal">nullptr</span>);</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="comment">// tensorflow/tensorflow/lite/core/interpreter_builder.cc</span></span><br><span class="line">InterpreterBuilder::<span class="built_in">InterpreterBuilder</span>(</span><br><span class="line">    <span class="type">const</span> FlatBufferModel&amp; model, <span class="type">const</span> OpResolver&amp; op_resolver,</span><br><span class="line">    <span class="type">const</span> InterpreterOptions* options_experimental)</span><br><span class="line">    : <span class="built_in">model_</span>(model.<span class="built_in">GetModel</span>()),</span><br><span class="line">      <span class="built_in">op_resolver_</span>(op_resolver),</span><br><span class="line">      <span class="built_in">error_reporter_</span>(<span class="built_in">ValidateErrorReporter</span>(model.<span class="built_in">error_reporter</span>())),</span><br><span class="line">      <span class="built_in">metadata_</span>(model.<span class="built_in">ReadAllMetadata</span>()),</span><br><span class="line">      <span class="built_in">allocation_</span>(model.<span class="built_in">allocation</span>()) &#123;</span><br><span class="line">  <span class="keyword">if</span> (options_experimental) &#123;</span><br><span class="line">    options_ = *options_experimental;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h2 id="运行模型"><a href="#运行模型" class="headerlink" title="运行模型"></a>运行模型</h2><p>​	运行模型首先还是调用的是java的API，这里是run函数。这个函数先判断一些错误检查，然后获取到input tensor，这个可以从之前说过的graph中的index获取。然后如果没有给tensor分配空间则分配空间。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// tensorflow/tensorflow/lite/java/src/main/java/org/tensorflow/lite/NativeInterpreterWrapper.java</span></span><br><span class="line"><span class="keyword">void</span> <span class="title function_">run</span><span class="params">(Object[] inputs, Map&lt;Integer, Object&gt; outputs)</span> &#123;</span><br><span class="line">    <span class="comment">// some error check</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// get input tensor and allocate space</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; inputs.length; ++i) &#123;</span><br><span class="line">      <span class="type">TensorImpl</span> <span class="variable">tensor</span> <span class="operator">=</span> getInputTensor(i);</span><br><span class="line">      <span class="type">int</span>[] newShape = tensor.getInputShapeIfDifferent(inputs[i]);</span><br><span class="line">      <span class="keyword">if</span> (newShape != <span class="literal">null</span>) &#123;</span><br><span class="line">        resizeInput(i, newShape);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">boolean</span> <span class="variable">allocatedTensors</span> <span class="operator">=</span> allocateTensorsIfNeeded();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; inputs.length; ++i) &#123;</span><br><span class="line">      getInputTensor(i).setTo(inputs[i]);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">long</span> <span class="variable">inferenceStartNanos</span> <span class="operator">=</span> System.nanoTime();</span><br><span class="line">    run(interpreterHandle, errorHandle);</span><br><span class="line">    <span class="type">long</span> <span class="variable">inferenceDurationNanoseconds</span> <span class="operator">=</span> System.nanoTime() - inferenceStartNanos;</span><br><span class="line">    ......</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"><span class="comment">// tensorflow/tensorflow/lite/java/src/main/java/org/tensorflow/lite/NativeInterpreterWrapper.java        </span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">native</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">(<span class="type">long</span> interpreterHandle, <span class="type">long</span> errorHandle)</span>;</span><br></pre></td></tr></table></figure>

<p>最后又调用了重载的run函数，可以看到又是一个JNI跳转，于是再次回到<code>tensorflow/tensorflow/lite/java/src/main/native/nativeinterpreterwrapper_jni.cc</code> 搜索跳转的包装函数run。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">JNIEXPORT <span class="keyword">void</span> JNICALL <span class="title function_">Java_org_tensorflow_lite_NativeInterpreterWrapper_run</span><span class="params">(</span></span><br><span class="line"><span class="params">    JNIEnv* env, jclass clazz, jlong interpreter_handle, jlong error_handle)</span> &#123;</span><br><span class="line">  <span class="comment">// ......</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (interpreter-&gt;Invoke() != kTfLiteOk) &#123;</span><br><span class="line">    <span class="comment">// TODO(b/168266570): Return InterruptedException.</span></span><br><span class="line">    ThrowException(env, tflite::jni::kIllegalArgumentException,</span><br><span class="line">                   <span class="string">&quot;Internal error: Failed to run on the given Interpreter: %s&quot;</span>,</span><br><span class="line">                   error_reporter-&gt;CachedErrorMessage());</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>​	核心在于第五行，调用了interpreter结构体的invoke函数。我们看看invoke函数做了什么, 这个interpreter已经是C++的结构体了，不再是java的结构体了，所以直接调用的C++代码，在<code>tensorflow/tensorflow/lite/core/interpreter.cc</code>文件。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// tensorflow/tensorflow/lite/core/interpreter.cc</span></span><br><span class="line"><span class="function">TfLiteStatus <span class="title">Interpreter::Invoke</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="function">ScopedRuntimeInstrumentationProfile <span class="title">scoped_runtime_event</span><span class="params">(root_profiler_.get(),</span></span></span><br><span class="line"><span class="params"><span class="function">                                                           <span class="string">&quot;invoke&quot;</span>)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// ......</span></span><br><span class="line"></span><br><span class="line">  <span class="built_in">TF_LITE_ENSURE_STATUS_WITH_SCOPED_INSTRUMENTATION</span>(</span><br><span class="line">      scoped_runtime_event, <span class="built_in">primary_subgraph</span>().<span class="built_in">Invoke</span>());</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (!allow_buffer_handle_output_) &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> tensor_index : <span class="built_in">outputs</span>()) &#123;</span><br><span class="line">      <span class="built_in">TF_LITE_ENSURE_STATUS_WITH_SCOPED_INSTRUMENTATION</span>(</span><br><span class="line">          scoped_runtime_event,</span><br><span class="line">          <span class="built_in">primary_subgraph</span>().<span class="built_in">EnsureTensorDataIsReadable</span>(tensor_index));</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> kTfLiteOk;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>​	可以发现调用了<code>primary_subgraph().Invoke()</code>,我们先看看<code>primary_subgraph()</code> 是什么东西:</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">  <span class="comment">//tensorflow/tensorflow/lite/core/interpreter.h</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Interpreter</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:  </span><br><span class="line">    <span class="function">Subgraph&amp; <span class="title">primary_subgraph</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> *subgraphs_.<span class="built_in">front</span>();  <span class="comment">// Safe as subgraphs_ always has 1 entry.</span></span><br><span class="line">      &#125;</span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="comment">// Subgraphs</span></span><br><span class="line">  std::vector&lt;std::unique_ptr&lt;Subgraph&gt;&gt; subgraphs_;</span><br><span class="line">   <span class="comment">// ......</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">//tensorflow/tensorflow/lite/core/interpreter.cc</span></span><br><span class="line">    Interpreter::<span class="built_in">Interpreter</span>(ErrorReporter* error_reporter)</span><br><span class="line">        : <span class="built_in">error_reporter_</span>(error_reporter ? error_reporter</span><br><span class="line">                                         : <span class="built_in">DefaultErrorReporter</span>()) &#123;</span><br><span class="line">    <span class="comment">//......</span></span><br><span class="line">            <span class="built_in">AddSubgraphs</span>(<span class="number">1</span>);</span><br><span class="line">            ...</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">Interpreter::AddSubgraphs</span><span class="params">(<span class="type">int</span> subgraphs_to_add,</span></span></span><br><span class="line"><span class="params"><span class="function">                                   <span class="type">int</span>* first_new_subgraph_index)</span> </span>&#123;</span><br><span class="line">       <span class="comment">// first_new_subgraph_index 默认是nullptr</span></span><br><span class="line">      <span class="type">const</span> <span class="type">size_t</span> base_index = subgraphs_.<span class="built_in">size</span>();</span><br><span class="line">      <span class="keyword">if</span> (first_new_subgraph_index) *first_new_subgraph_index = base_index;</span><br><span class="line"></span><br><span class="line">      subgraphs_.<span class="built_in">reserve</span>(base_index + subgraphs_to_add);</span><br><span class="line">      <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; subgraphs_to_add; ++i) &#123;</span><br><span class="line">        Subgraph* subgraph = <span class="keyword">new</span> <span class="built_in">Subgraph</span>(</span><br><span class="line">            error_reporter_, external_contexts_, &amp;subgraphs_, &amp;resources_,</span><br><span class="line">            &amp;resource_ids_, &amp;initialization_status_map_, subgraphs_.<span class="built_in">size</span>());</span><br><span class="line">        subgraphs_.<span class="built_in">emplace_back</span>(subgraph);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p> 这里设计到了一个<code>subgraphs_</code>的变量，这是什么呢，这其实是一个子图的vector容器，在创建Interpreter时，其有一个私有的成员变量为<code>subgraphs_</code>, 并且在Interpreter的构造函数中会将index为0的图加入这个vector中，也就是说primary_subgraph就是最初完整的那个模型图，后续会对这个图进行分裂成各个子图。这一部分在table subgraph中已经讲得很明确了。	</p>
<p>​	OK， 知道了就是获取到从文件中读取到的模型图，然后回来<code>invoke</code>函数,又是一层皮，还调用了<code>InvokeImpl</code>。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//tensorflow/tensorflow/lite/core/subgraph.cc</span></span><br><span class="line"><span class="function">TfLiteStatus <span class="title">Subgraph::Invoke</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">auto</span> status = <span class="built_in">InvokeImpl</span>();</span><br><span class="line">  telemetry::<span class="built_in">TelemetryReportEvent</span>(&amp;context_, <span class="string">&quot;Invoke&quot;</span>, status);</span><br><span class="line">  <span class="keyword">return</span> status;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function">TfLiteStatus <span class="title">Subgraph::InvokeImpl</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// ......</span></span><br><span class="line">  </span><br><span class="line">    <span class="built_in">EnsureTensorsVectorCapacity</span>();</span><br><span class="line">    tensor_resized_since_op_invoke_ = <span class="literal">false</span>;</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">auto</span> s = <span class="built_in">OpInvoke</span>(registration, &amp;node); s != kTfLiteOk) &#123;</span><br><span class="line">      <span class="keyword">auto</span> err = <span class="built_in">ReportOpError</span>(&amp;context_, node, registration, node_index,</span><br><span class="line">                               <span class="string">&quot;failed to invoke&quot;</span>);</span><br><span class="line">      <span class="keyword">return</span> s == kTfLiteCancelled ? s : err;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">   <span class="comment">//......</span></span><br><span class="line">  <span class="keyword">return</span> status;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以发现调用了<code>OpInvoke</code>函数, 然后他又调用了Registration的invoke函数，这就和前面结合起来了。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">TfLiteStatus <span class="title">Subgraph::OpInvoke</span><span class="params">(<span class="type">const</span> TfLiteRegistration&amp; op_reg,</span></span></span><br><span class="line"><span class="params"><span class="function">                                TfLiteNode* node)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (op_reg.registration_external &amp;&amp;</span><br><span class="line">      op_reg.registration_external-&gt;node_index != <span class="number">-1</span>) &#123;</span><br><span class="line">    TfLiteRegistration* referenced_registration =</span><br><span class="line">        &amp;nodes_and_registration_[op_reg.registration_external-&gt;node_index]</span><br><span class="line">             .second;</span><br><span class="line">    <span class="keyword">if</span> (referenced_registration-&gt;invoke == <span class="literal">nullptr</span>) <span class="keyword">return</span> kTfLiteError;</span><br><span class="line">    <span class="keyword">return</span> referenced_registration-&gt;<span class="built_in">invoke</span>(&amp;context_, node);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (op_reg.registration_external &amp;&amp; op_reg.registration_external-&gt;invoke) &#123;</span><br><span class="line">    <span class="keyword">return</span> op_reg.registration_external-&gt;<span class="built_in">invoke</span>(</span><br><span class="line">        <span class="built_in">reinterpret_cast</span>&lt;TfLiteOpaqueContext*&gt;(&amp;context_),</span><br><span class="line">        <span class="built_in">reinterpret_cast</span>&lt;TfLiteOpaqueNode*&gt;(node));</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (op_reg.invoke == <span class="literal">nullptr</span>) <span class="keyword">return</span> kTfLiteError;</span><br><span class="line">  <span class="keyword">return</span> op_reg.<span class="built_in">invoke</span>(&amp;context_, node);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="委托"><a href="#委托" class="headerlink" title="委托"></a>委托</h2><p>在运行模型那部分代码最后出现了一个结构体<code>TfLiteRegistrationExternal</code>, 这个类需要和<code>TfLiteRegistration</code> 一起分析。</p>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><a href="https://blog.actorsfit.com/a?ID=01000-9ed722be-d08c-4d27-a81e-157358f946e1">TensorFlow Lite 源代码分析-模型加载和执行 - actorfit (actorsfit.com)</a></p>
<p><a href="https://www.bilibili.com/video/av24219725/">TensorFlow Lite 深度解析 - 谷歌中国工程师教学视频_哔哩哔哩_bilibili</a></p>
<p><a href="https://resources.linaro.org/en/resource/ZDqBmZ9TWNc3Yi5vQeiqWF">LVC21-113: TensorFlow Lite Delegates on Arm-based Devices | Linaro Resources Hub</a></p>
]]></content>
      <categories>
        <category>note</category>
      </categories>
      <tags>
        <tag>gpu</tag>
      </tags>
  </entry>
  <entry>
    <title>cuda和GPU的探索(转自周杨叶)</title>
    <url>/2023/09/14/note/cuda_and_GPU/</url>
    <content><![CDATA[<h1 id="cuda和GPU的探索"><a href="#cuda和GPU的探索" class="headerlink" title="cuda和GPU的探索"></a>cuda和GPU的探索</h1><h2 id="简单的cuda程序样例"><a href="#简单的cuda程序样例" class="headerlink" title="简单的cuda程序样例"></a>简单的cuda程序样例</h2><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cstdlib&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cassert&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">add_vector</span><span class="params">(<span class="type">int</span>* res,<span class="type">int</span>* a,<span class="type">int</span>* b,<span class="type">int</span> num)</span></span>&#123;</span><br><span class="line">    <span class="type">int</span> index=threadIdx.x+blockIdx.x*blockDim.x;</span><br><span class="line">    <span class="keyword">if</span>(index&lt;num)&#123;</span><br><span class="line">        res[index]=a[index]+b[index];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">random_array</span><span class="params">(<span class="type">int</span>* a,<span class="type">int</span> n)</span></span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n;i++)&#123;</span><br><span class="line">        a[i]=<span class="built_in">rand</span>();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="type">int</span>* h_a;</span><br><span class="line">    <span class="type">int</span>* h_b;</span><br><span class="line">    <span class="type">int</span>* h_res;</span><br><span class="line">    <span class="type">int</span>* cuda_a;</span><br><span class="line">    <span class="type">int</span>* cuda_b;</span><br><span class="line">    <span class="type">int</span>* cuda_res;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> num=<span class="number">2048</span>*<span class="number">2048</span>;</span><br><span class="line">    <span class="type">int</span> numbyte=num*<span class="built_in">sizeof</span>(<span class="type">int</span>);</span><br><span class="line">    h_a=(<span class="type">int</span>*)<span class="built_in">malloc</span>(numbyte);</span><br><span class="line">    h_b=(<span class="type">int</span>*)<span class="built_in">malloc</span>(numbyte);</span><br><span class="line">    h_res=(<span class="type">int</span>*)<span class="built_in">malloc</span>(numbyte);</span><br><span class="line">    <span class="built_in">random_array</span>(h_a,num);</span><br><span class="line">    <span class="built_in">random_array</span>(h_b,num);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaMalloc</span>(&amp;cuda_a,numbyte);</span><br><span class="line">    <span class="built_in">cudaMalloc</span>(&amp;cuda_b,numbyte);</span><br><span class="line">    <span class="built_in">cudaMalloc</span>(&amp;cuda_res,numbyte);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(cuda_a,h_a,numbyte,cudaMemcpyHostToDevice);</span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(cuda_b,h_b,numbyte,cudaMemcpyHostToDevice);</span><br><span class="line">    add_vector&lt;&lt;&lt;num/<span class="number">512</span>,<span class="number">512</span>&gt;&gt;&gt;(cuda_res,cuda_a,cuda_b);</span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(h_res,cuda_res,numbyte,cudaMemcpyDeviceToHost);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;num;i++)&#123;</span><br><span class="line">        <span class="built_in">assert</span>(h_res==h_a+h_b);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaFree</span>(cuda_a);</span><br><span class="line">    <span class="built_in">cudaFree</span>(cuda_b);</span><br><span class="line">    <span class="built_in">cudaFree</span>(cuda_res);</span><br><span class="line">    <span class="built_in">free</span>(h_a);</span><br><span class="line">    <span class="built_in">free</span>(h_b);</span><br><span class="line">    <span class="built_in">free</span>(h_res);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这是一个demo实现的是使用GPU进行向量加法的加速，我们来分析一下这个简单的程序。</p>
<p>首先是无聊的前期准备工作，给h_a、h_b、h_res三个数组分配num大小的数组空间，然后用随机数初始化h_a、h_b数组，目标是计算h_a和h_b求和的结果，保存到h_res中</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> num=<span class="number">2048</span>*<span class="number">2048</span>;</span><br><span class="line"><span class="type">int</span> numbyte=num*<span class="built_in">sizeof</span>(<span class="type">int</span>);</span><br><span class="line">h_a=(<span class="type">int</span>*)<span class="built_in">malloc</span>(numbyte);</span><br><span class="line">h_b=(<span class="type">int</span>*)<span class="built_in">malloc</span>(numbyte);</span><br><span class="line">h_res=(<span class="type">int</span>*)<span class="built_in">malloc</span>(numbyte);</span><br><span class="line"><span class="built_in">random_array</span>(h_a,num);</span><br><span class="line"><span class="built_in">random_array</span>(h_b,num);</span><br></pre></td></tr></table></figure>
<p>为了让GPU可以计算h_a和h_b数组的内容，但是GPU只能直接访问GPU自己的专属现存的数据，无法直接访问CPU上面的内容，所以我们需要首先把需要计算的数据从host设备(CPU的内存)移到device设备(GPU内存)上来。</p>
<p>cudaMalloc(void** ptr,int num)函数传入一个指针的地址，然后它会向GPU申请分配一块num字节的显存空间，显存空间的首地址被保存到ptr指向的指针当中。于是我们向GPU申请了三块大小为numbyte的显存空间，地址被保存到cuda_a、cuda_b、cuda_res三个变量当中。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cudaMalloc</span>(&amp;cuda_a,numbyte);</span><br><span class="line"><span class="built_in">cudaMalloc</span>(&amp;cuda_b,numbyte);</span><br><span class="line"><span class="built_in">cudaMalloc</span>(&amp;cuda_res,numbyte);</span><br></pre></td></tr></table></figure>
<p>需要注意malloc申请的是Host的虚拟地址，只有在Host上使用是有意义的；cudaMalloc申请的是Device的虚拟地址，只有把这个地址的值传送给Device，让Device使用才是有意义的。</p>
<p>然后我们使用cudaMemcpy函数把Host的h_a和h_b向量的数据传递到Device的cuda_a、cuda_b数组上面。<code>cudaMemcpy(void* dst,void* src,int num,enum kind)</code>中kind指示了转递的类型，如果是cudaMemcpyHostToDevice那么就是从Host的内存传递数据给Device，dst需要是Device地址，src需要是Host地址；cudaMemcpyDeviceToHost就是从Devie内存传递数据给Host，dst需要时Host地址，src是Device地址。所以现在GPU获得他需要的数据了。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cudaMemcpy</span>(cuda_a,h_a,numbyte,cudaMemcpyHostToDevice);</span><br><span class="line"><span class="built_in">cudaMemcpy</span>(cuda_b,h_b,numbyte,cudaMemcpyHostToDevice);</span><br></pre></td></tr></table></figure>
<p>GPU的数据已经就位了，下一步就是运行GPU的程序，也就是如下代码。在cuda当中用__host__修饰的就是CPU执行的代码，可以省略不写，用__global__修饰的就是GPU执行的代码，这部分函数会被编译得到GPU的可执行文件，然后在运行add_Vector的时候被发送给GPU，GPU就会运行这部分代码实现我们需要的向量加法功能。</p>
<p><code>add_vector&lt;&lt;&lt;num/512,512&gt;&gt;&gt;(cuda_res,cuda_a,cuda_b);</code>这是cuda的GPU代码特有的调用方式，我们后续再进行介绍，总之它调用了GPU做add_vector，实现了cuda_a和cuda_b的向量相加，并且把结果加到了cuda_res上来。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">    add_vector&lt;&lt;&lt;num/<span class="number">512</span>,<span class="number">512</span>&gt;&gt;&gt;(cuda_res,cuda_a,cuda_b);</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">add_vector</span><span class="params">(<span class="type">int</span>* res,<span class="type">int</span>* a,<span class="type">int</span>* b,<span class="type">int</span> num)</span></span>&#123;</span><br><span class="line">    <span class="type">int</span> index=threadIdx.x+blockIdx.x*blockDim.x;</span><br><span class="line">    <span class="keyword">if</span>(index&lt;num)&#123;</span><br><span class="line">        res[index]=a[index]+b[index];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>之后我们再次调用cudaMemcpy将数据从GPU的cuda_res传递到CPU的h_res上去，就得到了h_a+h_b的结果。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cudaMemcpy</span>(h_res,cuda_res,numbyte,cudaMemcpyDeviceToHost);</span><br></pre></td></tr></table></figure>
<p>最后做一些内存的回收，free回收malloc分配的Host内存，cudaFree回收cudaMalloc分配的Device内存。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cudaFree</span>(cuda_a);</span><br><span class="line"><span class="built_in">cudaFree</span>(cuda_b);</span><br><span class="line"><span class="built_in">cudaFree</span>(cuda_res);</span><br><span class="line"><span class="built_in">free</span>(h_a);</span><br><span class="line"><span class="built_in">free</span>(h_b);</span><br><span class="line"><span class="built_in">free</span>(h_res);</span><br></pre></td></tr></table></figure>

<h2 id="SIMT编程模式"><a href="#SIMT编程模式" class="headerlink" title="SIMT编程模式"></a>SIMT编程模式</h2><p>在介绍<code>__global__ add_vector</code>的代码和调用为什么长得这么奇特之前，我们先介绍一波GPU的结构和编程的对应关系，具体的GPU的体系结构和微架构之类的细节，我们之后详谈，另外现在介绍的GPU结构模型是简化过、抽象过的，只是为了方便大家快速理解软件的构造，至于硬件真是怎么适配，那是另一个复杂的问题。</p>
<h3 id="thread与core"><a href="#thread与core" class="headerlink" title="thread与core"></a>thread与core</h3><p>对于CPU，我们可以将一个process编写一个多thread程序，然后我们有4个core，我们就可以每次调度4个thread到4个core上，然后一次算4个thread的内容。而对于GPU我们有上千个core，甚至上万个core，所以我们可以编写一个有数万thread的程序，然后交给GPU的数万个core运行。高度并行的批数据处理程序很适合编写这种多thread程序：比如向量加法，我们把两个1w维的向量a和1w维的向量b相加，我们可以写一个1万个thread的程序，第i个程序负责把a的第i个分量和b的第i个分量相加，这样所有的thread算完，我们的向量相加的任务就结束了。</p>
<p>我们看一下下面的程序，只是之前的简化版本。我们在add_vector后面的&lt;&lt;&lt;&gt;&gt;&gt;填入512，就说我们需要512个线程，那么GPU收到我们的命令之后就会产生512个thread，这本身也是GPU强大的地方，他可以快速地初始化大量的线程，这对于CPU是无法做到的。然后这些线程就会被分配到空闲的core上运行，比如我们有128个core，那么运行4批就算完了。对于所有的线程他们都执行add_vector的代码，基本同时开始并且同时结束，thread中间唯一的区别是它们的threadIdx号不一样，会被一次标号为0-511，这是每个TCB的一部分，除此之外没有任何的区别。程序员编程的时候可以根据这个threadIdx.x不同来访问不同的数据，比如第i个thread访问第i个向量分量。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">    add_vector&lt;&lt;&lt;<span class="number">1</span>,<span class="number">512</span>&gt;&gt;&gt;(cuda_res,cuda_a,cuda_b);</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">add_vector</span><span class="params">(<span class="type">int</span>* res,<span class="type">int</span>* a,<span class="type">int</span>* b,<span class="type">int</span> num)</span></span>&#123;</span><br><span class="line">    <span class="type">int</span> index=threadIdx.x;</span><br><span class="line">    <span class="keyword">if</span>(index&lt;num)&#123;</span><br><span class="line">        res[index]=a[index]+b[index];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="block与SM"><a href="#block与SM" class="headerlink" title="block与SM"></a>block与SM</h3><p>对于一个GPU来说他可能有1024个core，如果他产生了1024个thread，然后用一个中央的调度器把每一个thread分配到每一个core上面，对于这个调度器来说要求太大了，他必须同时具备同时处理1024个单独线程调度的能力。在硬件实现上，如果1024个core完全独立的一级层次，那么其他的所有部件都需要同时面对1024个core的调用请求，这个仲裁压力也太大了。所以对于core我们需要一个二级结构组织起来，这个就是SM(stream multiprocess)。</p>
<p>每个SM比如说包含128个core，然后一共有8个SM；对应的我们的1024个thread也是，我们把thread组织成block，每个block包含128个thread，一共只有8个block。于是我们的中央调度器先把8个block分配到对应的8个SM上就可以了，那他的调度压力就非常小了，只需要管理8个部件而已。于是我们的管理层次就是：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">grid----block----thread</span><br><span class="line"> GPU----  SM ---- core</span><br></pre></td></tr></table></figure>

<h3 id="warp与core组"><a href="#warp与core组" class="headerlink" title="warp与core组"></a>warp与core组</h3><p>每个block包含他的128个thread到达SM之后，SM有一个二级调度器负责调度128个thread，压力虽然不是1024那么大了，但是还是很大，所以进一步划分层次，我们将32个thread当成一个整体调度，成为一个warp，他们永远做一样的事情被调度器当作一个整体简单处理。这样的话每个SM其实只需要调度4个warp，那么它的调度压力也变得很小了，可以用简单的控制逻辑解决掉。于是我们的管理层次就变为了：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">grid----block---- wrap----thread</span><br><span class="line"> GPU----  SM ----cores---- core</span><br></pre></td></tr></table></figure>
<h3 id="GPC与cluster"><a href="#GPC与cluster" class="headerlink" title="GPC与cluster"></a>GPC与cluster</h3><p>此外对于GPU来说，8个SM直接调度似乎还是太多了，所以将比如4个SM组织为一个GPC，将block组织为cluster，这样顶级调度只需要将2个cluster发给2个GPC，GPC的调度器再将4个block分配个4个SM即可。这样的分层模式可以使得，每一级的压力都可以大大减小。于是我们的管理层次变为了：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">grid----cluster----block---- wrap----thread</span><br><span class="line"> GPU----  GPC  ----  SM ----cores---- core</span><br></pre></td></tr></table></figure>
<h3 id="回到cuda编程语法"><a href="#回到cuda编程语法" class="headerlink" title="回到cuda编程语法"></a>回到cuda编程语法</h3><p>所以我们使用add_vector的时候，<code>&lt;&lt;&lt;&gt;&gt;&gt;</code>里面就需要传入两个额外的参数作为block的个数和每个block的thread的个数，然后GPU就会产生对应个数的block和thread，然后自动分配给SM和core。比如<code>add_vector&lt;&lt;&lt;num/512,512&gt;&gt;&gt;(cuda_res,cuda_a,cuda_b)</code>就是定义了每个block包含512个thread，有<code>num/512</code>个block，这样每个向量分量都有一个对应的thread来进行计算。当然也可以少定义一些thread，每个thread多计算几个分量也是可以的，不考虑性能的优劣等细节，他们都是可行的选择。</p>
<p>此外我们的block的个数和thread的个数并不是一个一维的数字，实际上他们的数据类型为<code>dim3</code>，是一个三维的数据，比如一个block的512个thread可以选择设置维度为简单的(512)，也可以设置为(128,4)，也可以设置为(32,4,4)都是一样的，他们都意味着一个block有512个thread。我们一开始输入的512会被编译器转换为(512,1,1)，而(128,4)会被转换为(128,4,1)，因此其实都是三维向量表示thread的分布，唯一的区别是每个thread的编号threadIdx.x、threadIdx.y和threadIdx.z会不一样。</p>
<p>比如(4,1,1)得到的四个thread，它们的threadIdx依次是(0,0,0)、(1,0,0)、(2,0,0)、(3,0,0)；而对于(2,2,1)得到的编号就是(0,0,0)、(1,0,0)、(0,1,0)、(1,1,0)。但是在执行的时候这两种编号得到的线程不会被区别对待，可能说如果你需要用threadIdx作为二维矩阵索引的时候，它可以直接拿来使用，而第一种需要换算一波，某种意义上可以加速计算，但也仅此而已。另外对于一个block的thread维度被保存在blockDim这个特殊的dim3变量当中，可以在cuda编程的时候访问。</p>
<p>对于block也是如此，他也是一个三维的数据，道理和thread一样，三维的编号可以用编程时候的只读变量blockIdx来访问，block的维度可以用只读变量gridDim来访问。</p>
<h3 id="SIMT难以胜任的任务类型"><a href="#SIMT难以胜任的任务类型" class="headerlink" title="SIMT难以胜任的任务类型"></a>SIMT难以胜任的任务类型</h3><h4 id="1-并行度较低的程序"><a href="#1-并行度较低的程序" class="headerlink" title="1.并行度较低的程序"></a>1.并行度较低的程序</h4><p>我们一直说显卡可以加速图形计算、可以加速神经网络训练、可以加速批数据处理，但是并不是所有任务都适合GPU进行的。GPU的时钟周期比CPU慢不少，同样一个代码，如果CPU和GPU都是一个线程运行的话，CPU的时钟周期比GPU快很多，GPU跑一条指令，CPU可以跑比如4条；对于流水线常见的冲突问题，GPU一般就是死等，但是CPU可以分支预测、乱序执行、多发射等等技术，比如双发射四发射就一个周期多跑了好几条，有stall后面的指令在乱序和预测的支持下提前运行；对于内存访问，GPU的cache远少于CPU，cache命中率低，内存访问更慢。所以单线程而言说不定CPU可以比GPU快个10倍不止。但是对于数据批处理任务，比如向量加法，再烂的GPU也可以同时跑比如1024个thread，但是很多先进的CPU最多跑32个thread也很夸张了，哪怕单个核快10倍也还是慢。所以GPU的计算能力高度依赖于并行，如果是想编译这样的高度线性、高度复杂控制的任务，GPU远差于CPU，不如用CPU跑。</p>
<h4 id="2-同步要求高的程序"><a href="#2-同步要求高的程序" class="headerlink" title="2.同步要求高的程序"></a>2.同步要求高的程序</h4><p>CPU的thread之间可以用多种方式进行任意的同步，但是GPU的thread同步很困难，它只支持wrap内部的同步、一个block的所有thread的同步、一个grid的所有block的同步等粗粒度的同步，无法处理很精细的同步机制，或者说如果想要实现代价很大。像向量加法这种thread之间就没有任何的交流，那么GPU就可以很流畅的执行。而一旦需要加速同步等任务，CPU倒还好，GPU操作不当还很容易死锁。</p>
<h4 id="3-数据规模小的程序"><a href="#3-数据规模小的程序" class="headerlink" title="3.数据规模小的程序"></a>3.数据规模小的程序</h4><p>GPU的运行开销是比较大的，kernel的launch、线程的初始化、内存的分配、数据的传输和任务的释放都需要一定的开销，如果数据量太小不足以分摊这部分开销，那直接CPU现场跑掉算了，数据从CPU运到GPU也挺花时间的。</p>
<h2 id="内存的分配与管理"><a href="#内存的分配与管理" class="headerlink" title="内存的分配与管理"></a>内存的分配与管理</h2><h3 id="1-malloc"><a href="#1-malloc" class="headerlink" title="1.malloc"></a>1.malloc</h3><p><code>malloc</code>不是cuda的一部分，放在这里就是为了图个完整。他会从Host的heap上分配一块内存，但是这个地址对于Device是没有意义的，GPU无法用任何正常的方法访问这个内存区域，如果有bug另说。如果想要知道一个内存地址的类型，我们可以用如下的代码：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span>* ptr=(<span class="type">int</span>*)<span class="built_in">malloc</span>(<span class="built_in">sizeof</span>(<span class="type">int</span>)*<span class="number">1024</span>);</span><br><span class="line">cudaPointerAttributes attr;</span><br><span class="line"><span class="built_in">cudaPointerGetAttributes</span>(&amp;attr,ptr);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;type=%d,host=%p,device=%p\n&quot;</span>,attr.type,attr.hostPointer,attr.devicePointer);</span><br></pre></td></tr></table></figure>
<p><code>cudaPointerAttributes</code>是一个描述指针类型的结构，然后用<code>cudaPointerGetAttributes</code>函数就可以将一个地址的指针类型等信息存到这个结构里面。<code>cudaPointerAttributes</code>的type分量表示指针的类型，分为4种，分别是非分配、Host、Device和Managed，hostPointer是Host访问这块内存需要的地址，devicePointer是Device访问这块内存需要的地址，如果无法访问那么地址就是0。</p>
<p>对于malloc分配的内存，用<code>cudaPointerGetAttributes</code>得到的type是Host，hostPointer地址是heap的地址，devicePointer是nil无法访问。所以说明malloc是得到Host上的物理地址，Host得到heap的地址，Device无法直接访问这块内存。</p>
<h3 id="2-cudaMalloc"><a href="#2-cudaMalloc" class="headerlink" title="2.cudaMalloc"></a>2.cudaMalloc</h3><p><code>cudaMalloc</code>的使用方法如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span>* cuda_ptr;</span><br><span class="line"><span class="built_in">cudaMalloc</span>((<span class="type">void</span>**)&amp;cuda_ptr,<span class="built_in">sizeof</span>(<span class="type">int</span>)*<span class="number">1024</span>);</span><br></pre></td></tr></table></figure>
<p>使用<code>cudaPointerGetAttributes</code>得到的type是device，hostPointer是nil，devicePointer是有效地址数据，所以cudaMalloc分配得到的内存是Device上面的显存，只能Device用devicePointer的地址访问，Host无法直接访问这块Device的内存。</p>
<h3 id="3-cudaMallocHost"><a href="#3-cudaMallocHost" class="headerlink" title="3.cudaMallocHost"></a>3.cudaMallocHost</h3><p><code>cudaMallocHost</code>的使用方法如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span>* ptr;</span><br><span class="line"><span class="built_in">cudaMallocHost</span>((<span class="type">void</span>**)&amp;ptr,<span class="built_in">sizeof</span>(<span class="type">int</span>)*<span class="number">1024</span>);</span><br></pre></td></tr></table></figure>
<p>使用<code>cudaPointerGetAttributes</code>得到的type是host，该函数接口会分配一个host上面的物理内存，但是并不在heap上，而是用memory mapping新映射一个内存空间，同时这个host的内存地址也会被device映射到他的也表上。比如我们得到的cudaMallocHost的地址是0x3000000，那么当host访问0x3000000的时候就会直接通过host的页表找到对应的内存访问，和其他的host内存访问没有任何区别，仅仅是地址区域在逻辑上不在heap或者stack上罢了；当device访问0x3000000，它会通过页表得知这个内存是host的内存，然后用pcie去读取host的内存。所以虽然这块内存分配在host上，但是是device和host都可见的，而且用同一个内存地址访问。所以使用<code>cudaPointerGetAttributes</code>得到的type是host，hostPointer和devicePointer是同一个值。</p>
<p>此外，<code>cudaMallocHost</code>分配得到的页是pinned的页，所以说<code>cudaMallocHost</code>最好是页的整数倍，不然是一个很浪费的事情，好在GPU一般传递的都是大块的数据，所以问题不大。使用pinned页的好处在于，pcie数据传输可以更迅速，因为如果页没有被pinned住的话，这个页随时都可能会被swap出内存，因此pcie传输的时候，会先把这个页的数据拷贝到另一个pinned页上，然后再进行pcie的传输，反之亦然，所以直接使用pinned的内存，可以减少一次内存的拷贝，节约时间。</p>
<h3 id="4-cudaHostRegister"><a href="#4-cudaHostRegister" class="headerlink" title="4.cudaHostRegister"></a>4.cudaHostRegister</h3><p><code>cudaHostRegister</code>的使用方法如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span>* ptr;</span><br><span class="line"><span class="type">int</span>* cuda_ptr;</span><br><span class="line">ptr=(<span class="type">int</span>*)<span class="built_in">malloc</span>(<span class="built_in">sizeof</span>(<span class="type">int</span>)*<span class="number">1024</span>);</span><br><span class="line"><span class="built_in">cudaHostRegister</span>(ptr, <span class="built_in">sizeof</span>(<span class="type">int</span>)*<span class="number">1024</span>, cudaHostRegisterMapped);</span><br><span class="line"><span class="built_in">cudaHostGetDevicePointer</span>((<span class="type">void</span> **)&amp;cuda_ptr, ptr, <span class="number">0</span>);</span><br></pre></td></tr></table></figure>
<p>首先我们用<code>malloc</code>得到了一个Host的内存，这个时候这个内存地址仅对Host有意义，该内存也只有Host可以访问，然后我们用<code>cudaHostRegister</code>将这个Host的地址范围交给Device，向Device注册这个Host的地址，于是Device分出一块Device的逻辑地址空间来映射这个Host的地址空间，修改自己的页表。之后我们可以用<code>cudaHostGetDevicePointer</code>来得到Host地址注册到Device之后被Device分配得到的地址，之后的kernel执行的时候，Device可以用这个地址来访问Host上对应的内存。<code>cudaHostRegister</code>+<code>cudaHostGetDevicePointer</code>的组合和<code>cudaMallocHost</code>其实只是在使用上存在一些区别，实现上基本一致，最大的区别可能就是<code>cudaMallocHost</code>对于Host物理内存分配的虚拟地址是一样的，但是<code>cudaHostRegister</code>分配的虚拟地址是互异的。</p>
<p>所以使用<code>cudaPointerGetAttributes</code>得到的type是host，hostPointer是heap上的地址，devicePointer是另外映射的地址。</p>
<h3 id="5-cudaMallocManaged"><a href="#5-cudaMallocManaged" class="headerlink" title="5.cudaMallocManaged"></a>5.cudaMallocManaged</h3><p><code>cudaMallocManaged</code>的使用方法如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span>* ptr;</span><br><span class="line"><span class="built_in">cudaMallocManaged</span>(&amp;ptr,<span class="built_in">sizeof</span>(<span class="type">int</span>)*<span class="number">1024</span>,cudaMemAttachGlobal);</span><br></pre></td></tr></table></figure>
<p>使用<code>cudaPointerGetAttributes</code>得到的type是managed，hostPointer和devicePointer是相同的地址，Host和Device都可以用相同的虚拟地址访问这个内存，这点和<code>cudaMallocHost</code>是非常相似的，最大的区别就是物理内存并不是仅仅在Host上的。</p>
<p>Managed的物理内存并不分配，它仅仅是在host端注册了这个内存范围，比如vm_area_struct注册了这个内存块的信息，对于Device也是类似的，虽然不知道具体注册的函数接口之类的，但是也是类似的机制。然后当Host访问对应的虚拟地址的时候，因为page fault才分配对应的物理内存，Device也是当Device访问对应的虚拟地址的时候，Device才分配自己的显存。此外如果Host写了自己Managed的物理内存，它仅仅是在它Host的物理内存上写的，比如Host分配了1MB的内存，然后Host都写入了1，然后Device没读写过这部分内存，那么Device就不会分配对应的显存，也不需要把Host的数据传递到Device当中，如果Device读写了其中一部分，那么只有对应的那一部分数据会被Device分配内存，然后Host和Device传递数据同步这部分的数据。</p>
<p>也就是说，Host和Device访问了内存，对应的页才会在Host和Device上分配，Host和Device都读写了同一个内存地址，这个内存所在的页才会在Host和Device之间传递数据进行同步，没有被访问的内存范围不会分配实际的物理地址，没有被双方同时访问的页更不会相互传递数据。这样的好处一个是同一地址进行内存管理，内存的使用非常方便，当然如果愿意多敲几行代码，这也不是巨大的优点；第二就是内存的按需分配和按需传递，可以节约不必要的开支，也有利于多进程同时运行时，按需分配内存。当然如果分配内存的所有数据都要被Device和Host访问，而且要被反复使用的话，额外的管理开销可能会很巨大，效果也许不如直接<code>cudaMalloc</code>。</p>
<h2 id="cuda程序的编译和编译结果的组成"><a href="#cuda程序的编译和编译结果的组成" class="headerlink" title="cuda程序的编译和编译结果的组成"></a>cuda程序的编译和编译结果的组成</h2><p>cuda程序使用nvcc进行编译最后得到一个C的elf文件，那么他是怎么把一个GPU运行的程序转换为一个常见的C程序，对于GPU需要运行的代码它做了哪些的处理，对于cuda的语法糖它做了那些的转换呢？</p>
<h3 id="一些差异"><a href="#一些差异" class="headerlink" title="一些差异"></a>一些差异</h3><p>我们用readelf来输出一下sample.cu最后编译得到的sample文件，会发现它就是一个很正常的elf文件，但是它的segmentation多了一些东西，一个是在rodata部分多了一个nv_fatbin段和一个__nv_module_id段，在data部分多了一个.nvFatBinSegment段，这其中一定包含了和GPU执行代码紧密管理的部分。因为GPU执行的二进制代码一开始肯定是存储在elf当中的，并且因为这部分代码无法被CPU执行，所以他们肯定是在数据段部分，考虑到可执行代码一般无法被修改，所以很有可能就是rodata部分的nv_fatbin。</p>
<p>__nv_module_id的内容如下</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">Hex dump of section <span class="string">&#x27;__nv_module_id&#x27;</span>:</span><br><span class="line">  <span class="number">0x0008b9d0</span> <span class="number">5</span>f5f<span class="number">4e56</span> <span class="number">5</span>f4d4f44 <span class="number">554</span>c455f <span class="number">494400</span>   __NV_MODULE_ID.</span><br></pre></td></tr></table></figure>
<p>他就是一段魔数而已，所以没什么值得重点考量的，因此我们后期把重心放在.nv_fatbin和.nvFatBinSegment上。</p>
<p>之后我们观察objdump得到的代码，<code>cudaMalloc</code>之类的函数api调用都是正常的函数调用的模式，但是如<code>add&lt;&lt;&lt;grid,block&gt;&gt;&gt;(res,a,b,n)</code>得到的汇编却比较特殊，add函数进入之后是一个stub函数，然后进行一系列特殊的操作，因此对应CPU调用GPU对应的函数部分会进行一些特殊的处理，这其中应该也找到CPU如何调用GPU工作的线索。然后asm文件中处理我们手写的函数，add被增加的一堆函数还有很多<code>__cudart1-----__cudart3000</code>之类的函数，他们估计是cuda的库函数，但是因为函数名被隐去了，失去了可读性，难以直接找到有用的信息。</p>
<p>这些和常规C代码编译结果不同的地方隐含了cuda程序调用GPU工作的一些秘密，对他们如何编译得到，如果执行进行研究，也许有助于我们探索GPU和CPU如何协同工作。</p>
<h3 id="正式开始"><a href="#正式开始" class="headerlink" title="正式开始"></a>正式开始</h3><p>我们可以用<code>nvcc sample.cu -o sample --dryrun</code>命令输出nvcc编译sample.cu时候的中间命令，此外我们可以用<code>nvcc sample.cu -o sample --keep</code>保留nvcc编译得到的中间结果，所以综合这两部分，我们可以很方便的观察到sample编译得全过程。</p>
<p>使用<code>nvcc sample.cu -o sample --dryrun</code>得到的输出如下，我们删去了其中大量的参数部分，仅仅留下了中间文件之间的关联：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">gcc sample.cu -o sample.cpp<span class="number">1.</span>ii</span><br><span class="line"></span><br><span class="line">cicc --include_file_name sample.fatbin.c </span><br><span class="line">    --gen_module_id_file --module_id_file_name sample.module_id </span><br><span class="line">    --gen_c_file_name sample.cudafe<span class="number">1.</span>c </span><br><span class="line">    --stub_file_name sample.cudafe<span class="number">1.</span>stub.c </span><br><span class="line">    --gen_device_file_name sample.cudafe<span class="number">1.</span>gpu </span><br><span class="line">    sample.cpp<span class="number">1.</span>ii -o sample.ptx</span><br><span class="line"></span><br><span class="line">ptxas sample.ptx  -o sample.sm_<span class="number">52.</span>cubin</span><br><span class="line"></span><br><span class="line">fatbinary --image3=kind=elf,sm=<span class="number">52</span>,file=sample.sm_<span class="number">52.</span>cubin </span><br><span class="line">    --image3=kind=ptx,sm=<span class="number">52</span>,file=sample.ptx </span><br><span class="line">    --embedded-fatbin=sample.fatbin.c</span><br><span class="line"></span><br><span class="line">gcc sample.cu -o sample.cpp<span class="number">4.</span>ii</span><br><span class="line"></span><br><span class="line">cudafe++ --gen_c_file_name sample.cudafe<span class="number">1.</span>cpp </span><br><span class="line">    --stub_file_name sample.cudafe<span class="number">1.</span>stub.c </span><br><span class="line">    --module_id_file_name sample.module_id </span><br><span class="line">    sample.cpp<span class="number">4.</span>ii</span><br><span class="line"></span><br><span class="line">gcc sample.cudafe<span class="number">1.</span>cpp -o sample.o</span><br><span class="line"></span><br><span class="line">nvlink --<span class="keyword">register</span>-link-binaries=sample_dlink.reg.c </span><br><span class="line">    sample.o -o sample_dlink.sm_<span class="number">52.</span>cubin</span><br><span class="line"></span><br><span class="line">fatbinary -link </span><br><span class="line">    --image3=kind=elf,sm=<span class="number">52</span>,file=sample_dlink.sm_<span class="number">52.</span>cubin </span><br><span class="line">    --embedded-fatbin=sample_dlink.fatbin.c</span><br><span class="line"></span><br><span class="line">gcc -DFATBINFILE=sample_dlink.fatbin.c </span><br><span class="line">    -DREGISTERLINKBINARYFILE=sample_dlink.reg.c </span><br><span class="line">    -m64 /usr/lib/nvidia-cuda-toolkit/bin/crt/link.stub </span><br><span class="line">    -o sample_dlink.o</span><br></pre></td></tr></table></figure>

<p>使用<code>nvcc sample.cu -o sample --keep</code>保留的文件目录如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">.</span><br><span class="line">├── sample.cpp1.ii</span><br><span class="line">├── sample.cpp4.ii</span><br><span class="line">├── sample.cu</span><br><span class="line">├── sample.cudafe1.c</span><br><span class="line">├── sample.cudafe1.cpp</span><br><span class="line">├── sample.cudafe1.gpu</span><br><span class="line">├── sample.cudafe1.stub.c</span><br><span class="line">├── sample_dlink.fatbin</span><br><span class="line">├── sample_dlink.fatbin.c</span><br><span class="line">├── sample_dlink.o</span><br><span class="line">├── sample_dlink.reg.c</span><br><span class="line">├── sample_dlink.sm_52.cubin</span><br><span class="line">├── sample.fatbin</span><br><span class="line">├── sample.fatbin.c</span><br><span class="line">├── sample.module_id</span><br><span class="line">├── sample.o</span><br><span class="line">├── sample.ptx</span><br><span class="line">└── sample.sm_52.cubin</span><br></pre></td></tr></table></figure>
<p>现在我们依次分析一下每一条指令都做了什么，产生了哪些文件，每个文件的变化和功能。</p>
<h3 id="步骤一"><a href="#步骤一" class="headerlink" title="步骤一"></a>步骤一</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">gcc sample.cu -o sample.cpp1.ii</span><br></pre></td></tr></table></figure>
<p>sample.cu本身其实就是一个带了cuda语法扩展的C++程序，或者说带了cuda语法扩展和C++语法扩展的C程序，所以可以用gcc这个C编译器进行编译预处理(编译预处理的语法是一样的)，然后gcc会处理诸如<code>#define</code>、<code>#include</code>等命令，然后得到一个编译预处理结束的ii文件。这个文件非常庞大，这主要是因为它include的文件非常多，展开来就显得很庞大，但是实际上只有最末尾的一部分代码是我们自己编写的sample的部分。</p>
<h3 id="步骤二"><a href="#步骤二" class="headerlink" title="步骤二"></a>步骤二</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cicc --include_file_name sample.fatbin.c </span><br><span class="line">    --gen_module_id_file --module_id_file_name sample.module_id </span><br><span class="line">    --gen_c_file_name sample.cudafe1.c </span><br><span class="line">    --stub_file_name sample.cudafe1.stub.c </span><br><span class="line">    --gen_device_file_name sample.cudafe1.gpu </span><br><span class="line">    sample.cpp1.ii -o sample.ptx</span><br></pre></td></tr></table></figure>
<p>因为我们的cuda程序是CPU和GPU协同运行的，所以我们既需要编译得到常规CPU运行的C代码，也需要运行GPU可以运行的GPU的二进制代码；此外我们的CPU程序比如可以用<code>add&lt;&lt;&lt;grid,dim&gt;&gt;&gt;(res,a,b,n)</code>来调用GPU程序，但是GPU程序是无法直接被调用的，所以这里需要生成CPU间接调用GPU的代码；另外就是我们有很多GPU代码的信息，我们CPU需要执行GPU的代码就需要管理这部分信息，所以需要一些代码来注册和管理GPU代码的信息。而这些对应的代码的初始形态都是在这个命令中被产生的，包括GPU代码管理的CPU代码、GPU代码调用的CPU代码、GPU可执行的二进制代码的中间形态等。</p>
<h4 id="sample-module-id"><a href="#sample-module-id" class="headerlink" title="sample.module_id"></a>sample.module_id</h4><p>似乎不是每个文件都用的，有些文件之后似乎没有被用到，比如sample.module_id，里面只有一行<code>_394179f1_9_sample_cu_e9c26b7d</code>序号，估计只是cuda文件管理的时候派一下用场吧。</p>
<h3 id="sample-cudafe1-c"><a href="#sample-cudafe1-c" class="headerlink" title="sample.cudafe1.c"></a>sample.cudafe1.c</h3><p>里面的内容是一堆全局变量的定义，但是似乎没有人用它，估计不起到大的作用</p>
<h4 id="sample-cudafe1-gpu"><a href="#sample-cudafe1-gpu" class="headerlink" title="sample.cudafe1.gpu"></a>sample.cudafe1.gpu</h4><p>这部分会把sample.cpp1.ii当中GPU相关的那些代码，比如用<code>__device__</code>、<code>__shared__</code>，或者用<code>__global__</code>修饰的部分提取出来，得到这样一个文件。</p>
<p>文件开头是大量的enum、typedef、struct的定义，估计是类似于include的展开，等待被后续引用，不过大多数都用不上；然后中间部分是函数声明，所有我们使用过的CPU函数都会被他认为是一个<code>extern __device__</code>的函数，等待被外部链接，不过实际上这些并不是GPU需要的函数，所以后续也不会产生什么作用，无需理睬；然后是我们自己编写的<code>__global__</code>函数的函数声明，诸如<code>gpu_vector_add</code>函数会产生<code>_Z14gpu_vector_addPiS_S_i</code>的函数声明，这里的前缀和后缀应该是根据函数的调用参数来加的，另外还有两个特别的函数声明<code>_ZN4dim3C1Ejjj</code>和<code>_ZN4dim3C2Ejjj</code>我们后续介绍；之后是<code>__device__</code>涉及的一些全局变量。</p>
<p>之后就是<code>__global__</code>函数对应的函数定义，比如我们的<code>gpu_vector_add</code>就从一开始的</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">gpu_vector_add</span><span class="params">(<span class="type">int</span>* a,<span class="type">int</span>* b,<span class="type">int</span>* res,<span class="type">int</span> n)</span></span>&#123;</span><br><span class="line">    <span class="type">int</span> index=threadIdx.x+blockIdx.x*blockDim.x;</span><br><span class="line">    res[index]=a[index]+b[index];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>被编译为了sample.cudafe1.gpu中的：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">__global__ __var_used__ <span class="keyword">extern</span> <span class="type">void</span> _Z14gpu_vector_addPiS_S_i(<span class="type">int</span> *, <span class="type">int</span> *, <span class="type">int</span> *, <span class="type">int</span>);</span><br><span class="line">__global__ __var_used__ <span class="type">void</span> _Z14gpu_vector_addPiS_S_i(</span><br><span class="line"><span class="type">int</span> *a, </span><br><span class="line"><span class="type">int</span> *b, </span><br><span class="line"><span class="type">int</span> *res, </span><br><span class="line"><span class="type">int</span> n)&#123;</span><br><span class="line">&#123;</span><br><span class="line"> <span class="type">int</span> __cuda_local_var_54379_9_non_const_index;</span><br><span class="line">__cuda_local_var_54379_9_non_const_index = ((<span class="type">int</span>)((threadIdx.x) + ((blockIdx.x) * (blockDim.x))));</span><br><span class="line">(res[__cuda_local_var_54379_9_non_const_index]) = </span><br><span class="line">((a[__cuda_local_var_54379_9_non_const_index]) + (b[__cuda_local_var_54379_9_non_const_index])); </span><br><span class="line">&#125;&#125;</span><br></pre></td></tr></table></figure>
<p>可以看到两者除了变量名、函数名加了一堆前缀之外没有什么区别，而加前缀估计也只是为了方便编译阶段的处理。所以基本只是把我们定义的<code>__global__</code>函数都提取出来了而已。</p>
<p>最后我们稍微解释一下比较特别的<code>_ZN4dim3C1Ejjj</code>和<code>_ZN4dim3C2Ejjj</code>，他们的函数定义如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">__asm__(<span class="string">&quot;.align 2&quot;</span>);</span><br><span class="line">___device__(<span class="type">static</span>  __no_sc__) __inline__ <span class="type">void</span> _ZN4dim3C1Ejjj( </span><br><span class="line">    <span class="keyword">struct</span> dim3 *<span class="type">const</span> <span class="keyword">this</span>, </span><br><span class="line">    <span class="type">unsigned</span> vx, </span><br><span class="line">    <span class="type">unsigned</span> vy, </span><br><span class="line">    <span class="type">unsigned</span> vz)&#123;</span><br><span class="line">    (<span class="keyword">this</span>-&gt;x) = vx;</span><br><span class="line">    (<span class="keyword">this</span>-&gt;y) = vy;</span><br><span class="line">    (<span class="keyword">this</span>-&gt;z) = vz; </span><br><span class="line">&#125;</span><br><span class="line">__asm__(<span class="string">&quot;.align 2&quot;</span>);</span><br><span class="line">___device__(<span class="type">static</span>  __no_sc__) __inline__ <span class="type">void</span> _ZN4dim3C2Ejjj( <span class="keyword">struct</span> dim3 *<span class="type">const</span> <span class="keyword">this</span>,  <span class="type">unsigned</span> __T2,  <span class="type">unsigned</span> __T3,  <span class="type">unsigned</span> __T4)&#123; </span><br><span class="line">    _ZN4dim3C1Ejjj(<span class="keyword">this</span>, __T2, __T3, __T4);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>所以两个函数做的是一件事情，就是初始化dim3结构，我们的<code>add&lt;&lt;&lt;grid,block&gt;&gt;&gt;()</code>涉及到的grid和block就是两个dim3，他们在做赋值操作的时候就可以使用这两个函数，grid用的是第一个<code>_ZN4dim3C1Ejjj</code>，而block用的是第二个<code>_ZN4dim3C2Ejjj</code>。</p>
<h4 id="sample-ptx"><a href="#sample-ptx" class="headerlink" title="sample.ptx"></a>sample.ptx</h4><p>GPU上运行的kernel函数会被编译生成ptx文件，ptx类似于cuda汇编的ir，实际上它的ssa风格就是和C的ir高度一致的。GPU直接运行的指令集被称之为SASS，但是GPU的SASS每一个架构都会有很大的差异，所以如果允许用户直接编写SASS的话，nvidia公司必须维护SASS的兼容能力，因此它没有提供用户编写SASS的结构，而是提供了SASS的上层ir，称之为ptx code。用户可以直接编写ptx code，也可以在kernel中内嵌ptx code进行编程，然后再通过nvidia提供的编译器将ptx编译为sass被GPU执行。所以该文件就是GPU最后的可执行代码的初始形态。</p>
<p>比如说我们经典的<code>gpu_vector_add</code>对应的kernel就被编译为了：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">.visible .entry _Z14gpu_vector_addPiS_S_i(</span><br><span class="line">    .param .u64 _Z14gpu_vector_addPiS_S_i_param_0,</span><br><span class="line">    .param .u64 _Z14gpu_vector_addPiS_S_i_param_1,</span><br><span class="line">    .param .u64 _Z14gpu_vector_addPiS_S_i_param_2,</span><br><span class="line">    .param .u32 _Z14gpu_vector_addPiS_S_i_param_3</span><br><span class="line">    )</span><br><span class="line">&#123;</span><br><span class="line">    .reg .b32 %r&lt;8&gt;;</span><br><span class="line">    .reg .b64 %rd&lt;11&gt;;</span><br><span class="line"></span><br><span class="line">    ld.param.u64 %rd1, [_Z14gpu_vector_addPiS_S_i_param_0];</span><br><span class="line">    ld.param.u64 %rd2, [_Z14gpu_vector_addPiS_S_i_param_1];</span><br><span class="line">    ld.param.u64 %rd3, [_Z14gpu_vector_addPiS_S_i_param_2];</span><br><span class="line">    cvta.to.global.u64 %rd4, %rd3;</span><br><span class="line">    cvta.to.global.u64 %rd5, %rd2;</span><br><span class="line">    cvta.to.global.u64 %rd6, %rd1;</span><br><span class="line">    mov.u32 %r1, %tid.x;</span><br><span class="line">    mov.u32 %r2, %ctaid.x;</span><br><span class="line">    mov.u32 %r3, %ntid.x;</span><br><span class="line">    mad.lo.s32 %r4, %r2, %r3, %r1;</span><br><span class="line">    mul.wide.s32 %rd7, %r4, 4;</span><br><span class="line">    add.s64 %rd8, %rd6, %rd7;</span><br><span class="line">    ld.global.u32 %r5, [%rd8];</span><br><span class="line">    add.s64 %rd9, %rd5, %rd7;</span><br><span class="line">    ld.global.u32 %r6, [%rd9];</span><br><span class="line">    add.s32 %r7, %r6, %r5;</span><br><span class="line">    add.s64 %rd10, %rd4, %rd7;</span><br><span class="line">    st.global.u32 [%rd10], %r7;</span><br><span class="line">    ret;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>对于ptx我没有深入的研究它的语法，和ptx指令的语义，因为这主要就是遵循某种规范而已，比如load操作用ld实现，提供若干种ld格式和修饰，这都是比较平凡的事情，只需要有一个完整的官方文档可以查询即可。</p>
<p>稍微讲一些ptx比较有趣的现象：一开始出现的是函数的声明，我们的4个参数被依次传入，但是当ptx使用这个四个参数的时候使用的是ld指令，而不是直接使用。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">.param .u64 _Z14gpu_vector_addPiS_S_i_param_0,</span><br><span class="line">.param .u64 _Z14gpu_vector_addPiS_S_i_param_1,</span><br><span class="line">.param .u64 _Z14gpu_vector_addPiS_S_i_param_2,</span><br><span class="line">.param .u32 _Z14gpu_vector_addPiS_S_i_param_3</span><br><span class="line"></span><br><span class="line">ld.param.u64 %rd1, [_Z14gpu_vector_addPiS_S_i_param_0];</span><br><span class="line">ld.param.u64 %rd2, [_Z14gpu_vector_addPiS_S_i_param_1];</span><br><span class="line">ld.param.u64 %rd3, [_Z14gpu_vector_addPiS_S_i_param_2];</span><br></pre></td></tr></table></figure>
<p>这是因为在C函数调用的时候，我们可能说把参数传递到寄存器a0-a7当中，然后使用这个几个寄存器就可以直接使用传入的参数了，但是CPU没有办法把它的参数用寄存器传递给GPU。GPU是分配了一段constant memory，当kenerl被运行，参数被传递过来之后，传递的参数会被保存到constant memory对应的位置，然后当我们执行kernel的时候，再从constant memory的方式载入对应的参数即可，反正传入的参数只是值，没有对应的物理内存，不会被改变，当作constant量合情合理。</p>
<p>其次ptx code在这里使用的是SSA的模式，也就是每一个寄存器只会被赋值一次，这样的方法虽然会导致ptx code当中使用的寄存器很多，但是后续SSA分析进行寄存器分配会比较容易，多余的寄存器后续也会被合并掉，此外这里使用了r和rd两套寄存器，将地址和数据分开来处理，便于后续的编译。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">.reg .b32 %r&lt;8&gt;;</span><br><span class="line">.reg .b64 %rd&lt;11&gt;;</span><br></pre></td></tr></table></figure>

<p>最后就是特殊数据的读取，比如threadIdx、blockDim、blockIdx的读取，他们在ptx code阶段被认为保存在特殊的寄存器tid、ntid、ctaid当中，当然编译到SASS之后又会有新的区别，threadIdx、blockIdx每个thread和block是不一样的，它是由真实的寄存器保存的，但是blockDim和gridDim就是一个常数罢了，所以会被分配到constant memory，之后读取constant memory就可以了。此外为什么blockIdx对应的特殊寄存器不叫blockid而是叫ctaid呢，那是因为在硬件层面上这个block的分配又被称之为cooperative thread array，简称CTA，因而得名。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mov.u32 %r1, %tid.x;</span><br><span class="line">mov.u32 %r2, %ctaid.x;</span><br><span class="line">mov.u32 %r3, %ntid.x;</span><br></pre></td></tr></table></figure>

<h4 id="sample-cudafe1-stub-c"><a href="#sample-cudafe1-stub-c" class="headerlink" title="sample.cudafe1.stub.c"></a>sample.cudafe1.stub.c</h4><p>我们之前提到cicc编译得到GPU代码管理的CPU代码、GPU代码调用的CPU代码、GPU可执行的二进制代码的中间形态等三个关键部分，上卖弄的sample.ptx就是GPU可执行的二进制代码的中间形态，而sample.cudafe1.stub.c就是剩下的GPU代码管理的CPU代码、GPU代码调用的CPU代码。</p>
<p>编译命令当中的<code>--include_file_name sample.fatbin.c</code>就是为该文件准备的，这个文件会多一行</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;sample.fatbin.c&quot;</span></span></span><br></pre></td></tr></table></figure>
<p>这个文件是什么，派什么用场，我们后续再解释</p>
<p>对于每一个kernel函数，他都会转变为如下的函数，我们继续以<code>gpu_vector_add</code>为例子：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">extern</span> <span class="type">void</span> __device_stub__Z14gpu_vector_addPiS_S_i(<span class="type">int</span> *, <span class="type">int</span> *, <span class="type">int</span> *, <span class="type">int</span>);</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">gpu_vector_add</span><span class="params">( <span class="type">int</span> *__cuda_0,<span class="type">int</span> *__cuda_1,<span class="type">int</span> *__cuda_2,<span class="type">int</span> __cuda_3)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    __device_stub__Z14gpu_vector_addPiS_S_i( __cuda_0,__cuda_1,__cuda_2,__cuda_3);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> __device_stub__Z14gpu_vector_addPiS_S_i(<span class="type">int</span> *__par0, <span class="type">int</span> *__par1, <span class="type">int</span> *__par2, <span class="type">int</span> __par3)&#123;</span><br><span class="line">    __cudaLaunchPrologue(<span class="number">4</span>);</span><br><span class="line">    __cudaSetupArgSimple(__par0, <span class="number">0UL</span>);</span><br><span class="line">    __cudaSetupArgSimple(__par1, <span class="number">8UL</span>);</span><br><span class="line">    __cudaSetupArgSimple(__par2, <span class="number">16UL</span>);</span><br><span class="line">    __cudaSetupArgSimple(__par3, <span class="number">24UL</span>);</span><br><span class="line">    __cudaLaunch(((<span class="type">char</span> *)((<span class="built_in">void</span> ( *)(<span class="type">int</span> *, <span class="type">int</span> *, <span class="type">int</span> *, <span class="type">int</span>))gpu_vector_add)));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以看到我们的gpu_vector_add只是一个简单的函数跳板，调用gpu_vector_add其实是调用__device_stub__Z14gpu_vector_addPiS_S_i，然后该函数使用__cudaLaunchPrologue声明参数的个数，用__cudaSetupArgSimple传递参数，最后用__cudaLaunch调用对应的kernel函数。更具体的细节，我们在执行流程分析的时候再进一步的展开。</p>
<p>这些就是所谓的CPU调用GPU的函数，不过这里其实也只是一部分，仅仅是被调用方的C代码，被调用方还有另一部分的C代码，我们后面遇到了继续分析。</p>
<p>然后它额外产生了两个重要的函数，这两个函数负责CPU对GPUkernel代码的管理：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">static</span> <span class="type">void</span> __nv_cudaEntityRegisterCallback( <span class="type">void</span> **__T5) &#123;  </span><br><span class="line">    __nv_dummy_param_ref(__T5);</span><br><span class="line">    __nv_save_fatbinhandle_for_managed_rt(__T5);</span><br><span class="line">    __cudaRegisterEntry(__T5, ((<span class="built_in">void</span> ( *)(<span class="type">int</span> *, <span class="type">int</span> *, <span class="type">int</span> *, <span class="type">int</span>, <span class="type">int</span>, <span class="type">int</span>))gpu_matrix_mul), _Z14gpu_matrix_mulPiS_S_iii, (<span class="number">-1</span>));</span><br><span class="line">    __cudaRegisterEntry(__T5, ((<span class="built_in">void</span> ( *)(<span class="type">int</span> *, <span class="type">int</span> *, <span class="type">int</span> *))gpu_matrix_add), _Z14gpu_matrix_addPiS_S_, (<span class="number">-1</span>));</span><br><span class="line">    __cudaRegisterEntry(__T5, ((<span class="built_in">void</span> ( *)(<span class="type">int</span> *, <span class="type">int</span> *, <span class="type">int</span> *, <span class="type">int</span>))gpu_vector_add), _Z14gpu_vector_addPiS_S_i, (<span class="number">-1</span>));</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">static</span> <span class="type">void</span> __sti____cudaRegisterAll(<span class="type">void</span>) &#123;  </span><br><span class="line">    __cudaRegisterBinary(__nv_cudaEntityRegisterCallback);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>第一个__sti____cudaRegisterAll函数进行GPU执行的binary的第一阶段注册，然后调用__nv_cudaEntityRegisterCallback注册每一个kenerl函数的信息。我们稍微展开一下，我们最后肯定是会把GPU的可执行代码编译为一个binary段保存在elf当中的，然后__cudaRegisterBinary首先对这部分的binary做一个管理和注册，然后调用__nv_cudaEntityRegisterCallback。每一个kernel的C代码入口是唯一的，我们将这个唯一的C代码入口地址和bianry中对应的kenerl绑定，然后我们前面调用比如<code>__device_stub__Z14gpu_vector_addPiS_S_i</code>的时候，它的<code>__cudaLaunch(gpu_vector_add)</code>就可以根据gpu_vector_add找到对应的kernel结构，然后调用让gpu调用这个kernel。</p>
<h3 id="步骤三"><a href="#步骤三" class="headerlink" title="步骤三"></a>步骤三</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ptxas sample.ptx  -o sample.sm_52.cubin</span><br></pre></td></tr></table></figure>
<p>我们把sample.ptx编译为sample.sm_52.cubin，这个cubin就是所谓的GPU运行的binary，里面有text对应的SASS，还有对应的其他数据之类的信息，cubin也是一个elf格式组织的文件，只不过里面的段和C的不一样而已。sm_52是因为每一种GPU的架构是不一样的，我们称之为权能，也可以理解为GPU的架构编号，sm_52就是权能为5.2的GPU的可以直接执行的SASS，换言之这个cubin只有支持权能5.2的GPU才可以运行。5.2由major版本号5和minor版本号2组成，每个不同的nvidia系列一般是一个全新的major，系列内部的minor有差异，对于SASS指令集和微架构，同一个major内部差不多，但是major之间会大相径庭。</p>
<p>我们可以用cuobjdump观察sample.cm_52.cubin内部的结构，内部的段比如如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">64bit elf: type=2, abi=7, sm=52, toolkit=115, flags = 0x340534</span><br><span class="line">Sections:</span><br><span class="line">Index Offset   Size ES Align        Type        Flags Link     Info Name</span><br><span class="line">    1     40    1f5  0  1            STRTAB       0    0        0 .shstrtab</span><br><span class="line">    2    235    24b  0  1            STRTAB       0    0        0 .strtab</span><br><span class="line">    3    480    108 18  8            SYMTAB       0    2        8 .symtab</span><br><span class="line">    4    588     90  0  4         CUDA_INFO       0    3        0 .nv.info</span><br><span class="line">    5    618     a4  0  4         CUDA_INFO       0    3        c .nv.info._Z14gpu_matrix_mulPiS_S_iii</span><br><span class="line">    6    6bc     68  0  4         CUDA_INFO       0    3        d .nv.info._Z14gpu_matrix_addPiS_S_</span><br><span class="line">    7    724     74  0  4         CUDA_INFO       0    3        e .nv.info._Z14gpu_vector_addPiS_S_i</span><br><span class="line">    8    798     d8  8  8    CUDA_RELOCINFO       0    0        0 .nv.rel.action</span><br><span class="line">    9    870    164  0  4          PROGBITS       2    0        c .nv.constant0._Z14gpu_matrix_mulPiS_S_iii</span><br><span class="line">    a    9d4    158  0  4          PROGBITS       2    0        d .nv.constant0._Z14gpu_matrix_addPiS_S_</span><br><span class="line">    b    b2c    15c  0  4          PROGBITS       2    0        e .nv.constant0._Z14gpu_vector_addPiS_S_i</span><br><span class="line">    c    ca0    e40  0 20          PROGBITS       6    3 1c000008 .text._Z14gpu_matrix_mulPiS_S_iii</span><br><span class="line">    d   1ae0    140  0 20          PROGBITS       6    3  8000009 .text._Z14gpu_matrix_addPiS_S_</span><br><span class="line">    e   1c20    100  0 20          PROGBITS       6    3  800000a .text._Z14gpu_vector_addPiS_S_i</span><br></pre></td></tr></table></figure>
<p>可以看到每一个kernel都有自己对应的.nv.constant0段、.text段、.nv.info段，constant段是kernel需要的constant memory空间的内容，一般都是0，需要后期载入kernel的时候再填充，.text段就是对应的SASS，.nv.info是一些段的信息，比如传入参数的信息、堆栈的信息等，估计__sti____cudaRegisterAll会充分解释这部分的信息，之后constant的填充、参数的传递等也离不开.nv.info的指导。</p>
<h3 id="步骤四"><a href="#步骤四" class="headerlink" title="步骤四"></a>步骤四</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">fatbinary --image3=kind=elf,sm=52,file=sample.sm_52.cubin </span><br><span class="line">    --image3=kind=ptx,sm=52,file=sample.ptx </span><br><span class="line">    --embedded-fatbin=sample.fatbin.c</span><br></pre></td></tr></table></figure>
<p>该操作负责将sample.ptx和sample.sm_52.cubin打包生成一个sample.fatbin.c文件，得到的内容基本如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#define __CUDAFATBINSECTION  &quot;.nvFatBinSegment&quot;</span><br><span class="line">#define __CUDAFATBINDATASECTION  &quot;.nv_fatbin&quot;</span><br><span class="line">asm(</span><br><span class="line">&quot;.section .nv_fatbin, \&quot;a\&quot;\n&quot;</span><br><span class="line">&quot;.align 8\n&quot;</span><br><span class="line">&quot;fatbinData:\n&quot;</span><br><span class="line">&quot;.quad 0x00100001ba55ed50,0x0000000000002770,0x0000004001010002,0x00000000000020e0\n&quot;</span><br><span class="line">&quot;.quad 0x0000000000000000,0x0000003400010007,0x0000000000000000,0x0000000000000011\n&quot;</span><br><span class="line">........</span><br><span class="line">&quot;.quad 0x381901e9381a0223,0x38d00115371701e9,0x0a0a3b7465720a3a,0x00000000000a0a7d\n&quot;</span><br><span class="line">&quot;.text\n&quot;);</span><br><span class="line">extern const unsigned long long fatbinData[1264];</span><br><span class="line">static const __fatBinC_Wrapper_t __fatDeviceText __attribute__ ((aligned (8))) __attribute__ ((section (__CUDAFATBINSECTION)))= &#123; 0x466243b1, 1, fatbinData, 0 &#125;;</span><br></pre></td></tr></table></figure>
<p>其中定义了一个.nv_fatbin段，里面的内容就是原封不动的cubin和压缩之后的ptx，所以我们的.nv_fatbin就是我们GPU的可执行程序部分，这个段现在大小就是<code>unsigned long long fatbinData[1264]</code>的大小，所以访问fatbinDatat其实就是访问这个段。那为什么要包含SASS和ptx两部分呢？主要是因为不同的权能的GPU，它们的SASS不一样，如果他们执行的时候发现SASS不一样，那么就可以额外的执行cudalib的jit功能，将ptx重新编译为对应版本的SASS运行，从而提高了代码的可移植性和兼容性。</p>
<p>之后定义了.nvFatBinSegment段，这个段的数据结构被定义在”fatbinary_section.h”当中，</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> &#123;</span><br><span class="line">  <span class="type">int</span> magic;</span><br><span class="line">  <span class="type">int</span> version;</span><br><span class="line">  <span class="type">const</span> <span class="type">unsigned</span> <span class="type">long</span> <span class="type">long</span>* data;</span><br><span class="line">  <span class="type">void</span> *filename_or_fatbins;  <span class="comment">/* version 1: offline filename,</span></span><br><span class="line"><span class="comment">                               * version 2: array of prelinked fatbins */</span></span><br><span class="line">&#125; __fatBinC_Wrapper_t;</span><br></pre></td></tr></table></figure>
<p>第一个4字节的0x466243b1是一个魔数，没什么意义；第二个自己是版本，指示filename_or_fatbins的内容，第三个data就是fatbinData数组的地址；最后一个就是filename_or_fatbins的地址，可以看到可以指向一个文件名字符串，说明fatbin在这个文件中，也可以指向一个prelinked fatbins中，说明那个数组当中有一堆需要额外运行的fatbin。</p>
<p>所以nvFatBinSegemnt就是对.nv_fatbin的描述，对于这个.nv_fatbin段，nvFatBinSegment指出他的位置，且没有额外的file或者prelinked fatbins的依赖。</p>
<p>我们之前说了在sample.cudafe1.stub.c中include了sample.fatbin.c，所以我们的sample.cudafe1.stub.c就包含了这两个段，至此只要后续的代码include了我们的sample.cudafe1.stub.c，就包含了GPU代码管理的CPU代码、GPU代码调用的CPU代码、GPU可执行的二进制代码这GPU相关的三个关键部分。</p>
<h3 id="步骤5"><a href="#步骤5" class="headerlink" title="步骤5"></a>步骤5</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">gcc sample.cu -o sample.cpp4.ii</span><br></pre></td></tr></table></figure>
<p>和步骤1一样再次产生一个预编译处理文件，不同的地方在于编译的选项有所不同，所以最后的结果有所差异，估计关系不大</p>
<h3 id="步骤6"><a href="#步骤6" class="headerlink" title="步骤6"></a>步骤6</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cudafe++ --gen_c_file_name sample.cudafe1.cpp </span><br><span class="line">    --stub_file_name sample.cudafe1.stub.c </span><br><span class="line">    --module_id_file_name sample.module_id </span><br><span class="line">    sample.cpp4.ii</span><br></pre></td></tr></table></figure>
<p>生成sample.cudafe1.cpp文件，该文件include了之前的sample.stub.c，因此已经包含了GPU部分的代码，余下的cpp本身的代码就是在处理CPU部分的代码，生成的代码就是预处理之后大量的声明、定义等等，比较特别的是，所有GPU相关的代码被<code>#if 0 #endif</code>注释掉了，然后诸如<code>add&lt;&lt;&lt;grid,block&gt;&gt;&gt;(res,a,b,n)</code>被替换为了</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">(__cudaPushCallConfiguration(grid, block)) ? (<span class="type">void</span>)<span class="number">0</span> : <span class="built_in">add</span>(res,a,b,n); </span><br></pre></td></tr></table></figure>
<p>至此我们的cuda代码就正式变为了简单的C++代码，这部分的语法糖的修改就是完成了CPU调用GPU函数的调用方处的代码操作。</p>
<h3 id="步骤7"><a href="#步骤7" class="headerlink" title="步骤7"></a>步骤7</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">gcc sample.cudafe1.cpp -o sample.o</span><br></pre></td></tr></table></figure>
<p>编译得到.o文件，我们编写的所有代码，包括基本的CPU代码，CPU管理fatbin的代码，CPU调用GPU的代码、GPU执行的代码都在这里了。</p>
<h3 id="步骤8"><a href="#步骤8" class="headerlink" title="步骤8"></a>步骤8</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nvlink --register-link-binaries=sample_dlink.reg.c </span><br><span class="line">    sample.o -o sample_dlink.sm_52.cubin</span><br></pre></td></tr></table></figure>
<p>生成sample_dlink.reg.c，貌似没什么用；生成sample_dlink.sm_52.cubin，这是从原来的sample.o中抽离出来的，这部分cubin只包含简单的SASS，至于为什么要多此一举，并不是很清楚。</p>
<h3 id="步骤9"><a href="#步骤9" class="headerlink" title="步骤9"></a>步骤9</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">fatbinary -link </span><br><span class="line">    --image3=kind=elf,sm=52,file=sample_dlink.sm_52.cubin </span><br><span class="line">    --embedded-fatbin=sample_dlink.fatbin.c</span><br></pre></td></tr></table></figure>
<p>将sample_dlink.sm_52.cubin生成sample_dlink.fatbin.c，该文件和之前的sample_dlink.fatbin.c差不多，但是它及不包含SASS，也不包含ptx，所以fatbinData更小，这部分也是被定义在.nv_fatbin中，它的nvFatBinSegment段则是如下的：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">static const __fatBinC_Wrapper_t __fatDeviceText __attribute__ ((aligned (8))) __attribute__ ((section (__CUDAFATBINSECTION)))= </span><br><span class="line">	&#123; 0x466243b1, 2, fatbinData, (void**)__cudaPrelinkedFatbins &#125;;</span><br></pre></td></tr></table></figure>
<p>可以看到这个段并不是我们自己的kernel的nv_fatbin，而是用来表述__cudaPrelinkedFatbins当中的fatbin的，估计是GPU运行需要一些cuda另外预先编译好的SASS才可以运行，所以需要这个段作为跳板来链接这些内容。</p>
<p>最后sample_dlink.fatbin.c和sample.fatbin.c的内容都会被整合到.nv_fatbin和.nvFatBinSegment当中来。比如.nvFatBinSegment的内容如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Hex dump of section &#x27;.nvFatBinSegment&#x27;:</span><br><span class="line">  0x000a9058 b1436246 02000000 f08e0800 00000000 .CbF............</span><br><span class="line">  0x000a9068 e0910a00 00000000 b1436246 01000000 .........CbF....</span><br><span class="line">  0x000a9078 50920800 00000000 00000000 00000000 P...............</span><br></pre></td></tr></table></figure>
<p>前面24个字节就是sample_dlink.fatbin.c的nvFatBinSegment的内容，后面24个字节就是sample.fatbin.c的内容。</p>
<h3 id="步骤10"><a href="#步骤10" class="headerlink" title="步骤10"></a>步骤10</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">gcc -DFATBINFILE=sample_dlink.fatbin.c </span><br><span class="line">    -DREGISTERLINKBINARYFILE=sample_dlink.reg.c </span><br><span class="line">    -m64 /usr/lib/nvidia-cuda-toolkit/bin/crt/link.stub </span><br><span class="line">    -o sample_dlink.o</span><br></pre></td></tr></table></figure>
<p>将sample_dlink.fatbin.c编译为sample_dlink.o</p>
<h3 id="步骤11"><a href="#步骤11" class="headerlink" title="步骤11"></a>步骤11</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">g++ sample_dlink.o sample.o -lcudart_static -o sample</span><br></pre></td></tr></table></figure>
<p>然后把.o都链接得到最后的sample，这个时候需要一个-lcudart_static，他会把所有的cudalib静态链接到sample当中，则会也就是sample当中那么多的cudart的由来，但是虽然汇编都是有的，却没有其他任何lib信息，很难看懂。</p>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>所以我们可以得到最后编译的流程如下：<br><img src="https://zhuzhuzaiimgbed.oss-cn-hangzhou.aliyuncs.com/img/compile.jpg" alt="编译流程图"><br>右侧分支的<code>.cu-&gt;.cpp1.ii-&gt;.ptx-&gt;.cubin-&gt;.fatbin.c-&gt;cudafe1.stub.c</code>产生GPU的执行代码，和CPU管理和调用GPU的代码；左侧分支的<code>.cu-&gt;.cpp4.ii-&gt;.cudafe1.cpp-&gt;.o</code>得到CPU自身执行的代码，并包含GPU执行的部分；下方的<code>.o-&gt;_dlink.cubin-&gt;_dlink.fatbin.c-&gt;.o</code>得到prelink_fatbin相关的GPU代码；最后所有的.o链接得到最后的.exe文件。</p>
<h2 id="cuda程序的执行过程"><a href="#cuda程序的执行过程" class="headerlink" title="cuda程序的执行过程"></a>cuda程序的执行过程</h2><p>cuda、nvidia本身的资料非常有限，所以下面的分析基于一些零碎的资料+cuda的代码和个人的推测，同时因为amd的代码和cuda的有高度的对称性，也从那里获得了一些灵感，所以仅仅放在这里为其他研究cuda的朋友提供参考。</p>
<h3 id="初始化部分"><a href="#初始化部分" class="headerlink" title="初始化部分"></a>初始化部分</h3><p>首先elf运行的时候先是常规的启动过程，然后进入<code>dl_init</code>函数，该函数会遍历elf当中<code>.init_array</code>数组当中的每一个init函数，来初始化我们的程序。cuda的<code>.init_array</code>至少包含5个初始化函数。</p>
<h4 id="cudart412"><a href="#cudart412" class="headerlink" title="__cudart412"></a>__cudart412</h4><p><code>__cudart412-&gt;__cudart1594-&gt;pthread_once</code><br>这是第一个初始化函数的执行流程，因为是cuda的user runtime是闭源的，所以没有办法直接查到对应的资料，但他一定是在做cuda相关的初始化操作。</p>
<p>当一个cuda的process在运行的时候，GPU driver会为这个进程产生一个对应的context，此外因为CPU和GPU是异步工作的，当有一个线程在运行CPU的时候还需要另一个线程运行GPU，所以很有可能这个函数进行了context的初始化，并且进行了面向GPU driver线程的创建。这里仅做猜测。</p>
<h4 id="frame-dummy"><a href="#frame-dummy" class="headerlink" title="frame_dummy"></a>frame_dummy</h4><p>这个是C本身就会自带的唯一一个<code>init_array</code>的函数，基本上什么都不做。</p>
<h4 id="sti-cudaRegisterAllv"><a href="#sti-cudaRegisterAllv" class="headerlink" title="__sti____cudaRegisterAllv"></a>__sti____cudaRegisterAllv</h4><p>这个就是我们之前在sample.cudafe1.stub.c当中产生的函数，负责nv_fatbin的信息管理和kernel函数CPU调用的管理，这部分AMD有充分的源代码，我们笼统的看一下。</p>
<p>对于<code>__sti____cudaRegisterAllv</code>其中的内容如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">static</span> <span class="type">void</span> __sti____cudaRegisterAll(<span class="type">void</span>) &#123;  </span><br><span class="line">    __cudaRegisterBinary(__nv_cudaEntityRegisterCallback);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其实这些都是被定义在crt&#x2F;host_runtime.h中的宏，我们把宏展开，最后得到的结果如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">static</span> <span class="type">void</span> __sti____cudaRegisterAll(<span class="type">void</span>) &#123;</span><br><span class="line">    __cudaFatCubinHandle = __cudaRegisterFatBinary  ((<span class="type">void</span>*)&amp;__fatDeviceText);</span><br><span class="line">    <span class="built_in">void</span> (*callback_fp)(<span class="type">void</span> **) =  (<span class="built_in">void</span> (*)(<span class="type">void</span> **))(__nv_cudaEntityRegisterCallback); </span><br><span class="line">    (*callback_fp)(__cudaFatCubinHandle);</span><br><span class="line">    __cudaRegisterFatBinaryEnd(__cudaFatCubinHandle);</span><br><span class="line">    <span class="built_in">atexit</span>(__cudaUnregisterBinaryUtil);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>首先调用__cudaRegisterFatBinary函数，该函数会对nv_fatbin进行处理，将里面的信息保存到特定的数据结构当中，然后返回数据结构的handler。之后调用__nv_cudaEntityRegisterCallback，对handler继续做后续的注册管理工作。结束之后调用__cudaRegisterFatBinaryEnd做下一阶段的收尾处理。最后因为程序退出之后需要对bianry再做一些操作，所以把处理函数__cudaUnregisterBinaryUtil函数注册到atexit中，来做register的逆操作unregister。</p>
<p>对于<code>__nv_cudaEntityRegisterCallback</code>，他也是有一系列的宏组成的，我们把宏展开得到如下的内容：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">static</span> <span class="type">void</span> __nv_cudaEntityRegisterCallback( <span class="type">void</span> **handle)&#123;</span><br><span class="line">    <span class="keyword">volatile</span> <span class="type">static</span> <span class="type">void</span> **__ref __attribute__((unused));</span><br><span class="line">    __ref = (<span class="keyword">volatile</span> <span class="type">void</span> **)handle;</span><br><span class="line">    __nv_save_fatbinhandle_for_managed_rt(handle);</span><br><span class="line">    __cudaRegisterFunction(handle, (<span class="type">const</span> <span class="type">char</span>*)funptr, <span class="meta">#func, #fun, -1, (uint3*)0, (uint3*)0, (dim3*)0, (dim3*)0, (int*)0);</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>该函数首先把handle读到一个变量里面，不知道为什么要这么做。然后调用__nv_save_fatbinhandle_for_managed_rt处理handler。之后对于每一个kernel函数的CPU调用入口，我们用__cudaRegisterFunction注册这个调用入口地址和对应的GPU的SASS的关系。</p>
<h4 id="GLOBAL-sub-I-Zn7Compute11rand-memoryFPii"><a href="#GLOBAL-sub-I-Zn7Compute11rand-memoryFPii" class="headerlink" title="__GLOBAL_sub_I_Zn7Compute11rand_memoryFPii"></a>__GLOBAL_sub_I_Zn7Compute11rand_memoryFPii</h4><p>该函数调用<code>static_initialization_and_destruction</code>进行全局变量的构造函数，并注册对应的析构函数，所以和cuda没关系，是C++本身自带的函数。</p>
<h4 id="cudart424"><a href="#cudart424" class="headerlink" title="__cudart424"></a>__cudart424</h4><p>仅作纯粹的ALU计算，似乎没什么用</p>
<h4 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h4><p>初始化函数都运行完之后，程序就继续返回dl_main，然后进行动态连接和进入main函数，就和正常的C程序一样。所以初始化部分，cuda应该完成了context的建立、面向GPU driver的线程的建立、nv_fatbin信息的管理、CPU到GPU的符号注册等。</p>
<h3 id="cuda-API的调用"><a href="#cuda-API的调用" class="headerlink" title="cuda API的调用"></a>cuda API的调用</h3><p>cuda API的调用都是直接call函数即可，因为cuda做的事静态链接，所以直接跳到某一个__cudartxxxx函数当中，然后反复调用各种__cudartxxxx。虽然cuda的runtime做了静态链接，但是并不是全部的runtime代码都在这里了，实际上这部分runtime有可能调用外部cudalib.so的内容，哪怕elf没有对这个文件有动态连接的指示。</p>
<p>此外在第一次调用例如cudaMalloc函数的时候会发现这个函数执行的时间会比以后调用该函数的函数长很多，而且当且仅当这一次，程序会访问fatbin段。当然不排除别的地方我没注意到。之后阅读论文的时候发现，程序在一开始会进行一次数据传输，把cuda的GPU代码以数据的形式传输到GPU上，之后如果要执行这个GPU代码，仅仅只需要向GPU发送参数和命令即可，无需再次传输GPU的text段等信息。所以这一次malloc非常慢应该是因为内部执行的时候，第一次执行cuda API，检查某些cuda环境的时候触发了对应的机制，于是被传输过去了。例如说cudaMalloc需要修改页表，但是因为nvfatbin还没有传过去，对面的GPU没有为这个context分配页表，于是报错说页表不存在什么的，然后这里就知道nvfatbin还没传过去，就传过去了。</p>
<h3 id="kenerl调用"><a href="#kenerl调用" class="headerlink" title="kenerl调用"></a>kenerl调用</h3><p>让我们看看调用简单的<code>gpu_vector_add</code>会发生什么。</p>
<p>在一开始的sample.cu中，kernel函数的调用语法是：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">gpu&lt;&lt;&lt;grid,block,sharedmem,stream&gt;&gt;&gt;(res,a,b,n);</span><br></pre></td></tr></table></figure>
<p>这里的sharedmem和stream之前一直都是缺省的，那么后续就会默认这两个参数的值是0，就好像grid和block如果输入的不是dim3的结构而是简单的int数据的话，就会自动转换为dim3，只不过x、y、z中剩下的两个参数的值是1罢了。</p>
<p>然后经过了编译时期的步骤6，在sample.cudafe1.cpp当中这句语法糖被转换为了：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">(__cudaPushCallConfiguration(grid, block, sharedmem, stream)) ? (<span class="type">void</span>)<span class="number">0</span> : <span class="built_in">gpu_vector_add</span>(res,a,b,n); </span><br></pre></td></tr></table></figure>
<p>首先运行__cudaPushCallConfiguration函数，这个函数将4个参数传递到kernel函数调用的configuration堆栈当中，如果这个操作报错了，那么就不会进行后续的操作，不然的话就会调用gpu_vector_add函数开始执行。这里会用到我们在sample.gpu中提到的<code>_ZN4dim3C1Ejjj</code>和<code>_ZN4dim3C2Ejjj</code>，这里的4个参数是首先压入堆栈，然后才调用__cudaPushCallConfiguration函数的，而grid和block复制到堆栈的传参区域就是用这两个函数复制过去的。</p>
<p>然后执行gpu_vector_add函数，该函数在之前的sample.cudafe1.stub.c当中定义，它的内容是：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">gpu_vector_add</span><span class="params">( <span class="type">int</span> *__cuda_0,<span class="type">int</span> *__cuda_1,<span class="type">int</span> *__cuda_2,<span class="type">int</span> __cuda_3)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    __device_stub__Z14gpu_vector_addPiS_S_i( __cuda_0,__cuda_1,__cuda_2,__cuda_3);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>于是使用这个函数为跳板调用了__device_stub__Z14gpu_vector_addPiS_S_i函数，如下。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">void</span> __device_stub__Z14gpu_vector_addPiS_S_i(<span class="type">int</span> *__par0, <span class="type">int</span> *__par1, <span class="type">int</span> *__par2, <span class="type">int</span> __par3)&#123;</span><br><span class="line">    __cudaLaunchPrologue(<span class="number">4</span>);</span><br><span class="line">    __cudaSetupArgSimple(__par0, <span class="number">0UL</span>);</span><br><span class="line">    __cudaSetupArgSimple(__par1, <span class="number">8UL</span>);</span><br><span class="line">    __cudaSetupArgSimple(__par2, <span class="number">16UL</span>);</span><br><span class="line">    __cudaSetupArgSimple(__par3, <span class="number">24UL</span>);</span><br><span class="line">    __cudaLaunch(((<span class="type">char</span> *)((<span class="built_in">void</span> ( *)(<span class="type">int</span> *, <span class="type">int</span> *, <span class="type">int</span> *, <span class="type">int</span>))gpu_vector_add)));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里面的函数全部都是宏，也全部都定义在那个crt&#x2F;host_runtime.h中，展开来的结果如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">void</span> __device_stub__Z14gpu_vector_addPiS_S_i(<span class="type">int</span> *__par0, <span class="type">int</span> *__par1, <span class="type">int</span> *__par2, <span class="type">int</span> __par3)&#123;</span><br><span class="line">    <span class="type">void</span> * __args_arr[<span class="number">3</span>];</span><br><span class="line">    <span class="type">int</span> __args_idx = <span class="number">0</span>;</span><br><span class="line">    __args_arr[__args_idx] = (<span class="type">void</span> *)(<span class="type">char</span> *)&amp;par0;++__args_idx;</span><br><span class="line">    __args_arr[__args_idx] = (<span class="type">void</span> *)(<span class="type">char</span> *)&amp;par1;++__args_idx;</span><br><span class="line">    __args_arr[__args_idx] = (<span class="type">void</span> *)(<span class="type">char</span> *)&amp;par2;++__args_idx;</span><br><span class="line">    __args_arr[__args_idx] = (<span class="type">void</span> *)(<span class="type">char</span> *)&amp;par3;++__args_idx;</span><br><span class="line">    <span class="keyword">volatile</span> <span class="type">static</span> <span class="type">char</span> *__f __NV_ATTR_UNUSED_FOR_LAUNCH;</span><br><span class="line">    __f = fun;</span><br><span class="line">    dim3 __gridDim, __blockDim;</span><br><span class="line">    <span class="type">size_t</span> __sharedMem;</span><br><span class="line">    cudaStream_t __stream;</span><br><span class="line">    <span class="keyword">if</span>(__cudaPopCallConfiguration(&amp;__gridDim, &amp;__blockDim, &amp;__sharedMem, &amp;__stream) != cudaSuccess)</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    <span class="keyword">if</span> (__args_idx == <span class="number">0</span>) &#123;</span><br><span class="line">        (<span class="type">void</span>)<span class="built_in">cudaLaunchKernel</span>(fun, __gridDim, __blockDim, &amp;__args_arr[__args_idx], __sharedMem, __stream);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        (<span class="type">void</span>)<span class="built_in">cudaLaunchKernel</span>(fun, __gridDim, __blockDim, &amp;__args_arr[<span class="number">0</span>], __sharedMem, __stream);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>首先定义一个参数指针数组，然后把每一个参数的地址保存到这个arg数组当中，然后用__cudaPopCallConfiguration将之前push的4个参数保存到grid、block、sharedmem、stream四个参数中。如果pop正确可以继续执行，然后调用cudaLaunchKernel正式执行这个kernel，这里的参数就是CPU调用地址fun、4个kernel配置参数和arg数组。</p>
<p>所以复杂的kernel函数调用如果我们不去考虑那个<code>&lt;&lt;&lt;&gt;&gt;&gt;</code>的语法糖的话，直接使用C++的api执行就是如下的：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">void</span> *args_arr[<span class="number">3</span>]=&#123;&amp;arg0,&amp;arg1,&amp;arg2,&amp;arg3&#125;;</span><br><span class="line"><span class="built_in">cudaLaunchKernel</span>(gpu_vector_add,gridDim,blockDim,&amp;args_arr[<span class="number">3</span>],sharedMem,stream);</span><br></pre></td></tr></table></figure>
<p>变得如此简短。现为我们之前init注册的时候，将gpu_vector_add函数指针和字符串”__device_stub__Z14gpu_vector_addPiS_S_i”一起传入了__cudaFunctionRegister，因为在nvfatbin中可以用字符串”__device_stub__Z14gpu_vector_addPiS_S_i”找到对应的kernel的段，所以这些段的信息可以和函数指针gpu_vector_add绑定，因此调用cudaKernelLaunch的时候就可以根据函数指针找到对应的.nv.info，然后kernel的配置参数也有了，函数的参数也有了，后续的运行就可以齐全了。cudaLaunchKernel会向GPU发送需要执行的kernel的地址、参数、配置等命令包，然后GPU就会把显存中对应的kernel载入，设置线程，开始运行，运行完毕后返回运行结果等。</p>
<h4 id="stream和graph"><a href="#stream和graph" class="headerlink" title="stream和graph"></a>stream和graph</h4><p>我们进一步考量cudaKernelLaunch是如何工作的，这部分nvidia没有开源，网上也没有资料，所以参考的是AMD的源代码，但是我认为背后的肌理可能非常相似。首先引入两个概念stream和graph。每个process可以有多个stream，在运行kernel的时候可以指定执行这个kernel的stream，然后这个kernel就会到对应stream当中去排队等待执行。stream确保同一个stream中的流顺序执行，如果用户认为自己的两个kernel没有数据依赖，可以同时执行，那么可以用两个stream分别执行两个kernel，就可能会被GPU driver同时执行。而同一个stream的kernel除非显示声明，不然是依次执行的，所以对于有数据依赖的程序，比如A kernel的输出是B kernel得输入，那不如一个stream执行。一般调用kernel的时候如果不指定stream，那就是用默认的0号stream执行。</p>
<p>对于同一个stream中的kernel也是可以显式声明并行的，比如在kenerl1中插入<code>cudaTriggerProgrammaticLaunchCompletion();</code>那么当所有的kernel1执行完这个函数之后，第二个kernel2就会开始运行，这样如果kernel1的前半部分和kernel2有依赖，就可以用该函数来让kernel1的后半部分和kernel2并行。此外如果kernel2的后半部分会和kernel1发生冲突，那么可以在kernel2中插入<code>cudaGridDependencySynchronize();</code>这样的话，kernel2的所有线程运行到这个函数就会停顿直到kernel1运行完毕为止。所以对于下面的kernel：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">__global__ <span class="title">kernel1</span><span class="params">()</span></span>&#123;</span><br><span class="line">    partA;</span><br><span class="line">    <span class="built_in">cudaTriggerProgrammaticLaunchCompletion</span>();</span><br><span class="line">    partB;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function">__global__ <span class="title">kernel2</span><span class="params">()</span></span>&#123;</span><br><span class="line">    partC;</span><br><span class="line">    <span class="built_in">cudaGridDependencySynchronize</span>();</span><br><span class="line">    partD;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    kernel1&lt;&lt;&lt;grid,block,<span class="number">0</span>,stream&gt;&gt;&gt;();</span><br><span class="line">    kernel2&lt;&lt;&lt;grid,block,<span class="number">0</span>,stream&gt;&gt;&gt;();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这样的话partA先执行，然后触发<code>cudaTriggerProgrammaticLaunchCompletion</code>，partB和partC开始执行，然后触发<code>cudaGridDependencySynchronize</code>，在partB和partC都执行完之后partD开始执行。</p>
<p>不过尽管如此，这种并行语法还是很弱的，它只能使第一个和第二个顺序的kernel指定可以重叠运行的有且仅有一个部分，如果有多个子部分可以重叠运行，那么就会很困难，必须要把大kernel拆成一对小的，或者依靠比如global memory做同步之类的操作，反正很不方便。当然介于这种情况在流处理任务中不多见，所以不需要将太多精力放在这上面。</p>
<p>对于复杂的依赖性任务，我们可以用graph的形式表示。对于每一个kernel任务或者内存memcpy任务，我们为他们构造对应的graphnode，传入对应的参数，然后将有依赖的任务绘制一下有向边，然后我们让stream去执行这个graph，stream就会根据拓扑排序的顺序执行这个graph，让没有以来的任务被充分并行起来。相对于stream简单的串行或者前后两个kenrel重叠，这种graph结构表达能力更强，理解起来也很直观。</p>
<p>好了我们回过头来继续聊cudaLaunchKernel之后发生了什么。这里我们参考的是hipLaucnhKernel的代码，该函数会调用capturehipLaunchKernel函数，这个函数会检查参数是否正确，然后给自己的stream加一个锁，然后构造一个graphnode，将函数名、配置参数、输入参数存储到graphnode当中。所以对于一个stream而言，它运行的所有kernel最后都会变为一个graphnode，然后对于前面运行的kernel的每一个graphnode都和新的graphnode加一条依赖边，这样形成新的graph，除非前面的kernel都执行完毕，不然后面的kernel不会执行。所以stream的底层还是一张graph，构造图完毕后去掉之前的锁。然后函数返回。</p>
<p>kernel在GPU的执行和CPU是异步的，每一次kernel调用CPU只是把新的graphnode加入stream的node当中，所以另外存在一个线程会在GPU可以接受新的kernel的时候从graph中拿出一个新的节点，然后交给GPU执行，这也就是为什么之前猜测会构造新的线程的原因了，但是调试指出，这里的线程不止一个，有6-8个，可能各自有各自的用处。</p>
<p>因此kernel的执行和CPU的执行是异步的，所以当kernel还没运行完的时候访问GPU关联的内存其实是不安全的。有以下几种情况，比如我用cudaMemcpy拷贝kernel正在使用的GPU内存，这是安全的，因为cudaMemcpy会自动等关联的kernel结束工作才开始传输；如果GPU关联的是cudaMallocHost的CPU的内存，那么这个时候如果kernel没有运行结束会发生段错误，所以需要在访问以前执行一条比如cudaDeviceSynchrone的同步指令，等待kernel运行完毕才可以。</p>
<p>至此软件部分告一段落了。</p>
<h2 id="GPU的硬件执行"><a href="#GPU的硬件执行" class="headerlink" title="GPU的硬件执行"></a>GPU的硬件执行</h2><p>GPU是一个pcie设备，soc用MMIO的方式映射GPU的内存空间。soc对于GPU的内存空间映射分为两块，第一块是GPU的寄存器组，第二块是GPU的显存，可以看到前者主要负责控制信号的传递，后者主要负责数据的传递。此外GPU上是有一个小型的操作系统在运行的，类似于CPU的操作系统那种，可以处理一些调度、通信、内存管理之类的东西，毕竟靠GPU的流处理器做这些事效率很低，而且无法并行，不过nvidia的官方文档没有说他叫什么，所以我们不妨暂时称他为GPUos吧。资料很不全面，我尽量猜测对应的细节，其他跨度较大的阶段只能勉强看看了；此外在这里我并不会事先介绍所有的硬件，我只在必须介绍他们的时候引入，以免在一开始就考虑过多的可以被认为是透明的硬件细节。</p>
<h3 id="context创建和task运行"><a href="#context创建和task运行" class="headerlink" title="context创建和task运行"></a>context创建和task运行</h3><p>每当有一个CPU process在GPU上工作的时候，GPU os就会产生对应的一个context与之相对应，用来管理CPU process在GPU上的任务，这个context也包含了自己的页表，用来管理自己的虚拟地址空间。每一个GPU context都有自己对应的页表和虚拟地址空间，相互之间隔离开来。此外GPU os也给每一个context的task提供了时间片，这样多个context的task同时运行的时候就可以根据时间片进行任务的切换，进而进行GPU的multi-task。context的TCB和page table有可能是直接分配在global memory上的，当CPU用各种函数向GPU请求内存和注册内存的时候，页表都要进行对应的修改，有的页表映射到GPU的物理内存上，有的映射到CPU的物理内存上；GPU的操作系统有自己的进程调度机制、自己的内存管理机制、自己的缺页异常处理机制等一些列和CPU对标的任务，这些任务很多时候是不需要GPU高并行度流式处理的特性的，所以用简单的类似CPU的处理器就可以了，GPU每个task的thread有几万个甚至几十万个，但是GPU的task是比较少的，调度压力远小于Host的CPU。</p>
<p>当CPU的一个cuda程序开始执行的时候，他首先向GPU发送一个数据包，是GPU所有的nv_fatbin数据，这些数据可能包含了很多的kernel，并为这些kernel准备合适的页表。如果用cuda API分配内存、注册内存、释放内存，就填写对应的页表进行配置。然后之后CPU调用某一个kernel的时候，再发送一个命令包，包含要执行的kernel的地址、参数等信息，然后GPU才从nvfatbin中launch这个kernel，将text载入对应的地址、constant载入对应的constant memory、配置好对应的页表，然后初始化必要的block和thread，然后开始将block调度到对应的SM上去。这部分有疑问可以参看前面SIMT章节。</p>
<p>如果这些值都是依次初始化的那么其实对于比较小的任务，初始化的代价就会非常巨大，比如向量加法，它的代价甚至比初始化写六个寄存器还要小，那么就不值得了，所以tid应该有方法比较快速的批初始化才对。但是block可以比较明确的肯定他就是线性初始化和线性调度的，不过依次之间的间隔只有十几个到几十个时钟周期的差距，这个差距并不大。所以tid肯定是快速初始化的，不可能线性进行，不然无法再10个周期内完成。可能的方法是一开始就把一个block的所有tid都产生好，然后大家批量复用一下。</p>
<h3 id="block的调度"><a href="#block的调度" class="headerlink" title="block的调度"></a>block的调度</h3><p>block和thread的初始化和block的分配调度由硬件gigaThread engine执行。每个block和thread的初始化主要需要初始化的有PC和tid、ctaid寄存器，其中PC大家都是一样的，但是tid和ctaid是各不相同的，需要依次初始化为不一样的值。</p>
<h4 id="blcok的初始化和分配"><a href="#blcok的初始化和分配" class="headerlink" title="blcok的初始化和分配"></a>blcok的初始化和分配</h4><p>block的初始化和分配是线性进行的，这里参考的是<a href="https://www.cs.rochester.edu/~sree/fermi-tbs/fermi-tbs.html#sec-7-1">该文章</a>得到的结论。block被依次初始化对应的ctaid和其他内容，然后依次轮询每一个SM看是否可以放入这个block，如果可以的话就将该block放入该SM当中，每个block的初始化到调度大约需要10-20个SM周期的时间，当然如果让初始化和分配成为多个流水级，这个时间可以更久。对于一维的grid，block是根据blockIdx.x依次从小到大调度的，而对于二维的grid，block则是根据一种蛇形的走位方式进行调度的，如下图。正是<a href="https://www.cs.rochester.edu/~sree/fermi-tbs/fermi-tbs.html#sec-7-1">参考文献</a>中SM分配的轮询和二维grid中的特殊遍历方式暗示了block分配的线性进行。<br><img src="https://zhuzhuzaiimgbed.oss-cn-hangzhou.aliyuncs.com/img/5x5x2-pattern.png" alt="二维block矩阵的分配顺序"></p>
<h4 id="thread的初始化"><a href="#thread的初始化" class="headerlink" title="thread的初始化"></a>thread的初始化</h4><p>thread的初始化和分配不可以是线性的，它必须是常数时间内完成。如果N个thread需要O(N)的时间才可以完成，那么对于简单的向量加法CPU也只需要O(N)的时间就完成，做一次加法也许不比简单的tid赋值来的慢，那么GPU不能得到加速，何况block的调度只需要10-20个周期，这不可能完成512个thread的线性初始化，那么除非50个thread一个周期。比较可能的实现是一开始就为所有的thread都提供好对应的tid初始化结构，反正每个block要初始化的所有tid的结构是一样的，然后每次直接用这个结构批量初始化所有的thread即可。</p>
<h4 id="block的SM共享"><a href="#block的SM共享" class="headerlink" title="block的SM共享"></a>block的SM共享</h4><p>对于一个block，它需要的资源数量必须保证它可以被一个SM接受。比如一个SM最多只能运行1024个thread，但是block定义了2048个thread，那么在编译阶段就会报错；一个SM最多只能提供比如65536个寄存器，但是block的1024个thread分别需要使用1024个，那么也会报错；一个SM最多提供比如48KB的shared memory，但是一个block需要64KB也会报错。总之编译期间一定会检查你的block是不是满足资源，如果不满足就会报错。即使编译期间没有报错，执行的时候函数也会检查参数对应的资源需求是不是太大了，如果是的话kernel就不会被launch执行。所以放心吧，一个SM完全可以给一个block提供充足的资源，一个block完全可以在一个SM上被执行，不存在一个block需要多个SM才可以运行的情况。如果一个SM的资源可以放下多个block，可能是不同grid的block，也可能是同一个，那么他就可以共享这个SM运行。对于更高级的nvidia的GPU，如果一个block的部分wrap先运行完毕，这些wrap可以先行释放资源，那么可以一个SM只运行0.x个block，其他block使用释放的资源也是可以的。</p>
<h4 id="block的切换"><a href="#block的切换" class="headerlink" title="block的切换"></a>block的切换</h4><p>block除了可以分配SM、共用SM、释放SM还可以在SM上切换。因为上面指出context的task是有时间片的，可以多任务，所以如果一些task太长了会切换出来，交给下一个task。这个切换的代价是巨大的，每个SM的register、shared memory都需要被保存起来，每个block都需要自己的切换空间，而且新启动的时候需要载入原来的内容。但是实验表明这就是会发生的，甚至同一个task的block也会发生一个SM的切换。如果是多个block在一个SM上运行的切换，间隔仅仅使另一个可以连续运行的时间，但是如果是block直接切换的话，代价就会比较大了。</p>
<h3 id="wrap的执行和调度"><a href="#wrap的执行和调度" class="headerlink" title="wrap的执行和调度"></a>wrap的执行和调度</h3><p>现在我们的一个block，比如说他是1024个thread被调度到了一个SM上面，现在就可以在SM开始运行了。1024个thread当中每32个thread被组织为一个wrap，一个wrap的32个thread永远执行一样的指令，他们永远一起行动、一起等待，如果32个thread在执行指令的时候有一个thread没有就位，所有的thread等待他就位为止。这位知乎大佬的<a href="https://www.zhihu.com/people/xiaoguiren/posts">文章</a>中给出了一个生动的比喻，thread英文含义是线，wrap就是一束线，wrap执行一条指令就好比梭子纺过纱机的32根线，每一根线都会被码新的一层丝线。姑且我们就这么看待wrap吧。</p>
<h4 id="GPR介绍"><a href="#GPR介绍" class="headerlink" title="GPR介绍"></a>GPR介绍</h4><p>对于每个thread而言，它都有对应的寄存器组和PC，考虑到wrap是一个整体，所以只需要每个wrap提供一个PC寄存器就可以了，但是寄存器组还是每个thread都需要的。所以我们是提供了最多1024个寄存器组吗？并不是，实际上更加的灵活，SM是提供了一个大块的generation purpose register块，一共包含了若干个bank和总计65536个GPR。然后thread根据自己的需要分配对应数目的GPR，比如只有256个thread，每个thread需要10个GPR，那么就分摊走2560个GPR。不过每个thread的逻辑GPR是怎么映射到GPR块的物理GPR的也是一个存疑的问题，但是GPU的GPR不存在寄存器重命名的操作，因此不需要寄存器中命名的硬件支持，一旦一开始确定了映射，那么后续也就不会更改映射关系了。个人觉得可能是每一个thread的GPR在访问之前需要加一个偏移量，比如thread1的16个GPR从0开始到15，而thread2的16个GPR则16开始，16+0-16+15，以此类推。GPR还有一个特点就是，虽然它有65536个，但是他们不能被同时访问，这些GPR分为了多个bank，如果两个thread正好访问同一个bank就必须等待，或者一个thread的多个寄存器在同一个bank也需要等待。</p>
<p>GPR每个的大小都是4个字节。如果数据的大小正好就是4字节，那么存在这个GPR里是刚刚好的，如果数据小于4字节，那么在不考虑特殊操作的情况下也是占用一个GPR，会损失一些空间；但是可以用一些特殊指令或者track把比如两个16位的数据存到一个32位的GPR里，这样后续可以用一些特殊指令对两个半字同时进行加法运算等操作；如果是64位的数据比如double，那么就需要一次使用两个连续的GPR才可以，这个时候指令会隐式的指出这个GPR是多个GPR组成的，但是写汇编的时候只要写几个GPR中最小的那个就可以了，而且一定是对齐的。SASS指令给GPR寻址的域是8位，所以一个thread最多可以访问512个GPR，更多的GPR的使用会导致寄存器溢出等操作来额外处理，GPR的255是一个特殊的寄存器，他被认为访问了0寄存器。</p>
<h4 id="scheduler和dispatch-port"><a href="#scheduler和dispatch-port" class="headerlink" title="scheduler和dispatch port"></a>scheduler和dispatch port</h4><p>GPR和其他的寄存器解决了表示wrap和thread状态的数据的存储问题(就是PC、GPR和其他的特权寄存器等)，只要这个block还在这个SM上，这些thread就静静的躺在对应的GPR和PC寄存器中，直到scheduler调度了它们对应的wrap，dispatch port发射了对应的指令，写回的结果修改了对应的mmeory和register等。</p>
<p>一个SM可能有4个scheduler、8个dispatch port、128个core、128个FP、64个SFU、65536个GPR，上面有1个block的1024个thread。比如下图：<br><img src="https://zhuzhuzaiimgbed.oss-cn-hangzhou.aliyuncs.com/img/SM.jpg" alt="SM内部结构图"><br>那么这个时候这些资源可能是均匀分成4分来进行调度管理的，比如每个scheduler管理自己对应的2个dispatch port、32个core、32个FP、16个SFU、调度8个wrap，可以看到数字变小了以后，硬件设计的压力瞬间变小了。然后scheduler就调度这8个wrap看看谁是可以准备发射没有stall的，就将它的指令取出来放到dispatch port当中等待发射，可能是2个wrap一个提供一个inst，也可能是1个wrap提供2个inst，当然也可能只能凑出一个inst，甚至一个都没有。这里发射的指令绝对不做乱序，没有什么跳转预测、没有乱序执行、没有保留站、没有冲突检测，什么都没有，只是纯粹的顺序执行，最多双发射。SM的迅速依赖于wrap的32个thread同时运行，以及一个wrap停顿之后，下一个wrap马上顶上。</p>
<p>这种配置下的dispatch port可以跑两条不同类型的指令，算术整型指令是交给core、浮点指令交给fp、特殊指令交给sfu、访存指令交给访存单元、跳转指令交给其他部分，所以往往可以同时发射一条算术指令和一条其他指令。如果是算术指令32个core正好可以跑一组，对于SFU只有16个的可能就要跑两次。</p>
<p>所以block在SM的执行就是每个thread在GPR上分配自己的GPR区间，然后每个scheduler从所有的wrap中找到可以运行的wrap将他们可以发射的inst载入到dispatch port中发射，发射的指令如果是算术指令的话就从GPR中读取对应的寄存器的值，如果GPR冲突了还需要额外的等待，然后进入对应的计算单元计算，最后写回GPR。这个过程也是有简单的流水化操作的，虽然指令动不动就会stall一到两拍，但是多少可以并行一些。</p>
<h4 id="指令获取"><a href="#指令获取" class="headerlink" title="指令获取"></a>指令获取</h4><p>指令是有指令cache的，每次获取指令都是从指令cache中获得的，应该也会有指令的预取模块。</p>
<h3 id="指令执行"><a href="#指令执行" class="headerlink" title="指令执行"></a>指令执行</h3><h4 id="算术指令"><a href="#算术指令" class="headerlink" title="算术指令"></a>算术指令</h4><h5 id="整数指令和core"><a href="#整数指令和core" class="headerlink" title="整数指令和core"></a>整数指令和core</h5><p>整数指令包括加法指令、减法指令、移位指令、与或非逻辑指令等常见的指令。移位指令提供了一种特殊的指令，可以将2个32位指令当作一个整体进行移位操作，从而实现大整数的移位等操作。</p>
<p>此外还有整数乘法指令等，但是没有整数除法指令，自然也没有取余指令，这两类指令需要用其他整数指令用内嵌函数的方式实现，效率很慢，需要避免。如果是常数的乘法往往会做一些优化，比如2的幂次的常数转换为移位操作，简单常数的乘法可以转换为多个移位运算的组合等等。</p>
<p>整数运算的操作数可以是GPR寄存器、立即数、predicate寄存器、uniform寄存器、constant memory number等数据，这里操作数如果是内存只能是constant memory，原因我们在介绍访存的时候再介绍，其他几类寄存器也在相关指令介绍的时候再详谈。整数指令交由core运行，简单的整数指令可能只需要一个周期，复杂的可能要多个周期，对于stall的控制并不是使用动态监测，我们后面详细介绍。</p>
<p>常见的指令有：</p>
<table>
<thead>
<tr>
<th>指令</th>
<th>功能</th>
</tr>
</thead>
<tbody><tr>
<td>IADD</td>
<td>整数加法</td>
</tr>
<tr>
<td>ICMP</td>
<td>整数比较</td>
</tr>
<tr>
<td>IMAD</td>
<td>两个整数相乘，在和第三个整数相加，常用于矩阵运算等</td>
</tr>
<tr>
<td>IMNMX</td>
<td>计算两个整数较大的数，或者较小的数</td>
</tr>
<tr>
<td>IMUL</td>
<td>整数乘法</td>
</tr>
<tr>
<td>ISAD</td>
<td>整数求差的绝对值</td>
</tr>
<tr>
<td>LOP</td>
<td>整数逻辑运算，如与、或、异或</td>
</tr>
<tr>
<td>SHF</td>
<td>通道位移，就是两个32位整数当作整体位移</td>
</tr>
<tr>
<td>SHL</td>
<td>整数左移</td>
</tr>
<tr>
<td>SHR</td>
<td>整数右移</td>
</tr>
<tr>
<td>FLO</td>
<td>寻找整数第一个前导1的位置</td>
</tr>
<tr>
<td>POPC</td>
<td>计算整数中1的个数</td>
</tr>
<tr>
<td>I2I</td>
<td>整数不同类型的转换</td>
</tr>
<tr>
<td>其他的不罗列了，更多内容参见这篇<a href="https://www.informit.com/articles/article.aspx?p=2103809&seqNum=7">文章</a></td>
<td></td>
</tr>
</tbody></table>
<p>对于IADD、IMUL、SHL、SHR等指令，我们在cuda编程的时候可以用C的+、*、&lt;&lt;、&gt;&gt;等算子表示，然后编译器可以自动生成，但是很多的指令的功能可能C有限的运算符无法表示，这个时候有三种方法可以使用这些特殊的指令。第一是依靠编译器自动的优化，但是很多时候可能会不尽人意，或者不如直接指令特殊指令来的效果好；第二是用内联汇编的方式来进行，不过内联汇编可能和C语法不是很搭，而且这里涉及到了ptx语法是否兼容等问题；最后就是每个指令可能提供了配套的instrinc函数，只要使用这个函数就可以产生对应的一条指令，具体函数的名字可以查一下文档。比如POPC指令对应的__popc，SHF指令对应的__funnelshift_x系列等。具体的对应关系可以看这一系列<a href="https://www.informit.com/articles/article.aspx?p=2103809&seqNum=2">文章</a></p>
<h5 id="浮点数指令和FPU"><a href="#浮点数指令和FPU" class="headerlink" title="浮点数指令和FPU"></a>浮点数指令和FPU</h5><p>浮点数指令包括浮点加法、减法、乘法等，浮点的操作数除了可以是32位的GPR作为一个32位的浮点数，也可以是2个GPR作为一个64位的浮点数，也可以是1个GPR作为2个16位的浮点数，诸如此类。这些运算都是和CPU的FPU类似的运算部件，都是常规的高精度计算部件。</p>
<p>浮点数指令交给FU单元进行运算。常见的浮点指令有：</p>
<table>
<thead>
<tr>
<th>指令</th>
<th>功能</th>
</tr>
</thead>
<tbody><tr>
<td>DADD</td>
<td>双精度加法</td>
</tr>
<tr>
<td>FADD</td>
<td>单精度加法</td>
</tr>
<tr>
<td>DFMA</td>
<td>双精度乘法再做加法</td>
</tr>
<tr>
<td>FFMA</td>
<td>单精度乘法再做加法</td>
</tr>
<tr>
<td>DMAX</td>
<td>双精度求最大值</td>
</tr>
<tr>
<td>FMAX</td>
<td>单精度求最大值</td>
</tr>
<tr>
<td>DMIN</td>
<td>双精度求最小值</td>
</tr>
<tr>
<td>FMIN</td>
<td>单精度求最小值</td>
</tr>
<tr>
<td>DMUL</td>
<td>双精度乘法</td>
</tr>
<tr>
<td>FMUL</td>
<td>单精度乘法</td>
</tr>
<tr>
<td>F2F</td>
<td>浮点数不同精度之间的转换</td>
</tr>
<tr>
<td>I2F</td>
<td>不同类型的整数转换到不同精度的浮点数</td>
</tr>
<tr>
<td>F2I</td>
<td>不同精度的浮点数转换为不同类型的整数</td>
</tr>
</tbody></table>
<h5 id="特殊功能指令和SFU"><a href="#特殊功能指令和SFU" class="headerlink" title="特殊功能指令和SFU"></a>特殊功能指令和SFU</h5><p>SFU单元是special function unit，可以处理特殊的算数运算。上面的FP单元没有提供浮点的除法或者开方指令，因为浮点数的除法实现起来比乘法要慢很多，相反SFU实现了浮点数的倒数指令，可以求$f(x)&#x3D;1&#x2F;x$，还有求$f(x)&#x3D;1&#x2F;\sqrt{x}$的指令。在计算得到$1&#x2F;x$和$1&#x2F;\sqrt{x}$之后，将他们和y、x相乘就可以得到$y&#x2F;x$和$\sqrt{x}$，从而用两条指令实现除法和开方的目的。</p>
<p>这里的倒数运算采用的是牛顿迭代法的数值计算方式，要求$y&#x3D;1&#x2F;a$，则有</p>
<p>$$<br>\begin{aligned}<br>&amp;\because y&#x3D;1&#x2F;a \\<br>&amp;\therefore f(y)&#x3D;1&#x2F;y-a&#x3D;0 \\<br>&amp;\therefore y_{n}&#x3D;y_{n-1}-f(y_{n-1})&#x2F;f’{y_{n-1}} \\<br>&amp;\therefore y_{n}&#x3D;y_{n-1}-\frac{y_{n-1}^{-1}-a}{-y_{n-1}^{-2}} \\<br>&amp;\therefore y_{n}&#x3D;2y_{n-1}-ay_{n-1}^2<br>&amp;\end{aligned}<br>$$<br>这里的倒数运算采用的是牛顿迭代法的数值计算方式，要求$y&#x3D;1&#x2F;\sqrt{a}$，则有</p>
<p>$$<br>\begin{aligned}<br>&amp;\because y&#x3D;1&#x2F;\sqrt{a} \\<br>&amp;\therefore f(y)&#x3D;1&#x2F;y^2-a&#x3D;0 \\<br>&amp;\therefore y_{n}&#x3D;y_{n-1}-f(y_{n-1})&#x2F;f’{y_{n-1}} \\<br>&amp;\therefore y_n&#x3D;y_{n-1}-\frac{y^{-2}-a}{-2y^{-3}} \\<br>&amp;\therefore y_n&#x3D;\frac{3y_{n-1}-ay^3}{2}<br>\end{aligned}<br>$$<br>这样就可以用较快速的乘法、加法取代除法和开方运算，但是代价就是精度会有所损失，所以很多时候在实际使用时还是需要用一些数值方法，将多个除法进行配合进行使用，来提高精度。</p>
<p>此外还提供了log2、exp2、cos、sin等运算单元，都是采用一些近似或者数值的计算方法。对于cos和sin提供了rro操作可以将任意大小的浮点数转换到$-\pi~\pi$之间，然后在进行cos、sin的计算，这样可以大大提高精度。但是这些算法精度都没有非常高，高精度场景下还是需要额外的操作来矫正。</p>
<p>特殊功能的数学运算指令交给SFU来进行，提供的常见指令如下：</p>
<table>
<thead>
<tr>
<th>指令</th>
<th>功能</th>
</tr>
</thead>
<tbody><tr>
<td>LG2</td>
<td>log2运算</td>
</tr>
<tr>
<td>EX2</td>
<td>exp2运算</td>
</tr>
<tr>
<td>RCP</td>
<td>计算倒数</td>
</tr>
<tr>
<td>RSQ</td>
<td>计算开放根的倒数</td>
</tr>
<tr>
<td>RRO</td>
<td>在sin、cos之前使用，将数据范围缩减到2$\pi$范围</td>
</tr>
<tr>
<td>COS</td>
<td>cos运算</td>
</tr>
<tr>
<td>SIN</td>
<td>sin运算</td>
</tr>
</tbody></table>
<h6 id="功能单元的collector"><a href="#功能单元的collector" class="headerlink" title="功能单元的collector"></a>功能单元的collector</h6><p>core、FPU、SFU都有一个collector的寄存器组，这些寄存器组用来存放之后计算单元需要的数据的值，比如GPR的值、imm的值等等，当一条指令从dispatch port发射到计算单元开始运算之前需要首先取值，并将数值存放到对应的计算单元的collector当中去，流水线的中间寄存器很多时候就起到了这个作用。如果操作数的值需要取几个周期，比如GPR的bank冲突了，或者访存在等待，那么collector就要几个周期等数据收集齐全之后才可以开始后续的计算。</p>
<h4 id="访存指令"><a href="#访存指令" class="headerlink" title="访存指令"></a>访存指令</h4><p>访存单元是LD&#x2F;ST单元，用来处理访存事务，具体访存的硬件细节自然是查不到的，所以这里主要是介绍一些GPU的存储架构等内容。LD&#x2F;ST单元再进行访问之前会进行页表的翻译工作，所有的LD&#x2F;ST共用一个页表转换单元，这个页表转换单元也是有自己的TLB进行缓存，为了可以高效地进行地址转换，这个TLB会比较大。</p>
<h5 id="LDS-STS与shared-memory与L1-cache"><a href="#LDS-STS与shared-memory与L1-cache" class="headerlink" title="LDS&#x2F;STS与shared memory与L1 cache"></a>LDS&#x2F;STS与shared memory与L1 cache</h5><p>一个SM做在一个紧凑的片上区域，内部的数据传输和运算是非常高效和稳定。类似于CPU有自己的片上L1 cache和L2 cache等，GPU的SM也有自己的片上存储器，来方便快速的内存数据访问。这块片上内存的大小一般是64KB，然后被进一步分成大小为16KB和48KB的两部分，一部分是片上的L1 cache，就和CPU的L1 cache差不多，一个是shared memory。有的GPU可以配置16KB和48KB哪部分用来充当L1 cache，哪部分用来充当shared memory；有的GPU可能就是L1 cahe大小为16KB，而shared memory大小为48KB。因为是片上的存储，所以访问速度非常的快，一般只要1-2个周期就可以访问得到对应的值。</p>
<p>L1 cache大致就是和CPU的L1 cache差不多，不过因为SM分为多个thread、外部的内存也分了多种内存，所以L1 cache的tag除了virtual address等信息之外，可能还有threadIdx、memory kind等信息。当使用LD&#x2F;ST访问片外的存储，比如global memory之类的时候在LD&#x2F;ST中设置对应的操作位来选择要不要把数据缓存到cache当中，当数据要被反复读取的时候载入cache可以提高后续的收益，但是如果只会被访问一两次，那用GPR暂存就好了，没有必要存入L1 cache。</p>
<p>shared memory是SM的所有thread公用的内存，他们共享shared memory的地址空间。因为一个SM一次只跑一个block，而SM的shared memory只会被这个block共享，所以它不需要虚拟地址，是直接使用实地址访问的。而且所有的shared memory的地址在这个block的所有的thread眼中是一致的。不过也不绝对，现在一个SM可以跑多个block，那么shared memory就会被这些block共享，但是他们的shared memory地址是相互隔离的；再加上很多资料指出现在的cuda程序是统一内存管理，就是shared memory、global memory、constant memory等共享一个虚拟地址范围；所以可能shared memory还是需要虚拟内存的转译的。</p>
<p>shared memory可以使用ST&#x2F;LD指令访问的，当使用LD访问的时候，因为是一个wrap的所有thread同时访问，甚至多个wrap同时访问，可能会存在访问多个地址的情况。shared memory访问多个bank，如果访问的是不同的bank的地址，相互之间是不会发生冲突的，如果访问的是同一个bank的同一个address，那么也不会发生冲突，最后得到的数据会广播到所有的LD单元来提取满足要求的address对应的数据。如果是ST的话，即使访问的是同一个bank的同一个address，那么写入的数据还是要被排队，然后一个一个的写进去，即使做的不是原子访问操作。可以考虑到这样的布线会多么的恐怖，所以实际上GPU的内存管理、冲突处理等是非常的复杂的，个人觉得可能是GPU最复杂的地方，好在忽略具体实现就变得不难了。</p>
<p>当cuda编程的时候，如果数据结构前面声明了<code>__shared__</code>，那么就会被设置为shared memory的数据，然后再访存的时候就会自动使用STS和LDS指令，不需要担心shared memory提供的数据一个block使用，因为如果这样运行时会发现错误不执行或者编译时直接报错的。</p>
<h5 id="LDL-STL和local-memory"><a href="#LDL-STL和local-memory" class="headerlink" title="LDL&#x2F;STL和local memory"></a>LDL&#x2F;STL和local memory</h5><p>每个thread可能会有自己的local memory。比如说我们分配了一个数组变量<code>a[100]</code>，如果是简单的运算可能它会被优化为GPR，然是如果实在没法优化它就会被优化为数组。如果是C程序的话就是一个stack上的内存，但是thread是没有stack的，所以就会被分配一段local memory。</p>
<p>这段local memory实际上是在glocal memory上分配出来的，但是可以想见在每个thread眼中它们的虚拟地址都是一样的，但是实际上他的物理地址都是不一样的，那么使用LDL&#x2F;STL寻址的时候可能还要根据tid和ctaid的不同做一些偏移量的转换，来进一步区分对应的地址范围。比如说我们的所有local memory是在虚拟地址当中的一个大数组，例如一共32个thread，每人32个字，那么就是<code>int lcoal[32][32]</code>，于是乎寻址就是<code>base+threadIdx*scale+offset</code>，可能是这样，然后base、scale、tid、ctaid的值需要额外的寄存器依赖。如果不考虑寻址上的差异，这个local memory的访问操作和global memory的访问操作是一样的。</p>
<h5 id="LDG-STG和global-memory"><a href="#LDG-STG和global-memory" class="headerlink" title="LDG&#x2F;STG和global memory"></a>LDG&#x2F;STG和global memory</h5><p>所有的block共享global memory，当然是指context的page table指示的页表虚拟地址空间和被实际映射到的物理内存。global memory的数据每次读取是读取128个字节的，当wrap使用LDG&#x2F;STG访存global memory的时候，根据需要的地址范围被重新排列组织为128字节、128字节的任务系列，然后依次访问，每次访问往往要32-64个时钟周期以上。所以global memory的数据最好是128字节对齐的，如果一个LDG要读取的数据在两个128字节的列上，那么就会被设置为两个读取事务，读的就会比较慢。</p>
<p>如果LDG&#x2F;STG查询页表发现需要读写的数据是managed，而且没有分配就需要引发page fault，然后重新分配页；如果数据是host的，那么就需要从CPU那里把数据用pcie总线协议传递过来；如果数据是nil的就会读写失败，但是并不会报错，剩下的该执行的还是会执行的，虽然最后得到的数据也许是错误的。</p>
<p>所以LDG和STG需要的时间是无法实现确定的，需要一些特殊的处理手段。我们在后面介绍如何处理数据竞争的时候讲解这个问题。</p>
<h5 id="LDC和constant-memory"><a href="#LDC和constant-memory" class="headerlink" title="LDC和constant memory"></a>LDC和constant memory</h5><p>constant memory和global memory不是同一块memory，这个memory比较特殊，它可以存储来自cpu设置的数据，比如后续GPU程序需要使用的常量，但是无法使用GPU进行写，因为GPU程序眼中这里的数据是用来读的，不可以写。读context memory的场景有很多种，可以用LDC指令直接读constant memory的值，也可以在算术指令中操作数直接指定constant memory的地址。这是因为对于所有的thread而言，它们的同一条指令往往是读同一个constant地址的，所以其实对于constant一次只需要读出一个字就可以了，然后广播给所有的线程，当然如果是不同地址同一bank，那只能等待冲突解决。</p>
<p>constant在cuda编程的时候可以手动声明，比如<code>__const__</code>定义的数据就会在一开始被安排在constant内存，反正对于所有线程值都是一样的。那么对于const类型的变量，如果不适用常量初始化的可能就会被分配到GPR或者local memory，然后仅仅编译器确保编译期间不会被访问而已，但是可能会被一些恶意攻击在运行时写入。其他的一些常量也可能会被写入constant memory，比如函数的传入参数、gridDim、blockDim等常量就会被生成到constant memory当中去。</p>
<p>constant在SASS中往往是以<code>c[0][0x100]</code>，也就是第0bank的第0x100个字节之类的，但是可以想到每个kernel都可能会使用这个<code>c[0][0x100]</code>，所以实际的constant memory也是用虚拟地址需要转换过的。</p>
<h5 id="L2-cache"><a href="#L2-cache" class="headerlink" title="L2 cache"></a>L2 cache</h5><p>在所有的SM之外，global memory之上有一块L2 cache，就是片外cache。当访问global memory的时候可以先访问L2 cache来获得数据，这个过程是自动的，不想L1 cache需要手动管理。但是新的GPU提供了配置方法，可以指定某些内存范围被L2缓存的概率等因素，来防止多个数据被同时访问的时候发生cache的抢占，最后发生cache数据的扰动，使得效率大大降低。</p>
<h5 id="surface-memory和texture-memory"><a href="#surface-memory和texture-memory" class="headerlink" title="surface memory和texture memory"></a>surface memory和texture memory</h5><p>GPU对于纹理映射等操作提供了专门的texture memory、surface memory和数据结构来进行加速，不过本人不清楚纹理映射是干什么的，也不清楚texture memory和surface memory有啥特别之处，所以就不在这里展开了。可以用TEX指令读取texture memory，这个任务由texture fetch模块执行，surface memory也有对应的指令和单元，可以用LDSU&#x2F;STSU进行读写。texture memory只读，但是surface memory可以写。</p>
<p>访存相关的部分指令：</p>
<table>
<thead>
<tr>
<th>指令</th>
<th>功能</th>
</tr>
</thead>
<tbody><tr>
<td>LD&#x2F;LDG</td>
<td>global memory载入</td>
</tr>
<tr>
<td>ST&#x2F;STG</td>
<td>gloabl memory存储</td>
</tr>
<tr>
<td>LDC</td>
<td>constant memory载入</td>
</tr>
<tr>
<td>LDL</td>
<td>local memory载入</td>
</tr>
<tr>
<td>STL</td>
<td>local memory存储</td>
</tr>
<tr>
<td>LDS</td>
<td>shared memory载入</td>
</tr>
<tr>
<td>STS</td>
<td>shared memory存储</td>
</tr>
<tr>
<td>TEX</td>
<td>texture memory访存</td>
</tr>
<tr>
<td>LDSU</td>
<td>surface memory载入</td>
</tr>
<tr>
<td>STSU</td>
<td>surface memory存储</td>
</tr>
<tr>
<td>ATOM</td>
<td>原子内存操作，有返回值</td>
</tr>
<tr>
<td>RED</td>
<td>原子内存操作，没有返回值</td>
</tr>
</tbody></table>
<p>​	稍微解释一下RED和ATOM的区别。ATOM就是原子内存操作，可以做原子写、加、交换等操作，然后可以返回一个返回值，比如原子加的结果，原子交换的结果，但是有时候我们可能不需要返回值，这个时候就可以用RED，这被称为reduce操作，他在和内存交互完之后不返回结果，比如加一个数之后不返回和，这样就比ATOM做的事情更少，那么效率更高，也不容易发生什么读写冲突。</p>
<p>我们总结一下m各个memory的特性：</p>
<table>
<thead>
<tr>
<th>存储单元</th>
<th>位置</th>
<th>是否cache</th>
<th>访存速度</th>
<th>是否可写</th>
<th>共享范围</th>
</tr>
</thead>
<tbody><tr>
<td>GPR</td>
<td>on chip</td>
<td>NA</td>
<td>快</td>
<td>yes</td>
<td>thread</td>
</tr>
<tr>
<td>shared memory</td>
<td>on chip</td>
<td>NA</td>
<td>较快</td>
<td>yes</td>
<td>block</td>
</tr>
<tr>
<td>local memory</td>
<td>off chip</td>
<td>no</td>
<td>慢</td>
<td>yes</td>
<td>thread</td>
</tr>
<tr>
<td>global memory</td>
<td>off chip</td>
<td>yes</td>
<td>慢</td>
<td>yes</td>
<td>grid</td>
</tr>
<tr>
<td>constant memory</td>
<td>off chip</td>
<td>yes</td>
<td>中</td>
<td>no</td>
<td>grid</td>
</tr>
<tr>
<td>texture memory</td>
<td>off chip</td>
<td>yes</td>
<td>中</td>
<td>no</td>
<td>grid</td>
</tr>
</tbody></table>
<p>​	下图为memory的层次结构图：<br><img src="https://zhuzhuzaiimgbed.oss-cn-hangzhou.aliyuncs.com/img/memory.jpg" alt="层次结构图"></p>
<h4 id="控制流指令"><a href="#控制流指令" class="headerlink" title="控制流指令"></a>控制流指令</h4><p>我们之前提到，wrap的32个thread每次运行的是同一条指令的，那么如果我们遇到了if-else这样的操作，我们有的thread可以满足条件需要运行，有的thread不满足条件不能运行，那我们要怎么让有的thread运行，有的thread不运行呢？我们介绍三种方法，不过可能有些退出历史舞台了。</p>
<h5 id="predicate寄存器和predicate指令"><a href="#predicate寄存器和predicate指令" class="headerlink" title="predicate寄存器和predicate指令"></a>predicate寄存器和predicate指令</h5><p>GPU提供了一组一位的谓词寄存器组，称之为predicate register，一共提供了8个编号，前面的p0-p6是正常的寄存器，p7时pT就是恒等于true。可以使用一些逻辑指令或者别的指令设置p0-p6寄存器的值，计算可以使用GPR、predicate、imm、constant等。此外predicate还可以用于整数的计算，比如predicate充当进位，然后可以配合add实现x86的adc的功能。常见的指令有</p>
<table>
<thead>
<tr>
<th>指令</th>
<th>功能</th>
</tr>
</thead>
<tbody><tr>
<td>SETP.EQ</td>
<td>进行等于计算，然后设置predicate值</td>
</tr>
<tr>
<td>SETP.NE</td>
<td>进行不等于计算，然后设置predicate值</td>
</tr>
<tr>
<td>SETP.LT</td>
<td>进行小于计算，然后设置predicate值</td>
</tr>
<tr>
<td>SETP.LE</td>
<td>进行小于等于计算，然后设置predicate值</td>
</tr>
<tr>
<td>SETP.GT</td>
<td>进行大于计算，然后设置predicate值</td>
</tr>
<tr>
<td>SETP.GE</td>
<td>进行大于等于计算，然后设置predicate值</td>
</tr>
<tr>
<td>SETP.AND</td>
<td>进行与计算，然后设置predicate值</td>
</tr>
<tr>
<td>SETP.OR</td>
<td>进行或计算，然后设置predicate值</td>
</tr>
<tr>
<td>R2P</td>
<td>将GPR值赋值predicate</td>
</tr>
<tr>
<td>P2R</td>
<td>将predicate值赋值GPR</td>
</tr>
</tbody></table>
<p>这些指令都是很容易理解的，和CPU的比较单元没什么本质的区别，关键是它的使用。对于每一条指令，我们可以用一个@Px的修饰符来指定，该指令只有在Px为真的情况下才会运行，@!Px则是为假才运行。所以对于如下的if-else语句：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span>(R0==R1)&#123;</span><br><span class="line">    R0+=<span class="number">1</span>;</span><br><span class="line">&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">    R1+=<span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>我们就可以得到SASS汇编为</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SETP.EQ P0,R0,R1</span><br><span class="line">@P0 IADD R0,R0,1</span><br><span class="line">@!P0 IADD R1,R1,1</span><br></pre></td></tr></table></figure>
<p>如果只是简单的if-else等指令就可以使用这样的方式进行，一个wrap中的32个thread满足条件的就会在P0的控制下运行，不满足条件的就不运行。这就类似于ARM的条件执行指令，和x86的条件执行指令。predicate的控制方法其实只是把操作的写回操作删除掉，即使这个操作的thread是Px&#x3D;&#x3D;false的，它对应的core还是会执行运算，只是运算的结果不会写回而已，还是要消耗能源的。但是如果if-else背后的指令短小精悍，那么用这个@P0的方法还是很好的，在x86等操作中对于if-else用条件执行简单指令组合代替跳转，也是常见的抵消分支预测代价的操作，更不要说GPU一旦分支跳转清空流水线的代价会更大。</p>
<p>7个predicate是可以满足所有的分支的复杂情况的。一个predicate可以表示两种状态，6个predicate就足以表示32个状态，我们的if-else无论多么的复杂，最多也就32种分支，那么也足够分散表示每个的执行流了，提供一种简单的方法：一开始所有的寄存器都是0，在第一次分流的时候满足条件的寄存器设置为1；第N次分流的时候，满足条件的寄存器使用<code>SETP.COND.AND PN,R0,R1,R{N-1}</code>指令就可以进一步分流，PN只是了当前满足条件的thread。当进入下一个分支的时候就可以使用<code>SETP.NE.AND PN,PN,PT,R{N-1}</code>来使能第N次分流的下一个分支。以此类推。不过如果只剩下一个流的时候就要加以分辨选择直接跳过，不然的话就要运行没有一个流的代码，虽然也不是不可以。</p>
<p>对于predicate有一种使用技巧，比如我们的伪C代码是这样的：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span>(R0==R1)&#123;</span><br><span class="line">    mem[R1]=mem[R1]<span class="number">+1</span>;</span><br><span class="line">&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">    mem[R0]=mem[R0]<span class="number">+1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>直接写成predicate的方法就是这样的：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SETP.EQ P0,R0,R1</span><br><span class="line">@P0 LDG R3,[R1]</span><br><span class="line">@P0 IADD R3,R3,1</span><br><span class="line">@P0 STD R3,[R1]</span><br><span class="line">@!P0 LDG R4,[R0]</span><br><span class="line">@!P0 IADD R4,R4,1</span><br><span class="line">@!P0 STG R4,[R0]</span><br></pre></td></tr></table></figure>
<p>但我们可以改成这样</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SETP.EQ P0,R0,R1</span><br><span class="line">@P0 LDG R3,[R1]</span><br><span class="line">@!P0 LDG R4,[R0]</span><br><span class="line">@P0 IADD R3,R3,1</span><br><span class="line">@!P0 IADD R4,R4,1</span><br><span class="line">@P0 STD R3,[R1]</span><br><span class="line">@!P0 STG R4,[R0]</span><br></pre></td></tr></table></figure>
<p>分支1的LDG在进行访存的时候，需要等待，也许分支2的部分指令可以先行一步开始并行，那么在分支1等待的时候，就可以先一步运行分支2的指令，如此交替执行就可以比较好的利用不同分支不相冲突的指令让他们充分并行起来，相对于所谓的遮盖时延，我更愿意使用充分并行这个词来指代这个思想。</p>
<h5 id="branch-synchronization-stack"><a href="#branch-synchronization-stack" class="headerlink" title="branch synchronization stack"></a>branch synchronization stack</h5><p>相对于分支一复杂，predicate要人工构造层次，branch synchronization stack就可以人工构造层次。当要第一次if-else分流的时候，计算对应的P0，然后使用push修饰符就可以把这一组的P0保存到branch synchronization stack当中，这个stack影响的就不是写回的wen信号了，而是直接影响thread的active信号，这样只有真正要运行的thread才会真正让core工作，比较节约能源。之后再一次需要分流的时候，那么在设置一次P0，再次push即可。等这个分支运行完，需要运行下一个分支的时候，修饰符执行complement，stack的active取反，那么另外一半的线程开始工作；等分支合流的时候就修饰符执行pop，那么所有线程返回上一个分流的集合继续工作。相对于predicate的手动管理，stack提供了另一组硬件，可以自动管理，而且不占用predicate的资源，比predicate会高效一些。因为一个wrap只有32个thread，所以可以压入6个stack就足够了，此外stack需要可以分辨是不是只有0个thread了，如果是的话要可以明智的选择跳过。但是branch synchronization stack本质上并不比predicate更先进，因为他还是一部分等待，另一部分继续执行。branch synchronization stack也可以想predicate那样交错执行两个分支，只要他返回complement stack top就可以了。<br>代码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SETP.EQ P0,R0,R1</span><br><span class="line">*PUSH</span><br><span class="line">LDG R3,[R1]</span><br><span class="line">IADD R3,R3,1</span><br><span class="line">STD R3,[R1]</span><br><span class="line">*COMPLEMENT</span><br><span class="line">LDG R4,[R0]</span><br><span class="line">IADD R4,R4,1</span><br><span class="line">STG R4,[R0]</span><br><span class="line">*POP</span><br></pre></td></tr></table></figure>

<h5 id="SSY-SYNC机制"><a href="#SSY-SYNC机制" class="headerlink" title="SSY+SYNC机制"></a>SSY+SYNC机制</h5><p>在GPU种wrap的分流和合流操作英文称之为Divergence and Convergence。相对于前面的先左侧或者先右侧，他比较特别，我不太清楚他的硬件建模是什么样子的，但是可以直接讲一下它的意思。首先我们知道代码在0x100之后要分流，会在第0x200的地方合流，所以我们在0x100之前的某个位置比如0x80加入一条<code>SSY 0x200</code>，指示在0x200的地方会合流，然后在0x200的地方加入一条SYNC。然后wrap分流之后就会自动将两个分流部分当作两个wrap那样进行交错调度执行，直到一方执行到0x200的SYNC的时候就会自动暂停等待，等所有的指令都到了0x200的时候，就可以继续执行了。代码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">0x80  SSY 0x200</span><br><span class="line">....</span><br><span class="line">0x100 @P0 BRA 0x150</span><br><span class="line">0x108 ADD R0,R0,1</span><br><span class="line">....</span><br><span class="line">0x148 BRA 0x200</span><br><span class="line">0x150 ADD R0,R0,1</span><br><span class="line">....</span><br><span class="line">0x200 SYNC</span><br></pre></td></tr></table></figure>

<p>执行的图就从原来的if-else模式变为了下图的ssy-sync模式：<br><img src="https://zhuzhuzaiimgbed.oss-cn-hangzhou.aliyuncs.com/img/if-else.webp" alt="if-else"><br><img src="https://zhuzhuzaiimgbed.oss-cn-hangzhou.aliyuncs.com/img/ssy-sync.jpg" alt="ssy-sync"></p>
<p>常见的控制流指令有：</p>
<table>
<thead>
<tr>
<th>指令</th>
<th>功能</th>
</tr>
</thead>
<tbody><tr>
<td>BRA</td>
<td>相对偏移地址跳转，类似branch</td>
</tr>
<tr>
<td>BRK</td>
<td>break跳出循环</td>
</tr>
<tr>
<td>BRX</td>
<td>跳到相对索引地址，switch那种跳</td>
</tr>
<tr>
<td>CAL</td>
<td>call函数调用，相对地址</td>
</tr>
<tr>
<td>JCAL</td>
<td>call函数调用，绝对地址</td>
</tr>
<tr>
<td>RET</td>
<td>return返回函数调用</td>
</tr>
<tr>
<td>JMP</td>
<td>跳到绝对地址</td>
</tr>
<tr>
<td>CONT</td>
<td>continue</td>
</tr>
<tr>
<td>EXIT</td>
<td>结束程序</td>
</tr>
<tr>
<td>SSY</td>
<td>设置分流的同步点</td>
</tr>
<tr>
<td>BPT</td>
<td>打断点</td>
</tr>
</tbody></table>
<p>具体的硬件实现细节其实难以考察，虽然说编写__global__程序的时候可以调用__device__的程序，但是一般来说__device__的程序都是直接inline到__global__程序当中去的，所以没有遇到过；对于递归调用是会被转换为循环的模式的，反正可以用堆栈解决这个问题，但是开销很大，不提倡使用；对于CALL和RET那么会不会有对应的stack，是使用local memory吗？</p>
<p>对于函数调用是可以调用C的函数的，他会把任务发还给CPU，等CPU运行完在把结果返回回去，其中的细节也有待深究，比如可以执行printf；BRX这种每个thread跳转到不同地址的情况就很复杂，不知道怎么处理分流，考虑到现在每一个thread都有自己的PC了，难道真的可以以thread为单位进行调度？编程得到的SASS就是SSY+SYNC，难道只要SSY之后，所有的thread就都自由了，可以自由调度了吗？</p>
<p>BRK和CONT是不会后面跟随地址的，所以地址存在哪里，难道是branch synchronization stack吗？他可以确定BRK的地址，但是对于CONT是怎么做到的呢？</p>
<p>这些问题都是存疑的。</p>
<h4 id="uniform指令"><a href="#uniform指令" class="headerlink" title="uniform指令"></a>uniform指令</h4><p>一个wrap虽然有32个thread，他们可能有一部分指令每次计算的内容都是一样的，比如读取一个constant memory的值，然后对他做一些加减乘除，对于这32个thread而言，这他们计算的数据流、相关的控制流都是完全一样的，所以我们是不是可以这样：这部分指令只要有一个线程计算就可以了，其他的线程拿一下对应的结果就可以了。于是uniform处理单元和uniform指令集就应运而生了。</p>
<p>cuda编程的时候没法指定那些部分使用uniform指令，除非内联汇编，但是cuda的编译器会检测哪些部分是所有的thread共有的，然后把它转化为uniform指令，如果数据流和控制流是每个thread互异的，那么就继续保持原来的指令。对应的我们的硬件也提供了一套uniform专用的register、predicate regisyer、core等，现在我们换一个视角，我们的SM包含大块GPR+32个core的一套并行电路和小型的register组+1个core的小型uniform电路，然后一个wrap开始执行，所有thread共用的指令交给uniform执行，不公用的部分交给正常的core执行，如是而已。</p>
<p>此外还需要有指令可以读取uniform的寄存器到GPR中，或者GPR计算的时候直接使用uniform的寄存器，这个操作很简单，只要发送一条指令，然后uniform对应寄存器的值广播到每个thread的寄存器组或者core即可，那么自然没有办法从GPR传递数据到uniform，因为32个thread的32个数传到uniform的一个寄存器是做不到的，也是没意义的。</p>
<h4 id="同步和通信"><a href="#同步和通信" class="headerlink" title="同步和通信"></a>同步和通信</h4><p>对于wrap间的指令，我们使用SYNC进行wrap内部的同步，如果大家因为某些原因分流了，就可以使用SYNC同步到一起，然后继续一起流淌。这个细节前面讲过了，就不再多重复了，可以用instrinc函数__synchrone_wrap插入该指令。</p>
<p>对于wrap内部的32个thread，有时候我们的下一阶段的行动时需要32个thread一起决定的，比如如果32个线程读内存得到的结果都是0，那么就退出，不然就继续执行，这个时候需要检查32个内存是不是都满足都满足都写条件，或者部分满足某些条件什么的。为此提供了投票指令VOTE，他会检查32个thread的predicate是不是都是0或者1，或者部分是0或者1，如此多种模式，进而根据32个thread的情况协同之后的操作。</p>
<p>wrap之间的thread有的时候需要通信，比如说第1个线程需要第7个线程的某个变量的值，所以提供了shuffle指令可以进行wrap的线程之间的数据传递。shuffle分为4种，首先有一个位宽参数指定交流的范围，如果是32那么就是32个thread当作一个整体做交流，如果是16就是把thread分为两组在内部进行交流，如果是8就是4组，如此类推。之后第一种shuffle是指定一个ID，然后每一组的第ID个thread就把他的某个值发送给其他的thread；第二种是指定一个offset，然后每一组的thread得到自己的ID+offset的那个thread的值；第三种是ID-offset的值；第四种是指定一个mask，然后ID^mask的值。</p>
<p>如果是块内的需要做同步可以用__synchrone来同步，也可以用shared memory来做块内的通信。如果是grid内部，没有办法同步所有的block，可以用global memory来通信。所以通信和同步对于GPU还是很难得，能不用最好不用。</p>
<p>总结一下指令：、</p>
<table>
<thead>
<tr>
<th>指令</th>
<th>功能</th>
</tr>
</thead>
<tbody><tr>
<td>SYNC</td>
<td>同步指令</td>
</tr>
<tr>
<td>VOTE</td>
<td>投票指令</td>
</tr>
<tr>
<td>SHUF</td>
<td>shuffle指令</td>
</tr>
</tbody></table>
<h4 id="特殊寄存器访问"><a href="#特殊寄存器访问" class="headerlink" title="特殊寄存器访问"></a>特殊寄存器访问</h4><p>特殊寄存器基本都是只读的，所以SASS只有S2R的特殊寄存器读取指令，没有特殊寄存器写入指令。要读什么特权寄存器，用S2R就可以了，罗列一些特殊寄存器。比如tid.x、tid.y、tid.z和ctaid.x、ctaid.y、ctaid.z这六个寄存器分别对应threadIdx.x、threadIdx.y、threadIdx.z和blockIdx.x、blockIdx.y、blcokIdx.z，用来表示thread和block的编号。此外还有clock和clock64，可以在cuda中用clock()和clock64()来得到，一个是SM的clock寄存器，一个是GPU全局的clock寄存器，每一个时钟周期就会加1，可以用于计时，不精确的指令测速可以使用这两个寄存器的值。</p>
<h4 id="控制码和竞争处理"><a href="#控制码和竞争处理" class="headerlink" title="控制码和竞争处理"></a>控制码和竞争处理</h4><p>对于结构竞争和控制竞争，GPU是检测到了之后开始等待。那么对于数据竞争是怎么做的？比如第一条指令写了R1，第二条指令要读R1，他是怎么调度来处理RAW、WAR、WAW的呢？首先cuda的编译器是很强大的，他会做算法的优化、指令的重排和调度，让指令之间的冲突尽可能的少，相邻最好不占用同一个发射通道、伪数据相关的WAR和WAW因为GPU不会做寄存器重名可以事先分开等等。而对于之后还留下来的数据竞争则是stall的方法来解决的，stall等待没有竞争为止，而对于stall他也不是动态对之前的几条指令检测的，而是实现用编译器静态分析好，预先计算出每条指令怎么等待、等待多久，然后记录到control code的编码之中保存到指令中，然后执行指令的时候根据control code的值进行指令发射的stall。对于control code可以参看这篇<a href="https://zhuanlan.zhihu.com/p/166180054">文章</a>和这篇<a href="https://github.com/NervanaSystems/maxas/wiki/Control-Codes">文章</a></p>
<p>control code由如下几个域组成</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">| reuse | wait barry |read barry|write barry| yield |  stall |</span><br><span class="line">|  4bit |    6bit    |   3bit   |    3bit   |  1bit |  4bit  |</span><br></pre></td></tr></table></figure>
<p>我们依次介绍每个域设置的原因和起到的作用，有的时候个人觉得原因比作用更重要。相比于我们有一个什么方法，这个方法是什么，他可以达到什么效果；我们遇到什么问题，如何解决这个问题，我们是用了什么方法是更好的介绍方式。</p>
<h5 id="reuse"><a href="#reuse" class="headerlink" title="reuse"></a>reuse</h5><p>我们之前提到每一个计算单元core、FPU和SFU都有自己的collector用来收集需要使用的数据，比如GPR寄存器的值、特殊寄存器的值、predicate寄存器的值等等，但是这些值有的时候获得是需要一到两个周期的，比如GPR的读取有时候可能因为bank冲突就需要多读几个周期，那么有没有办法加加速呢？</p>
<p>现在我们有两条指令</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ADD R0,R2,R3</span><br><span class="line">ADD R1,R2,R4</span><br></pre></td></tr></table></figure>
<p>那么执行完第一条指令之后，R2、R3的值已经保存到了core的collector的第一个寄存器和第二个寄存器里面了，那么执行第二条指令的时候我们发现collector第一个寄存器需要载入的R2已经在collector里了，所以其实就不需要再读一次GPR的了，而第二个寄存器需要R4但是里面的是R3那还是需要再读一次GPR。因此我们可以在control code里面为每一个collector的槽设置一个reuse bit，如果这个指令的第x个寄存器的值和下一个指令的第x寄存器的值是一样的，那么就可以把reuse的第xbit设置为1，那么下一条指令就可以省去collector第x槽读数的操作了。对于计算指令一般来说有至少3个操作数，比如乘法指令，所以需要至少三个reuse bit，但是GPU的control code提供了4个，可能是因为存在4操作数指令或者为将来的扩展做预留吧。</p>
<p>另外对于下面这个例子，这是<a href="https://zhuanlan.zhihu.com/p/166180054">文章</a>作者疑惑的地方，但是我们可以给出解释：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1: [R---:B------:R-:W-:-:S02]     FSETP.GT.AND P1, PT, R9.reuse, c[0x0][0x18c], PT ;</span><br><span class="line">2: [----:B------:R-:W-:-:S02]     LEA.HI.X.SX32 R4, R4, c[0x0][0x164], 0x1, P3 ;    </span><br><span class="line">3: [R---:B------:R-:W-:-:S02]     LEA R5, P3, R0.reuse, R5, 0x2 ;                   </span><br><span class="line">4: [----:B------:R-:W-:-:S02]     FSEL R9, R9, c[0x0][0x18c], !P1 ;                 </span><br><span class="line">5: [----:B------:R-:W-:-:S02]     LEA.HI.X R4, R0, R4, R3, 0x2, P3 ;</span><br></pre></td></tr></table></figure>
<p>我们可以看到第1条和第4条的R9是相同的，第3条和第5条的R0是相同的，所以作者在疑惑是不是应该把第1条和第4条放在一起，第3条和第5条放在一起？其实没有必要，因为reuse不是和指令的顺序相关联的，而是和指令的执行不见得collector相关联的，我们的第一条指令在FPU执行，第2、3条去core执行，第4条之后去了FPU执行，这个时候他检查的collector就是被第1条指令影响的，所以它的R9可以和第1条的R9匹配，可以用reuse保留collector对应槽寄存器的值，第五条指令进入core的时候检查collector是被第3条指令影响的，所以它的R0和第3条的R0匹配，可以reuse。另外core指令和FPU指令交错有它的好处，可以在发射的时候dispatch同时发射一条core指令和一条fpu指令，从而提高发射的速度。</p>
<p>这里也暗示wrap的调度可能不是简单的轮询，如果是多个wrap轮询发射，那么core的collector的寄存器的值对其他的wrap毫无意义，那么reuse也会变得没有意义，所以大概率是如果wrap还可以发射，应该有先让他继续发射，后面的yield应该也体现了这一点。</p>
<h5 id="stall"><a href="#stall" class="headerlink" title="stall"></a>stall</h5><p>stall是好理解的，比如我的指令1在FPU运行需要3拍才可以执行完，这个因为我了解硬件是可以事先知道的，而我的指令2也要在FPU运行，因此他要等待3拍才可以被发射出去。那么我就可以在control code的stall为上写3，那么这条指令发射之后等3拍在发射下一条指令，那么他就可以正常运行了。</p>
<p>对于core、SPU、FPU这些封闭性很强的指令，他们每条指令执行的时间是事先都可以知道的，因此我们在编译的时候就可以计算出这些简单指令占据运算单元的时间，然后后续发射的指令如果要没有结构竞争或者没有数据竞争需要stall的时间，把这个stall记录到control code即可。因为编译器事先解决了这个冲突stall时间的问题，所以硬件就可以把这些冲突stall检查的逻辑全部删去，就可以大大节省运行能耗和硬件的开销。</p>
<p>stall一共是4位，所以最多可以等待15个周期。</p>
<h5 id="barry"><a href="#barry" class="headerlink" title="barry"></a>barry</h5><p>wait barry、read barry和write barry是结合起来工作的。如果我们只有算数指令和控制指令，每个指令的运算部件都是自己私有的，他们的运算时间都是事先可以知道的，所以我们可以是先计算出确切的stall，然后让他等待既可以了，但是对于store、load指令，访存的逻辑是复杂的，他的执行时间受到其他的block和访问的address等大量数据的影响，所以是无法预先计算出对应的访存时间。那怎么办呢？不能静态检测就只能动态监测了，那么就是用scoreboard呗。</p>
<p>GPU为wrap提供了6个barry寄存器，来充当scoreboard。对于如下的指令：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">LDG R0,[R1]</span><br><span class="line">ADD R2,R0,1</span><br></pre></td></tr></table></figure>
<p>我们的ADD指令的R0是依赖于LDG这条指令的，所以必须要等待LDG指令运行完毕才可以继续运行。因此LDG在执行的时候就需要把对应的barry寄存器设置为1，然后等执行完毕之后就会设置为0。而ADD指令则选择等待对应的barry直到它的值变为0然后才可以发射出去执行。</p>
<p>对于6个barry，如果要设置barry，读指令在control code的3位read barry处选择要设置的barry的编号，然后就可以在发射之后将对应的barry置位。我们的read barry域虽然有3位可以索引0-7，但是很可惜barry只有6个，000表示不设置barry，001-110表示设置0-5号barry，111没有意义也不会出现。barry在32个load开始运行的时候，每开始运行一个load，barry的值加1，然后每完成一个load，barry的值减1，直到最后load执行完毕，barry的值减为1。如果是写的store指令，那么就设置write barry为6个barry的序号。编译器选择要使用的barry序号，确保在一个barry没有释放之前不会被再次使用。</p>
<p>而等待barry的一方则在wait barry哪里设置要等待的barry序号，如果要等待0-5号barry就把wait barry的0-5位设置为1即可。不同于设置方一次只能设置一个barry，等待方可能有多个操作数都要等待其他指令的barry，所以6个barry都要可以管理到，因此采用了one-hot编码的方式。</p>
<h5 id="yield"><a href="#yield" class="headerlink" title="yield"></a>yield</h5><p>没有确切的文献指出他实锤是干什么的，可以知道的是yield是和stall搭配工作的，然后yield&#x3D;1可能是在告诉scheduler这个wrap可以被调度出去，让其他的wrap有先运行，因为stall的时间可能会很久。具体不清楚。这也说明了我们的wrap调度大概率不是轮询的，而是可能一个wrap可以执行就尽量让他先被满足，减少调度切换的成本，这估计也是reuse和yield可以发挥作用的原因。</p>
<h5 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h5><p>可以看到一条指令的长度是64位，对应的control code需要21位，所以他们选择将3条指令的control code总计63位打包，然后加上一个无效位就是64位，然后3条指令+1条control code作为一个整体排不在text段当中。早期的GPU体系架构因为control code比较短，所以是7条指令+1条control code，之后就是3条指令+1条control code，所以可以想象到我们的instruction fetch单元每次取指令一定是8条或者4条一个整体fetch出来的，然后再重新把指令和对应的control code组合起来。到后面control code进一步增加，现在已经变为了1条inst+1条control code，所以干脆control code就直接是inst的一部分就可以了，所以现在的SASS一个指令是128位，也没必要打包解包了。</p>
<h2 id="AI模型如何在GPU上运行"><a href="#AI模型如何在GPU上运行" class="headerlink" title="AI模型如何在GPU上运行"></a>AI模型如何在GPU上运行</h2><p>因为组会额外讨论了这部分，所以我在这里插入叙述一下AI模型在GPU上运行的基本流程，当然落实到细节说不定就是另一个样子了。</p>
<p>我们以普通的图像分类神经网络为例，他可能是14个卷积层+relu层的组合一次连接，最后加上一个全连接层+relu层的组合。AI模型在运行的时候图像依次经过卷积层+relu层的计算，得到一个新的二维结果，然后展开为1维向量在经过全连接层+relu层的计算得到最后的结果。现在我们把他们编译为cuda程序对应的binary会是什么样子的？AI模型每个层的参数会被保存到其他的文件当中，每个层的参数会保存到code段或者data段或者外部文件中，然后每个层最后就是一个单纯的cudnn.lib的kernel函数，比如卷积层就是比如叫conv这样的kernel，relu就是叫relu的kernel，全连接层就是比如叫matrix_mul这样的kernel，其实我们也可以自己手搓，最多比较慢而已，然后这些kernel可能就被打包到了nv_fatbin这样的段里。</p>
<p>等模型开始运行的时候，我们把神经网络需要的网络层对应的kernel们发送给GPU，GPU把他们暂存起来。然后对于每一个层都有一堆的模型参数，于是CPU向GPU请求空间，然后把参数从文件里读出来传递过去。如果大家运行过tensorflow框架的话，tensorflow运行一开始输出得log就是一堆层的memory的申请，如果显存不够大memory申请失败，tensorflow还会给出warning，因为G神经网络的参数只能寄存到CPU的memory种，GPU运行AI模型速度会比较慢。</p>
<p>之后我们比如要推理一张图像，我们载入这张图像，在GPU中分配内存，把图像存入GPU，然后开始推理。第一个层是比如3*3的卷积层，我们CPU向GPU发送命令，要launch卷积层的kernel，kernel中的data、const data就被存入对应的地方；传递参数比如卷积核的大小、卷积核存放的GPU地址、图像的大小、图像存放的地址，这些值会被写入const data。然后GPU开始运行code，运行完毕之后得到新的结果写入某个memory，这样第一个conv层就运算完毕了，之后依此类推即可。</p>
<h2 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h2><p>至此前段时间对于nvidia GPU的研究就告一段落了，可能很长一段时间都不会在接触这个领域，所以在我忘记之前把记得的都写下来，希望可以帮助朋友们和未来的自己。好了，向着ARM的mali GPU进发。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#cluster-group-cg">https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#cluster-group-cg</a><br><a href="https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#release-notes">https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#release-notes</a><br><a href="https://zhuanlan.zhihu.com/p/75720006">https://zhuanlan.zhihu.com/p/75720006</a><br><a href="https://github.com/NervanaSystems/maxas/wiki/Control-Codes">https://github.com/NervanaSystems/maxas/wiki/Control-Codes</a><br><a href="https://www.informit.com/articles/article.aspx?p=2103809&seqNum=7">https://www.informit.com/articles/article.aspx?p=2103809&amp;seqNum=7</a><br><a href="http://link.zhihu.com/?target=https://github.com/nintyconservation9619/nintyconservation9619.github.io/tree/master/Switch%2520SDK/Docs-JAP/Documents/Package/contents/SASS">http://link.zhihu.com/?target=https%3A//github.com/nintyconservation9619/nintyconservation9619.github.io/tree/master/Switch%2520SDK/Docs-JAP/Documents/Package/contents/SASS</a><br><a href="https://zhuanlan.zhihu.com/p/413145211">https://zhuanlan.zhihu.com/p/413145211</a><br><a href="https://www.cnblogs.com/timlly/p/11471507.html#321-nvidia-tesla%E6%9E%B6%E6%9E%84">https://www.cnblogs.com/timlly/p/11471507.html#321-nvidia-tesla%E6%9E%B6%E6%9E%84</a><br><a href="https://www.cs.rochester.edu/~sree/fermi-tbs/fermi-tbs.html#sec-7-1">https://www.cs.rochester.edu/~sree/fermi-tbs/fermi-tbs.html#sec-7-1</a></p>
]]></content>
      <categories>
        <category>note</category>
      </categories>
      <tags>
        <tag>gpu</tag>
      </tags>
  </entry>
  <entry>
    <title>Securing DMA through Virtualization</title>
    <url>/2022/05/08/paper_reading/DMA/Securing%20DMA%20through%20Virtualization/</url>
    <content><![CDATA[<h1 id="Securing-DMA-through-Virtualization"><a href="#Securing-DMA-through-Virtualization" class="headerlink" title="Securing DMA through Virtualization"></a>Securing DMA through Virtualization</h1><h2 id="problems"><a href="#problems" class="headerlink" title="problems:"></a>problems:</h2><p>这篇paper发于2012年，当时很多嵌入式设备并没有支持IOMMU，且ARM架构的版本较老，没有支持硬件虚拟化，而很多DMA相关的work并没有关注于DMA攻击，于是本文利用DMA虚拟化方式来保证隔离，防止DMA attack。</p>
<h2 id="contribution"><a href="#contribution" class="headerlink" title="contribution:"></a>contribution:</h2><ul>
<li>描述了如何使用虚拟化在ARMv5上来保护DMA</li>
<li>展示了不需要额外硬件支持的DMA虚拟化</li>
<li>对方案进行安全性和性能分析</li>
<li>形式化验证*</li>
</ul>
<h2 id="Related-work："><a href="#Related-work：" class="headerlink" title="Related work："></a>Related work：</h2><p>过去的工作都是在嵌入式系统中使用虚拟化，并关注于移植虚拟化层面和性能分析层面。<br>有人提出了在没有IOMMU时候监控存在的恶意设备驱动程序，但是没有支持多guest，也没有调度相关功能。</p>
<h2 id="Assumptions："><a href="#Assumptions：" class="headerlink" title="Assumptions："></a>Assumptions：</h2><ul>
<li>DMAC是一个通用的DMAC，并且需要CPU对其进行编程，且DMAC接口暴露给hypervisor。</li>
<li>MMU支持对ARM domains的管理。外设是内存映射的，通过MMU可以控制对它们的访问。</li>
<li>MMU和DMAC等硬件都是正常工作的，没有恶意。</li>
<li>Hypervisor和boot loader&#x2F;BIOS都是可信的。</li>
</ul>
<h2 id="Threat-model"><a href="#Threat-model" class="headerlink" title="Threat model"></a>Threat model</h2><p>攻击者假设拥有Guest完全的控制权，包括运行代码和获取正常权限的数据，Guest目的是攻击其他guest，修改或者读取code和data，或者阻止其运行code。假设其无法决定DMA是否被其他部分使用，（即无法通过测信道攻击通过延迟时间判断。）</p>
<h2 id="Requirements"><a href="#Requirements" class="headerlink" title="Requirements"></a>Requirements</h2><ul>
<li>每次访问DMAC都会陷入hypervisor。</li>
<li>DMAC只执行符合访问策略的操作。即MMU支持权限的读写。</li>
<li>guest不能代表其他guest发送DMA请求。</li>
<li>调度不会影响安全性。</li>
<li>hypervisor不能被guest修改。</li>
<li>DMAC任务要么由DMAC处理，要么进入队列。</li>
<li>每个DMA请求都会被处理，处理了之后从DMAC删除。</li>
</ul>
<p>1-5保证了隔离性，6-7保证了可用性（Availability）。</p>
<h2 id="Design："><a href="#Design：" class="headerlink" title="Design："></a>Design：</h2><p>设备被映射进内存，于是受MMU控制，于是可以控制拦截与DMAC相关的操作。<br>DMAC是OVP模拟的，hypervisor是一个别人实现轻量级的。核心就是DMA虚拟化，即模拟DMAC，就是在使用真是DMAC之前，会陷入hypervisor，在模拟DMAC处进行管理转发。</p>
<ul>
<li>Shadow Copies and Scheduling：为每个客户模式设置一个DMAC副本，从而防止DMAC设置期间的干扰，当guest需要写入DMAC寄存器时，被hypervisor拦截，然后将其写入shadow DMAC，物理DMAC只接受hypervisor发送过来的数据。然后用一个队列去调度所有的DMA tasks，相应的shadow DMAC中的任务被设置为waiting状态和active状态。</li>
<li>Trapping with the Data Abort Handler：陷入hypervisor后，data abort handler会对虚拟的DMA请求进行翻译，载入真实的物理DMAC。</li>
<li>Trapping with the Data Abort Handler：？？直接用MMU相关的权限。</li>
<li>Handling DMA Interrupts：用以通知DMA已经完成，hypervisor会收到这些interrupts，然后发送给guest。</li>
</ul>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>DMA</tag>
      </tags>
  </entry>
  <entry>
    <title>HyperFuzzer：An Efficient Hybrid Fuzzer for Virtual CPUs</title>
    <url>/2022/05/08/paper_reading/Fuzz/HyperFuzzer/</url>
    <content><![CDATA[<h1 id="HyperFuzzer-An-Efficient-Hybrid-Fuzzer-for-Virtual-CPUs"><a href="#HyperFuzzer-An-Efficient-Hybrid-Fuzzer-for-Virtual-CPUs" class="headerlink" title="HyperFuzzer: An Efficient Hybrid Fuzzer for Virtual CPUs"></a>HyperFuzzer: An Efficient Hybrid Fuzzer for Virtual CPUs</h1><h2 id="contribution"><a href="#contribution" class="headerlink" title="contribution"></a>contribution</h2><ul>
<li>The first efficient hybrid fuzzer for virtual CPUs without using a slow hardware emulator. </li>
<li>The Nimble Symbolic Execution technique that enables whitebox fuzzing for virtual CPUs with only a control-flow trace recorded by the commodity hardware. </li>
<li>An effective prototype of HyperFuzzer that has found 11 previously unknown virtual CPU bugs in the Hyper-V hypervisor.</li>
</ul>
<h2 id="motivation"><a href="#motivation" class="headerlink" title="motivation"></a>motivation</h2><p>​	这篇paper以一个hyperfuzzer找到的bug来解释动机。这个bug发生在16bit 保护模式下的情况，并且没有页面保护的时候，VM试图执行一个APIC的MMIO区域的指令，该指令被map在物理地址0xFEE00000位置，随后会trap进入hypervisor模拟该指令，在这种情况下，hypervisor发现VM处于16bit情况下，于是会把前面的物理地址转为低16位，即0x0000，从而发生bug。这主要是由于hypervisor无法理解在x86上16bit实模式和16bit保护模式的区别。16bit实模式和保护模式的有效数据地址都是16bit，然后指令指针在实模式下是16bit，在保护模式下是32bit。（这种差异在手册中也没有详细说明）。</p>
<p>​	为了找寻这种bug，从而开发了hyperfuzzer，并且提出了两个requirements：</p>
<ul>
<li>必须mutate一个VM entire state，而不是仅仅是它运行的指令。这是由于有些状态定义了vm的模式状态，就比如上面bug所说的16bit保护模式，这些状态是被GDT中的两个bit位控制的。</li>
<li>HyperFuzzer必须支持基于动态符号执行的精确输入生成。为了在16位保护模式下生成新的虚拟机状态，HyperFuzzer需要对guest GDT中的2位进行反置。这要求它精确地跟踪虚拟机管理程序检查guest VM模式时的路径约束。</li>
</ul>
<h2 id="overview"><a href="#overview" class="headerlink" title="overview"></a>overview</h2><h3 id="thread-model"><a href="#thread-model" class="headerlink" title="thread model"></a>thread model</h3><p>​	假设攻击者能够完全控制guest VM，并且能够控制虚拟硬盘，由此可以控制boot的代码以及guestOS。</p>
<h3 id="hyperfuzzer’s-design"><a href="#hyperfuzzer’s-design" class="headerlink" title="hyperfuzzer’s design"></a>hyperfuzzer’s design</h3><p><img src="https://raw.githubusercontent.com/unsatisfying/picture-server/main/img/image-20211209131632848.png" alt="image-20211209131632848"></p>
<p>Inputs就是一个完整的VM state，即一些寄存器状态，一些即将运行的指令以及这些指令运行的上下文环境。</p>
<p>每个input loop会在hyper-V的一个VM中运行，这些VM会触发VCPU的执行，然后可能会暂停VM 触发一个陷入到hypervisor。在这个过程中，hyperfuzzer利用Intel PT等硬件特性去记录控制流。</p>
<h2 id="Design"><a href="#Design" class="headerlink" title="Design"></a>Design</h2><h3 id="fuzzing-setup"><a href="#fuzzing-setup" class="headerlink" title="fuzzing setup"></a>fuzzing setup</h3><p><img src="https://raw.githubusercontent.com/unsatisfying/picture-server/main/img/image-20211209132958700.png" alt="image-20211209132958700"></p>
<h3 id="输入模型：将-VM-完整状态作为-fuzzing-input"><a href="#输入模型：将-VM-完整状态作为-fuzzing-input" class="headerlink" title="输入模型：将 VM 完整状态作为 fuzzing input"></a>输入模型：将 VM 完整状态作为 fuzzing input</h3><ul>
<li>传统的 fuzzing 通常把“指令”、“参数”或“系统调用”作为输入来变异。HyperFuzzer 的 insight 是：<strong>虚拟 CPU 的行为主要由虚拟机状态（VM state，包括寄存器、内存、控制结构等）决定</strong>。</li>
<li>因此每个 fuzzing 样本是一个 VM 的完整状态快照（或者说足够完整以使得 hypervisor 在第一次 VM 退出时可以执行）。通过变异该状态，既可以变异要执行的指令，也可以变异周围的架构环境（例如段寄存器、页表、控制寄存器等）。</li>
<li>为了效率，HyperFuzzer 并不要求 snapshot 包含冗余无用状态，而是精简到“架构上必须的那部分”（例如页表只有在必要时候才包含等）。这样输入体积可以压得很小（几百字节级别），便于快速变异与恢复。</li>
</ul>
<h3 id="Fuzzing-运行方式：只触发第一个-VM-trap"><a href="#Fuzzing-运行方式：只触发第一个-VM-trap" class="headerlink" title="Fuzzing 运行方式：只触发第一个 VM trap"></a>Fuzzing 运行方式：只触发第一个 VM trap</h3><ul>
<li>为了简化分析，HyperFuzzer 设计让 VM 在恢复后 <strong>立即触发一次 VM 退出（VMEXIT）</strong>，即 guest 执行一条特殊指令或者通过单步强制退出，以便 hypervisor 介入。然后抓取这次退出进入 hypervisor 的控制流执行，处理完这次退出之后就停止该执行。即只 fuzz “单次 trap 进入 hypervisor 的这条路径”。</li>
<li>这样做的好处是：<ol>
<li>避免在 guest 中做大量执行与符号追踪（减少复杂性）<ol start="2">
<li>每次测试的路径较短，使得符号执行、约束求解更加可控</li>
</ol>
</li>
</ol>
</li>
<li>虽然看似只能覆盖一次 VMEXIT 的代码路径，但论文认为：因为你可以对 VM 状态做变异，不同的状态就可能触发 hypervisor 内不同的分支／退出行为，从而整体可以探索较为全面的 vCPU 实现。</li>
</ul>
<h3 id="Nimble-Symbolic-Execution（NSE）：用低开销控制流-重构近似执行轨迹"><a href="#Nimble-Symbolic-Execution（NSE）：用低开销控制流-重构近似执行轨迹" class="headerlink" title="Nimble Symbolic Execution（NSE）：用低开销控制流 + 重构近似执行轨迹"></a>Nimble Symbolic Execution（NSE）：用低开销控制流 + 重构近似执行轨迹</h3><ul>
<li>传统的符号执行（白盒分析）需要详尽的执行轨迹（control flow + data flow）记录。但这样会带巨大的开销，尤其是在 hypervisor 级别。HyperFuzzer 不记录完整数据流，仅借助<strong>硬件跟踪机制</strong>（如 Intel Processor Trace, PT）来记录 <strong>控制流</strong>，即指令&#x2F;分支走向（不记录寄存器或内存具体值）</li>
<li>然后，通过已知的 fuzzing input（即 VM 状态）+ 控制流记录，<strong>在用户态重构一个“近似”的执行轨迹</strong>，在这个轨迹上做符号执行、路径约束处理，生成新的输入。这个过程就是论文称的 <strong>Nimble Symbolic Execution (NSE)</strong>。</li>
<li>在重构过程中面临两大挑战：<br>  \1. <strong>缺失内部未知状态</strong>：hypervisor 内部可能有一些状态在控制流记录里不可见（例如超内核内部状态、缓存、内部指针），这些状态若被用到路径约束或决定 memory 地址，会影响符号执行。论文通过“占位赋值”（给未知内存&#x2F;寄存器赋一个任意合法具体值）在多数情况下规避问题；并指出在 CPU 虚拟化场景下约 98% 的路径判断不依赖这些未知内部状态。<br>  \2. <strong>隐藏硬件检查 (hidden hardware constraints)</strong>：硬件在做 VMEXIT 前会对 VM 状态做一些验证、检查（这些在 hypervisor 代码里不可见），这些检查不在控制流里也不会被符号执行捕获。若生成的新输入违反这些硬件检查，则硬件可能拒绝进入 hypervisor。论文为此做了两方面缓解：<br>  - 对符号变量做<strong>按位建模</strong>，防止在求解新输入时无意间破坏那些硬件已有的约束（比如某个 bit 一定要为 1）<br>  - 应用 “无关约束消除”（unrelated constraint elimination）技巧：在构造 path constraint 时，移除与欲翻流程分支无关的符号变量或约束，以减少可能引入与硬件检查冲突的改动。</li>
</ul>
<h3 id="混合机制：覆盖导向-符号指导结合"><a href="#混合机制：覆盖导向-符号指导结合" class="headerlink" title="混合机制：覆盖导向 + 符号指导结合"></a>混合机制：覆盖导向 + 符号指导结合</h3><ul>
<li>HyperFuzzer 的 fuzzing 循环融合了灰盒变异 (coverage-guided mutation, 如 AFL) 和 白盒输入生成 (通过 NSE) 两部分。对于进入新 coverage 的样本，会交给 NSE 去生成新的输入；新输入再执行、判断是否扩展 coverage。</li>
<li>为了效率，只有一部分样本（“interesting inputs”）才会被送去 NSE 符号处理，而非所有样本都做符号执行，从而节省资源。</li>
</ul>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>Fuzz</tag>
      </tags>
  </entry>
  <entry>
    <title>中断</title>
    <url>/2022/04/27/note/%E4%B8%AD%E6%96%AD/</url>
    <content><![CDATA[<h1 id="中断"><a href="#中断" class="headerlink" title="中断"></a>中断</h1><p>​	说到中断离不开处理器架构，在x86架构下同步的称为异常，异步的称为中断，其区别为：</p>
<ul>
<li>中断：中断分为可屏蔽中断和不可屏蔽中断，其可以发生在指令执行的任何时间，其中可屏蔽中断是由外部设备发出的中断，不可屏蔽中断通过NMI引脚接入CPU。</li>
<li>异常：指的是CPU执行指令的同时发现执行该指令出错，可以分为处理器检测异常和编程异常，其中处理器检测异常包括故障，陷阱，终止；编程异常包括程序调用int等指令时发出的异常（这种异常有时候也被成为软中断，命名问题，本文称其为异常）</li>
</ul>
<h2 id="misc"><a href="#misc" class="headerlink" title="misc"></a>misc</h2><p>本文基于Linux-5.15。主要涉及中断处理，异常处理，系统调用三个方面的函数调用以及Linux处理逻辑，防止混淆。硬件上的内容就不说了，都耳熟能详了。</p>
<p>在<code>arch/x86/include/asm/irq_vectors.h</code>中列了一些宏，用以表示<code>IDT</code>表的一些布局情况，其中可以知道</p>
<ul>
<li>Vectors   0 …  31 	: system traps and exceptions - hardcoded events</li>
<li>Vectors  32 … 127   : device interrupts</li>
<li>Vector  128              : legacy int80 syscall interface</li>
<li>Vectors 129 … LOCAL_TIMER_VECTOR-1</li>
<li>Vectors LOCAL_TIMER_VECTOR … 255 : special interrupts</li>
</ul>
<p>其中0 ~ 31号为CPU保留的异常，32 ~ 127号为外部设备中断，128号为系统调用。</p>
<h2 id="异常处理"><a href="#异常处理" class="headerlink" title="异常处理"></a>异常处理</h2><p>先从异常处理开始吧，因为异常是在表中是0~31号向量。</p>
<p>在文件<code>arch/x86/include/asm/trapnr.h</code>中保存了异常向量的定义：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> X86_TRAP_DE		 0	<span class="comment">/* Divide-by-zero */</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> X86_TRAP_DB		 1	<span class="comment">/* Debug */</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> X86_TRAP_NMI		 2	<span class="comment">/* Non-maskable Interrupt */</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> X86_TRAP_BP		 3	<span class="comment">/* Breakpoint */</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> X86_TRAP_OF		 4	<span class="comment">/* Overflow */</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> X86_TRAP_BR		 5	<span class="comment">/* Bound Range Exceeded */</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> X86_TRAP_UD		 6	<span class="comment">/* Invalid Opcode */</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> X86_TRAP_NM		 7	<span class="comment">/* Device Not Available */</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> X86_TRAP_DF		 8	<span class="comment">/* Double Fault */</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> X86_TRAP_OLD_MF		 9	<span class="comment">/* Coprocessor Segment Overrun */</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> X86_TRAP_TS		10	<span class="comment">/* Invalid TSS */</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> X86_TRAP_NP		11	<span class="comment">/* Segment Not Present */</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> X86_TRAP_SS		12	<span class="comment">/* Stack Segment Fault */</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> X86_TRAP_GP		13	<span class="comment">/* General Protection Fault */</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> X86_TRAP_PF		14	<span class="comment">/* Page Fault */</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> X86_TRAP_SPURIOUS	15	<span class="comment">/* Spurious Interrupt */</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> X86_TRAP_MF		16	<span class="comment">/* x87 Floating-Point Exception */</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> X86_TRAP_AC		17	<span class="comment">/* Alignment Check */</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> X86_TRAP_MC		18	<span class="comment">/* Machine Check */</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> X86_TRAP_XF		19	<span class="comment">/* SIMD Floating-Point Exception */</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> X86_TRAP_VE		20	<span class="comment">/* Virtualization Exception */</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> X86_TRAP_CP		21	<span class="comment">/* Control Protection Exception */</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> X86_TRAP_VC		29	<span class="comment">/* VMM Communication Exception */</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> X86_TRAP_IRET		32	<span class="comment">/* IRET Exception */</span></span></span><br></pre></td></tr></table></figure>



<h3 id="异常向量初始化"><a href="#异常向量初始化" class="headerlink" title="异常向量初始化"></a>异常向量初始化</h3><p>首先启动内核时候，需要初始化异常向量表。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">start_kernel()  <span class="comment">//init/main.c</span></span><br><span class="line"> -&gt;trap_init() 	<span class="comment">//arch/x86/kernel/traps.c</span></span><br><span class="line">  -&gt;idt_setup_traps()	<span class="comment">//arch/x86/kernel/idt.c</span></span><br><span class="line">   -&gt;idt_setup_from_table(idt_table, def_idts, ARRAY_SIZE(def_idts), <span class="literal">true</span>);</span><br></pre></td></tr></table></figure>

<p>上面最后调用在函数<code>idt_setup_from_table</code>中，我们看看这个函数的几个参数定义。在<code>arch/x86/kernel/idt.c</code>中定义了idt表和描述符。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">static</span> gate_desc idt_table[IDT_ENTRIES] __page_aligned_bss;</span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="class"><span class="keyword">struct</span> <span class="title">desc_ptr</span> <span class="title">idt_descr</span> __<span class="title">ro_after_init</span> =</span> &#123;</span><br><span class="line">	.size		= IDT_TABLE_SIZE - <span class="number">1</span>,</span><br><span class="line">	.address	= (<span class="type">unsigned</span> <span class="type">long</span>) idt_table,</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="type">const</span> __initconst <span class="class"><span class="keyword">struct</span> <span class="title">idt_data</span> <span class="title">def_idts</span>[] =</span> &#123;</span><br><span class="line">	INTG(X86_TRAP_DE,		asm_exc_divide_error),</span><br><span class="line">	ISTG(X86_TRAP_NMI,		asm_exc_nmi, IST_INDEX_NMI),</span><br><span class="line">	INTG(X86_TRAP_BR,		asm_exc_bounds),</span><br><span class="line">	INTG(X86_TRAP_UD,		asm_exc_invalid_op),</span><br><span class="line">	INTG(X86_TRAP_NM,		asm_exc_device_not_available),</span><br><span class="line">	INTG(X86_TRAP_OLD_MF,		asm_exc_coproc_segment_overrun),</span><br><span class="line">	INTG(X86_TRAP_TS,		asm_exc_invalid_tss),</span><br><span class="line">	INTG(X86_TRAP_NP,		asm_exc_segment_not_present),</span><br><span class="line">	INTG(X86_TRAP_SS,		asm_exc_stack_segment),</span><br><span class="line">	INTG(X86_TRAP_GP,		asm_exc_general_protection),</span><br><span class="line">	INTG(X86_TRAP_SPURIOUS,		asm_exc_spurious_interrupt_bug),</span><br><span class="line">	INTG(X86_TRAP_MF,		asm_exc_coprocessor_error),</span><br><span class="line">	INTG(X86_TRAP_AC,		asm_exc_alignment_check),</span><br><span class="line">	INTG(X86_TRAP_XF,		asm_exc_simd_coprocessor_error),</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_X86_32</span></span><br><span class="line">	TSKG(X86_TRAP_DF,		GDT_ENTRY_DOUBLEFAULT_TSS),</span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line">	ISTG(X86_TRAP_DF,		asm_exc_double_fault, IST_INDEX_DF),</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">	ISTG(X86_TRAP_DB,		asm_exc_debug, IST_INDEX_DB),</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_X86_MCE</span></span><br><span class="line">	ISTG(X86_TRAP_MC,		asm_exc_machine_check, IST_INDEX_MCE),</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_AMD_MEM_ENCRYPT</span></span><br><span class="line">	ISTG(X86_TRAP_VC,		asm_exc_vmm_communication, IST_INDEX_VC),</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">	SYSG(X86_TRAP_OF,		asm_exc_overflow),</span><br><span class="line"><span class="meta">#<span class="keyword">if</span> defined(CONFIG_IA32_EMULATION)</span></span><br><span class="line">	SYSG(IA32_SYSCALL_VECTOR,	entry_INT80_compat),</span><br><span class="line"><span class="meta">#<span class="keyword">elif</span> defined(CONFIG_X86_32)</span></span><br><span class="line">	SYSG(IA32_SYSCALL_VECTOR,	entry_INT80_32),</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p><code>idt_setup_from_table</code>函数本质就是将<code>def_idts</code>内容赋给<code>idt_table</code>。</p>
<p>我们一个个分析，在分析<code>def_idts</code>之前首先得看几个宏，如下所示。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> G(_vector, _addr, _ist, _type, _dpl, _segment)	\</span></span><br><span class="line"><span class="meta">	&#123;						\</span></span><br><span class="line"><span class="meta">		.vector		= _vector,		\</span></span><br><span class="line"><span class="meta">		.bits.ist	= _ist,			\</span></span><br><span class="line"><span class="meta">		.bits.type	= _type,		\</span></span><br><span class="line"><span class="meta">		.bits.dpl	= _dpl,			\</span></span><br><span class="line"><span class="meta">		.bits.p		= 1,			\</span></span><br><span class="line"><span class="meta">		.addr		= _addr,		\</span></span><br><span class="line"><span class="meta">		.segment	= _segment,		\</span></span><br><span class="line"><span class="meta">	&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* Interrupt gate */</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> INTG(_vector, _addr)				\</span></span><br><span class="line"><span class="meta">	G(_vector, _addr, DEFAULT_STACK, GATE_INTERRUPT, DPL0, __KERNEL_CS)</span></span><br><span class="line"><span class="comment">/* System interrupt gate */</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> SYSG(_vector, _addr)				\</span></span><br><span class="line"><span class="meta">	G(_vector, _addr, DEFAULT_STACK, GATE_INTERRUPT, DPL3, __KERNEL_CS)</span></span><br></pre></td></tr></table></figure>

<p>于是便可知道其内容为x86架构下中断门描述符，其格式如下，其实IDT（INTERRUPT DESCRIPTOR TABLE）表中的表项，该表由IDTR寄存器指向，其格式如下图所示。</p>
<p><img src="https://raw.githubusercontent.com/unsatisfying/picture-server/main/imgimage-20220426205810991.png" alt="image-20220426205810991"></p>
<p><img src="https://raw.githubusercontent.com/unsatisfying/picture-server/main/imgx86%20%E4%B8%AD%E6%96%AD%E9%97%A8%E6%8F%8F%E8%BF%B0%E7%AC%A6.png" alt="image-20220426171754324"></p>
<p>最后再来看手册里一张图，这张图大有门道，首先可以看到Linux中用<code>__KERNEL_CS</code>作为其段描述符，也就是图中的GDT表中的索引，而我们知道Linux使用的是平坦内存模型，所以段基址为0，也就导致offset就是异常处理函数的地址。</p>
<p><img src="https://raw.githubusercontent.com/unsatisfying/picture-server/main/imgx86-interrupt%20call.png" alt="image-20220426173926048"></p>
<p>​	上述过程将IDT表设置好之后，在后面会通过调用<code>load_idt(&amp;idt_descr);</code>将描述符写入IDTR寄存器，至此就完成了IDT的初始化。</p>
<h3 id="异常向量处理函数"><a href="#异常向量处理函数" class="headerlink" title="异常向量处理函数"></a>异常向量处理函数</h3><p>前面我们说到把IDT的内容填充完，使得CPU硬件能够找到异常向量处理函数的入口地址，接下来我们来看这些函数内部是如何处理的。</p>
<p>在文件<code>arch/x86/kernel/traps.c</code>中有类似如下的定义，可以看到这些定义大部分最后都会调用的<code>do_error_trap</code>来进行处理。也有一部分是自己实现的函数，自己调用。只不过这部分的C代码定义有点难看懂，知道异常处理后面到这来了就行。(老的kernel版本是通过汇编中定义的DO_ERROR函数来作为统一的入口，新的kernel现在改了，下一节我们会讲。这也是因此网上和很多书上都讲解的是DO_ERROR和do_sym那一套)。实际上下面的代码显示的code并不是在IDT表中填充的地址，硬件上虽然设计了可以让进程在触发异常时跳转到异常处理函数的硬件逻辑，但是Linux不是那么做的，Linux将所有IDT表项中call的异常处理函数地址是一个统一的入口，该入口会在下一节讲解。 </p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> DEFINE_IDTENTRY(func)						\</span></span><br><span class="line"><span class="meta">static __always_inline void __##func(struct pt_regs *regs);		\</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line">DEFINE_IDTENTRY(exc_divide_error)</span><br><span class="line">&#123;</span><br><span class="line">	do_error_trap(regs, <span class="number">0</span>, <span class="string">&quot;divide error&quot;</span>, X86_TRAP_DE, SIGFPE,</span><br><span class="line">		      FPE_INTDIV, error_get_trap_addr(regs));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">DEFINE_IDTENTRY(exc_overflow)</span><br><span class="line">&#123;</span><br><span class="line">	do_error_trap(regs, <span class="number">0</span>, <span class="string">&quot;overflow&quot;</span>, X86_TRAP_OF, SIGSEGV, <span class="number">0</span>, <span class="literal">NULL</span>);</span><br><span class="line">&#125;</span><br><span class="line">DEFINE_IDTENTRY_ERRORCODE(exc_invalid_tss)</span><br><span class="line">&#123;</span><br><span class="line">	do_error_trap(regs, error_code, <span class="string">&quot;invalid TSS&quot;</span>, X86_TRAP_TS, SIGSEGV,</span><br><span class="line">		      <span class="number">0</span>, <span class="literal">NULL</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">DEFINE_IDTENTRY_ERRORCODE(exc_segment_not_present)</span><br><span class="line">&#123;</span><br><span class="line">	do_error_trap(regs, error_code, <span class="string">&quot;segment not present&quot;</span>, X86_TRAP_NP,</span><br><span class="line">		      SIGBUS, <span class="number">0</span>, <span class="literal">NULL</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>OK，总之异常处理我们现在知道最后走到了<code>do_error_trap</code>，我们看看这个函数里面是什么东西，同样是traps.c文件。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">static</span> <span class="type">void</span> <span class="title function_">do_error_trap</span><span class="params">(<span class="keyword">struct</span> pt_regs *regs, <span class="type">long</span> error_code, <span class="type">char</span> *str,</span></span><br><span class="line"><span class="params">	<span class="type">unsigned</span> <span class="type">long</span> trapnr, <span class="type">int</span> signr, <span class="type">int</span> sicode, <span class="type">void</span> __user *addr)</span></span><br><span class="line">&#123;</span><br><span class="line">	RCU_LOCKDEP_WARN(!rcu_is_watching(), <span class="string">&quot;entry code didn&#x27;t wake RCU&quot;</span>);</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> (notify_die(DIE_TRAP, str, regs, error_code, trapnr, signr) !=</span><br><span class="line">			NOTIFY_STOP) &#123;</span><br><span class="line">		cond_local_irq_enable(regs);</span><br><span class="line">		do_trap(trapnr, signr, str, regs, error_code, sicode, addr);</span><br><span class="line">		cond_local_irq_disable(regs);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="type">void</span></span><br><span class="line"><span class="title function_">do_trap</span><span class="params">(<span class="type">int</span> trapnr, <span class="type">int</span> signr, <span class="type">char</span> *str, <span class="keyword">struct</span> pt_regs *regs,</span></span><br><span class="line"><span class="params">	<span class="type">long</span> error_code, <span class="type">int</span> sicode, <span class="type">void</span> __user *addr)</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">task_struct</span> *<span class="title">tsk</span> =</span> current;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> (!do_trap_no_signal(tsk, trapnr, str, regs, error_code))</span><br><span class="line">		<span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">	show_signal(tsk, signr, <span class="string">&quot;trap &quot;</span>, str, regs, error_code);</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> (!sicode)</span><br><span class="line">		force_sig(signr);</span><br><span class="line">	<span class="keyword">else</span></span><br><span class="line">		force_sig_fault(signr, sicode, addr);</span><br><span class="line">&#125;</span><br><span class="line">NOKPROBE_SYMBOL(do_trap);</span><br></pre></td></tr></table></figure>

<p>可以看到，很多处理过程最后都走到了<code>do_trap</code>函数里，且该函数里通过发送一些信号给进程来进行处理异常，而进程收到信号之后会执行信号处理函数。</p>
<h3 id="真正的从用户态陷入内核态执行的代码"><a href="#真正的从用户态陷入内核态执行的代码" class="headerlink" title="真正的从用户态陷入内核态执行的代码"></a>真正的从用户态陷入内核态执行的代码</h3><p>​	很多细心的人应该发现，调用异常处理函数的时候会有一个参数pt_regs, 也就是说明这个函数其实不是真正填到中断向量表里跳转的函数，而是后面分发的函数，那么问题就来了，pt_regs参数是什么，是在什么时候构造的？接下来我们就来讲解真正的从用户态陷入内核态执行的代码逻辑。前方包含大量复杂的汇编和宏，很晦涩难懂。</p>
<p>​	首先Linux-kernel在<code>arch/x86/entry/entry.S</code>中定义了所有内核的入口函数，其中idtentry（idt entry，这样就明白了）函数就是真正写在IDT表中的地址，其代码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line"> * idtentry - Macro to generate entry stubs for simple IDT entries</span><br><span class="line"> * @vector:		Vector number</span><br><span class="line"> * @asmsym:		ASM symbol for the entry point</span><br><span class="line"> * @cfunc:		C function to be called</span><br><span class="line"> * @has_error_code:	Hardware pushed error code on stack</span><br><span class="line"> *</span><br><span class="line"> * The macro emits code to set up the kernel context for straight forward</span><br><span class="line"> * and simple IDT entries. No IST stack, no paranoid entry checks.</span><br><span class="line"> */</span><br><span class="line">.macro idtentry vector asmsym cfunc has_error_code:req</span><br><span class="line">SYM_CODE_START(\asmsym)</span><br><span class="line">	UNWIND_HINT_IRET_REGS offset=\has_error_code*8</span><br><span class="line">	ASM_CLAC</span><br><span class="line"></span><br><span class="line">	.if \has_error_code == 0</span><br><span class="line">		pushq	$-1			/* ORIG_RAX: no syscall to restart */</span><br><span class="line">	.endif</span><br><span class="line"></span><br><span class="line">	.if \vector == X86_TRAP_BP</span><br><span class="line">		/*</span><br><span class="line">		 * If coming from kernel space, create a 6-word gap to allow the</span><br><span class="line">		 * int3 handler to emulate a call instruction.</span><br><span class="line">		 */</span><br><span class="line">		testb	$3, CS-ORIG_RAX(%rsp)</span><br><span class="line">		jnz	.Lfrom_usermode_no_gap_\@</span><br><span class="line">		.rept	6</span><br><span class="line">		pushq	5*8(%rsp)</span><br><span class="line">		.endr</span><br><span class="line">		UNWIND_HINT_IRET_REGS offset=8</span><br><span class="line">.Lfrom_usermode_no_gap_\@:</span><br><span class="line">	.endif</span><br><span class="line"></span><br><span class="line">	idtentry_body \cfunc \has_error_code</span><br><span class="line"></span><br><span class="line">_ASM_NOKPROBE(\asmsym)</span><br><span class="line">SYM_CODE_END(\asmsym)</span><br><span class="line">.endm</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>稍微分析一下，idtentry是一个生成IDT entries的宏，其会生成一个函数，该函数接收一个vecter参数，一个asmsym参数，一个cfunc参数，一个has_error_code参数，其参数说明都在注释里。</p>
<p>但是在执行这个函数之前，也就是在CPU自动跳转到异常处理函数的同时，cpu硬件上会做一些事情，首先他会到TSS中(tr寄存器指向的一个硬件上下文表在GDT中的索引，该表在CPU设计的本意是用于硬件上下文的保存，但是Linux并不那么做，Linux用软件进行保存，而在其中存了kernel stack的地址，tss结构在linux中定义如下)找到kernel stack，其中<code>sp0</code>字段存储了内核栈的地址（64位和32位的定义有所不同，不过这是架构相关内容，得看手册，太细的东西就没必要知道那么清楚了）。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">x86_hw_tss</span> &#123;</span></span><br><span class="line">	u32			reserved1;</span><br><span class="line">	u64			sp0;</span><br><span class="line">	u64			sp1;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * Since Linux does not use ring 2, the &#x27;sp2&#x27; slot is unused by</span></span><br><span class="line"><span class="comment">	 * hardware.  entry_SYSCALL_64 uses it as scratch space to stash</span></span><br><span class="line"><span class="comment">	 * the user RSP value.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	u64			sp2;</span><br><span class="line"></span><br><span class="line">	u64			reserved2;</span><br><span class="line">	u64			ist[<span class="number">7</span>];</span><br><span class="line">	u32			reserved3;</span><br><span class="line">	u32			reserved4;</span><br><span class="line">	u16			reserved5;</span><br><span class="line">	u16			io_bitmap_base;</span><br><span class="line"></span><br><span class="line">&#125; __attribute__((packed));</span><br></pre></td></tr></table></figure>

<p>切换到内核栈之后，CPU还会自动将寄存器压栈，压栈顺序如下图(error code由软件压)，左边是32位，右边是64位，最先入栈是SS，然后是RSP，因为内核栈是从上往下增长的。其中的error code字段有些异常处理会有，有些没有，所以在<code>idtentry()</code>宏中13~18行会进行判断是否有error code，如果有会开辟error code的空间并压栈。</p>
<p><img src="https://raw.githubusercontent.com/unsatisfying/picture-server/main/imgimage-20220426212350991.png" alt="image-20220426212350991"></p>
<p>接着函数就运行<code>idtentry_body \cfunc \has_error_code</code>到了idtentry_body函数处，该函数定义如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line"> * idtentry_body - Macro to emit code calling the C function</span><br><span class="line"> * @cfunc:		C function to be called</span><br><span class="line"> * @has_error_code:	Hardware pushed error code on stack</span><br><span class="line"> */</span><br><span class="line">.macro idtentry_body cfunc has_error_code:req</span><br><span class="line"></span><br><span class="line">	call	error_entry</span><br><span class="line">	UNWIND_HINT_REGS</span><br><span class="line"></span><br><span class="line">	movq	%rsp, %rdi			/* pt_regs pointer into 1st argument*/</span><br><span class="line"></span><br><span class="line">	.if \has_error_code == 1</span><br><span class="line">		movq	ORIG_RAX(%rsp), %rsi	/* get error code into 2nd argument*/</span><br><span class="line">		movq	$-1, ORIG_RAX(%rsp)	/* no syscall to restart */</span><br><span class="line">	.endif</span><br><span class="line"></span><br><span class="line">	call	\cfunc</span><br><span class="line"></span><br><span class="line">	jmp	error_return</span><br><span class="line">.endm</span><br></pre></td></tr></table></figure>

<p>该函数在error_entry函数中构造pt_reg结构体，即把用户态的旧寄存器压栈，然后将栈顶指针(rsp指向pt_reg结构体，该结构体是栈上空间构造的)传递给rdi，我们都知道rdi是x64函数调用的第一个参数，也就终于回到了前面所提的参数是pt_regs的问题了，所以这里call \cfunc才是前面<code>DEFINE_IDTENTRY</code>定义的真正函数，而该参数也是从idtentry中一直传递下来的，相当于:</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">IDT表指向</span><br><span class="line">-&gt;idtentry(<span class="built_in">vector</span>, asmsym, cfunc, has_error_code)</span><br><span class="line">	-&gt;idtentry_body(cfun, has_error_code)</span><br><span class="line">		-&gt;cfunc(pt_regs)</span><br></pre></td></tr></table></figure>

<p>终于清楚了所有的逻辑，我们最后看看error_entry中怎么做的把。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/*</span><br><span class="line"> * Save all registers in pt_regs, and switch GS if needed.</span><br><span class="line"> */</span><br><span class="line">SYM_CODE_START_LOCAL(error_entry)</span><br><span class="line">	UNWIND_HINT_FUNC</span><br><span class="line">	cld</span><br><span class="line">	PUSH_AND_CLEAR_REGS save_ret=1</span><br><span class="line">	ENCODE_FRAME_POINTER 8</span><br><span class="line">	testb	$3, CS+8(%rsp)</span><br><span class="line">	jz	.Lerror_kernelspace</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * We entered from user mode or we&#x27;re pretending to have entered</span><br><span class="line">	 * from user mode due to an IRET fault.</span><br><span class="line">	 */</span><br><span class="line">	SWAPGS</span><br><span class="line">	FENCE_SWAPGS_USER_ENTRY</span><br><span class="line">	/* We have user CR3.  Change to kernel CR3. */</span><br><span class="line">	SWITCH_TO_KERNEL_CR3 scratch_reg=%rax</span><br><span class="line"></span><br><span class="line">.Lerror_entry_from_usermode_after_swapgs:</span><br><span class="line">	/* Put us onto the real thread stack. */</span><br><span class="line">	popq	%r12				/* save return addr in %12 */</span><br><span class="line">	movq	%rsp, %rdi			/* arg0 = pt_regs pointer */</span><br><span class="line">	call	sync_regs</span><br><span class="line">	movq	%rax, %rsp			/* switch stack */</span><br><span class="line">	ENCODE_FRAME_POINTER</span><br><span class="line">	pushq	%r12</span><br><span class="line">	ret</span><br><span class="line"></span><br><span class="line">.Lerror_entry_done_lfence:</span><br><span class="line">	FENCE_SWAPGS_KERNEL_ENTRY</span><br><span class="line">.Lerror_entry_done:</span><br><span class="line">	ret</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * There are two places in the kernel that can potentially fault with</span><br><span class="line">	 * usergs. Handle them here.  B stepping K8s sometimes report a</span><br><span class="line">	 * truncated RIP for IRET exceptions returning to compat mode. Check</span><br><span class="line">	 * for these here too.</span><br><span class="line">	 */</span><br><span class="line">.Lerror_kernelspace:</span><br><span class="line">	leaq	native_irq_return_iret(%rip), %rcx</span><br><span class="line">	cmpq	%rcx, RIP+8(%rsp)</span><br><span class="line">	je	.Lerror_bad_iret</span><br><span class="line">	movl	%ecx, %eax			/* zero extend */</span><br><span class="line">	cmpq	%rax, RIP+8(%rsp)</span><br><span class="line">	je	.Lbstep_iret</span><br><span class="line">	cmpq	$.Lgs_change, RIP+8(%rsp)</span><br><span class="line">	jne	.Lerror_entry_done_lfence</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * hack: .Lgs_change can fail with user gsbase.  If this happens, fix up</span><br><span class="line">	 * gsbase and proceed.  We&#x27;ll fix up the exception and land in</span><br><span class="line">	 * .Lgs_change&#x27;s error handler with kernel gsbase.</span><br><span class="line">	 */</span><br><span class="line">	SWAPGS</span><br><span class="line">	FENCE_SWAPGS_USER_ENTRY</span><br><span class="line">	jmp .Lerror_entry_done</span><br><span class="line"></span><br><span class="line">.Lbstep_iret:</span><br><span class="line">	/* Fix truncated RIP */</span><br><span class="line">	movq	%rcx, RIP+8(%rsp)</span><br><span class="line">	/* fall through */</span><br><span class="line"></span><br><span class="line">.Lerror_bad_iret:</span><br><span class="line">	/*</span><br><span class="line">	 * We came from an IRET to user mode, so we have user</span><br><span class="line">	 * gsbase and CR3.  Switch to kernel gsbase and CR3:</span><br><span class="line">	 */</span><br><span class="line">	SWAPGS</span><br><span class="line">	FENCE_SWAPGS_USER_ENTRY</span><br><span class="line">	SWITCH_TO_KERNEL_CR3 scratch_reg=%rax</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * Pretend that the exception came from user mode: set up pt_regs</span><br><span class="line">	 * as if we faulted immediately after IRET.</span><br><span class="line">	 */</span><br><span class="line">	mov	%rsp, %rdi</span><br><span class="line">	call	fixup_bad_iret</span><br><span class="line">	mov	%rax, %rsp</span><br><span class="line">	jmp	.Lerror_entry_from_usermode_after_swapgs</span><br><span class="line">SYM_CODE_END(error_entry)</span><br></pre></td></tr></table></figure>

<p>其通过调用<code>PUSH_AND_CLEAR_REGS</code>构造pt_regs结构体，将相应的通用寄存器入栈。</p>
<figure class="highlight cos"><table><tr><td class="code"><pre><span class="line">.macro PUSH_AND_CLEAR_REGS rdx=<span class="built_in">%rdx</span> rax=<span class="built_in">%rax</span> save_ret=<span class="number">0</span></span><br><span class="line">	PUSH_REGS rdx=\rdx, rax=\rax, save_ret=\save_ret</span><br><span class="line">	CLEAR_REGS</span><br><span class="line">.endm</span><br><span class="line"></span><br><span class="line">.macro PUSH_REGS rdx=<span class="built_in">%rdx</span> rax=<span class="built_in">%rax</span> save_ret=<span class="number">0</span></span><br><span class="line">	.<span class="keyword">if</span> \save_ret</span><br><span class="line">	pushq	<span class="built_in">%rsi</span>		<span class="comment">/* pt_regs-&gt;si */</span></span><br><span class="line">	movq	<span class="number">8</span>(<span class="built_in">%rsp</span>), <span class="built_in">%rsi</span>	<span class="comment">/* temporarily store the return address in %rsi */</span></span><br><span class="line">	movq	<span class="built_in">%rdi</span>, <span class="number">8</span>(<span class="built_in">%rsp</span>)	<span class="comment">/* pt_regs-&gt;di (overwriting original return address) */</span></span><br><span class="line">	.<span class="keyword">else</span></span><br><span class="line">	pushq   <span class="built_in">%rdi</span>		<span class="comment">/* pt_regs-&gt;di */</span></span><br><span class="line">	pushq   <span class="built_in">%rsi</span>		<span class="comment">/* pt_regs-&gt;si */</span></span><br><span class="line">	.endif</span><br><span class="line">	pushq	\rdx		<span class="comment">/* pt_regs-&gt;dx */</span></span><br><span class="line">	pushq   <span class="built_in">%rcx</span>		<span class="comment">/* pt_regs-&gt;cx */</span></span><br><span class="line">	pushq   \rax		<span class="comment">/* pt_regs-&gt;ax */</span></span><br><span class="line">	pushq   <span class="built_in">%r</span>8		<span class="comment">/* pt_regs-&gt;r8 */</span></span><br><span class="line">	pushq   <span class="built_in">%r</span>9		<span class="comment">/* pt_regs-&gt;r9 */</span></span><br><span class="line">	pushq   <span class="built_in">%r</span>10		<span class="comment">/* pt_regs-&gt;r10 */</span></span><br><span class="line">	pushq   <span class="built_in">%r</span>11		<span class="comment">/* pt_regs-&gt;r11 */</span></span><br><span class="line">	pushq	<span class="built_in">%rbx</span>		<span class="comment">/* pt_regs-&gt;rbx */</span></span><br><span class="line">	pushq	<span class="built_in">%rbp</span>		<span class="comment">/* pt_regs-&gt;rbp */</span></span><br><span class="line">	pushq	<span class="built_in">%r</span>12		<span class="comment">/* pt_regs-&gt;r12 */</span></span><br><span class="line">	pushq	<span class="built_in">%r</span>13		<span class="comment">/* pt_regs-&gt;r13 */</span></span><br><span class="line">	pushq	<span class="built_in">%r</span>14		<span class="comment">/* pt_regs-&gt;r14 */</span></span><br><span class="line">	pushq	<span class="built_in">%r</span>15		<span class="comment">/* pt_regs-&gt;r15 */</span></span><br><span class="line">	UNWIND_HINT_REGS</span><br><span class="line"></span><br><span class="line">	.<span class="keyword">if</span> \save_ret</span><br><span class="line">	pushq	<span class="built_in">%rsi</span>		<span class="comment">/* return address on top of stack */</span></span><br><span class="line">	.endif</span><br><span class="line">.endm</span><br></pre></td></tr></table></figure>

<p>接着后面就不细讲了，其中16行有一个SWAPGS指令，其会交换kernel的CR3和user的CR3，CR3是页表基址，很多人会问地址空间kernel和user不是一起的吗，其实这里是由于KPTI的缘故，因为熔断meltdown和幽灵specter的硬件缺陷导致的漏洞，内核采用了KPTI，将用户页表和内核页表隔离来防止用户通过侧信道攻击获取内核数据，这里便是KPTI的体现，具体自己去查资料。</p>
<p>最后贴一个pt_regs结构体定义，省的读者去找，看了之后是不是突然就明了了栈上的寄存器存储的顺序（64位的）。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">pt_regs</span> &#123;</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * C ABI says these regs are callee-preserved. They aren&#x27;t saved on kernel entry</span></span><br><span class="line"><span class="comment"> * unless syscall needs a complete, fully filled &quot;struct pt_regs&quot;.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> r15;</span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> r14;</span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> r13;</span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> r12;</span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> bp;</span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> bx;</span><br><span class="line"><span class="comment">/* These regs are callee-clobbered. Always saved on kernel entry. */</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> r11;</span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> r10;</span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> r9;</span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> r8;</span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> ax;</span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> cx;</span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> dx;</span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> si;</span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> di;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * On syscall entry, this is syscall#. On CPU exception, this is error code.</span></span><br><span class="line"><span class="comment"> * On hw interrupt, it&#x27;s IRQ number:</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> orig_ax;</span><br><span class="line"><span class="comment">/* Return frame for iretq */</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> ip;</span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> cs;</span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> flags;</span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> sp;</span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> ss;</span><br><span class="line"><span class="comment">/* top of stack page */</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="有始有终"><a href="#有始有终" class="headerlink" title="有始有终"></a>有始有终</h3><p>执行完了异常处理函数，总得返回用户态把，再来看看返回时候的逻辑。在idtentry_body函数中最后会<code>jmp error_return</code>返回，其会判断保存的cs是kernel的还是user的，如果是user则返回user，如果是kernel返回kernel。毕竟执行kernel代码也可能出现异常。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SYM_CODE_START_LOCAL(error_return)</span><br><span class="line">	UNWIND_HINT_REGS</span><br><span class="line">	DEBUG_ENTRY_ASSERT_IRQS_OFF</span><br><span class="line">	testb	$3, CS(%rsp)</span><br><span class="line">	jz	restore_regs_and_return_to_kernel</span><br><span class="line">	jmp	swapgs_restore_regs_and_return_to_usermode</span><br><span class="line">SYM_CODE_END(error_return)</span><br></pre></td></tr></table></figure>

<p>然后截取几段比较重要的，和弹出寄存器相关的代码，其中POP_REGS弹出相关寄存器，然后通过iretq指令会弹出最后的SS:RSP,得到存储的用户&#x2F;内核栈进行返回。这里嵌套了很多跳转的地方，总而言之最后都会到iretq的指令，中间细节就不细讲了。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SYM_CODE_START_LOCAL(common_interrupt_return)</span><br><span class="line">SYM_INNER_LABEL(swapgs_restore_regs_and_return_to_usermode, SYM_L_GLOBAL)</span><br><span class="line">	POP_REGS pop_rdi=0</span><br><span class="line">	addq	$8, %rsp	/* skip regs-&gt;orig_ax */</span><br><span class="line">	</span><br><span class="line">	......</span><br><span class="line"></span><br><span class="line">	popq	%rdi</span><br><span class="line">	SWAPGS</span><br><span class="line">	INTERRUPT_RETURN	/*#define INTERRUPT_RETURN	jmp native_iret*/</span><br><span class="line">SYM_INNER_LABEL(restore_regs_and_return_to_kernel, SYM_L_GLOBAL)</span><br><span class="line">	POP_REGS</span><br><span class="line">	addq	$8, %rsp	/* skip regs-&gt;orig_ax */</span><br><span class="line">	/*</span><br><span class="line">	 * ARCH_HAS_MEMBARRIER_SYNC_CORE rely on IRET core serialization</span><br><span class="line">	 * when returning from IPI handler.</span><br><span class="line">	 */</span><br><span class="line">	INTERRUPT_RETURN  /*#define INTERRUPT_RETURN	jmp native_iret*/</span><br><span class="line">SYM_INNER_LABEL_ALIGN(native_iret, SYM_L_GLOBAL)</span><br><span class="line">	UNWIND_HINT_IRET_REGS</span><br><span class="line">	</span><br><span class="line">	......</span><br><span class="line"></span><br><span class="line">SYM_INNER_LABEL(native_irq_return_iret, SYM_L_GLOBAL)	</span><br><span class="line">	iretq</span><br><span class="line">SYM_CODE_END(common_interrupt_return)</span><br><span class="line">_ASM_NOKPROBE(common_interrupt_return)</span><br></pre></td></tr></table></figure>



<h2 id="中断处理"><a href="#中断处理" class="headerlink" title="中断处理"></a>中断处理</h2><p>讲完了异常再来讲中断。还是一样的过程，先是初始化，然后是发生中断时候的逻辑，最后是退出中断的逻辑。</p>
<h3 id="中断向量初始化"><a href="#中断向量初始化" class="headerlink" title="中断向量初始化"></a>中断向量初始化</h3><p>中断向量初始化的函数调用逻辑如下</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">start_kernel()</span><br><span class="line">    -&gt;init_IRQ()</span><br><span class="line">        -&gt;native_init_IRQ()</span><br><span class="line">            -&gt;idt_setup_apic_and_irq_gates()</span><br><span class="line">                -&gt;idt_setup_from_table(idt_table, apic_idts, ARRAY_SIZE(apic_idts), <span class="literal">true</span>);</span><br><span class="line">			for_each_clear_bit_from(i, system_vectors, FIRST_SYSTEM_VECTOR) &#123;</span><br><span class="line">				entry = irq_entries_start + <span class="number">8</span> * (i - FIRST_EXTERNAL_VECTOR);</span><br><span class="line">				set_intr_gate(i, entry);</span><br><span class="line">			&#125;</span><br><span class="line">                -&gt;load_idt(&amp;idt_descr);</span><br></pre></td></tr></table></figure>

<p>又是熟悉的操作呗，<code>idt_setup_from_table</code>函数把<code>apic_idts</code>的内容拷贝到<code>idt_table</code>,上面讲过<code>idt_table</code>是什么，这里我们就看看<code>apic_idts</code>定义,哈哈明了了，又是一样的东西：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">static</span> <span class="type">const</span> __initconst <span class="class"><span class="keyword">struct</span> <span class="title">idt_data</span> <span class="title">apic_idts</span>[] =</span> &#123;</span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_SMP</span></span><br><span class="line">	INTG(RESCHEDULE_VECTOR,			asm_sysvec_reschedule_ipi),</span><br><span class="line">	INTG(CALL_FUNCTION_VECTOR,		asm_sysvec_call_function),</span><br><span class="line">	INTG(CALL_FUNCTION_SINGLE_VECTOR,	asm_sysvec_call_function_single),</span><br><span class="line">	INTG(IRQ_MOVE_CLEANUP_VECTOR,		asm_sysvec_irq_move_cleanup),</span><br><span class="line">	INTG(REBOOT_VECTOR,			asm_sysvec_reboot),</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_X86_THERMAL_VECTOR</span></span><br><span class="line">	INTG(THERMAL_APIC_VECTOR,		asm_sysvec_thermal),</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_X86_MCE_THRESHOLD</span></span><br><span class="line">	INTG(THRESHOLD_APIC_VECTOR,		asm_sysvec_threshold),</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_X86_MCE_AMD</span></span><br><span class="line">	INTG(DEFERRED_ERROR_VECTOR,		asm_sysvec_deferred_error),</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_X86_LOCAL_APIC</span></span><br><span class="line">	INTG(LOCAL_TIMER_VECTOR,		asm_sysvec_apic_timer_interrupt),</span><br><span class="line">	INTG(X86_PLATFORM_IPI_VECTOR,		asm_sysvec_x86_platform_ipi),</span><br><span class="line"><span class="meta"># <span class="keyword">ifdef</span> CONFIG_HAVE_KVM</span></span><br><span class="line">	INTG(POSTED_INTR_VECTOR,		asm_sysvec_kvm_posted_intr_ipi),</span><br><span class="line">	INTG(POSTED_INTR_WAKEUP_VECTOR,		asm_sysvec_kvm_posted_intr_wakeup_ipi),</span><br><span class="line">	INTG(POSTED_INTR_NESTED_VECTOR,		asm_sysvec_kvm_posted_intr_nested_ipi),</span><br><span class="line"><span class="meta"># <span class="keyword">endif</span></span></span><br><span class="line"><span class="meta"># <span class="keyword">ifdef</span> CONFIG_IRQ_WORK</span></span><br><span class="line">	INTG(IRQ_WORK_VECTOR,			asm_sysvec_irq_work),</span><br><span class="line"><span class="meta"># <span class="keyword">endif</span></span></span><br><span class="line">	INTG(SPURIOUS_APIC_VECTOR,		asm_sysvec_spurious_apic_interrupt),</span><br><span class="line">	INTG(ERROR_APIC_VECTOR,			asm_sysvec_error_interrupt),</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="中断处理函数"><a href="#中断处理函数" class="headerlink" title="中断处理函数"></a>中断处理函数</h3><p>​	还是同样的，瞅瞅中断处理函数的定义吧，这里截取了一小部分，熟悉的DECLARE_IDTENTRY宏：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* System vector entry points */</span></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_X86_LOCAL_APIC</span></span><br><span class="line">DECLARE_IDTENTRY_SYSVEC(ERROR_APIC_VECTOR,		sysvec_error_interrupt);</span><br><span class="line">DECLARE_IDTENTRY_SYSVEC(SPURIOUS_APIC_VECTOR,		sysvec_spurious_apic_interrupt);</span><br><span class="line">DECLARE_IDTENTRY_SYSVEC(LOCAL_TIMER_VECTOR,		sysvec_apic_timer_interrupt);</span><br><span class="line">DECLARE_IDTENTRY_SYSVEC(X86_PLATFORM_IPI_VECTOR,	sysvec_x86_platform_ipi);</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_SMP</span></span><br><span class="line">DECLARE_IDTENTRY(RESCHEDULE_VECTOR,			sysvec_reschedule_ipi);</span><br><span class="line">DECLARE_IDTENTRY_SYSVEC(IRQ_MOVE_CLEANUP_VECTOR,	sysvec_irq_move_cleanup);</span><br><span class="line">DECLARE_IDTENTRY_SYSVEC(REBOOT_VECTOR,			sysvec_reboot);</span><br><span class="line">DECLARE_IDTENTRY_SYSVEC(CALL_FUNCTION_SINGLE_VECTOR,	sysvec_call_function_single);</span><br><span class="line">DECLARE_IDTENTRY_SYSVEC(CALL_FUNCTION_VECTOR,		sysvec_call_function);</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">......</span><br></pre></td></tr></table></figure>

<p>​	当然函数内容也截取一小部分，就是真正处理中断的地方。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">DEFINE_IDTENTRY_SYSVEC_SIMPLE(sysvec_reschedule_ipi)</span><br><span class="line">&#123;</span><br><span class="line">	ack_APIC_irq();</span><br><span class="line">	trace_reschedule_entry(RESCHEDULE_VECTOR);</span><br><span class="line">	inc_irq_stat(irq_resched_count);</span><br><span class="line">	scheduler_ipi();</span><br><span class="line">	trace_reschedule_exit(RESCHEDULE_VECTOR);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">DEFINE_IDTENTRY_SYSVEC(sysvec_apic_timer_interrupt)</span><br><span class="line">&#123;</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">pt_regs</span> *<span class="title">old_regs</span> =</span> set_irq_regs(regs);</span><br><span class="line"></span><br><span class="line">	ack_APIC_irq();</span><br><span class="line">	trace_local_timer_entry(LOCAL_TIMER_VECTOR);</span><br><span class="line">	local_apic_timer_interrupt();</span><br><span class="line">	trace_local_timer_exit(LOCAL_TIMER_VECTOR);</span><br><span class="line"></span><br><span class="line">	set_irq_regs(old_regs);</span><br><span class="line">&#125;</span><br><span class="line">......</span><br></pre></td></tr></table></figure>

<p>当然上面列出的是有中断处理函数定义的地方，但是不是所有的32~127号中断向量都被定义了的，肯定会有一些空缺，空缺的地方怎么填呢，回忆一下中断向量初始化的函数调用逻辑，可以看到在函数<code>idt_setup_apic_and_irq_gates</code>有那么一部分代码，如下所示，其将IDT中空缺的位置用irq_entries_start加上了一个偏移填充，也就是跳转到了irq_entries_start数组中某个index的地方。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">for_each_clear_bit_from(i, system_vectors, FIRST_SYSTEM_VECTOR) &#123;</span><br><span class="line">	entry = irq_entries_start + <span class="number">8</span> * (i - FIRST_EXTERNAL_VECTOR);</span><br><span class="line">	set_intr_gate(i, entry);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>OK我们来看看irq_entries_start里面是什么：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">	.align 8</span><br><span class="line">SYM_CODE_START(irq_entries_start)</span><br><span class="line">    vector=FIRST_EXTERNAL_VECTOR</span><br><span class="line">    .rept NR_EXTERNAL_VECTORS</span><br><span class="line">	UNWIND_HINT_IRET_REGS</span><br><span class="line">0 :</span><br><span class="line">	.byte	0x6a, vector</span><br><span class="line">	jmp	asm_common_interrupt</span><br><span class="line">	nop</span><br><span class="line">	/* Ensure that the above is 8 bytes max */</span><br><span class="line">	. = 0b + 8</span><br><span class="line">	vector = vector+1</span><br><span class="line">    .endr</span><br><span class="line">SYM_CODE_END(irq_entries_start)</span><br></pre></td></tr></table></figure>

<p>看不懂没关系，其实这个数组中填充了8字节的汇编指令，每8字节都是如下的形式。</p>
<figure class="highlight scss"><table><tr><td class="code"><pre><span class="line"><span class="number">0</span><span class="built_in">x6a</span>(push) xxx </span><br><span class="line"><span class="number">0</span><span class="built_in">xe9</span>(jmp) asm_common_interrupt</span><br><span class="line"><span class="number">0</span><span class="built_in">x90</span>(nop)</span><br></pre></td></tr></table></figure>

<p>也就是往栈上push了一个向量号，然后跳转到<code>asm_common_interrupt</code>处。</p>
<h3 id="真正陷入内核态执行的地方"><a href="#真正陷入内核态执行的地方" class="headerlink" title="真正陷入内核态执行的地方"></a>真正陷入内核态执行的地方</h3><p>上回书我们说到<code>asm_common_interrupt</code>的地方，这边是中断处理的真正函数入口点。其定义如下，也用到了DECLARE_IDTENTRY_IRQ。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">//定义</span></span><br><span class="line">DECLARE_IDTENTRY_IRQ(X86_TRAP_OTHER,	common_interrupt);</span><br></pre></td></tr></table></figure>

<p>那就跟之前一样了，跟异常那块串起来了，也是跳到idtentry的汇编代码处，然后，硬件把一些寄存器压栈，软件上会构造pt_regs，等等，都是异常处理部分讲过的内容，最后会调用<code>common_interrupt</code>函数。我们来看看<code>common_interrupt</code>做了什么</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">DEFINE_IDTENTRY_IRQ(common_interrupt)</span><br><span class="line">&#123;</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">pt_regs</span> *<span class="title">old_regs</span> =</span> set_irq_regs(regs);</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">irq_desc</span> *<span class="title">desc</span>;</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">/* entry code tells RCU that we&#x27;re not quiescent.  Check it. */</span></span><br><span class="line">	RCU_LOCKDEP_WARN(!rcu_is_watching(), <span class="string">&quot;IRQ failed to wake up RCU&quot;</span>);</span><br><span class="line"></span><br><span class="line">	desc = __this_cpu_read(vector_irq[<span class="built_in">vector</span>]);</span><br><span class="line">	<span class="keyword">if</span> (likely(!IS_ERR_OR_NULL(desc))) &#123;</span><br><span class="line">		handle_irq(desc, regs);</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">		ack_APIC_irq();</span><br><span class="line"></span><br><span class="line">		<span class="keyword">if</span> (desc == VECTOR_UNUSED) &#123;</span><br><span class="line">			pr_emerg_ratelimited(<span class="string">&quot;%s: %d.%u No irq handler for vector\n&quot;</span>,</span><br><span class="line">					     __func__, smp_processor_id(),</span><br><span class="line">					     <span class="built_in">vector</span>);</span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			__this_cpu_write(vector_irq[<span class="built_in">vector</span>], VECTOR_UNUSED);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	set_irq_regs(old_regs);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>OK，总之就是对中断进行一些处理，如果描述表中没有会报<code>No irq handler for vector</code>等等，然后又是中断返回那一套，具体看异常处理中有始有终章节即可。</p>
<h2 id="系统调用"><a href="#系统调用" class="headerlink" title="系统调用"></a>系统调用</h2><p>系统调用也经过过时代的变迁，首先早期的系统执行系统调用时候，即通过INT指令调用，INT指令的作用是触发一个中断向量，其参数作为中断向量号，而处理器执行<code>INT 0x80</code>便是系统调用的中断向量号(0x80,128)。但是现在处理器有了新的指令SYSCALL指令，其也是x86_64内核默认使用的方法，64位的defconfig没有下面两个config选项了。所以这里我们将两种方式都进行讲解。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">if</span> defined(CONFIG_IA32_EMULATION)</span></span><br><span class="line">	SYSG(IA32_SYSCALL_VECTOR,	entry_INT80_compat),</span><br><span class="line"><span class="meta">#<span class="keyword">elif</span> defined(CONFIG_X86_32)</span></span><br><span class="line">	SYSG(IA32_SYSCALL_VECTOR,	entry_INT80_32),</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br></pre></td></tr></table></figure>

<h3 id="int-0x80"><a href="#int-0x80" class="headerlink" title="int 0x80"></a>int 0x80</h3><p>首先是老式的办法，通过指令触发中断，执行INT指令，然后触发0x80中断向量进行系统调用处理，如果在64位内核上要强制使用需要打开上述config，随后便和前述逻辑中的处理方式一样，进入<code>entry_INT80_compat</code>的汇编代码入口处，而32位使用的入口是<code>entry_INT80_32</code>，这里我们就看看64位的吧：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SYM_CODE_START(entry_INT80_compat)</span><br><span class="line">	UNWIND_HINT_EMPTY</span><br><span class="line">	/*</span><br><span class="line">	 * Interrupts are off on entry.</span><br><span class="line">	 */</span><br><span class="line">	ASM_CLAC			/* Do this early to minimize exposure */</span><br><span class="line">	SWAPGS</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * User tracing code (ptrace or signal handlers) might assume that</span><br><span class="line">	 * the saved RAX contains a 32-bit number when we&#x27;re invoking a 32-bit</span><br><span class="line">	 * syscall.  Just in case the high bits are nonzero, zero-extend</span><br><span class="line">	 * the syscall number.  (This could almost certainly be deleted</span><br><span class="line">	 * with no ill effects.)</span><br><span class="line">	 */</span><br><span class="line">	movl	%eax, %eax</span><br><span class="line"></span><br><span class="line">	/* switch to thread stack expects orig_ax and rdi to be pushed */</span><br><span class="line">	pushq	%rax			/* pt_regs-&gt;orig_ax */</span><br><span class="line">	pushq	%rdi			/* pt_regs-&gt;di */</span><br><span class="line"></span><br><span class="line">	/* Need to switch before accessing the thread stack. */</span><br><span class="line">	SWITCH_TO_KERNEL_CR3 scratch_reg=%rdi</span><br><span class="line"></span><br><span class="line">	/* In the Xen PV case we already run on the thread stack. */</span><br><span class="line">	ALTERNATIVE &quot;&quot;, &quot;jmp .Lint80_keep_stack&quot;, X86_FEATURE_XENPV</span><br><span class="line"></span><br><span class="line">	movq	%rsp, %rdi</span><br><span class="line">	movq	PER_CPU_VAR(cpu_current_top_of_stack), %rsp</span><br><span class="line"></span><br><span class="line">	pushq	6*8(%rdi)		/* regs-&gt;ss */</span><br><span class="line">	pushq	5*8(%rdi)		/* regs-&gt;rsp */</span><br><span class="line">	pushq	4*8(%rdi)		/* regs-&gt;eflags */</span><br><span class="line">	pushq	3*8(%rdi)		/* regs-&gt;cs */</span><br><span class="line">	pushq	2*8(%rdi)		/* regs-&gt;ip */</span><br><span class="line">	pushq	1*8(%rdi)		/* regs-&gt;orig_ax */</span><br><span class="line">	pushq	(%rdi)			/* pt_regs-&gt;di */</span><br><span class="line">.Lint80_keep_stack:</span><br><span class="line"></span><br><span class="line">	pushq	%rsi			/* pt_regs-&gt;si */</span><br><span class="line">	xorl	%esi, %esi		/* nospec   si */</span><br><span class="line">	pushq	%rdx			/* pt_regs-&gt;dx */</span><br><span class="line">	xorl	%edx, %edx		/* nospec   dx */</span><br><span class="line">	pushq	%rcx			/* pt_regs-&gt;cx */</span><br><span class="line">	xorl	%ecx, %ecx		/* nospec   cx */</span><br><span class="line">	pushq	$-ENOSYS		/* pt_regs-&gt;ax */</span><br><span class="line">	pushq   %r8			/* pt_regs-&gt;r8 */</span><br><span class="line">	xorl	%r8d, %r8d		/* nospec   r8 */</span><br><span class="line">	pushq   %r9			/* pt_regs-&gt;r9 */</span><br><span class="line">	xorl	%r9d, %r9d		/* nospec   r9 */</span><br><span class="line">	pushq   %r10			/* pt_regs-&gt;r10*/</span><br><span class="line">	xorl	%r10d, %r10d		/* nospec   r10 */</span><br><span class="line">	pushq   %r11			/* pt_regs-&gt;r11 */</span><br><span class="line">	xorl	%r11d, %r11d		/* nospec   r11 */</span><br><span class="line">	pushq   %rbx                    /* pt_regs-&gt;rbx */</span><br><span class="line">	xorl	%ebx, %ebx		/* nospec   rbx */</span><br><span class="line">	pushq   %rbp                    /* pt_regs-&gt;rbp */</span><br><span class="line">	xorl	%ebp, %ebp		/* nospec   rbp */</span><br><span class="line">	pushq   %r12                    /* pt_regs-&gt;r12 */</span><br><span class="line">	xorl	%r12d, %r12d		/* nospec   r12 */</span><br><span class="line">	pushq   %r13                    /* pt_regs-&gt;r13 */</span><br><span class="line">	xorl	%r13d, %r13d		/* nospec   r13 */</span><br><span class="line">	pushq   %r14                    /* pt_regs-&gt;r14 */</span><br><span class="line">	xorl	%r14d, %r14d		/* nospec   r14 */</span><br><span class="line">	pushq   %r15                    /* pt_regs-&gt;r15 */</span><br><span class="line">	xorl	%r15d, %r15d		/* nospec   r15 */</span><br><span class="line"></span><br><span class="line">	UNWIND_HINT_REGS</span><br><span class="line"></span><br><span class="line">	cld</span><br><span class="line"></span><br><span class="line">	movq	%rsp, %rdi</span><br><span class="line">	call	do_int80_syscall_32</span><br><span class="line">	jmp	swapgs_restore_regs_and_return_to_usermode</span><br><span class="line">SYM_CODE_END(entry_INT80_compat)</span><br></pre></td></tr></table></figure>

<p>粗略讲一下：2-29行大概就是一些关中断，然后处理KPTI等等的一些处理过程，随后是进行pt_regs构建压栈，最后调用（call）<code>do_int80_syscall_32</code>函数，其会从pt_regs中读取相应的系统调用号，然后进行相应的处理，就不过多叙述了。最后就是<code>swapgs_restore_regs_and_return_to_usermode</code>，就是处理KPTI，将寄存器弹出，然后返回用户态balabala一大堆。</p>
<h3 id="SYSCALL-SYSENTER指令方式"><a href="#SYSCALL-SYSENTER指令方式" class="headerlink" title="SYSCALL&#x2F;SYSENTER指令方式"></a>SYSCALL&#x2F;SYSENTER指令方式</h3><p>该指令会从<code>IA32_LSTAR_MSR</code>寄存器中取出系统调用入口到RIP寄存器，然后执行相应的系统调用统一入口函数，其方式比上述方式快。那么Linux内核中怎么做的呢，下面一一道来：</p>
<h4 id="寄存器初始化"><a href="#寄存器初始化" class="headerlink" title="寄存器初始化"></a>寄存器初始化</h4><p>在<code>arch/x86/kernel/cpu/common.c</code>文件中的syscall_init函数对寄存器进行初始化，其通过wrmsr将<code>entry_SYSCALL_64</code>的系统调用入口写入<code>MSR_LSTAR</code>寄存器(Linux定义的寄存器名字)，也就是上面所说的<code>IA32_LSTAR_MSR</code>（Intel定义的寄存器名字）。下面代码也可以看到如果开启了32位等选项，也可以使用SYSCALL指令进行跳转到<code>entry_SYSCALL_compat</code>处，该函数前面一节已经分析了。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">syscall_init</span><span class="params">(<span class="type">void</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">	wrmsr(MSR_STAR, <span class="number">0</span>, (__USER32_CS &lt;&lt; <span class="number">16</span>) | __KERNEL_CS);</span><br><span class="line">	wrmsrl(MSR_LSTAR, (<span class="type">unsigned</span> <span class="type">long</span>)entry_SYSCALL_64);</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_IA32_EMULATION</span></span><br><span class="line">	wrmsrl(MSR_CSTAR, (<span class="type">unsigned</span> <span class="type">long</span>)entry_SYSCALL_compat);</span><br><span class="line">	.....</span><br></pre></td></tr></table></figure>

<h4 id="调用SYSCALL指令前后"><a href="#调用SYSCALL指令前后" class="headerlink" title="调用SYSCALL指令前后"></a>调用SYSCALL指令前后</h4><p>OK我们来看看<code>entry_SYSCALL_64</code>里面做了什么，首先猜一下应该就是硬件寄存器压栈，软件把寄存器压栈，跳转系统调用函数，处理完成返回那一套呗。就把代码都贴上了，粗略看一下果然就是那么做的。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SYM_CODE_START(entry_SYSCALL_64)</span><br><span class="line">	UNWIND_HINT_EMPTY</span><br><span class="line"></span><br><span class="line">	swapgs</span><br><span class="line">	/* tss.sp2 is scratch space. */</span><br><span class="line">	movq	%rsp, PER_CPU_VAR(cpu_tss_rw + TSS_sp2)</span><br><span class="line">	SWITCH_TO_KERNEL_CR3 scratch_reg=%rsp</span><br><span class="line">	movq	PER_CPU_VAR(cpu_current_top_of_stack), %rsp</span><br><span class="line"></span><br><span class="line">SYM_INNER_LABEL(entry_SYSCALL_64_safe_stack, SYM_L_GLOBAL)</span><br><span class="line"></span><br><span class="line">	/* Construct struct pt_regs on stack */</span><br><span class="line">	pushq	$__USER_DS				/* pt_regs-&gt;ss */</span><br><span class="line">	pushq	PER_CPU_VAR(cpu_tss_rw + TSS_sp2)	/* pt_regs-&gt;sp */</span><br><span class="line">	pushq	%r11					/* pt_regs-&gt;flags */</span><br><span class="line">	pushq	$__USER_CS				/* pt_regs-&gt;cs */</span><br><span class="line">	pushq	%rcx					/* pt_regs-&gt;ip */</span><br><span class="line">SYM_INNER_LABEL(entry_SYSCALL_64_after_hwframe, SYM_L_GLOBAL)</span><br><span class="line">	pushq	%rax					/* pt_regs-&gt;orig_ax */</span><br><span class="line"></span><br><span class="line">	PUSH_AND_CLEAR_REGS rax=$-ENOSYS</span><br><span class="line"></span><br><span class="line">	/* IRQs are off. */</span><br><span class="line">	movq	%rsp, %rdi</span><br><span class="line">	/* Sign extend the lower 32bit as syscall numbers are treated as int */</span><br><span class="line">	movslq	%eax, %rsi</span><br><span class="line">	call	do_syscall_64		/* returns with IRQs disabled */</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * Try to use SYSRET instead of IRET if we&#x27;re returning to</span><br><span class="line">	 * a completely clean 64-bit userspace context.  If we&#x27;re not,</span><br><span class="line">	 * go to the slow exit path.</span><br><span class="line">	 * In the Xen PV case we must use iret anyway.</span><br><span class="line">	 */</span><br><span class="line"></span><br><span class="line">	ALTERNATIVE &quot;&quot;, &quot;jmp	swapgs_restore_regs_and_return_to_usermode&quot;, \</span><br><span class="line">		X86_FEATURE_XENPV</span><br><span class="line"></span><br><span class="line">	movq	RCX(%rsp), %rcx</span><br><span class="line">	movq	RIP(%rsp), %r11</span><br><span class="line"></span><br><span class="line">	cmpq	%rcx, %r11	/* SYSRET requires RCX == RIP */</span><br><span class="line">	jne	swapgs_restore_regs_and_return_to_usermode</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * On Intel CPUs, SYSRET with non-canonical RCX/RIP will #GP</span><br><span class="line">	 * in kernel space.  This essentially lets the user take over</span><br><span class="line">	 * the kernel, since userspace controls RSP.</span><br><span class="line">	 *</span><br><span class="line">	 * If width of &quot;canonical tail&quot; ever becomes variable, this will need</span><br><span class="line">	 * to be updated to remain correct on both old and new CPUs.</span><br><span class="line">	 *</span><br><span class="line">	 * Change top bits to match most significant bit (47th or 56th bit</span><br><span class="line">	 * depending on paging mode) in the address.</span><br><span class="line">	 */</span><br><span class="line">#ifdef CONFIG_X86_5LEVEL</span><br><span class="line">	ALTERNATIVE &quot;shl $(64 - 48), %rcx; sar $(64 - 48), %rcx&quot;, \</span><br><span class="line">		&quot;shl $(64 - 57), %rcx; sar $(64 - 57), %rcx&quot;, X86_FEATURE_LA57</span><br><span class="line">#else</span><br><span class="line">	shl	$(64 - (__VIRTUAL_MASK_SHIFT+1)), %rcx</span><br><span class="line">	sar	$(64 - (__VIRTUAL_MASK_SHIFT+1)), %rcx</span><br><span class="line">#endif</span><br><span class="line"></span><br><span class="line">	/* If this changed %rcx, it was not canonical */</span><br><span class="line">	cmpq	%rcx, %r11</span><br><span class="line">	jne	swapgs_restore_regs_and_return_to_usermode</span><br><span class="line"></span><br><span class="line">	cmpq	$__USER_CS, CS(%rsp)		/* CS must match SYSRET */</span><br><span class="line">	jne	swapgs_restore_regs_and_return_to_usermode</span><br><span class="line"></span><br><span class="line">	movq	R11(%rsp), %r11</span><br><span class="line">	cmpq	%r11, EFLAGS(%rsp)		/* R11 == RFLAGS */</span><br><span class="line">	jne	swapgs_restore_regs_and_return_to_usermode</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * SYSCALL clears RF when it saves RFLAGS in R11 and SYSRET cannot</span><br><span class="line">	 * restore RF properly. If the slowpath sets it for whatever reason, we</span><br><span class="line">	 * need to restore it correctly.</span><br><span class="line">	 *</span><br><span class="line">	 * SYSRET can restore TF, but unlike IRET, restoring TF results in a</span><br><span class="line">	 * trap from userspace immediately after SYSRET.  This would cause an</span><br><span class="line">	 * infinite loop whenever #DB happens with register state that satisfies</span><br><span class="line">	 * the opportunistic SYSRET conditions.  For example, single-stepping</span><br><span class="line">	 * this user code:</span><br><span class="line">	 *</span><br><span class="line">	 *           movq	$stuck_here, %rcx</span><br><span class="line">	 *           pushfq</span><br><span class="line">	 *           popq %r11</span><br><span class="line">	 *   stuck_here:</span><br><span class="line">	 *</span><br><span class="line">	 * would never get past &#x27;stuck_here&#x27;.</span><br><span class="line">	 */</span><br><span class="line">	testq	$(X86_EFLAGS_RF|X86_EFLAGS_TF), %r11</span><br><span class="line">	jnz	swapgs_restore_regs_and_return_to_usermode</span><br><span class="line"></span><br><span class="line">	/* nothing to check for RSP */</span><br><span class="line"></span><br><span class="line">	cmpq	$__USER_DS, SS(%rsp)		/* SS must match SYSRET */</span><br><span class="line">	jne	swapgs_restore_regs_and_return_to_usermode</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * We win! This label is here just for ease of understanding</span><br><span class="line">	 * perf profiles. Nothing jumps here.</span><br><span class="line">	 */</span><br><span class="line">syscall_return_via_sysret:</span><br><span class="line">	/* rcx and r11 are already restored (see code above) */</span><br><span class="line">	POP_REGS pop_rdi=0 skip_r11rcx=1</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * Now all regs are restored except RSP and RDI.</span><br><span class="line">	 * Save old stack pointer and switch to trampoline stack.</span><br><span class="line">	 */</span><br><span class="line">	movq	%rsp, %rdi</span><br><span class="line">	movq	PER_CPU_VAR(cpu_tss_rw + TSS_sp0), %rsp</span><br><span class="line">	UNWIND_HINT_EMPTY</span><br><span class="line"></span><br><span class="line">	pushq	RSP-RDI(%rdi)	/* RSP */</span><br><span class="line">	pushq	(%rdi)		/* RDI */</span><br><span class="line"></span><br><span class="line">	/*</span><br><span class="line">	 * We are on the trampoline stack.  All regs except RDI are live.</span><br><span class="line">	 * We can do future final exit work right here.</span><br><span class="line">	 */</span><br><span class="line">	STACKLEAK_ERASE_NOCLOBBER</span><br><span class="line"></span><br><span class="line">	SWITCH_TO_USER_CR3_STACK scratch_reg=%rdi</span><br><span class="line"></span><br><span class="line">	popq	%rdi</span><br><span class="line">	popq	%rsp</span><br><span class="line">	swapgs</span><br><span class="line">	sysretq</span><br><span class="line">SYM_CODE_END(entry_SYSCALL_64)</span><br></pre></td></tr></table></figure>

<p>首先2-9行由于SYSCALL指令没有IDT表那一块硬件逻辑，硬件不会自动加载TSS中的内核栈位置给寄存器，所以需要手动用软件的方式进行加载内核栈地址，也是从tss结构体中加载。然后看注释就知道，就构建pt_regs结构体，之后27行call了<code>do_syscall_64</code>，进行真正的系统调用处理，然后最后都会到<code>swapgs_restore_regs_and_return_to_usermode</code>进行返回，大差不差。</p>
<h4 id="do-syscall-64进行系统调用处理"><a href="#do-syscall-64进行系统调用处理" class="headerlink" title="do_syscall_64进行系统调用处理"></a>do_syscall_64进行系统调用处理</h4><p>行吧，具体逻辑就不说了，贴个代码看看就行了，大概就是读一下系统调用号，然后跳转到相应的系统调用处理函数进行执行，然后返回就完了。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">__visible noinstr <span class="type">void</span> <span class="title function_">do_syscall_64</span><span class="params">(<span class="keyword">struct</span> pt_regs *regs, <span class="type">int</span> nr)</span></span><br><span class="line">&#123;</span><br><span class="line">	add_random_kstack_offset();	<span class="comment">//ASLR，安全问题，就给栈加了个偏移</span></span><br><span class="line">	nr = syscall_enter_from_user_mode(regs, nr); <span class="comment">//一些初始化的处理，检查等操作</span></span><br><span class="line"></span><br><span class="line">	instrumentation_begin();<span class="comment">//KMSAN相关操作，如果没开选项则为空</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//do_syscall_x64处理64位系统调用，里面会调用系统调用表中的函数，x32就是32位的，不过是运行在64位kernel上的32位程序使用的</span></span><br><span class="line">	<span class="keyword">if</span> (!do_syscall_x64(regs, nr) &amp;&amp; !do_syscall_x32(regs, nr) &amp;&amp; nr != <span class="number">-1</span>) &#123;</span><br><span class="line">		<span class="comment">/* Invalid system call, but still a system call. */</span></span><br><span class="line">		regs-&gt;ax = __x64_sys_ni_syscall(regs);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	instrumentation_end();<span class="comment">//同前</span></span><br><span class="line">	syscall_exit_to_user_mode(regs);<span class="comment">//退出之前的最后处理，什么开关中断啊什么的。</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>Linux-kernel source code 5.15</p>
<p>Intel spec</p>
]]></content>
      <categories>
        <category>note</category>
      </categories>
      <tags>
        <tag>os</tag>
      </tags>
  </entry>
  <entry>
    <title>内存管理1</title>
    <url>/2022/04/19/note/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%861/</url>
    <content><![CDATA[<h1 id="内存管理"><a href="#内存管理" class="headerlink" title="内存管理"></a>内存管理</h1><p>​	内存管理的主要功能有</p>
<ul>
<li>内存空间的分配与回收</li>
<li>地址转换</li>
<li>内存空间的扩充</li>
<li>内存共享</li>
<li>存储保护</li>
</ul>
<h2 id="程序的链接与装入"><a href="#程序的链接与装入" class="headerlink" title="程序的链接与装入"></a>程序的链接与装入</h2><p>用户程序在磁盘上存储形式为二进制文件，当执行程序时，其会被调入内存，并组织成进程的形式。通常这一过程需要以下几个步骤：</p>
<ul>
<li><p>预处理：将用户源代码中的头文件和宏等进行替代，删除所有注释等等一系列操作</p>
</li>
<li><p>编译：由编译器将用户源代码编译成汇编文件，并汇总所有符号。main.c-&gt;main.S</p>
</li>
<li><p>汇编：将汇编文件(.S文件)根据特定平台等生成二进制文件，即将指令翻译成二进制形式，并合并符号表等。main.S-&gt;main.o，其中.o文件称为目标对象模块。</p>
</li>
<li><p>链接：由链接器将目标对象模块和若干库函数链接在一起，形成一个完整的加载模块，生成可执行文件。需要进行符号解析和地址重定位。链接有三种方式：</p>
</li>
<li><p>装入：将可执行文件载入内存运行。</p>
</li>
</ul>
<p>而程序的符号地址绑定可以分为三部分确定：</p>
<ul>
<li>在编译时确定：如果编译时候就知道进程将在内存驻留的地址，那么就可以生成绝对地址，在MS-DOS系统上的.COM格式文件就是如此。</li>
<li>在加载时确定：如果编译时候不知道，则编译器会产生可重定位代码，其地址绑定会延迟到加载时候进行。</li>
<li>在执行时确定：进程执行时候可以从一个内存段转移到另一个内存段，此时地址绑定需要执行时候才能确定，大多数操作系统采用这种办法。</li>
</ul>
<h3 id="程序链接的三种形式"><a href="#程序链接的三种形式" class="headerlink" title="程序链接的三种形式"></a>程序链接的三种形式</h3><p>程序的链接也有三种形式：</p>
<ul>
<li><p>静态链接：在程序运行前需要将各个模块和库函数组装在一起，形成一个完整的模块，而每个模块内部的符号都是从0开始的相对地址，装成一个大模块时需要对其进行修改；同时一些模块会向外部提供调用接口，也需要将外部调用符号转变为相应的相对地址。</p>
<p><img src="https://raw.githubusercontent.com/unsatisfying/picture-server/main/img%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E9%9D%99%E6%80%81%E9%93%BE%E6%8E%A5.png" alt="image-20220417172720338"></p>
</li>
<li><p>装入时动态链接：将用户源程序编译后得到一组目标模块，在装入内存时候采用边装入边链接的方式，即在装入时若发生一个外部模块调用,将引起装入程序去找出相应的外部目标模块,并将它装入内存,还要修改目标模块中的相对地址。其优点是便于修改和更新，便于实现对目标模块的共享。</p>
<p>虽然前面所介绍的动态装入方式，可将一个装入模块装入到内存的任何地方，但装入模块的结构是静态的，它主要表现在两个方面：一是在进程的整个执行期间，装入模块不改变；再者是每次运行时的装入模块都是相同的。实际上，在许多情况下，每次要运行的模块可能是不相同的，但由于事先无法知道本次要运行哪些模块，故只能是将所有可能要运行到的模块，在装入时全部链接在一起，是每次执行时的装入模块是相同的。显然这是低效的。因为这样，在装入模块的运行过程中，往往会有某些目标模块根本就不运行。比较典型的例子是错误处理模块，如果程序在整个运行过程中，都不出现错误，便不会用到该模块。对某些目标模块的链接，是在程序执行中需要该模块才进行的，凡在执行过程中需要的模块会被调入内存，链接到装入模块上，其能节省大量内存空间，因为不需要的部分都不会被加载入内存。</p>
</li>
<li><p>执行时动态链接：可将某些目标模块的链接，推迟到执行时才进行。即在执行过程中，若发现一个被调用模块尚未装入内存时由OS去找到该模块，将它装入内存，并把它连接到调用者模块上。</p>
</li>
</ul>
<p>做个比喻就是，静态链接就好像机关枪，把所有子弹都装好，然后突突突，但是所耗费很大空间，很笨重。而装入时动态链接就好像子弹先装入弹夹中，装入使用的时候把弹夹装上枪，然后开始执行，虽然小巧了很多，但是很多错误处理的代码等等还是会被加载入内存。执行时动态链接就好像一把老式kar98，每次要狙人开枪的时候，装入一颗子弹，节约了很多空间。</p>
<h3 id="程序装入的三种方式"><a href="#程序装入的三种方式" class="headerlink" title="程序装入的三种方式"></a>程序装入的三种方式</h3><p>在将程序装入内存时也有三种形式：</p>
<ul>
<li>绝对装入：只适用于<strong>单道程序环境</strong>，在编译时就知道程序所在的内存位置，于是生成的是绝对地址的目标代码，其程序中的逻辑地址与真实的物理地址相同。</li>
<li>可重定位装入：在<strong>多道程序环境下</strong>，多个目标模块的起始地址通常从0开始，程序中的其他地址都是相对于起始地址的。在装入时对目标程序中指令和数据地址的修改过程称为<strong>重定位</strong>。</li>
<li>动态运行时装入：程序如果发生移动，则需要动态装入方式，装入程序把装入模块放入内存后并不立即把装入模块的地址转化成绝对地址，而是在程序真正要执行时候才真正转化，该种方式需要硬件上有重定位寄存器支持。优点是可以将程序分配到不连续的存储区，在程序运行之前可以只装入部分代码即可运行，然后在程序执行期间，根据需要动态申请内存，也便于程序段共享。</li>
</ul>
<h2 id="进程的内存布局"><a href="#进程的内存布局" class="headerlink" title="进程的内存布局"></a>进程的内存布局</h2><p>​	如图所示是一个进程在内存中的映像，64位和32位有所不同，但是大差不差。</p>
<p><img src="https://raw.githubusercontent.com/unsatisfying/picture-server/main/img%E8%BF%9B%E7%A8%8B%E7%9A%84%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80" alt="进程的存布局"></p>
<h3 id="miscellaneous（杂项）"><a href="#miscellaneous（杂项）" class="headerlink" title="miscellaneous（杂项）"></a>miscellaneous（杂项）</h3><p>其中比较关键的是由上图可以看到系统会把进程的ELF文件(ELF文件长啥样就谷歌搜，一大堆图)去掉<code>header</code>之后装入了地址为<code>0x40000000</code>的位置处，肯定有人会问为什么是这个地址。emmm很多网上资料都没讲清楚。</p>
<p>​	首先，为什么前面要有一段空洞，不论是32位还是64位，主要是为了防止<code>NULL POINTER</code>被访问的问题，这样做0地址就是一个非法地址，访问时能被操作系统捕获。但是有人肯定会问，为什么不能装载在虚拟地址为1处？其实也是可以的，但是操作系统一般会为了分页方便，就前面空出一部分空间，这个空出的多大空间不是固定的，至少我测了三种环境下（<code>QEMU跑的64位linux</code>，<code>腾讯云服务器</code>，<code>双系统的物理主机上的linux</code>）都是不一样的。其中一部分原因是开启了<code>ASLR</code>的缘故，但是我关了之后还是不一样的。（网上有人是<code>0x400000</code>，换算下来是4M，说是因为Linux分页机制，有些页面是大页，不是4K大小，所以就开得大点，保证一页装不下。这种说法我不确定是否正确）。</p>
<p>​	网上很多图针对于32位的地址空间会说前面128M是空洞（我手上没有32位机器，没法去验证，至少64位我验证了。其次我也不明白为什么32位要开128M那么大，像64位这样开小点不行吗？）</p>
<p>​	还要说的一点是linux是通过mmap将elf文件载入内存的，而Linux对mmap可映射的地址范围做了限制，由变量MMAP_MIN_ADDR(该值一般为65532，可以通过命令<code>cat /proc/sys/vm/mmap_min_addr</code>查看)限制，也就是说装载的地址首先要求不能小于这个值，否则无法mmap。其次这个映射的基质是由链接器中的一个变量定义的（网上一篇blog说的，我也不知道正确不正确，我记得他说在一个文件名为elf_x86_64xxx的文件里）。</p>
<h3 id="内存各个部分含义"><a href="#内存各个部分含义" class="headerlink" title="内存各个部分含义"></a>内存各个部分含义</h3><ul>
<li>.text：其中<code>.text</code>段为代码段，用以存储包括<code>_init</code>等初始化函数在内的程序片段。</li>
<li>.rodata：用以存储只读数据，包括一些字符串什么。而且同样的字符串只会在其中保存有一个副本，所以当创建两个指针指向两个一样的字符串时候，这两个指针的值是一样的。</li>
<li>.data：用以存储读写数据，包括已初始化不为0的全局变量和静态变量。</li>
<li>.bss：用以存储初始化为0的全局变量和静态变量。</li>
</ul>
<h2 id="内存分配方式"><a href="#内存分配方式" class="headerlink" title="内存分配方式"></a>内存分配方式</h2><p>​	内存分配方式有很多种，包括连续内存分配，分段，分页，段页式等等。</p>
<h3 id="连续内存分配"><a href="#连续内存分配" class="headerlink" title="连续内存分配"></a>连续内存分配</h3><h4 id="内存保护"><a href="#内存保护" class="headerlink" title="内存保护"></a>内存保护</h4><p>为了防止进程访问不属于自己的空间，可以采取两种方式进行内存保护：</p>
<ul>
<li>在CPU中设置上下限寄存器，用以存储存放用户进程在主存中的上界和下界，从而防止内存读取越界。</li>
<li>在CPU中设置重定位寄存器和界限寄存器，当CPU访问地址的时候和界限寄存器进行比较，判断是否在可访问范围内。其中重定位寄存器存储最小的物理地址，界限寄存器存储最大的逻辑地址。</li>
</ul>
<h4 id="内存分配"><a href="#内存分配" class="headerlink" title="内存分配"></a>内存分配</h4><p>​	最简单的分配方式为<strong>多分区方法</strong>：将内存分为多个固定大小的分区，每个分区包含一个进程。该种方法现在已经不再使用。</p>
<p>​	随后衍生出的是<strong>可变分区法</strong>：操作系统中有一个表记录哪些内存可用，哪些内存不可用。最开始内存为一整块空闲，当一个用户进程来之后，操作系统根据内存需求和现有内存使用情况进行分配，决定哪些进程可以被分配内存空间，然后这些进程进入内存开始竞争CPU，这些进程运行结束后释放内存空间，操作系统回收这部分内存。 这种方法会导致内存中存在很多空洞和碎片。</p>
<h4 id="动态存储分配问题及算法"><a href="#动态存储分配问题及算法" class="headerlink" title="动态存储分配问题及算法"></a>动态存储分配问题及算法</h4><p>​	根据一组空闲孔来分配大小为n的请求问题为动态存储分配问题，一般可以通过首次适应，最优适应和最差适应的方法分配。</p>
<ul>
<li>首次适应：分配首个足够大的孔。</li>
<li>邻近适应：也是分配首个足够大的孔，不过和首次适应的区别在于首次适应是每次从链表头开始查找，而邻近适应每次从上次查找结束的位置开始查找。</li>
<li>最优适应：分配最小足够大的孔。</li>
<li>最差适应：分配最大的孔。</li>
</ul>
<h3 id="分段"><a href="#分段" class="headerlink" title="分段"></a>分段</h3><p>​	分段管理方式提出考虑了程序员和编程视角，由于用户的内存视图和实际物理内存不一样，但是分段提供了一种方式，将程序员的视角映射到实际的物理内存，这样系统可以更自由地管理内存，程序员也有一个更自然的编程环境。</p>
<p>​	程序员不再认为内存是一个字节的线性数组，而是看做不同长度的段。因为程序员更关心堆栈，数学库，主程序等名词，而不关心这些元素所在的位置，他也并不关心堆栈放在主程序之前还是之后。由此逻辑地址空间便是由一组段组成的，每个段有自己的名称和长度，逻辑地址是段的名称和段内偏移组合。</p>
<p>​	图为分段机制的程序员视角。</p>
<p><img src="https://raw.githubusercontent.com/unsatisfying/picture-server/main/img%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E5%88%86%E6%AE%B5%E7%A8%8B%E5%BA%8F%E5%91%98%E8%A7%86%E8%A7%92.png" alt="image-20220417232909018"></p>
<h4 id="分段的硬件支持"><a href="#分段的硬件支持" class="headerlink" title="分段的硬件支持"></a>分段的硬件支持</h4><h5 id="16位"><a href="#16位" class="headerlink" title="16位"></a>16位</h5><p>​	硬件上<code>x86</code>在实模式和保护模式中有所不同。在实模式中寄存器都是16位的，而CPU提供四个段寄存器CS,DS,SS,ES，于是寻址方式为，可以最多访问2^20^大小内存：</p>
<figure class="highlight armasm"><table><tr><td class="code"><pre><span class="line">物理地址 = （段寄存器 &lt;&lt; <span class="number">4</span>） + （<span class="built_in">ip</span>寄存器(偏移量））</span><br></pre></td></tr></table></figure>

<h5 id="32位"><a href="#32位" class="headerlink" title="32位"></a>32位</h5><p>​	但是到了32位保护模式，CPU变成了32位，同时变成了6个段寄存器，多了FS和GS，可是为了兼容16位程序，其寄存器大小还是16位，于是之前的模式无法满足32位的寻址了。于是Intel增加了两个寄存器：GDTR（全局描述符表），LDTR（局部描述符表）寄存器，新增的寄存器为32位，记录了表的基址。表中每个表项占8个字节（寄存器只有2个字节，所以只能将表放在内存中），其中记录了段的基址和段界限，而相应的CS,DS,SS,ES中存放的是段描述符的索引值。</p>
<p><img src="https://raw.githubusercontent.com/unsatisfying/picture-server/main/img%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E5%88%86%E6%AE%B5%E6%9C%BA%E5%88%B6.png" alt="image-20220417232229951"></p>
<blockquote>
<p>说到gdtr寄存器和ldtr寄存器，就来说说全局描述符和局部描述符的区别吧，一般来说全局描述符整个系统中只有一个，其中也存了很多ldt描述符表的基址作为表项（因为理论上来说ldt表也是一段内存，也可以认为是一个段），而给每个任务分配一个ldt表，任务切换的时候切换ldtr寄存器，gdtr寄存器不变，由此每个任务可以由自己的代码段堆栈段等，而全局描述符表中除了存储内核的堆栈段等段，还要存储所有任务的局部描述符表段。</p>
</blockquote>
<p>​	用网上的图吧，该图吧描述符的格式和段寄存器的格式也标明了。</p>
<p><img src="https://raw.githubusercontent.com/unsatisfying/picture-server/main/img%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E5%88%86%E6%AE%B5%E6%9C%BA%E5%88%B6%E7%BD%91%E5%9B%BE.png" alt="image-20220417232357149"></p>
<p>而linux系统在段描述符表中把所有的段基址都设为了<code>0x0</code>,即平坦内存模型，linux中只有一个段。</p>
<h5 id="64位"><a href="#64位" class="headerlink" title="64位"></a>64位</h5><p>​	在64位模式下：处理器把CS&#x2F;DS&#x2F;ES&#x2F;SS的段基都当作0，忽略与之关联的段描述符中的段基地址。因为在64位模式中，CPU可以访问所有可寻址的内存空间。今天大多数的64位CPU只需要访问40位到48位的物理内存，因此不再需要段寄存器去扩展。</p>
<h3 id="分页"><a href="#分页" class="headerlink" title="分页"></a>分页</h3><p>分段允许进程的物理地址空间非连续，而分页是另一种提供这种优势的方案。且分页能够避免外部碎片和紧缩，分段不可以。除此之外分页更有利于内存块交换到交换空间。</p>
<h4 id="硬件支持"><a href="#硬件支持" class="headerlink" title="硬件支持"></a>硬件支持</h4><p>都耳熟能详了，CR3，MMU那一套呗贴几张图把。</p>
<h5 id="32位-1"><a href="#32位-1" class="headerlink" title="32位"></a>32位</h5><p><img src="https://raw.githubusercontent.com/unsatisfying/picture-server/main/img%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%8632%E4%BD%8D%E5%88%86%E9%A1%B5%E6%9C%BA%E5%88%B6.png" alt="image-20220418000133826"></p>
<h5 id="64位-1"><a href="#64位-1" class="headerlink" title="64位"></a>64位</h5><p><img src="https://raw.githubusercontent.com/unsatisfying/picture-server/main/img%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E5%88%86%E9%A1%B5%E6%9C%BA%E5%88%B664%E4%BD%8D.png" alt="image-20220418000207908"></p>
<h3 id="段页式内存管理"><a href="#段页式内存管理" class="headerlink" title="段页式内存管理"></a>段页式内存管理</h3><p>​	将分段和分页结合的方式，也耳熟能详了吧，也贴一张图就完了。</p>
<p><img src="https://raw.githubusercontent.com/unsatisfying/picture-server/main/img%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E6%AE%B5%E9%A1%B5%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86.png" alt="image-20220418000509846"></p>
]]></content>
      <categories>
        <category>note</category>
      </categories>
      <tags>
        <tag>os</tag>
      </tags>
  </entry>
  <entry>
    <title>存储管理</title>
    <url>/2022/04/19/note/%E5%AD%98%E5%82%A8%E7%AE%A1%E7%90%86/</url>
    <content><![CDATA[<h1 id="存储管理"><a href="#存储管理" class="headerlink" title="存储管理"></a>存储管理</h1><h2 id="存储介质"><a href="#存储介质" class="headerlink" title="存储介质"></a>存储介质</h2><p>​	存储介质可以分为磁盘(hard disk)、固态磁盘(Solid-State Disk)、磁带(magnetic tape)。</p>
<h2 id="磁盘调度"><a href="#磁盘调度" class="headerlink" title="磁盘调度"></a>磁盘调度</h2><ul>
<li>寻道时间：磁臂移动磁头到包含目标扇区的柱面的时间。</li>
<li>旋转延迟时间：磁盘旋转目标扇区到磁头下的时间。</li>
<li>磁盘带宽：传输字节的总数除以服务时间。</li>
</ul>
<h3 id="先来先服务调度（First-come-first-served，FCFS）"><a href="#先来先服务调度（First-come-first-served，FCFS）" class="headerlink" title="先来先服务调度（First come first served，FCFS）"></a>先来先服务调度（First come first served，FCFS）</h3><p>​	顾名思义</p>
<h3 id="最短寻道时间优先（shortest-seek-time-first，SSTF）"><a href="#最短寻道时间优先（shortest-seek-time-first，SSTF）" class="headerlink" title="最短寻道时间优先（shortest seek time first，SSTF）"></a>最短寻道时间优先（shortest seek time first，SSTF）</h3><p>​	优先选择离当前磁头近的请求，本质上是一种最短作业优先调度，会导致请求饥饿。</p>
<h3 id="扫描算法（SCAN-algorithm）"><a href="#扫描算法（SCAN-algorithm）" class="headerlink" title="扫描算法（SCAN algorithm）"></a>扫描算法（SCAN algorithm）</h3><p>​	磁臂从磁盘的一端开始向另一端移动，到达一端后磁头反转。有时候也被称为<strong>电梯算法（elevator algorithm）</strong></p>
<h3 id="循环扫描算法（circular-SCAN，-C-SCAN）"><a href="#循环扫描算法（circular-SCAN，-C-SCAN）" class="headerlink" title="循环扫描算法（circular SCAN， C-SCAN）"></a>循环扫描算法（circular SCAN， C-SCAN）</h3><p>​	如果请求是均匀的，SCAN在扫描的时候，当前所在位置的处理因为刚扫过，所以附近的请求数较少，而相反另一端请求数肯定较多。于是就衍生出了C-SCAN。即扫到一端后立即返回，但是不处理任何请求，然后又重新开始扫。</p>
<h3 id="LOOK调度与C-LOOK调度"><a href="#LOOK调度与C-LOOK调度" class="headerlink" title="LOOK调度与C-LOOK调度"></a>LOOK调度与C-LOOK调度</h3><p>​	类似于SCAN和C-SCAN，但是它不移动整个磁盘宽度，而是移动到最远的一个请求为止。</p>
<h2 id="磁盘管理"><a href="#磁盘管理" class="headerlink" title="磁盘管理"></a>磁盘管理</h2><h3 id="磁盘格式化"><a href="#磁盘格式化" class="headerlink" title="磁盘格式化"></a>磁盘格式化</h3><ul>
<li>低级格式化&#x2F;物理格式化：将空白磁盘分成扇区，并使用特殊数据结构填充（其中包括ECC（纠错码），用以校对和修复错误字节）</li>
<li>分区：将磁盘分为由柱面组成的分区，不同分区上可以装不同的操作系统。</li>
<li>逻辑格式化：即创建文件系统。</li>
</ul>
<h3 id="引导块"><a href="#引导块" class="headerlink" title="引导块"></a>引导块</h3><p>​	bootstrap程序（处于ROM中）找到磁盘上的引导块，将其加载入内存，然后该引导块的代码找到操作系统所在分区，并将操作系统加载入内存。</p>
<h3 id="坏块"><a href="#坏块" class="headerlink" title="坏块"></a>坏块</h3><p>​	磁盘上一般有备用块作为坏块的备份，当某些块损坏时候，磁盘可以利用这些备用块进行补充。</p>
<h2 id="交换空间管理"><a href="#交换空间管理" class="headerlink" title="交换空间管理"></a>交换空间管理</h2><p>交换空间可分为文件或者交换分区。</p>
<ul>
<li>文件：位于普通文件系统之上，但是效率低，因为需要访问磁盘目录等结构，需要额外的时间，同时可能需要遍历文件系统。</li>
<li>交换分区：在单独的原始分区上创建交换空间，不存在文件系统，但是可能会增加内部碎片。</li>
</ul>
<p>Linux 的交换空间仅用于匿名内存（即堆，栈，进程未初始化数据等区域），而代码等本来是从磁盘上读的，可以直接丢弃。而别的部分通过交换映射进行交换。交换映射为一个数组，数组中内容表示该对应的交换页由多少进程使用（可能有共享内存，导致数组值大于1，为0则表明空闲）</p>
<h2 id="磁盘冗余阵列（Redundant-Arrays-of-Independent-Disk，RAID）"><a href="#磁盘冗余阵列（Redundant-Arrays-of-Independent-Disk，RAID）" class="headerlink" title="磁盘冗余阵列（Redundant Arrays of Independent Disk，RAID）"></a>磁盘冗余阵列（Redundant Arrays of Independent Disk，RAID）</h2><p>磁盘的并行可以加速文件的读取，比如同时有8个盘，可以同时读取，每个盘上读取一位则形成了一个字。</p>
<ul>
<li>RAID0：有多个磁盘，但是没有冗余数据。</li>
<li>RAID1：镜像磁盘，即每个磁盘有一个一模一样的镜像磁盘，需要两倍大小存储空间。</li>
<li>RAID2：内存方式的差错纠正组织。用多个额外的位用于奇偶校验位，当奇偶校验位出错时候，可以由内存系统检测。由此在一定程度上可以修复单个位出错（奇变偶，偶变奇）。如第一个磁盘存储第一个字节，第二个磁盘存储第二个字节。。。然后剩下几个磁盘存储奇偶校验位。比RAID1稍微节约了空间。</li>
<li>RAID3：位交错奇偶校验位结构。只有一个额外的磁盘作为校验位，类似于RAID2，但是磁盘控制器来检测扇区读取是否正确。</li>
<li>RAID4：块交错奇偶校验位结构。</li>
<li>RAID5：块交错分布奇偶校验结构。将数据和奇偶校验分散在每一个磁盘上，而RAID4和3是用一个单独的磁盘存储奇偶校验。（最为常见）</li>
<li>RAID6：P+Q冗余方案。类似RAID5，但是保存了额外的冗余信息，可以容忍两个磁盘故障。</li>
<li>RAID0+1：0和1组合，先分条，再镜像。</li>
<li>RAID1+0：先镜像，再分条。</li>
</ul>
]]></content>
      <categories>
        <category>note</category>
      </categories>
      <tags>
        <tag>os</tag>
      </tags>
  </entry>
  <entry>
    <title>死锁</title>
    <url>/2022/04/19/note/%E6%AD%BB%E9%94%81/</url>
    <content><![CDATA[<h1 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h1><h2 id="死锁的原因"><a href="#死锁的原因" class="headerlink" title="死锁的原因"></a>死锁的原因</h2><ul>
<li>系统资源的竞争</li>
<li>进程推进顺序的非法</li>
</ul>
<h2 id="死锁的必要条件"><a href="#死锁的必要条件" class="headerlink" title="死锁的必要条件"></a>死锁的必要条件</h2><ul>
<li>互斥(mutual exclusion):至少存在一个资源使得两个进程需要互斥使用，即一个进程在使用时，另一个进程必须等待。</li>
<li>占有并等待(hold and wait):一个进程占有了某个资源后等待另一个资源，但是另一个资源被另外一个进程所占有。</li>
<li>非抢占(no preemption):资源不能被抢占，只能被占有的资源资源释放。</li>
<li>循环等待(circular wait):一组资源，A等待B抢占的资源，B等待C抢占的资源…….最后N等待A抢占的资源，从而形成环。</li>
</ul>
<p>四个条件同时成立便会出现死锁，且四个条件并不完全独立(如循环等待可能需要占有并等待的条件才能满足)。</p>
<h2 id="资源分配图"><a href="#资源分配图" class="headerlink" title="资源分配图"></a>资源分配图</h2><p>如图所示即资源分配图，其中圆形表示进程，矩形表示资源，P-&gt;R表示一条申请边，R-&gt;P表示分配边。</p>
<p>可以证明如果分配图中没有环，则系统中没有死锁进程，如果有环则<strong>可能</strong>存在死锁。而刚好每种资源只有一个时候，存在环则说明有死锁情况发生。</p>
<p><img src="https://raw.githubusercontent.com/unsatisfying/picture-server/main/img%E6%AD%BB%E9%94%81-%E8%B5%84%E6%BA%90%E5%88%86%E9%85%8D%E5%9B%BE.png" alt="image-20220416203128743"></p>
<h2 id="死锁处理方法"><a href="#死锁处理方法" class="headerlink" title="死锁处理方法"></a>死锁处理方法</h2><ul>
<li>死锁预防：限制死锁的四个条件，破坏其中一个或几个条件。</li>
<li>死锁避免：资源分配过程中，防止系统进入不安全状态。</li>
<li>死锁检测及解除：不采取任何措施，但是在系统运行中及时检测死锁的存在，然后解除他们。</li>
</ul>
<h3 id="死锁预防"><a href="#死锁预防" class="headerlink" title="死锁预防"></a>死锁预防</h3><h4 id="互斥"><a href="#互斥" class="headerlink" title="互斥"></a>互斥</h4><p>​	互斥条件必须成立。</p>
<h4 id="持有且等待"><a href="#持有且等待" class="headerlink" title="持有且等待"></a>持有且等待</h4><p>​	在申请一个资源时候不能占有其他资源(即申请资源的系统调用在其他系统调用之前进行，或者申请时候释放已分配的资源，或者在进程运行前一次性分配所有的资源)，这样做缺点就是资源利用率低，且可能发生饥饿。</p>
<h4 id="非抢占"><a href="#非抢占" class="headerlink" title="非抢占"></a>非抢占</h4><p>​	在申请资源时候，现有的资源都可被抢占或者释放。会增加系统的开销，降低系统的吞吐率，适合于CPU寄存器和内存。</p>
<h4 id="循环等待"><a href="#循环等待" class="headerlink" title="循环等待"></a>循环等待</h4><p>​	对所有资源进行排序，资源申请必须按照给定的顺序进行申请。需要程序员自觉遵守顺序，且如果增加了新类型的设备，会改变既定的分配顺序，则编程代码都需要改变。</p>
<h3 id="死锁避免"><a href="#死锁避免" class="headerlink" title="死锁避免"></a>死锁避免</h3><p>避免死锁需要额外的信息，即如何申请资源，获知每个进程的资源请求和释放顺序之后，系统可以决定在进程请求资源时候避免未来可能的死锁。而保持系统一直处于<strong>安全状态</strong>即可避免死锁。但是并非所有的不安全状态都是死锁状态，但当系统进入不安全状态之后，便可能进入死锁状态。</p>
<h4 id="资源分配图算法"><a href="#资源分配图算法" class="headerlink" title="资源分配图算法"></a>资源分配图算法</h4><p>​	在前述资源分配图中增加需求边。这种边与申请边(P-&gt;R)一样，但是是虚线。</p>
<p>​	当进程申请资源时候则把其变为P-&gt;R的申请边，当申请到资源之后则变成R-&gt;P的分配边，资源释放之后R-&gt;的分配边变为P-&gt;R的虚线需求边。</p>
<p>​	资源分配图算法要求，在进程申请资源时，只有将其申请边变为分配边时，不会导致资源分配图形成环。如图所示图一如果变成图二，则会形成环，于是图二被认为是不安全状态，不予分配资源。</p>
<p><img src="https://raw.githubusercontent.com/unsatisfying/picture-server/main/img%E6%AD%BB%E9%94%81-%E8%B5%84%E6%BA%90%E5%88%86%E9%85%8D%E5%9B%BE%E7%AE%97%E6%B3%95.png" alt="image-20220416210119664"></p>
<h4 id="银行家算法"><a href="#银行家算法" class="headerlink" title="银行家算法"></a>银行家算法</h4><p>一句话来说就是假设分配给一个进程资源之后，系统是否处于不安全状态，如果是不安全状态则不给该次分配。</p>
<p>具体过程就是根据这句话，然后把三个矩阵变来变去，懒得讲了，直接看书比较实在(书上balabala讲了一堆估计也懒得看，反正记住这句话就行了)</p>
<h3 id="死锁检测"><a href="#死锁检测" class="headerlink" title="死锁检测"></a>死锁检测</h3><h4 id="死锁定理及资源分配图简化算法"><a href="#死锁定理及资源分配图简化算法" class="headerlink" title="死锁定理及资源分配图简化算法"></a>死锁定理及资源分配图简化算法</h4><p>还是这张图，简化算法如下：</p>
<ul>
<li>在资源分配图中找到既不阻塞，也不孤点的进程P<del>i</del>，并消除其所有请求边和分配边。即找到一条有向申请边，其尾部对应该进程P<del>i</del>，其边箭头所指的资源申请数量小于等于系统中空闲资源数量。(如图中资源R<del>2</del>资源有两个，其中分配出去给P<del>2</del>一个，所以空闲的是一个，而P<del>1</del>进程申请边请求一个，满足小于等于，也就说明P<del>1</del>可以正常申请且运行，然后将其所有的分配边和申请边全删除，表明进程运行完成资源释放。)</li>
<li>不断删去所有这样的进程，最后能够删除所有的边，则表明此资源分配图可简化。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/unsatisfying/picture-server/main/img%E6%AD%BB%E9%94%81-%E8%B5%84%E6%BA%90%E5%88%86%E9%85%8D%E5%9B%BE.png" alt="image-20220416203128743"></p>
<p>​	<strong>死锁定理</strong>表明，S为死锁的条件是当且仅当S状态的资源分配图是不可完全简化的。</p>
<h4 id="等待图"><a href="#等待图" class="headerlink" title="等待图"></a>等待图</h4><p>​	如果所有资源只有单个实例，则可以使用等待图的方式。等待图即从资源分配图中删除所有资源类型的节点，并合并适当的边即可。即如果资源分配图中存在P<del>i</del> -&gt;R<del>q</del>和R<del>q</del>-&gt;P<del>j</del>的两条边，则等待图中存在一条P<del>i</del>-&gt;P<del>j</del>的一条边。如图a为资源分配图，b为对应的等待图。</p>
<p><img src="https://raw.githubusercontent.com/unsatisfying/picture-server/main/img%E6%AD%BB%E9%94%81-%E7%AD%89%E5%BE%85%E5%9B%BE.png" alt="image-20220416214133325"></p>
<p>​	当等待图中有一个环则系统死锁。</p>
<h3 id="死锁恢复-解除"><a href="#死锁恢复-解除" class="headerlink" title="死锁恢复&#x2F;解除"></a>死锁恢复&#x2F;解除</h3><p>当检测算法确定当前系统状态存在死锁，于是需要采取一定措施来解除死锁。</p>
<ul>
<li>中止部分&#x2F;全部死锁进程：可以一次性中止所有进程，又或者一次中止一个进程，直到消除死锁循环。</li>
<li>资源抢占：挂起死锁进程，并抢占其所有资源给其他进程使用，且被强占资源的进程需要回滚，同时要确保进程不能发生饥饿情况。</li>
<li>进程回退：让一个&#x2F;多个进程回退到某个状态，使得系统状态到达没有死锁的状态。需要保存历史信息，并设置还原点。</li>
</ul>
]]></content>
      <categories>
        <category>note</category>
      </categories>
      <tags>
        <tag>os</tag>
      </tags>
  </entry>
  <entry>
    <title>True IOMMU Protection from DMA Attacks：When Copy is Faster than Zero Copy</title>
    <url>/2022/04/19/paper_reading/DMA/ASPLOS%20%E2%80%9916True%20IOMMU%20Protection%20from%20DMA%20Attacks%20When%20Copy%20is%20Faster%20than%20Zero%20Copy/</url>
    <content><![CDATA[<p>some paper of DMA:</p>
<p>ISCA’10 IOMMU: Strategies for Mitigating the IOTLB Bottleneck</p>
<p>ATC’11 vIOMMU: Efficient IOMMU Emulation</p>
<p>ATC’15 Utilizing the IOMMU Scalably</p>
<p>ASPLOS’15 rIOMMU: Efficient IOMMU for I&#x2F;O Devices that Employ Ring Buffers</p>
<p>ASPLOS’16 True IOMMU Protection from DMA Attacks: When Copy is Faster than Zero Copy</p>
<p>ASPLOS’18 DAMN: Overhead-free IOMMU Protection for Networking</p>
<p>ATC’20 coIOMMU: A Virtual IOMMU with Cooperative DMA Buffer Tracking for Efficient Memory Management in Direct I&#x2F;O</p>
<p>Security’21 Static Detection of Unsafe DMA Accesses in Device Drivers</p>
<p>EuroSys’21 Characterizing, exploiting, and detecting DMA code injection vulnerabilities in the presence of an IOMMU</p>
<p><a href="https://zhuanlan.zhihu.com/p/20393380">https://zhuanlan.zhihu.com/p/20393380</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/20383904">https://zhuanlan.zhihu.com/p/20383904</a></p>
<p><a href="https://hardenedlinux.github.io/system-security/2020/01/18/peripheral-based_attack_memory.html">https://hardenedlinux.github.io/system-security/2020/01/18/peripheral-based_attack_memory.html</a></p>
<h1 id="ASPLOS-’16-True-IOMMU-Protection-from-DMA-Attacks-When-Copy-is-Faster-than-Zero-Copy"><a href="#ASPLOS-’16-True-IOMMU-Protection-from-DMA-Attacks-When-Copy-is-Faster-than-Zero-Copy" class="headerlink" title="ASPLOS ’16:True IOMMU Protection from DMA Attacks: When Copy is Faster than Zero Copy"></a>ASPLOS ’16:True IOMMU Protection from DMA Attacks: When Copy is Faster than Zero Copy</h1><h2 id="problems"><a href="#problems" class="headerlink" title="problems:"></a>problems:</h2><ul>
<li>(1) it provides protection at page granularity only, whereas DMA buffers can reside on the same page as other data: maps other data in an iommu-mapped page.</li>
<li>(2) it delays DMA buffer unmaps due to performance considerations, creating a vulnerability window in which devices can access in-use memory: because of IOTLB, unmapping is expensive. For the sake of performance, OSes implement deferred protection.</li>
</ul>
<h2 id="contribution"><a href="#contribution" class="headerlink" title="contribution:"></a>contribution:</h2><ul>
<li>(1) observing that copying DMA buffers is preferable to IOTLB invalidation; </li>
<li>(2) providing a truly secure, fast, and scalable intra-OS protection scheme with strict sub-page safety; </li>
<li>(3) implementing the new scheme in Linux and evaluating it with networking workloads at 40 Gb&#x2F;s.</li>
</ul>
<h2 id="Assumptions"><a href="#Assumptions" class="headerlink" title="Assumptions:"></a>Assumptions:</h2><p>1.protecting the OS from unauthorized DMAs to targets not mapped with the DMA API;</p>
<p>2.IOMMU trustworthy，secure boot-stage.</p>
<p>3.only focus on no-mapping DMA accesses.</p>
<h2 id="Attacker-Model"><a href="#Attacker-Model" class="headerlink" title="Attacker Model:"></a>Attacker Model:</h2><p>The attacker controls a set of DMA-capable hardware devices but cannot otherwise access the OS.<br>However, shadow copy design can support untrusted drivers.</p>
<h2 id="Intra-OS-Protection-via-DMA-Shadowing-Key-design"><a href="#Intra-OS-Protection-via-DMA-Shadowing-Key-design" class="headerlink" title="Intra-OS Protection via DMA Shadowing(Key design)"></a>Intra-OS Protection via DMA Shadowing(Key design)</h2><p>The basic idea is simple: we restrict a device’s DMAs to a set of shadow DMA buffers that are permanently mapped in the IOMMU, and copy data to (or from) these buffers from (or to) the OS-allocated DMA buffers.</p>
<h2 id="Goals"><a href="#Goals" class="headerlink" title="Goals"></a>Goals</h2><p>1.Transparency: without modifying DMA API, it can intergrate into any OSes. describe in $5.2, extend in $5.4.</p>
<p>2.Scalability: to reduce overhead, it must minimize synchronization. (locks that are for multiple cores is global)describe in $5.3</p>
<p>3.Generality:support all workloads, including huge DMA buffers. describe in $5.5</p>
<h2 id="5-2-DMA-Shadowing-Implementation-of-the-DMA-API"><a href="#5-2-DMA-Shadowing-Implementation-of-the-DMA-API" class="headerlink" title="$5.2 DMA Shadowing Implementation of the DMA API"></a>$5.2 DMA Shadowing Implementation of the DMA API</h2><h3 id="primitive-DMA-API"><a href="#primitive-DMA-API" class="headerlink" title="primitive DMA API:"></a>primitive DMA API:</h3><ul>
<li>dma_map: <ul>
<li>input: buf addr, size, device rights.</li>
<li>functionality:alloc a IOVA region from device’s IOVA space. create IOMMU page table.</li>
<li>return value: starting of IOVA region.</li>
<li>misc: after do this, devices can access this region while OS&#x2F;driver cannot.</li>
</ul>
</li>
<li>dma_unmap:<ul>
<li>input:IOVA</li>
<li>functonality: remove the mapping in IOMMU, delete the device’s IOMMU page table.</li>
<li>return value: </li>
<li>misc: after do this, devices cannot access this region while OS&#x2F;driver can again.</li>
</ul>
</li>
<li>dma_alloc_coherent of shared buffer:<ul>
<li>input:</li>
<li>functonality:</li>
<li>return value: </li>
<li>misc: alloc a region that drivers and devices can access it simultaneously. In page grained. use dma free coherent to free.</li>
</ul>
</li>
</ul>
<h3 id="shadowing-Implementation-DMA-API"><a href="#shadowing-Implementation-DMA-API" class="headerlink" title="shadowing Implementation DMA API:"></a>shadowing Implementation DMA API:</h3><ul>
<li>dma_map: acquires a shadow buffer of the appropriate size<br>and access rights from the pool, then associated it with mapped OS buffer. return shadow buffer’s IOVA.</li>
<li>dma_unmap: finds the shadow buffer associated with the OS<br>buffer. copy the contents of shadow buffer into OS buffer, then releases the shadow buffer and return.</li>
<li>dma_alloc_coherent and dma_free_coherent: infrequent operations, implement equally with the primitive DMA API.</li>
</ul>
<h3 id="security"><a href="#security" class="headerlink" title="security:"></a>security:</h3><p>although the devices could always access all the shadow buffers, the OS only read value from OS buffer on the time of invoking dma_map and write at dma_unmap time.</p>
<h2 id="5-3-Shadow-Buffer-Pool"><a href="#5-3-Shadow-Buffer-Pool" class="headerlink" title="$5.3 Shadow Buffer Pool"></a>$5.3 Shadow Buffer Pool</h2><ul>
<li>Each device is associated with a unique shadow buffer pool.</li>
<li>API of shadow buffer pool:<ul>
<li>iova t acquire_shadow(buf, size, rights): Acquires a shadow buffer and associates it with the OS buffer buf.</li>
<li>void* find_shadow(iova):Looks up the shadow buffer whose IOVA is iova and returns the OS buffer associated with it.</li>
<li>void release_shadow(shbuf):Releases the shadow buffer shbuf back to the pool, disassociating it from its OS buffer.</li>
</ul>
</li>
</ul>
<h3 id="pool-design"><a href="#pool-design" class="headerlink" title="pool design"></a>pool design</h3><p>A pool maintains a unique set of free lists. Each list holds free shadow buffers of a particular size and device access rights. </p>
<p>each size &#x3D; 3 lisss: read, write, both. </p>
<p>each core &#x3D; own free lists -&gt; concurrent operations,</p>
<p>inter-numa-node access -&gt; quickly access</p>
<p>free page to the list where it was allocated -&gt; never change its rights of mapping -&gt; no flush IOTLB</p>
<h3 id="shadow-buffer-metadata"><a href="#shadow-buffer-metadata" class="headerlink" title="shadow buffer metadata:"></a>shadow buffer metadata:</h3><p>each numa domain &#x3D; a array of Shadow buffer metadata structures for each size class.</p>
<p><img src="https://raw.githubusercontent.com/unsatisfying/picture-server/main/img/![]().png"></p>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>DMA</tag>
      </tags>
  </entry>
  <entry>
    <title>SEIMI：Efficient and Secure SMAP-Enabled Intra-process Memory Isolation</title>
    <url>/2021/09/08/paper_reading/memory%20security/SEIMI/</url>
    <content><![CDATA[<h1 id="标题和来源"><a href="#标题和来源" class="headerlink" title="标题和来源"></a>标题和来源</h1><p><a href="https://www-users.cse.umn.edu/~kjlu/papers/seimi.pdf">2020S&amp;P:SEIMI: Efficient and Secure SMAP-Enabled Intra-process Memory Isolation</a></p>
<h1 id="contribute"><a href="#contribute" class="headerlink" title="contribute"></a>contribute</h1><ul>
<li>提供了一种新奇的domain-based的隔离机制：利用SMAP的机制提出了一种有效防御内存腐败攻击。</li>
<li>一种隔离user 代码的新方法：定义了一种新的安全威胁，在ring运行不信任的user code，然后提出了对于这种威胁的隔离方法。表明了运行user code在privileged mode 是可行的。</li>
<li>New insights from implementation and evaluation：（emmmm，这也算贡献吗，讲道理，但是毕竟中科院的论文，说是贡献就是吧，毕竟咱菜）</li>
</ul>
<h1 id="background"><a href="#background" class="headerlink" title="background"></a>background</h1><ul>
<li>A：Information Hiding（IH）technique：即利用随机化的方式将内存放在一个随机位置。</li>
<li>B：Intra-process Memory Isolation：进程内部的内存隔离比IH的方法更安全一点。这里指把sensitive data保护起来。其中sensitive data分为三类：1）Confidentiality only. 2）Integrity only 3）Both confidentiality and integrity。同时现有的memory-isolation机制分为两类：一类是address-based，一类是domain-based。前者利用边界检查等方式进行隔离（MPX），后者利用RW权限来进行隔离（MPK）。</li>
</ul>
<p>PS：前面那三类sensitive data，第一类和第三类貌似有点难以区分，第二类指的是和完整性相关但是不用加密的，比如返回地址啊，PID这类的数据，第一类和第三类比如秘钥啊，随机数啊这些的东西。</p>
<ul>
<li>C：Intel VT技术</li>
<li>SMAP和smep技术：防止kernel运行userspace的code（smep），防止kernel获取userspace的数据（smap），类似的有ARM中的PAN和RISC-V中的SUM。同时RFLAGS寄存器的AC（access control）flag用于控制是否允许Supervisor-mode访问User-page。</li>
</ul>
<h1 id="Threat-model"><a href="#Threat-model" class="headerlink" title="Threat model"></a>Threat model</h1><ul>
<li>seimi的目的是为了提供进程内部的隔离，即提供一块安全的内存区域，防御被内存腐败攻击。并且假设目标程序可能具有能够被攻击的漏洞，使得攻击者获得二进制读写能力。但是seimi认为程序编写者不是恶意的，即恶意软件不算在保护的范畴。</li>
<li>同时假设内存腐败防御是安全的，也就是说打破seimi的内存隔离是损坏内存防御的前提条件。</li>
<li>当seimi有效的时候，攻击者不能执行code注入攻击和code-reuse攻击，即不能恶意地修改SMAP flag。</li>
<li>同时认为OS是信任的并且安全的。</li>
</ul>
<h1 id="Design"><a href="#Design" class="headerlink" title="Design"></a>Design</h1><h2 id="high-level"><a href="#high-level" class="headerlink" title="high-level"></a>high-level</h2><p><img src="https://raw.githubusercontent.com/unsatisfying/picture-server/main/img/image-20210902153800618.png" alt="image-20210902153800618"></p>
<p>隔离的domain被认为是user-page，其余的内存都被设定为S-page，如图所示。当受信任的code要访问isolate memory时候，执行STAC去disbale smap，当完成访问后执行CLAC去enable samp。并且smap是线程安全的，即一个线程所在的CPU核disable了smap，别的CPU核仍然是不允许访问的（这是由于smap是由RFLAGS寄存器控制的，线程安全的），并且STAC&#x2F;CLAC指令比switching MPK更快。	</p>
<p>同时由于在ring-0（S-mode）运行untrust的程序可能会攻击内核，所以seimi把kernel放在ring -1运行，即用VT-x技术将应用程序和kernel分离，将应用程序放在VMX non-root mode（guest），kernel放在root mode（host）。</p>
<h2 id="challenge-and-approaches"><a href="#challenge-and-approaches" class="headerlink" title="challenge and approaches"></a>challenge and approaches</h2><ul>
<li>需要区分SMAP的Read和write权限：通过分配两个虚拟地址指向同一个物理地址来区分，其中一个映射设置为U-page，可以用于read和write，另一个映射设置为S-page，并且只允许读。</li>
<li>防止泄露一些关键的特权级数据结构比如IDT，PGTable，SDT等：把特权数据结构以及他们的操作放在了VMX root mode下。通常当内核访问这些数据结构的时候都是通过系统调用，中断和异常来操作的，所以利用VT-x技术去拦截这些操作，导致VMExit。</li>
<li>可能会在特权级下滥用硬件的特性，比如使用mov 指令修改pagetable的WPbit来修改权限等：1）触发VMexit，并暂停执行。2）使运行结果失效。3）引发处理器异常并禁用执行。</li>
</ul>
<h1 id="architecture"><a href="#architecture" class="headerlink" title="architecture"></a>architecture</h1><p><img src="https://raw.githubusercontent.com/unsatisfying/picture-server/main/img/image-20210908115842290.png" alt="image-20210908115842290"></p>
<p>如上图示SEIMI的整体架构，它将kernel放在VMX root mode 下，进程运行在vmx non-root模式下的ring0和ring3，其中ring3部分用以isolation，别的process运行在vmx root 模式下的ring3.</p>
<p>SEIMI包含了三个组件，包括</p>
<ul>
<li>内存管理：用以目标process的管理和配置regular&#x2F;isolated 的内存区域</li>
<li>特权级指令的预防：预防特权指令被攻击者滥用</li>
<li>event的重定向。：配置和截断vmexit，当应用使用syscall，中断和异常时候，触发vmexit。</li>
</ul>
<h2 id="内存管理"><a href="#内存管理" class="headerlink" title="内存管理"></a>内存管理</h2><p>因为non-root mode没有 kernel，所以page table要在host的kernel中进行管理，然后将host的pagetable 拷贝到guest作为guest的pagetable，并且修改相应的S-page和U-page即可。并且这样带来一个好处是guest并不能获取page table，因为那是host kernel memory 分配的，guest不能访问到host。同时为了减轻开销，复制全部的page table比较耗时，所以只复制第一层的page table。由此提出了一个shadow mechanism。</p>
<p><img src="https://raw.githubusercontent.com/unsatisfying/picture-server/main/img/image-20210908124656272.png" alt="image-20210908124656272"></p>
<h3 id="A-shadow-mechanism-for-only-page-table-root"><a href="#A-shadow-mechanism-for-only-page-table-root" class="headerlink" title="A shadow mechanism for (only) page-table root."></a>A shadow mechanism for (only) page-table root.</h3><p>如图a所示，将host的PML4的前面256个entry设为u-page，后面256设为S-page。然后把这一页copy给process（图片中称为PML4’ page），它将后面256个kernel的entry清除（因为guest不能访问kernel的页），其余的256个user的page是一样的。</p>
<h3 id="Configuring-the-U-page-and-S-page"><a href="#Configuring-the-U-page-and-S-page" class="headerlink" title="Configuring the U-page and S-page."></a>Configuring the U-page and S-page.</h3><p>在page table中，如果所有级别的页表的U&#x2F;S bit都是1，则它将是u-page，否则任何一个级别的是0，则它是S-page。而在guest中，0-254entry被设置成S-page，255设置成U-page。从而形成二者的隔离。</p>
<h3 id="Supporting-the-read-only-isolated-S-page-region"><a href="#Supporting-the-read-only-isolated-S-page-region" class="headerlink" title="Supporting the read-only isolated S-page region."></a>Supporting the read-only isolated S-page region.</h3><p>SEIMI将#254 entry设置成R&#x2F;W为0，而#255 entry设置成R&#x2F;W为1，从而在user mode下是可读可写， supervisor mode下只能读。</p>
<h2 id="特权级指令的预防（这部分内容比较多且细节，详细内容看paper，讲很清楚）"><a href="#特权级指令的预防（这部分内容比较多且细节，详细内容看paper，讲很清楚）" class="headerlink" title="特权级指令的预防（这部分内容比较多且细节，详细内容看paper，讲很清楚）"></a>特权级指令的预防（这部分内容比较多且细节，详细内容看paper，讲很清楚）</h2><p><img src="https://raw.githubusercontent.com/unsatisfying/picture-server/main/img/image-20210908130214527.png" alt="image-20210908130214527"></p>
<p>上表列出了所有预防的特权指令，</p>
<p>文中细讲了exp type中的部分指令：</p>
<p>#UD VMCS中配置了运行这些会触发</p>
<p>#GP:如何利用段描述符和segment cache来阻止切换segment等等。</p>
<p>#PF：page fault</p>
<p>INV：不让运行</p>
<h2 id="重定向event"><a href="#重定向event" class="headerlink" title="重定向event"></a>重定向event</h2><h3 id="system-call-handling"><a href="#system-call-handling" class="headerlink" title="system call handling"></a>system call handling</h3><p>由于syscall指令不能将控制权从non-root mode切换成root-mode，由此可以用vmcall代替syscall。其中利用设置IA32_LSTAR MSR寄存器，当syscall发生时候，控制流转而运行vmcall指令，然后下一条指令地址会被存储在RCX寄存器中，然后seimi通过在rootmode中重定向到相应的syscall，然后再通过vmresume指令返回，并jmp %rcx运行。</p>
<h3 id="Hardening-system-calls-against-confused-deputy"><a href="#Hardening-system-calls-against-confused-deputy" class="headerlink" title="Hardening system calls against confused deputy"></a>Hardening system calls against confused deputy</h3><p>一些系统调用比如read和write会以地址和count作为参数，通过对这些系统调用进行校验，防止访问到隔离的区域（即non-root mode下的ring0 想去访问ring3.）</p>
<h3 id="Interrupts-and-exceptions-handling"><a href="#Interrupts-and-exceptions-handling" class="headerlink" title="Interrupts and exceptions handling"></a>Interrupts and exceptions handling</h3><p>所有的异常和中断都会触发vmexit，从而进入到seimi中，然后seimi根据中断向量表，进行检查后call handler。</p>
<h3 id="Linux-signal-handling"><a href="#Linux-signal-handling" class="headerlink" title="Linux signal handling"></a>Linux signal handling</h3><p>具体看paper。</p>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>isolation</tag>
      </tags>
  </entry>
  <entry>
    <title>Practical Protection of Kernel Integrity for Commodity OS from Untrusted Extensions</title>
    <url>/2021/09/08/paper_reading/memory%20security/overall/</url>
    <content><![CDATA[<h1 id="challenge"><a href="#challenge" class="headerlink" title="challenge"></a>challenge</h1><ul>
<li><p>针对于单一方面的攻击和防御能够非常有效，比如针对于code完整性，数据完整性和控制流完整性。但是没有针对于多方面的共同保护。</p>
</li>
<li><p>如何使得保护变得通用和实用。比如一些有问题的driver中，某些函数可能是良性的，有些函数是恶意的。很多方法虽然保证了控制流完整性，但是同时也禁止了良性函数的运行。需要达到更细粒度的保护。</p>
</li>
<li><p>现有可以用VMM在OSkernel上再加一层的保护，这种方法虽然有效，但是只能保护很小一部分的object，并且会有很大的开销问题。</p>
</li>
</ul>
<h1 id="target"><a href="#target" class="headerlink" title="target"></a>target</h1><ul>
<li>kernel code&#x2F;data不能被不可信的extenstion修改</li>
<li>寄存器（控制寄存器，标志位寄存器）等硬件结构环境不能被不可信的extenstion修改</li>
<li>控制流不能被不可信的extenstion修改，函数调用一致性（call-return consistency）必须被严格遵守</li>
<li>栈完整性保证，恶意代码不能被注入kernel栈；不可信扩展不能通过自己栈上的番薯指针和返回地址推翻控制流；在栈上属于kernel的non-control data不能被不可信扩展腐败。</li>
</ul>
<h2 id="HUKO"><a href="#HUKO" class="headerlink" title="HUKO"></a>HUKO</h2><ul>
<li>提供了四种状态，user,oskernel,untrusted extensions,trusted extensions.</li>
<li>针对于不同的状态用不用的HAP（硬件辅助页表，即EPT等）来标识不同权限，针对TLB做优化</li>
<li>对于kernel的不同object（task_struct等关键数据）做了label（具体来说应该是给含有object的物理页打了标签），这些标签用了页表中reserve的bit，最多支持32种类型的标签。</li>
<li>并实现了一个trusted driver，用来关注hypervisor的分配和回收页面，并且关注guest对于页面的使用情况，讲情况报告给hypervisor。</li>
<li>把所有kernel symbol table以及一些管理员认定的label成trust。所有新load的都是untrust。管理员可以认证其为trust。如果untrust做了一些违规操作就是报错。所有untrust的行为会被跟踪。</li>
</ul>
<h2 id="实现细节"><a href="#实现细节" class="headerlink" title="实现细节"></a>实现细节</h2><ul>
<li>对于一些大页，可能混合了data和code，就把2M的page细分成512个4KB的page，对于4KBpage打混合标签，所有的访问都会引起hypervisor的关注。</li>
<li>实现了一个labeling helper的extension，用以帮助trace 动态的object（静态的像kernel code 这些都在systemmap上知道地址），告知hypervisor分配页面的时候什么页面上的object是什么（用hypercall接口告知）。</li>
</ul>
<h2 id="一些奇怪的点"><a href="#一些奇怪的点" class="headerlink" title="一些奇怪的点"></a>一些奇怪的点</h2><p>他claim自己低overhead，实际上是和shadow page  table 和EPT比较，当然overhead低啊。</p>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>isolation</tag>
      </tags>
  </entry>
  <entry>
    <title>SoK：Eternal War in Memory</title>
    <url>/2021/08/26/paper_reading/memory%20security/SoK%EF%BC%9AEternal%20War%20in%20Memory/</url>
    <content><![CDATA[<h1 id="论文来源"><a href="#论文来源" class="headerlink" title="论文来源"></a>论文来源</h1><p><a href="https://nebelwelt.net/publications/files/13Oakland.pdf">IEEE Security&amp;Privacy’13：SoK: Eternal War in Memory</a></p>
<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><ul>
<li>描述了一些当今系统的攻击方式；</li>
<li>并介绍了防御的一些策略；</li>
<li>同时分析了为什么没有部署更严格的防御策略的原因；</li>
<li>在不同的策略之间进行比较，为了找到安全和效率之间的平衡。</li>
<li>提供了一些当今的研究问题，并给了一些建议。</li>
</ul>
<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>​	如今的防御措施有几个方面的原因导致不能大面积部署：</p>
<ul>
<li>performance不够好，overhead太大；</li>
<li>方法和过去的代码或者feature不兼容；</li>
<li>方法不够健壮，提供的保护也不是很完整；</li>
<li>有些保护依赖于修改工具链和编译器，但是很多工具链也并不是开源的。</li>
</ul>
<h2 id="contribution"><a href="#contribution" class="headerlink" title="contribution"></a>contribution</h2><ul>
<li>总结内存损坏攻击的通用模型，并根据模型确定不同的可执行安全策略;</li>
<li>通过将攻击手段的执行阶段与利用阶段做匹配，总结哪些攻击目前还没被保护的，或者过去提出的方法不适用的;</li>
<li>评估和比较提出的方法的performance，兼容性和鲁棒性。</li>
<li>讨论了为什么很多防御措施没有被大范围接受，然后新的措施的标准是什么。</li>
</ul>
<h1 id="attack"><a href="#attack" class="headerlink" title="attack"></a>attack</h1><p>一张各个阶段的攻击总结：</p>
<p><img src="https://raw.githubusercontent.com/unsatisfying/picture-server/main/img/image-20210826141804129.png" alt="image-20210826141804129"></p>
<h2 id="一些词的解释"><a href="#一些词的解释" class="headerlink" title="一些词的解释"></a>一些词的解释</h2><p><code>dangling pointer</code>：空悬指针，指针指向的内存已经释放。</p>
<p><code>spatial error</code>：访问越界的指针错误</p>
<p><code>temporal error</code>：解引用一个dangling指针引起的错误</p>
<p><code>Return Oriented Programming (ROP)</code>：返回现有代码的攻击，组合现有代码完成一些操作。</p>
<p><code>Jump Oriented Programming (JOP)</code>：面向跳转编程，即用直接跳转完成类似ROP的效果</p>
<h2 id="内存corruption（下面的序号对应图中最左边圆形的序号）"><a href="#内存corruption（下面的序号对应图中最左边圆形的序号）" class="headerlink" title="内存corruption（下面的序号对应图中最左边圆形的序号）"></a>内存corruption（下面的序号对应图中最左边圆形的序号）</h2><h3 id="指针"><a href="#指针" class="headerlink" title="指针"></a>指针</h3><p>1.指针错误类型：</p>
<ul>
<li>通过指针越界或者访问释放了的内存来使得指针失效，主要有<code>buffer overflow/underflow</code>。</li>
<li>通过边界检查错误造成的越界或者整数溢出，主要有<code>integer overflow</code>，截断，符号错误，指针转换错误。</li>
<li>也可能通过内存腐败，修改了指针数据而造成指针error。</li>
</ul>
<p>2.获取这样的指针：</p>
<ul>
<li>通过不正确的异常处理bug，比如有些程序释放了一个对象之后没有把指向该对象的指针初始化。这种被叫做<code>use-after-free</code>。可以在堆分配和释放的时候做一些手脚。</li>
<li>一些局部变量指针被全局指针赋值时候也可能会导致问题，因为这样的指针在函数返回时候释放了局部的变量，但是全局的部分称为了悬挂指针。</li>
</ul>
<p>3.有了这样的指针之后如何利用：</p>
<p>​	利用之前获得的指针进行读或者写的时候，就可以泄露一些内部的数据。</p>
<ul>
<li><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">//比如如下这种情况，下一次的控制流跳转是跳转到执行表中的某个函数，但是因为index是用户控制的，就可能产生任意地址的跳转,</span></span><br><span class="line"><span class="comment">//攻击者可以让jump_table指向攻击者可以控制的地方</span></span><br><span class="line">func_ptr jump_table[<span class="number">3</span>] = &#123;fn_0, fn_1, fn_2&#125;;</span><br><span class="line">jump_table[user_input]();</span><br></pre></td></tr></table></figure>
</li>
<li><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">//printf format string bug,利用类似的bug攻击者可以读任意地址内存</span></span><br><span class="line"><span class="built_in">printf</span>(user_input); <span class="comment">// input &quot;%3$x&quot; prints the</span></span><br><span class="line"><span class="comment">// 3rd integer on the stack</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>如果攻击者控制的是写指针，那么任何指针都可能被覆盖写，甚至任何数据都可能被覆盖写。<br>比如<code>buffer overflow/underflow</code>和下标错误，可以写覆盖写敏感错误的数据比如返回地址或者虚表指针。其中重写虚表指针就造成了图中3-&gt;1的反向循环。第一轮循环通过前述方式修改虚表指针，然后第二轮循环由于别的code解引用了这个虚表指针，从而造成控制流的劫持。从此循环反复，越来越多的指针就能被利用。</p>
</li>
<li><p>攻击者利用corrupting的指针调用free()也能造成内存破坏。[jp, “Advanced Doug Lea’s malloc exploits,” Phrack, vol. 11, no. 61, Aug 2003.]</p>
</li>
<li><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">//打印时候解引用的指针也会造成信息的泄露，控制err_msg指针的指向可以进行任意地址的读</span></span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;%s\n&quot;</span>, err_msg);</span><br></pre></td></tr></table></figure>

<p>下面是针对temporal error的利用</p>
</li>
<li><p>当解引用悬挂指针的时候，指向的内存可能被内存分配器比如堆分配器分配给了别的object，就可以利用悬挂指针对别的object进行控制读写，甚至double-free也能造成任意读写，即新的object也被错误地释放了。</p>
</li>
</ul>
<h3 id="Code-corruption-攻击"><a href="#Code-corruption-攻击" class="headerlink" title="Code corruption 攻击"></a>Code corruption 攻击</h3><p>​	利用上述bug去重写程序在内存中的code，但是把code设置成read-only。</p>
<p>​	但是他不支持“程序自己修改代码”和“Just-In-Time（JIT）即时编译”。如今大部分浏览器用的都是JIT用以解析Flash和JS脚本，这会给代码部分一个可写的窗口期。</p>
<h3 id="控制流挟持攻击"><a href="#控制流挟持攻击" class="headerlink" title="控制流挟持攻击"></a>控制流挟持攻击</h3><p>4.通过前述指针的error，可以修改return address来跳转到攻击者可控的地址空间。这可被地址空间随机化缓解（不能根除）</p>
<p>5.通过直接call或者间接跳转或者函数返回指令ret来造成CFI（Control-flow Integrity）的破坏。</p>
<p>6.第六步就是运行恶意代码，比如shellcode。这样可以被数据页面不可执行缓解，即W⊕X (Write XOR Execute) 策略，即页面要么可写，要么可执行，但是不能同时可写可执行。同样JIT和self-modifying code的情况不适用。于是提出了（Instruction Set Randomization），即加密代码，但是performance太差了，慢慢被淘汰。同时攻击者为了绕过权限，设计了重用现有代码，实现ROP攻击比如return-to-libc攻击或者通过gadgets小组件来执行恶意操作，还有JOP的攻击。目前这种类型只能缓解，不能根除。比如面向编译器的一些缓解方式，二进制重写以及消除大块。（个人知识，paper里没写：目前Intel和ARM各自有硬件上的缓解措施，比如CET，形成第二个shadow stack记录跳转地址。）</p>
<h3 id="data-only攻击"><a href="#data-only攻击" class="headerlink" title="data-only攻击"></a>data-only攻击</h3><p>3.总的来说攻击者目标就是恶意修改程序逻辑，获得更多的控制权限，甚至修改特权级以及泄露信息，这个目标可以通过不修改显式控制流相关数据比如返回地址，跳转地址这种来完成，可以通过修改变量来改变程序执行逻辑。比如如下代码：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">bool</span> isAdmin = <span class="literal">false</span>;</span><br><span class="line">...</span><br><span class="line"><span class="keyword">if</span> (isAdmin) <span class="comment">// do privileged operations</span></span><br></pre></td></tr></table></figure>

<p>可以通过数据空间随机化以及增加数据熵的方式缓解。</p>
<h3 id="信息泄露"><a href="#信息泄露" class="headerlink" title="信息泄露"></a>信息泄露</h3><p>任何内存错误都可能造成信息泄露，而利用信息泄露可以绕过ASLR，解决的办法是数据空间随机化。</p>
<h2 id="real-world的保护和利用"><a href="#real-world的保护和利用" class="headerlink" title="real-world的保护和利用"></a>real-world的保护和利用</h2><p>用的最多的是stack smashing  protection，DEP&#x2F;W⊕X 和 ASLR。windows还用SafeSEH 和 SEHOP保护堆元数据和异常处理，但是这样的保护很有限，仅仅是在跳转时候check一下，也仅仅是检查了返回地址和异常处理函数等方面，没有覆盖到全部，并且这种可以被绕过，比如利用索引来攻击，而不是覆盖。</p>
<ul>
<li>stack smashing  protection：在栈上返回地址和buffer之间放一个随机值（cookie或者canary），然后在返回之前check</li>
<li>SafeSEH and SEHOP：在使用异常处理指针时候先用cookie验证一下。</li>
</ul>
<p>DEP&#x2F;W⊕X可以保护code注入的攻击，但是不能保护ROP这种code reuse攻击，这种攻击可以用ASLR稍微防护一下，但是可以被去随机化和信息泄露等方式破解ASLR。</p>
<p>现在PDF viewers, 办公应用，web浏览器等运行user可控的脚本，可以用来动态构建payload，并使目标机器运行。</p>
<h1 id="方法和评价标准"><a href="#方法和评价标准" class="headerlink" title="方法和评价标准"></a>方法和评价标准</h1><ul>
<li><p>主要分为两大类：概率性保护（probabilistic）和确定性保护（deterministic）</p>
<p>概率性主要是随机化：Instruction Set Randomization, Address Space Randomization, or Data Space Randomization, build on randomization or encryption</p>
<p>其他的都是确定性的保护。</p>
</li>
</ul>
<h2 id="memory-safety"><a href="#memory-safety" class="headerlink" title="memory safety"></a>memory safety</h2><p>指针边界检查：</p>
<ul>
<li>胖指针：要修改指针结构和代码结构，让一个指针结构体记录额外的信息</li>
<li>SoftBound：将元数据和指针分离开来，用一个熵来记录，数据都存在一个特定的区域，类似哈希的方式（这里为了防止别人破解用的加密方式），在指针解引用的时候去特定区域取数据。</li>
</ul>
<p>基于对象的指针检查：由于我们不知道指针是不是指向正确的对象，尽管有边界检查，对象指错了也不行。基于对象的指针关注于指针运算，而非解引用。但是这样的过程只关注于对象创建和释放的时候，在对象被修改的时候是注意不到的。</p>
<h2 id="Temporal-safety"><a href="#Temporal-safety" class="headerlink" title="Temporal safety"></a>Temporal safety</h2><p>特殊的分配器：不再使用相同的虚拟地址。或者地址只能被相同类型的对象使用。或者随机分配位置的分配器</p>
<p>根据对象的方法：</p>
<p>根据指针的方法：不仅要维护边界，还要维护分配信息保证安全。</p>
<h1 id="别的资料"><a href="#别的资料" class="headerlink" title="别的资料"></a>别的资料</h1><p><a href="http://www.pl-enthusiast.net/2014/07/21/memory-safety/">What is memory safety</a></p>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>security</tag>
      </tags>
  </entry>
  <entry>
    <title>SPP(Sub-page protection)</title>
    <url>/2021/08/17/paper_reading/spp/spp/</url>
    <content><![CDATA[<h1 id="SPP-Sub-page-protection"><a href="#SPP-Sub-page-protection" class="headerlink" title="SPP(Sub-page protection)"></a>SPP(Sub-page protection)</h1><h2 id="1-SPP-in-manual（28-2-4-翻译）"><a href="#1-SPP-in-manual（28-2-4-翻译）" class="headerlink" title="1. SPP in manual（28.2.4 翻译）"></a>1. SPP in manual（28.2.4 翻译）</h2><ul>
<li>在Intel中用 <strong>Sub-Page Write Permissions</strong> 来形容<strong>SPP</strong>。 它允许了对于GPA上更细粒度的划分，划分成128字节对齐的子页。</li>
</ul>
<span id="more"></span>

<ul>
<li><p>一些不适用的情况：</p>
<p>* </p>
</li>
<li><p>具体过程：</p>
<ul>
<li><p>GPA的[11:7] bit 决定了子页的idx，用以标识子页面</p>
</li>
<li><p>对于每一个enable了SPP的GPA页面，都有一个64bit的SPP vector来控制每个子页的权限，假设页面idx为S（GPA[11:7]），如果SPP vector中2S处的bit位为1时，才能往该子页写，（2S+1）处还没使用，必须为0.</p>
</li>
<li><p>SPP vector处于内存中，获取SPP vector过程如下（SPPTP - root SPP table - SPPL3 table - SPPL2 table - SPPL1 table - 查看对应页(GPA[20:12]) 指向偏移，查看该 64 位向量的偏移(子页号 GPA[11:7])）：</p>
<ul>
<li>SPPTP(子页面权限表指针) VM-execution control 包含 4KB 大小的 root SPP table，GPA[47:39] 标识了该表中的一个 64 位项，称为 SPPL4E。</li>
<li>4KB 的 SPPL3 table 位于 SPPL4E 所保存的物理地址中。GPA[38:30] 标识了该表中的一个 64 位项，称为 SPPL3E。</li>
<li>4KB 的 SPPL2 table 位于 SPPL3E 所保存的物理地址中。GPA[29:21]标识该表中的一个 64 位项，称为 SPPL2E。</li>
<li>SPPL2E 保存了 4KB 大小的 SPPL1 table 的物理地址。GPA[20:12] 标识了该地址的 64 位 SPP 向量。子页许可向量的位 2S 决定了地址是否可以被写入，其中 S 是地址位 11:7 的值。</li>
</ul>
<p>（用于访问这些表的内存类型在 IA32_VMX_BASIC MSR 的位 53:50 中指出，Appendix A.1）</p>
</li>
<li><p>仅当页面的 SPP 向量中的指示位针对每个子页面时，才允许对单个 4KB 页面上的多个 128B 子页面进行写访问。以下项目适用于访问写入两个 4KB 页面的情况：</p>
<ul>
<li>如果根据 Section 28.2.3.2，不允许对任何一页面进行写入，则即使该页面的 GPA 符合子页面写入权限，也可能不允许访问。</li>
<li>只有在以下情况下才允许访问：要么对于每一页，Section 28.2.3.2 允许对该页写入；要么 GPA 有资格获得子页面写许可并且页面的子页面向量允许写入。</li>
</ul>
</li>
<li><p>每个项（SPPL4E、SPPL3E、SPPL2E）的位 0 为该项的有效位。如果在映射过程中，发现位 0 为 0，那么映射过程终止，逻辑处理器发生 SPP 未命中（<strong>SPP miss</strong>）。</p>
</li>
<li><p>每个项（SPPL4E、SPPL3E、SPPL2E）中，保留位 11:1，以及 63:N，其中 N 是处理器的物理地址宽度。如果对保留位置位，则映射过程终止，并且逻辑处理器触发 SPP misconfiguration。</p>
</li>
<li><p>奇数位置的 SPP 向量中的位也被保留；SPP misconfiguration 也会发生在当这些向量中的保留位被置位时。</p>
</li>
<li><p>SPP misses 和 SPP misconfigurations 被称为 SPP-related events，二者均会导致 VM exits。</p>
</li>
</ul>
</li>
</ul>
<h2 id="2-overview"><a href="#2-overview" class="headerlink" title="2. overview"></a>2. overview</h2><p><img src="https://raw.githubusercontent.com/unsatisfying/picture-server/main/img/image-20210714170006047.png" alt="image-20210714170006047"></p>
<h2 id="3-KVM-support"><a href="#3-KVM-support" class="headerlink" title="3.KVM  support"></a>3.KVM  support</h2><p><a href="https://lwn.net/ml/linux-kernel/cover.1543481993.git.yi.z.zhang@linux.intel.com/">https://lwn.net/ml/linux-kernel/cover.1543481993.git.yi.z.zhang@linux.intel.com/</a></p>
]]></content>
      <categories>
        <category>note</category>
      </categories>
      <tags>
        <tag>virtualization</tag>
      </tags>
  </entry>
  <entry>
    <title>KVM 逃逸漏洞 From Project Zero</title>
    <url>/2021/08/17/paper_reading/%E8%99%9A%E6%8B%9F%E5%8C%96/KVM%20escape/</url>
    <content><![CDATA[<h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><p>主要参考<a href="https://googleprojectzero.blogspot.com/2021/06/an-epyc-escape-case-study-of-kvm.html">链接</a>。</p>
<h2 id="初衷"><a href="#初衷" class="headerlink" title="初衷"></a>初衷</h2><p>由于过去KVM逃逸的漏洞大多是因为user态下的qemu的问题造成的，很少有KVM自身的代码有漏洞。</p>
<h1 id="前置知识"><a href="#前置知识" class="headerlink" title="前置知识"></a>前置知识</h1><ul>
<li>AMD的虚拟化扩展成为<a href="https://www.amd.com/system/files/TechDocs/24593.pdf">SVM</a>，其中重要的一个指令是VMRUN，该指令有一个隐式的参数：运行该指令时RAX寄存器指向了页对齐的VMCB的物理地址（在intel中叫VMCS）。</li>
<li>虚拟化和嵌套虚拟化的知识在别的文章里有讲。</li>
<li>大部分的嵌套虚拟化的代码都在 <a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/arch/x86/kvm/svm/nested.c?h=v5.11">arch&#x2F;x86&#x2F;kvm&#x2F;svm&#x2F;nested.c</a>中，KVM拦截VMRUN指令的实现在函数<font color=blue>nested_svm_vmrun</font>:</li>
</ul>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">nested_svm_vmrun</span><span class="params">(<span class="keyword">struct</span> vcpu_svm *svm)</span> <span class="comment">//struct vcpu_svm是vcpu的结构体</span></span><br><span class="line">&#123;</span><br><span class="line">        <span class="type">int</span> ret;</span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">vmcb</span> *<span class="title">vmcb12</span>;</span><span class="comment">//vmcb12指的是guest hypervisor创建的的结构体，L1为了运行L2用的</span></span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">vmcb</span> *<span class="title">hsave</span> =</span> svm-&gt;nested.hsave;<span class="comment">//vmcb12的hsave，即L1的状态</span></span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">vmcb</span> *<span class="title">vmcb</span> =</span> svm-&gt;vmcb;<span class="comment">//与当前运行的vcpu绑定的vmcb结构体 vmcb01</span></span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">kvm_host_map</span> <span class="title">map</span>;</span> <span class="comment">//负责将GPA转换成HPA的map</span></span><br><span class="line">        u64 vmcb12_gpa;</span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">        vmcb12_gpa = svm-&gt;vmcb-&gt;save.rax; ** <span class="number">1</span> ** <span class="comment">//L1中的GPA，该GPA用于存放vmcb12结构体。</span></span><br><span class="line">        ret = kvm_vcpu_map(&amp;svm-&gt;vcpu, gpa_to_gfn(vmcb12_gpa), &amp;<span class="built_in">map</span>); ** <span class="number">2</span> **<span class="comment">//利用之前的map完成地址转换</span></span><br><span class="line">        …</span><br><span class="line">        ret = kvm_skip_emulated_instruction(&amp;svm-&gt;vcpu);</span><br><span class="line"></span><br><span class="line">        vmcb12 = <span class="built_in">map</span>.hva;<span class="comment">//并把HPA映射到HVA上，保证KVM能够直接访问</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (!nested_vmcb_checks(svm, vmcb12)) &#123; ** <span class="number">3</span> **			<span class="comment">//一旦映射完成就开始检查vmcb12的内容</span></span><br><span class="line">                vmcb12-&gt;control.exit_code    = SVM_EXIT_ERR;</span><br><span class="line">                vmcb12-&gt;control.exit_code_hi = <span class="number">0</span>;</span><br><span class="line">                vmcb12-&gt;control.exit_info_1  = <span class="number">0</span>;</span><br><span class="line">                vmcb12-&gt;control.exit_info_2  = <span class="number">0</span>;</span><br><span class="line">                <span class="keyword">goto</span> out;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * Save the old vmcb, so we don&#x27;t need to pick what we save, but can</span></span><br><span class="line"><span class="comment">         * restore everything when a VMEXIT occurs</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="comment">//把vmcb01的guest state存入vmcb12的host</span></span><br><span class="line">        hsave-&gt;save.es     = vmcb-&gt;save.es;</span><br><span class="line">        hsave-&gt;save.cs     = vmcb-&gt;save.cs;</span><br><span class="line">        hsave-&gt;save.ss     = vmcb-&gt;save.ss;</span><br><span class="line">        hsave-&gt;save.ds     = vmcb-&gt;save.ds;</span><br><span class="line">        hsave-&gt;save.gdtr   = vmcb-&gt;save.gdtr;</span><br><span class="line">        hsave-&gt;save.idtr   = vmcb-&gt;save.idtr;</span><br><span class="line">        hsave-&gt;save.efer   = svm-&gt;vcpu.arch.efer;</span><br><span class="line">        hsave-&gt;save.cr0    = kvm_read_cr0(&amp;svm-&gt;vcpu);</span><br><span class="line">        hsave-&gt;save.cr4    = svm-&gt;vcpu.arch.cr4;</span><br><span class="line">        hsave-&gt;save.rflags = kvm_get_rflags(&amp;svm-&gt;vcpu);</span><br><span class="line">        hsave-&gt;save.rip    = kvm_rip_read(&amp;svm-&gt;vcpu);</span><br><span class="line">        hsave-&gt;save.rsp    = vmcb-&gt;save.rsp;</span><br><span class="line">        hsave-&gt;save.rax    = vmcb-&gt;save.rax;</span><br><span class="line">        <span class="keyword">if</span> (npt_enabled)</span><br><span class="line">                hsave-&gt;save.cr3    = vmcb-&gt;save.cr3;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">                hsave-&gt;save.cr3    = kvm_read_cr3(&amp;svm-&gt;vcpu);</span><br><span class="line">        copy_vmcb_control_area(&amp;hsave-&gt;control, &amp;vmcb-&gt;control);</span><br><span class="line">        svm-&gt;nested.nested_run_pending = <span class="number">1</span>;</span><br><span class="line">    	<span class="comment">//进入L2的函数，</span></span><br><span class="line">        <span class="keyword">if</span> (enter_svm_guest_mode(svm, vmcb12_gpa, vmcb12)) ** <span class="number">4</span> **</span><br><span class="line">                <span class="keyword">goto</span> out_exit_err;</span><br><span class="line">        <span class="keyword">if</span> (nested_svm_vmrun_msrpm(svm))</span><br><span class="line">                <span class="keyword">goto</span> out;</span><br><span class="line">out_exit_err:</span><br><span class="line">        svm-&gt;nested.nested_run_pending = <span class="number">0</span>;</span><br><span class="line">        svm-&gt;vmcb-&gt;control.exit_code    = SVM_EXIT_ERR;</span><br><span class="line">        svm-&gt;vmcb-&gt;control.exit_code_hi = <span class="number">0</span>;</span><br><span class="line">        svm-&gt;vmcb-&gt;control.exit_info_1  = <span class="number">0</span>;</span><br><span class="line">        svm-&gt;vmcb-&gt;control.exit_info_2  = <span class="number">0</span>;</span><br><span class="line">        nested_svm_vmexit(svm);</span><br><span class="line">out:</span><br><span class="line">        kvm_vcpu_unmap(&amp;svm-&gt;vcpu, &amp;<span class="built_in">map</span>, <span class="literal">true</span>);</span><br><span class="line">        <span class="keyword">return</span> ret;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>进入从L0进入L1的函数是enter_svm_guest_mode，这里还是L0的上下文</li>
</ul>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">enter_svm_guest_mode</span><span class="params">(<span class="keyword">struct</span> vcpu_svm *svm, u64 vmcb12_gpa,</span></span><br><span class="line"><span class="params">                         <span class="keyword">struct</span> vmcb *vmcb12)</span></span><br><span class="line">&#123;</span><br><span class="line">        <span class="type">int</span> ret;</span><br><span class="line">        svm-&gt;nested.vmcb12_gpa = vmcb12_gpa; <span class="comment">//把vmcb12_gpa(这里是从L0视角来看的vmcb12)赋值给svm中相应的结构</span></span><br><span class="line">    </span><br><span class="line">		<span class="comment">//这里把vmcb12的control area直接赋值给svm-&gt;nest.ctl，（这里的SVM是vmcb02）但是这里有个问题，前面是check过的，但是这里使用并没有check(博客里是这么说的)</span></span><br><span class="line">        load_nested_vmcb_control(svm, &amp;vmcb12-&gt;control);<span class="comment">//貌似5.11的源码还没这一行，不知道为什么博客里给了这一行</span></span><br><span class="line">        nested_prepare_vmcb_save(svm, vmcb12);<span class="comment">//5.11源码里这里将vmcb12赋值给svm-&gt;vmcb-&gt;save.*</span></span><br><span class="line">        nested_prepare_vmcb_control(svm);<span class="comment">//5.11源码里将svm-&gt;nested.ctl赋值给svm-&gt;vmcb-&gt;control。。并把VCPU进入guest模式，准备进入L2。</span></span><br><span class="line"></span><br><span class="line">        ret = nested_svm_load_cr3(&amp;svm-&gt;vcpu, vmcb12-&gt;save.cr3,</span><br><span class="line">                                  nested_npt_enabled(svm));</span><br><span class="line">        <span class="keyword">if</span> (ret)</span><br><span class="line">                <span class="keyword">return</span> ret;</span><br><span class="line"></span><br><span class="line">        svm_set_gif(svm, <span class="literal">true</span>);<span class="comment">//global interrupt flag</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="type">void</span> <span class="title function_">load_nested_vmcb_control</span><span class="params">(<span class="keyword">struct</span> vcpu_svm *svm,</span></span><br><span class="line"><span class="params">                                     <span class="keyword">struct</span> vmcb_control_area *control)</span></span><br><span class="line">&#123;</span><br><span class="line">        copy_vmcb_control_area(&amp;svm-&gt;nested.ctl, control);</span><br><span class="line">        ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="BUG"><a href="#BUG" class="headerlink" title="BUG"></a>BUG</h1><p>上面说明了在函数<font color=blue>enter_svm_guest_mode</font>中，因为在赋值时候没有double check，导致的bug，那么如何利用这个bug呢，首先我们先看看函数<font color=blue>nested_vmcb_check_controls</font>做了哪些检查：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">static</span> <span class="type">bool</span> <span class="title function_">nested_vmcb_check_controls</span><span class="params">(<span class="keyword">struct</span> vmcb_control_area *control)</span></span><br><span class="line">&#123;</span><br><span class="line">        <span class="keyword">if</span> ((vmcb_is_intercept(control, INTERCEPT_VMRUN)) == <span class="number">0</span>)</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (control-&gt;asid == <span class="number">0</span>)<span class="comment">//asid用于区分不同虚拟机的地址空间</span></span><br><span class="line">                <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">if</span> ((control-&gt;nested_ctl &amp; SVM_NESTED_CTL_NP_ENABLE) &amp;&amp;</span><br><span class="line">            !npt_enabled)<span class="comment">//嵌套虚拟化控制</span></span><br><span class="line">                <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>第一次检查中，检查VMRUN指令是否可以被截断，但是SVM的VMCB中包含了一个bit用来控制guest中运行VMRUN是否可以被截断，并且清除这个位会导致VMExit的发生（因为他不被硬件支持）。所以我们可以通过竞争的方式，在多核系统上不断反复翻转这个bit，就可能会导致问题的产生。</p>
<p>既然设置这个bit会导致VMexit，那我们先来看看KVM中VMexit的处理函数：<font color=blue>handle_exit</font> in <a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/arch/x86/kvm/svm/svm.c?h=v5.11">arch&#x2F;x86&#x2F;kvm&#x2F;svm.c</a>,每次退出时候都要判断该退出原因是由L0处理还是L1的hypervisor处理。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"> <span class="type">static</span> <span class="type">int</span> <span class="title function_">handle_exit</span><span class="params">(<span class="keyword">struct</span> kvm_vcpu *vcpu, <span class="type">fastpath_t</span> exit_fastpath)</span></span><br><span class="line">&#123;</span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">vcpu_svm</span> *<span class="title">svm</span> =</span> to_svm(vcpu);</span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">kvm_run</span> *<span class="title">kvm_run</span> =</span> vcpu-&gt;run;</span><br><span class="line">        u32 exit_code = svm-&gt;vmcb-&gt;control.exit_code;</span><br><span class="line"></span><br><span class="line">        … </span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (is_guest_mode(vcpu)) &#123;<span class="comment">//判断是L1的vcpu发生exit还是L0的vcpu发生exit，即是从L2退出到L0还是从L1退出到L0。如果为真则是L2退出。</span></span><br><span class="line">                <span class="type">int</span> vmexit;</span><br><span class="line"></span><br><span class="line">                trace_kvm_nested_vmexit(exit_code, vcpu, KVM_ISA_SVM);</span><br><span class="line"></span><br><span class="line">                vmexit = nested_svm_exit_special(svm);<span class="comment">//如果退出原因是中断或者别的特殊原因（INTR,NMI,NPF），就先L0处理，然后return NESTED_EXIT_HOST，否则return NESTED_EXIT_CONTINUE，由L1接着处理。</span></span><br><span class="line">            </span><br><span class="line">			   <span class="comment">//L1的hypervisor处理</span></span><br><span class="line">                <span class="keyword">if</span> (vmexit == NESTED_EXIT_CONTINUE)</span><br><span class="line">                        vmexit = nested_svm_exit_handled(svm); <span class="comment">//进入处理L0要干的一些事情，如果要注入</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (vmexit == NESTED_EXIT_DONE)<span class="comment">//用于处理nested_svm_exit_special中处理过了的vmexit，因为在nested_svm_exit_handled中处理的在该函数中自己已经返回guest运行了</span></span><br><span class="line">                        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">nested_svm_exit_handled</span><span class="params">(<span class="keyword">struct</span> vcpu_svm *svm)</span></span><br><span class="line">&#123;</span><br><span class="line">        <span class="type">int</span> vmexit;</span><br><span class="line"></span><br><span class="line">        vmexit = nested_svm_intercept(svm); <span class="comment">//调用nested_svm_intercept查看exit是否需要处理，如果要L1处理则返回NESTED_EXIT_DONE，否则返回NESTED_EXIT_HOST。</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (vmexit == NESTED_EXIT_DONE)</span><br><span class="line">                nested_svm_vmexit(svm); <span class="comment">//将相应的内容写入vmcb12中，然后恢复guest运行，通过enter_svm_guest_mode函数恢复运行。</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> vmexit;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="type">int</span> <span class="title function_">nested_svm_intercept</span><span class="params">(<span class="keyword">struct</span> vcpu_svm *svm)</span></span><br><span class="line">&#123;</span><br><span class="line">        <span class="comment">// exit_code==INTERCEPT_VMRUN when the L2 guest executes vmrun</span></span><br><span class="line">        u32 exit_code = svm-&gt;vmcb-&gt;control.exit_code;</span><br><span class="line">        <span class="type">int</span> vmexit = NESTED_EXIT_HOST;</span><br><span class="line">        <span class="keyword">switch</span> (exit_code) &#123;</span><br><span class="line">        <span class="keyword">case</span> SVM_EXIT_MSR:</span><br><span class="line">                vmexit = nested_svm_exit_handled_msr(svm);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> SVM_EXIT_IOIO:</span><br><span class="line">                vmexit = nested_svm_intercept_ioio(svm);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">        … </span><br><span class="line">        <span class="keyword">default</span>: &#123;</span><br><span class="line">                <span class="keyword">if</span> (vmcb_is_intercept(&amp;svm-&gt;nested.ctl, exit_code)) </span><br><span class="line">		<span class="comment">//判断svm-&gt;nested.ctl是否为1.而且这是default的情况，通常情况下都会为1，并且返回NESTED_EXIT_DONE.</span></span><br><span class="line">                        vmexit = NESTED_EXIT_DONE;</span><br><span class="line">        	&#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> vmexit;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">nested_svm_vmexit</span><span class="params">(<span class="keyword">struct</span> vcpu_svm *svm)</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="type">int</span> rc;</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">vmcb</span> *<span class="title">vmcb12</span>;</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">vmcb</span> *<span class="title">hsave</span> =</span> svm-&gt;nested.hsave;</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">vmcb</span> *<span class="title">vmcb</span> =</span> svm-&gt;vmcb;</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">kvm_host_map</span> <span class="title">map</span>;</span></span><br><span class="line"></span><br><span class="line">	rc = kvm_vcpu_map(&amp;svm-&gt;vcpu, gpa_to_gfn(svm-&gt;nested.vmcb12_gpa), &amp;<span class="built_in">map</span>);</span><br><span class="line">	<span class="keyword">if</span> (rc) &#123;</span><br><span class="line">		<span class="keyword">if</span> (rc == -EINVAL)</span><br><span class="line">			kvm_inject_gp(&amp;svm-&gt;vcpu, <span class="number">0</span>);</span><br><span class="line">		<span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	vmcb12 = <span class="built_in">map</span>.hva;<span class="comment">//将VMCB12映射到L0，使得L0能够直接访问</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">/* Exit Guest-Mode */</span></span><br><span class="line">	leave_guest_mode(&amp;svm-&gt;vcpu);</span><br><span class="line">	svm-&gt;nested.vmcb12_gpa = <span class="number">0</span>;</span><br><span class="line">	WARN_ON_ONCE(svm-&gt;nested.nested_run_pending);</span><br><span class="line"></span><br><span class="line">	kvm_clear_request(KVM_REQ_GET_NESTED_STATE_PAGES, &amp;svm-&gt;vcpu);</span><br><span class="line"></span><br><span class="line">	<span class="comment">/* in case we halted in L2 */</span></span><br><span class="line">	svm-&gt;vcpu.arch.mp_state = KVM_MP_STATE_RUNNABLE;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/* Give the current vmcb to the guest */</span></span><br><span class="line"></span><br><span class="line">	vmcb12-&gt;save.es     = vmcb-&gt;save.es;</span><br><span class="line">	vmcb12-&gt;save.cs     = vmcb-&gt;save.cs;</span><br><span class="line">	vmcb12-&gt;save.ss     = vmcb-&gt;save.ss;</span><br><span class="line">	vmcb12-&gt;save.ds     = vmcb-&gt;save.ds;</span><br><span class="line">	vmcb12-&gt;save.gdtr   = vmcb-&gt;save.gdtr;</span><br><span class="line">	vmcb12-&gt;save.idtr   = vmcb-&gt;save.idtr;</span><br><span class="line">	vmcb12-&gt;save.efer   = svm-&gt;vcpu.arch.efer;</span><br><span class="line">	vmcb12-&gt;save.cr0    = kvm_read_cr0(&amp;svm-&gt;vcpu);</span><br><span class="line">	vmcb12-&gt;save.cr3    = kvm_read_cr3(&amp;svm-&gt;vcpu);</span><br><span class="line">	vmcb12-&gt;save.cr2    = vmcb-&gt;save.cr2;</span><br><span class="line">	vmcb12-&gt;save.cr4    = svm-&gt;vcpu.arch.cr4;</span><br><span class="line">	vmcb12-&gt;save.rflags = kvm_get_rflags(&amp;svm-&gt;vcpu);</span><br><span class="line">	vmcb12-&gt;save.rip    = kvm_rip_read(&amp;svm-&gt;vcpu);</span><br><span class="line">	vmcb12-&gt;save.rsp    = kvm_rsp_read(&amp;svm-&gt;vcpu);</span><br><span class="line">	vmcb12-&gt;save.rax    = kvm_rax_read(&amp;svm-&gt;vcpu);</span><br><span class="line">	vmcb12-&gt;save.dr7    = vmcb-&gt;save.dr7;</span><br><span class="line">	vmcb12-&gt;save.dr6    = svm-&gt;vcpu.arch.dr6;</span><br><span class="line">	vmcb12-&gt;save.cpl    = vmcb-&gt;save.cpl;</span><br><span class="line"></span><br><span class="line">	vmcb12-&gt;control.int_state         = vmcb-&gt;control.int_state;</span><br><span class="line">	vmcb12-&gt;control.exit_code         = vmcb-&gt;control.exit_code;</span><br><span class="line">	vmcb12-&gt;control.exit_code_hi      = vmcb-&gt;control.exit_code_hi;</span><br><span class="line">	vmcb12-&gt;control.exit_info_1       = vmcb-&gt;control.exit_info_1;</span><br><span class="line">	vmcb12-&gt;control.exit_info_2       = vmcb-&gt;control.exit_info_2;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> (vmcb12-&gt;control.exit_code != SVM_EXIT_ERR)</span><br><span class="line">		nested_vmcb_save_pending_event(svm, vmcb12);</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> (svm-&gt;nrips_enabled)</span><br><span class="line">		vmcb12-&gt;control.next_rip  = vmcb-&gt;control.next_rip;</span><br><span class="line"></span><br><span class="line">	vmcb12-&gt;control.int_ctl           = svm-&gt;nested.ctl.int_ctl;</span><br><span class="line">	vmcb12-&gt;control.tlb_ctl           = svm-&gt;nested.ctl.tlb_ctl;</span><br><span class="line">	vmcb12-&gt;control.event_inj         = svm-&gt;nested.ctl.event_inj;</span><br><span class="line">	vmcb12-&gt;control.event_inj_err     = svm-&gt;nested.ctl.event_inj_err;</span><br><span class="line"></span><br><span class="line">	vmcb12-&gt;control.pause_filter_count =</span><br><span class="line">		svm-&gt;vmcb-&gt;control.pause_filter_count;</span><br><span class="line">	vmcb12-&gt;control.pause_filter_thresh =</span><br><span class="line">		svm-&gt;vmcb-&gt;control.pause_filter_thresh;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/* Restore the original control entries */</span></span><br><span class="line">	copy_vmcb_control_area(&amp;vmcb-&gt;control, &amp;hsave-&gt;control);</span><br><span class="line"></span><br><span class="line">	<span class="comment">/* On vmexit the  GIF is set to false */</span></span><br><span class="line">	svm_set_gif(svm, <span class="literal">false</span>);</span><br><span class="line"></span><br><span class="line">	svm-&gt;vmcb-&gt;control.tsc_offset = svm-&gt;vcpu.arch.tsc_offset =</span><br><span class="line">		svm-&gt;vcpu.arch.l1_tsc_offset;</span><br><span class="line"></span><br><span class="line">	svm-&gt;nested.ctl.nested_cr3 = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/* Restore selected save entries */</span></span><br><span class="line">	svm-&gt;vmcb-&gt;save.es = hsave-&gt;save.es;</span><br><span class="line">	svm-&gt;vmcb-&gt;save.cs = hsave-&gt;save.cs;</span><br><span class="line">	svm-&gt;vmcb-&gt;save.ss = hsave-&gt;save.ss;</span><br><span class="line">	svm-&gt;vmcb-&gt;save.ds = hsave-&gt;save.ds;</span><br><span class="line">	svm-&gt;vmcb-&gt;save.gdtr = hsave-&gt;save.gdtr;</span><br><span class="line">	svm-&gt;vmcb-&gt;save.idtr = hsave-&gt;save.idtr;</span><br><span class="line">	kvm_set_rflags(&amp;svm-&gt;vcpu, hsave-&gt;save.rflags);</span><br><span class="line">	svm_set_efer(&amp;svm-&gt;vcpu, hsave-&gt;save.efer);</span><br><span class="line">	svm_set_cr0(&amp;svm-&gt;vcpu, hsave-&gt;save.cr0 | X86_CR0_PE);</span><br><span class="line">	svm_set_cr4(&amp;svm-&gt;vcpu, hsave-&gt;save.cr4);</span><br><span class="line">	kvm_rax_write(&amp;svm-&gt;vcpu, hsave-&gt;save.rax);</span><br><span class="line">	kvm_rsp_write(&amp;svm-&gt;vcpu, hsave-&gt;save.rsp);</span><br><span class="line">	kvm_rip_write(&amp;svm-&gt;vcpu, hsave-&gt;save.rip);</span><br><span class="line">	svm-&gt;vmcb-&gt;save.dr7 = <span class="number">0</span>;</span><br><span class="line">	svm-&gt;vmcb-&gt;save.cpl = <span class="number">0</span>;</span><br><span class="line">	svm-&gt;vmcb-&gt;control.exit_int_info = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">	vmcb_mark_all_dirty(svm-&gt;vmcb);</span><br><span class="line"></span><br><span class="line">	trace_kvm_nested_vmexit_inject(vmcb12-&gt;control.exit_code,</span><br><span class="line">				       vmcb12-&gt;control.exit_info_1,</span><br><span class="line">				       vmcb12-&gt;control.exit_info_2,</span><br><span class="line">				       vmcb12-&gt;control.exit_int_info,</span><br><span class="line">				       vmcb12-&gt;control.exit_int_info_err,</span><br><span class="line">				       KVM_ISA_SVM);</span><br><span class="line"></span><br><span class="line">	kvm_vcpu_unmap(&amp;svm-&gt;vcpu, &amp;<span class="built_in">map</span>, <span class="literal">true</span>);</span><br><span class="line"></span><br><span class="line">	nested_svm_uninit_mmu_context(&amp;svm-&gt;vcpu);</span><br><span class="line"></span><br><span class="line">	rc = nested_svm_load_cr3(&amp;svm-&gt;vcpu, hsave-&gt;save.cr3, <span class="literal">false</span>);</span><br><span class="line">	<span class="keyword">if</span> (rc)</span><br><span class="line">		<span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> (npt_enabled)</span><br><span class="line">		svm-&gt;vmcb-&gt;save.cr3 = hsave-&gt;save.cr3;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * Drop what we picked up for L2 via svm_complete_interrupts() so it</span></span><br><span class="line"><span class="comment">	 * doesn&#x27;t end up in L1.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	svm-&gt;vcpu.arch.nmi_injected = <span class="literal">false</span>;</span><br><span class="line">	kvm_clear_exception_queue(&amp;svm-&gt;vcpu);</span><br><span class="line">	kvm_clear_interrupt_queue(&amp;svm-&gt;vcpu);</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>However, if the L1 guest exploited the race condition described above svm-&gt;nested.ctl won’t have the INTERCEPT_VMRUN bit set and the VM exit will be handled by KVM itself. This results in a second call to nested_svm_vmrun while still running inside the L2 guest context. nested_svm_vmrun isn’t written to handle this situation and will blindly overwrite the L1 context stored in svm-&gt;nested.hsave with data from the currently active svm-&gt;vmcb which contains data for the L2 guest:</p>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>virtualization</tag>
      </tags>
  </entry>
  <entry>
    <title>Nested virtualization</title>
    <url>/2021/08/17/paper_reading/%E8%99%9A%E6%8B%9F%E5%8C%96/%E5%B5%8C%E5%A5%97%E8%99%9A%E6%8B%9F%E5%8C%96%20nest%20virtualization/</url>
    <content><![CDATA[<h1 id="Nested-Virtualization"><a href="#Nested-Virtualization" class="headerlink" title="Nested Virtualization"></a>Nested Virtualization</h1><p>在<code>Intel processor</code>已经支持来了<code>VMX</code> 特性，用以运行虚拟机。但是在guest中如果想嵌套地再运行一层<code>hypervisor</code> 是不被允许的，因为<code>VMRun</code>，<code>VMResume</code> 是两个特权指令，不能在<code>guest mode</code>下被运行，由此提出了嵌套虚拟化技术。</p>
<span id="more"></span>

<h2 id="CPU-perspective"><a href="#CPU-perspective" class="headerlink" title="CPU perspective"></a>CPU perspective</h2><p><img src="https://raw.githubusercontent.com/unsatisfying/picture-server/main/img/image-20210812100834355.png" alt="image-20210812100834355"></p>
<h2 id="define"><a href="#define" class="headerlink" title="define"></a>define</h2><ul>
<li>如图所示，当只有两层的时候，为了说明方便，把硬件之上的hypervisor定义为L0，把L0运行的虚拟机定义为L1，把L1guest套娃运行的虚拟机成为L2。同时相应的，在x86架构下（<code>Intel AMD</code>），从L0到L1有VMCS<sub>0-&gt;1</sub> ,从L1到L2有VMCS<sub>1-&gt;2</sub> 。但是为了更好地管理L1与L2,L0的hypervisor中还有VMCS<sub>0-&gt;2</sub> .</li>
</ul>
<h2 id="exception-trap-and-emulate"><a href="#exception-trap-and-emulate" class="headerlink" title="exception, trap and emulate"></a>exception, trap and emulate</h2><ul>
<li><p>CPU在正常情况会由于运行特权指令或者异常指令而导致exception和trap。</p>
</li>
<li><p>相应的，在VMX硬件扩展下，CPU支持root和non-root两种模式。当CPU在non-root模式下执行一些root模式的指令（VMRun,VMResume）等等，就会发生一次VMexit从non-root模式退出到root模式运行。而从软件视角来看就是当虚拟机正在跑自己的代码的时候（指令），突然运行了一条异常或者特权指令就需要切换到root模式去执行，而guest运行时候的状态都会被保存的VMCS结构中。然后加载VMCS结构中的host状态，从而发生一次切换，让CPU运行host的hypervisor处理异常。</p>
</li>
</ul>
<h2 id="嵌套情况下的CPU虚拟化"><a href="#嵌套情况下的CPU虚拟化" class="headerlink" title="嵌套情况下的CPU虚拟化"></a>嵌套情况下的CPU虚拟化</h2><ul>
<li>L<sub>0</sub>为了运行L<sub>1</sub>需要为L<sub>1</sub>准备VMCS<sub>0-&gt;1</sub>结构，从硬件角度来说运行L<sub>0</sub>时CPU处于root-mode，运行L<sub>1</sub>时，CPU处于non-root-mode，L<sub>1</sub>并不能感知自己处于guest-mode。</li>
<li>在L<sub>1</sub>中为了运行L<sub>2</sub>，需要为L<sub>2</sub>准备VMCS<sub>1-&gt;2</sub> ,该结构从L<sub>1</sub>的视角保存了L<sub>2</sub>的上下文环境。</li>
<li>而VMCS<sub>0-&gt;1</sub>和VMCS<sub>1-&gt;2</sub> 结合成VMCS<sub>0-&gt;2</sub>，具体结合规则如下：<ul>
<li>host state区域：VMCS<sub>0-&gt;2</sub>的host region&#x3D;VMCS<sub>0-&gt;1</sub>的host region，VMCS<sub>1-&gt;2</sub>的host region&#x3D;VMCS<sub>0-&gt;1</sub> 的guest region</li>
<li>guest state区域：VMCS<sub>0-&gt;2</sub>的guest region&#x3D;VMCS<sub>1-&gt;2</sub>的guest region，VMCS<sub>0-&gt;1</sub>的guest region&#x3D;VMCS<sub>1-&gt;2</sub> 的host region</li>
<li>control data区域：分几种情况，具体怎么合并的看源码。（情况2还没仔细去看源码）<ul>
<li>1：VMCS<sub>1-&gt;2</sub>会退出而VMCS<sub>0-&gt;1</sub>不会退出，即L<sub>1</sub>定义了某个特定事件会发生VMexit，但是L<sub>0</sub>定义该事件不会退出。由于不论是L<sub>1</sub>还是L<sub>2</sub>发生VMexit都是到L<sub>0</sub>，所以这种情况下，L<sub>2</sub>因为执行了特殊代码，必须要导致退出，所以在VMCS<sub>0-&gt;2</sub>的control data中必须记录所有这种情况的事件。</li>
<li>2：VMCS<sub>1-&gt;2</sub>不会退出而VMCS<sub>0-&gt;1</sub>会退出。（猜测就不退出了呗，反正1-&gt;2不退出，那接着运行不就好了，运行的毕竟是L2的代码，管L1啥事）</li>
<li>3：都会退出的情况。（参考1）</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="嵌套情况下的VMExit"><a href="#嵌套情况下的VMExit" class="headerlink" title="嵌套情况下的VMExit"></a>嵌套情况下的VMExit</h3><p>因为VMrun，VMresume是特权指令，所以在嵌套虚拟化的情况下，L1和L2运行这些指令都会导致VMexit到L0 ，而L0需要对这些指令进行模拟。这里只讲L2情况下的VMExit。</p>
<p>L2的VMExit有两种可能的原因，</p>
<ul>
<li>一种是外部中断，非屏蔽中断（NMI），还有在VMCS<sub>0-&gt;2</sub>中记录的，但是在VMCS<sub>1-&gt;2</sub>中没有记录的会导致VMExit的事件，这些事件只需要由L0来处理完成之后直接恢复L2即可。</li>
<li>另一种是由于在VMCS<sub>1-&gt;2</sub>中记录的会导致VMExit的事件。这种情况下退出到L0，L0再将退出的原因写入到VMCS<sub>1-&gt;2</sub>中，然后恢复运行L1，这样L1恢复之后就会认为是L2退出导致的事件，然后在L1中处理完了之后要恢复运行L2，会执行VMrun或者VMresume指令，这是特权指令，所以又会导致VMexit进入到L0，L0利用VMCS<sub>0-&gt;2</sub>帮忙模拟，直接运行L2。</li>
</ul>
<h2 id="嵌套情况下的内存虚拟化"><a href="#嵌套情况下的内存虚拟化" class="headerlink" title="嵌套情况下的内存虚拟化"></a>嵌套情况下的内存虚拟化</h2><p>但是对于嵌套情况下的内存虚拟化，由于硬件最多只支持两段page walk，即stage1和stage2，嵌套的情况下可能有三段，甚至更多段的page walk，所以需要对除了stage1以外的page walk压缩成一段。</p>
<p><strong>影子页表</strong>：当处理器不支持虚拟化硬件特性的时候，最早是用影子页表。我们都知道，intel是用cr3寄存器来记录地址翻译的时候的页表的物理地址的，但是在虚拟化的环境下，如果只用原本的页表去做地址翻译，只能讲GVA翻译成GPA，但是这并不是真实的物理地址，所以影子页表就此诞生了，它旨在把所有虚拟机内部对于页表的操作（包括缺页中断，INVLPG指令和上下文切换等等），都被VMM拦截，并在VMM生成一个相应的影子页表，对影子页表进行修改，然后把影子页表的基址替换CR3寄存器的页表基址，这样虚拟机恢复运行的时候，就能正确把GVA翻译成HPA了。</p>
<p>在讲压缩过程之前，需要了解intel EPT的特性可以在L0和L1的hypervisor中选择开启或者不开启，所以就有四种选择，这主要是由于L1的vcpu是由L0虚拟化出来的，他可以在里面决定vcpu的特性是否支持VMX.</p>
<table>
<thead>
<tr>
<th></th>
<th>情况1</th>
<th>情况2</th>
<th>情况3</th>
<th>情况4</th>
</tr>
</thead>
<tbody><tr>
<td>L1</td>
<td>影子页表</td>
<td>影子页表</td>
<td>EPT</td>
<td>EPT</td>
</tr>
<tr>
<td>L0</td>
<td>影子页表</td>
<td>EPT</td>
<td>EPT</td>
<td>影子页表</td>
</tr>
</tbody></table>
<p>第四种情况比较笨比，有EPT了非要整个影子页表增加overhead，正常情况下肯定没人用啊，就不讲了，讲前面三种，分别对应下图中的1,2,3.</p>
<p><img src="https://raw.githubusercontent.com/unsatisfying/picture-server/main/img/image-20210818191252056.png" alt="image-20210818191252056"></p>
<p>如图所示，SPT（shadow page table），GPT（guest page table），EPT（extend page table）。</p>
<ul>
<li>1.影子页表+影子页表的形式：L0为了运行L1创建了SPT01，L1为了运行L2创建了SPT12，但是L0同时要为L2的运行，需要为L2准备SPT02。这样就能将L2的GVA通过SPT02的基址替换CR3，就能直接将GVA翻译成HVA了。</li>
<li>2.影子页表+EPT：L1为运行L2准备了SPT12，通过CR3将L2的GVA直接翻译成L1的GPA，然后L1的GPA经过EPT翻译成L0的HPA。</li>
<li>3.EPT+EPT：L0把两个EPT压缩成一个EPT，第一阶段为用L2自身的页表将L2的GVA转换成L2的GPA，然后第二阶段将L2的GPA直接转换成L0的HPA。</li>
</ul>
<p><strong>缺页中断</strong>：当L2发生缺页中断之后，根据如上三种情况形成三种不同的解决路径。</p>
<ul>
<li>影子页表+影子页表：所有的L2中修改页表的操作都需要被L0拦截，然后生成和修改相应的SPT02，再恢复运行。</li>
<li>影子页表+EPT：所有L2的修改页表操作，都要发生VMexit到L0，但是由于该事件需要由L1处理，所以L0需要把修复页表这个事件注入到L1，L1处理完成之后再恢复运行L2（此时又会发生VMexit，到L0，然后L0运行L2）。所以它甚至比影子页表+影子页表的形式更慢。</li>
<li>EPT+EPT：L2缺页首先由自己kernel修复，当GPT修复完成之后再执行访存，会导致EPT缺页，发生VMexit到L0，由于EPT需要由EPT12和EPT01合并形成，所以首先检查EPT12是否有缺失，如果有则L0将EPT缺失事件注入到L1，然后运行L1处理（这里有一个问题，就是所有的EPT12修改，都要导致EPT02的修改，所以L0为了拦截EPT12的修改，将L0中的存储EPT12的内存区域的EPT01设置为只读（设置的是EPT01，设置的区域存储了EPT12），这样L1在运行的时候就会导致内存访问错误，然后L0来帮忙修改），L1当然处理不了，因为是只读权限，所以又发生写内存时间，陷入到L0，L0处理帮忙写了之后恢复到L1，L1处理完了运行vmresume，又退出到L0，然后L0直接运行L2，L2又运行之前出错指令，发现又EPT出错退出到L0，L0继续检查发现是EPT01没有配置，所以他又配置EPT01，然后恢复L2运行。（很绕，但是没得办法。。。）</li>
</ul>
<p><strong>TLB问题</strong>：硬件上有VPID机制，但是在嵌套虚拟化的情况下，需要把L1使用的VPID，映射进L0使用的VPID中，保证没有冲突（paper就简单提了一下，具体需要看源码，回头再来改这里，先这么写着。）</p>
<h2 id="嵌套情况下的IO虚拟化"><a href="#嵌套情况下的IO虚拟化" class="headerlink" title="嵌套情况下的IO虚拟化"></a>嵌套情况下的IO虚拟化</h2><p>comming soon</p>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>virtualization</tag>
      </tags>
  </entry>
  <entry>
    <title>xMP：Selective Memory Protection for Kernel and User Space</title>
    <url>/2021/08/17/paper_reading/%E8%99%9A%E6%8B%9F%E5%8C%96/xmp/</url>
    <content><![CDATA[<h1 id="需要的背景知识"><a href="#需要的背景知识" class="headerlink" title="需要的背景知识"></a>需要的背景知识</h1><h2 id="altp2m"><a href="#altp2m" class="headerlink" title="altp2m"></a>altp2m</h2><ul>
<li><p>p2m: guest Physical memory to machine physical</p>
<p>p2m代表从客户机物理地址到机器真实物理地址的内存管理层。这一层是为了多个VM之间的隔离。在XEN中，这一层叫Hardware Assisted Paging(hap).</p>
</li>
<li><p>altp2m</p>
<p>​    而 altp2m允许为每个VM创建多个EPT表，并且Intel已经支持了这种特性，在VMCS结构中最多允许有512个EPT指针。</p>
<p>​    因为当VM的某个访问页面的权限出问题了的时候，会陷入的VMM，在VM内部并不知道外面做了什么事情。而有的时候对于多个vcpu的系统来说，对于一块页面访问出现了权限问题，可能要放松对于该页面的权限，但是这会导致别的vcpu可能会因为竞争关系访问到宽松权限后的权限，这就会导致有安全问题，于是允许为不同的vcpu设置不同的stage2页表，就可以避免这种问题。当然也可以在访问的时候暂停别的vcpu，这种方案会导致很多的overhead。也可以采用软件模拟的方式，捕获的访问的异常，然后在需要放松权限的地方，陷入到VMM进行模拟。（这种方式对于XEN好像不太友好。原话是这样的：This solution, while supported in Xen, is not particularly ideal either as Xen’s emulator is incomplete and is known to have issues that can lead to guest instability. ）</p>
<p>​    利用这种特性，可以将VM映射到不同的物理页，也可以将VM对同一物理页有不同的权限。总之就是允许stage2的页表更加灵活，并且有多个。</p>
</li>
</ul>
<h2 id="VE-Virtualization-Exception"><a href="#VE-Virtualization-Exception" class="headerlink" title="#VE:Virtualization Exception"></a>#VE:Virtualization Exception</h2><p>​	#VE是intel的CPU提供的一个特性。原本一些异常的操作会导致VM exit，现在允许将一些设定的情形不再导致VM exit，而是出发一个#VE，然后再guest中进行处理，减少开销。</p>
<p>​	开启#VE需要设置<code> EPT-violation #VE” VM-execution control</code> 。当发生VE的时候，CPU会将关于异常的信息保存到<code> virtualization-exception information area</code>。一些VMM允许guest访问这个area，并改一些这个area的设置，来防止发生VM exit。</p>
<p>​	特别的，EPT的访问再没设置VE时候都会导致VM exit。如果设置了VE，一些特定的EPT违规行为就会触发VE。page entry的第63位bit设置则表明抑制VE。一些EPT违规的情形能够设置为VE参考手册 卷3-25.5.7。</p>
<p>​	具体来说，如果VMCS中的异常位图的第20位（#VE）为1，则该VE会导致VM exit，并将信息存入VMCS中VM exit区域。如果该位为0并且是没有导致VM exit的情况则直接在guest中使用IDT表中的20号中断，如果导致VM exit，则会在<code> IDT-vectoring information field</code> 中存入异常信息。</p>
<h2 id="VMFUNC"><a href="#VMFUNC" class="headerlink" title="VMFUNC"></a>VMFUNC</h2><p>​	VMFUNC是一条Intel CPU提供的指令。详情参考手册卷3-25.5.6</p>
<p>​	相较于hypercall使用的VMCALL指令而言，VMFUNC是在guest中运行VMM的函数，不会导致VM exit。 而hypercall是向VMM请求服务，会导致VM exit，将控制权转至VMM。</p>
<h2 id="MPK-Memory-Protection-Key"><a href="#MPK-Memory-Protection-Key" class="headerlink" title="MPK:Memory-Protection Key"></a>MPK:Memory-Protection Key</h2><p>​	MPK是Intel CPU提供的一种特性，用以页级粒度的保护。它只针对数据获取的权限（accessable，writable），没有针对指令获取。并且只有64位时候有MPK，32位没有。该特性使得能够给用户态提供申请保护，而不用陷入内核修改页表项，减小了开销。</p>
<p>​	MPK最多提供16个key（stage1 page entry中的（59-62）4个bit位。）。对于用户态：CR4.PKE决定了从用户态地址获取页面的MPK开启。PKRU寄存器（32位）中存放了不同的key的权限。对于内核态：CR4.PKS决定了从内核态地址获取页面的MPK的开启，IA32_PKRS MSR寄存器(64位寄存器，但是低32位存放了权限，高32位必须为0)存放了不同key的权限。</p>
<p>​	对于每个key的权限，用两个bit表示，所以16个key就是32位。 偶数位是access-disable bit,奇数位是write-disable bit。</p>
<p>​	kernel提供了syscall给用户态用以申请MPK。详情见</p>
<h2 id="EPTP-switch"><a href="#EPTP-switch" class="headerlink" title="EPTP switch"></a>EPTP switch</h2><p>​	EPTP switching 是VMFUNC 0.这个函数允许在guest中为自己切换EPT表，但是这些EPT表是提前在hypervisor中配置好的。详情见手册卷3-25.5.6.3</p>
<p>​	寄存器ECX用以选择EPTP。Intel现在最多支持512个EPTP，所以ECX超过512就会导致VM exit。</p>
<h1 id="Impletment"><a href="#Impletment" class="headerlink" title="Impletment"></a>Impletment</h1><h2 id="buddy-allocator"><a href="#buddy-allocator" class="headerlink" title="buddy allocator"></a>buddy allocator</h2><p>​	对于内存分配器中的buddy allocator，增加了__GFP_XMP标志位，用以申请xMP domain区域的页。通过8个bit来分配256个domain。利用altp2m可以切换每个domain的view（不同权限）</p>
<h2 id="slab-allocator"><a href="#slab-allocator" class="headerlink" title="slab allocator"></a>slab allocator</h2><p>​	slab是建立在buddy之上，更加细粒度的分配器。它将一页分成了多个部分，分配给一些特定的结构，并且有专门的slab cache用于分配和释放内核的数据结构（例如task_struct）。</p>
<p>​	xMP允许在使用slab的时候，将slab放到xMP domain中，因为他是建立在buddy之上的。每当slab cache 要申请新的页时，就可以利用xMP的接口申请xMP domain的页。</p>
<h2 id="Switches-across-Execution-Contexts"><a href="#Switches-across-Execution-Contexts" class="headerlink" title="Switches across Execution Contexts"></a>Switches across Execution Contexts</h2><h3 id="上下文切换"><a href="#上下文切换" class="headerlink" title="上下文切换"></a>上下文切换</h3><p>​	在task_struct中增加了domian index字段，用于识别当前thread处于何种xMP view。该字段初始值为最严格的domain view。 当要进入domain区域的时候会切换index值，从而切换权限。之后再上下文切换的时候index值相应的会保存。</p>
<h3 id="硬中断"><a href="#硬中断" class="headerlink" title="硬中断"></a>硬中断</h3><p>​	在硬件中断的时候，将view切换成最严格的domain，防止潜在的中断处理程序问题访问受保护的内存。然后当结束中断返回时，如果要访问xMP domain的内容，会产生一个#VE（原本因为权限问题会陷入VMM），然后#VE handler 处理，验证thread 访问domain的合法性，然后切换domain view，然后继续运行。</p>
<h3 id="软中断"><a href="#软中断" class="headerlink" title="软中断"></a>软中断</h3><p>​	软中断指的是硬件中断中断之后，中断的下半部分机制，这部分kernel由软件实现。（软件中断和软中断在中文上有区别，因为翻译问题）二者区别参考</p>
<p>[知乎]: <a href="https://zhuanlan.zhihu.com/p/80371745">https://zhuanlan.zhihu.com/p/80371745</a>	“知乎的解答”</p>
<p>​	这部分利用Linux的（CONFIG_RCU_NOCB_CPU），不用软中断处理，而是起另一个线程来处理，这样就可以根据不同的线程可能要在callback中访问xMP domain，就可以分别给每个线程处理irq时候起的线程进行配置。（这部分还不是特别明白，先这么写）</p>
<h3 id="User-space-API"><a href="#User-space-API" class="headerlink" title="User space API"></a>User space API</h3><p>​	创建了四个系统调用，类似MPK的系统调用，创建sys_xmp_{alloc,free,mprotect}，但是他不能像MPK那样在用户空间使用VMFUNC指令，所以新建了一个系统调用sys_xmp_enter，用以进入xMP domain，并更新domain view。</p>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>virtualization</tag>
      </tags>
  </entry>
  <entry>
    <title>V-Shuttle：Scalable and Semantics-Aware Hypervisor Virtual Device Fuzzing</title>
    <url>/2021/08/17/paper_reading/%E8%99%9A%E6%8B%9F%E5%8C%96/V-shuffle/</url>
    <content><![CDATA[<h1 id="V-Shuttle-Scalable-and-Semantics-Aware-Hypervisor-Virtual-Device-Fuzzing"><a href="#V-Shuttle-Scalable-and-Semantics-Aware-Hypervisor-Virtual-Device-Fuzzing" class="headerlink" title="V-Shuttle: Scalable and Semantics-Aware Hypervisor Virtual Device Fuzzing"></a>V-Shuttle: Scalable and Semantics-Aware Hypervisor Virtual Device Fuzzing</h1><h2 id="2-背景知识"><a href="#2-背景知识" class="headerlink" title="2.背景知识"></a>2.背景知识</h2><h3 id="2-1-虚拟设备"><a href="#2-1-虚拟设备" class="headerlink" title="2.1 虚拟设备"></a>2.1 虚拟设备</h3><p>​	 所谓虚拟设备，就是提供给guest的外围仿真设备。guest中的驱动可以处理这些虚拟设备，就好像他们处理物理设备一样。每一个设备的协议规定了寄存器级别的硬件接口，用以设备和os之间的交互。总的来说虚拟化设计虚拟设备是根据SPEC来设计的，但是这会提供一种攻击hypervisor的方式。</p>
<h3 id="2-2-驱动与设备交互"><a href="#2-2-驱动与设备交互" class="headerlink" title="2.2 驱动与设备交互"></a>2.2 驱动与设备交互</h3><p>​	总的来说，一个虚拟设备暴露了三种重要的交互方式，MMIO,PIO,DMA（IOMMU）。（这三个就不细说了，具体原理看王柏生、谢广军撰写的《深度探索Linux系统虚拟化：原理与实现》一书第三章）。</p>
<p>​	在最开始设备执行的时候，guest的驱动会写入一些数据到MMIO或者PIO regions，从而做一些初始化相关的工作，比如设置设备状态，寄存器地址初始化等等。完成初始化之后，设备进入ready状态，可以进行处理交互数据。最初始的数据交互机制是DMA，它允许设备和guest之间交换大量复杂的数据。由于数据处理部分是设备驱动的主要code part，所以这一部分也比别的部分更加危险，更容易受攻击。</p>
<h3 id="2-3-核心挑战-嵌套的结构体"><a href="#2-3-核心挑战-嵌套的结构体" class="headerlink" title="2.3 核心挑战-嵌套的结构体"></a>2.3 核心挑战-嵌套的结构体</h3><p>​	hypervisor是被用于guest memory和设备驱动交互的。这种转换操作是用特定的和DMA相关的API，比如QEMU里的<code>pci_dma_read</code> 和<code>pci_dma_write</code>。<code>pci_dma_read</code>从guest的内存复制了一个block的数据到host的buffer，write则相反。通过指定的地址参数，DMA操作可以访问任意位置的guest的物理内存。</p>
<p>​	我们观察到通过DMA的机制访问的一些数据结构通常被组织成nested structures。<img src="https://raw.githubusercontent.com/unsatisfying/picture-server/main/img/image-20211122154306324.png" alt="image-20211122154306324"></p>
<p>​	如图。这些结构体有很多种类和很多层，所以hypervisor通过树形结构组织这些structure，这些structure开始于一个root node。这些特定导致fuzz的一些问题：</p>
<p>​	1）Nested Form Construction。</p>
<p>对于fuzz来说，构建复杂的多层数据对象于结构，或者子结构是很困难的，因为这些对象可以是任意层次的。其一，数据的分层结构，树的相互嵌套等等导致的复杂，fuzz方法很难构造这种数据；其二，每个node内部的指针和数据的偏移也不是固定的，而fuzz mutator会把这些node一视同仁，从而导致不容易变异数据。并且也由于缺少数据语义（semantics），更导致了fuzz的困难。</p>
<p>​	2）Node Type Awareness。</p>
<p>由于设备根据规范支持各种数据类型，因此需要关于嵌套节点的细粒度语义知识。不同node之间的连接也是尤为重要，有些连接是固定的，所以需要我们在node之中建立正确的连接方式。有些指针关系甚至可能在运行时候才知道，因为很多field可以指向不同种类的数据。所以在node level，fuzzer需要知道具体的指针语，从而能够构造正确的数据结构，进入深层次的fuzz，而不是在程序开始阶段就导致crash。</p>
<p>​	为了更好的说明这些nested structure是如何被hypervisor支持的，接下来讲一些hypervisor处理nested structure的通常情况。</p>
<p>​	1）从root节点开始，hypervisor开始获得了一个指针（一般由address register获得），该指针指向一个处理guest memory中的数据结构 A。</p>
<p>​	2）hyervisor动态地allocate buff，该buff是用以存储A的副本。</p>
<p>​	3）hypervisor 通过pci_dma_read拷贝A到buff中。</p>
<p>​	4）当A中有指针指向别的结构B的时候，hypervisor用同样的方法，构造一个副本B的buff。</p>
<p>​	5）再次利用pci_dma_read拷贝B到buff中。</p>
<p>如此反复，从而递归地获取一个structure。然后用上图做一个例子。</p>
<p>一个直观地方法来处理这些数据结构就是用structure-aware fuzzing。这些方法需要开发者构造一个规范的模型。并且还需要把这些数据结构连接起来，所以会很费时，并且还容易出错。并且这些数据结构的SPEC也很庞大，需要大量工作来定义。手工的工作也很容易出错。并且开发人员可能会增加新的机制，因此这些方法都不太适合大范围的hypervisor fuzz。</p>
<h2 id="3-V-SHUTTLE-DESIGN"><a href="#3-V-SHUTTLE-DESIGN" class="headerlink" title="3. V-SHUTTLE DESIGN"></a>3. V-SHUTTLE DESIGN</h2><p>V-shuttle是一个轻量级的，可度量的，语义感知的hypervisor fuzz framwork，并且结合了civerage-guided fuzz和静态分析。为了定位前面所说的challenge, V-shuttle用了两种方法：1）重定向DMA相关的函数。2）通过seedpools的语义感知fuzz。</p>
<h3 id="3-1-Threat-model"><a href="#3-1-Threat-model" class="headerlink" title="3.1 Threat model"></a>3.1 Threat model</h3><p>假设攻击者是一个privileged guest user，同时拥有VM内的所有内存权限，由此可以向device输送二进制数据。</p>
<h3 id="3-2-System-overview"><a href="#3-2-System-overview" class="headerlink" title="3.2 System overview"></a>3.2 System overview</h3><p><img src="https://raw.githubusercontent.com/unsatisfying/picture-server/main/img/image-20211123195225888.png" alt="image-20211123195225888"></p>
<p>它利用集成在hypervisor中的fuzz代理，向虚拟设备喂测试数据，持续向虚拟设备发送读写请求。主要由两部分，fuzzer和fuzzing agent。</p>
<h4 id="fuzzer"><a href="#fuzzer" class="headerlink" title="fuzzer"></a>fuzzer</h4><p>fuzzer在hypervisor之外，并且启用持久模式，即不用每次测试都新启动一个新的实例。因为1）重启一个hypervisor进程或者恢复一个快照是有开销的。2）hypervisor是event-based system，它设计的目的就是长时间的交互。并且大多数的BUG是通过对已发现的分支进行深层次的fuzz发现的，这些深层次状态很可能依赖于之前很多状态的交互构建出来的。</p>
<h4 id="fuzzing-agent"><a href="#fuzzing-agent" class="headerlink" title="fuzzing agent"></a>fuzzing agent</h4><p>它是被放置在hypervisor中的核心组件。1）驱动fuzzing loop和（fuzzer 和 device）的交互 。2）管理DMA&#x2F;MMIO 的上下文分配。为了适应传统的application-fuzz的方法。把guest system中的数据交互重定向到了fuzzed input中。然后fuzzing agent模拟攻击者控制的恶意guest kernel driver，拦截所有device发出的DMA和IO 读写指令，所有从hypervisor的读写操作都被发送到了一个fuzzing agent中的注册函数里。该注册函数会执行操作并返回fuzz生成的数据给device。所以增加新设备的时候，没必要额外的labor，因为它是嵌入在hypervisor中的。</p>
<h3 id="3-3-DMA-重定向"><a href="#3-3-DMA-重定向" class="headerlink" title="3.3 DMA 重定向"></a>3.3 DMA 重定向</h3><p>由于给大量的device创建合法的数据结构工作量很大，并且很复杂，所以设计了DMA重定向的方法。通过拦截设备请求guest memory，来扁平化嵌套结构。他把DMA传输转化成fuzz input的读取，即把所有的DMA相关的API中以及他们的包装函数中都插入宏，从而所有的API都被替换成从文件中读取数据，从而是读取fuzzing input。下图给了个例子。</p>
<p><img src="https://raw.githubusercontent.com/unsatisfying/picture-server/main/img/image-20211123201912737.png" alt="image-20211123201912737"></p>
<p>而关注于DMA是因为他们负责guest和host之间的数据交互，也是构建这些嵌套数据结构的关键机制。同时这样也消除了DMA的寻址操作。并且由于完全控制DMA机制，任何的DMA请求都能够用传统coverage-guided fuzzer，不论数据结构中的指针指向哪里，即使他们是0. 从图上可以看出原本需要buffer_addr，现在只需要从文件中读取，所以任意地址都行。并且V-shuttle只是操作设备从guest中读取的数据，并不管写入的数据，因为一般来说攻击者都是向设备来input一些数据来攻击的，所以不管他们收到的。</p>
<p>当收到device向guest memory中的read 请求：</p>
<p>​	1）V-thuttle确保DMA读取函数调用源自于正在监视的目标设备，因为对其他来自系统组件的DMA传输请求不感兴趣，这些请求不受guest控制。<br>​	2）给定的host 的buffer和 buffer size，V-shuttle从seed file中选定适合的数据，而不是去读guest 内存。下图给了大致示意图</p>
<p><img src="https://raw.githubusercontent.com/unsatisfying/picture-server/main/img/image-20211123202951628.png" alt="image-20211123202951628"></p>
<p>相比于传统的在guest中构建数据结构，V-shuttle从hypervisor中构建测试数据，从而把所有的多维数据结构变成了一维，并且保证了nested structure的语义。这样所有的底层代码都可以访问。对于每一次的模糊迭代，模糊器引擎首先通过突变的方式生成DMA数据序列，然后设备开始遍历树，然后每个DMA请求都从file中获取input。消除了每个节点中的指针，同时仍然保持每个节点隐含的指针依赖信息，所以这不会破坏设备的正常进行。</p>
<h3 id="3-4-Semantics-Aware-Fuzzing-via-SeedPools"><a href="#3-4-Semantics-Aware-Fuzzing-via-SeedPools" class="headerlink" title="3.4 Semantics-Aware Fuzzing via SeedPools"></a>3.4 Semantics-Aware Fuzzing via SeedPools</h3><p>但是上面的方法也存在一个问题，就是它并没有把node type给考虑进去，所以效率会比较低。而且有些node type是动态决定的，所以有些时候控制流也是动态改变的。并且一些节点之间连接的语义也很容易在迭代的时候消失。（有个例子没看懂），然后就给每个fuzz数据加了一个type_id，这样同一类的node就可以更好的异变迭代。如下图，把接口中加了一个参数。</p>
<p><img src="https://raw.githubusercontent.com/unsatisfying/picture-server/main/img/image-20211123205350914.png" alt="image-20211123205350914"></p>
<p>由此，就能够把数据结构之间进行解耦合，然后每个结构的数量又是有限的，所以独立地进行generate。</p>
<p>1）对DMA对象进行静态分析。大概就是backward data flow analysis（他们call这个叫live-variable analysis），通过一些函数（比如pic_dma_read），去反向找这些数据的type。（这块属实不是我的长项，就贴原文把<br>Therefore, we define a DMA object as a host’s structure that holds the copy of the guest’s data through DMA. Each DMA object represents a unique type of node. Aiming to label all the DMA objects, V-Shuttle performs static analysis on the hypervisor’s source code. In particular, V-Shuttle utilizes a live-variable analysis, which is a special type of data flow analysis. Considering the host’s buffer field of DMA operations (e.g., pci_dma_read, and its wrapped function) as the source, we do the backward data flow analysis from the source to its declaration or definition (the DMA object). After collecting all the DMA objects, we assign unique IDs to each of them. These labeled objects help us identify the node type of each DMA request at runtime and ensure that each type of DMA object can be correctly grouped）</p>
<p>2）通过每次读取input增加的type_id进行特定的读取。</p>
<p>3）同时为了解决多种类型的input，就扩展了AFL，增加了seedpool，这样就fuzzer在每个seed queue上变异，由此对每个type的structure单独变异出input。然后根据coverage的feedback反馈，就fuzzing就可以知道如何给每一种类型的type变异生成input。</p>
<p>4）语义感知 fuzzing过程。伪算法如下：</p>
<p><img src="https://raw.githubusercontent.com/unsatisfying/picture-server/main/img/image-20211123221219163.png" alt="image-20211123221219163"></p>
<p>这里给了一个example：USB-UHCI：</p>
<p><img src="https://raw.githubusercontent.com/unsatisfying/picture-server/main/img/image-20211123221601596.png" alt="image-20211123221601596"></p>
<h3 id="3-5-lightweight-fuzzing-loop"><a href="#3-5-lightweight-fuzzing-loop" class="headerlink" title="3.5 lightweight fuzzing loop"></a>3.5 lightweight fuzzing loop</h3><p>过去的方式通过在guest os中增加代理来实现，这样在vmexit的时候会造成很大的开销，但是此方法不会</p>
<p><strong>环境主要功能模型</strong>：</p>
<p><img src="https://raw.githubusercontent.com/unsatisfying/picture-server/main/img/image-20211123222556008.png" alt="image-20211123222556008"></p>
<h2 id="5-evaluation"><a href="#5-evaluation" class="headerlink" title="5 evaluation"></a>5 evaluation</h2><p>测试了Qemu5.1.0和VirtualBox6.1.14，</p>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>virtualization</tag>
      </tags>
  </entry>
</search>
